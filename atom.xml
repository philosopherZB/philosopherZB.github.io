<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://philosopherzb.github.io</id>
    <title>Philosopher</title>
    <updated>2023-03-03T08:37:00.986Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://philosopherzb.github.io"/>
    <link rel="self" href="https://philosopherzb.github.io/atom.xml"/>
    <subtitle>WORLD AS CODE</subtitle>
    <logo>https://philosopherzb.github.io/images/avatar.png</logo>
    <icon>https://philosopherzb.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Philosopher</rights>
    <entry>
        <title type="html"><![CDATA[ES7架构原理及选举源码]]></title>
        <id>https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/</id>
        <link href="https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/">
        </link>
        <updated>2022-02-28T07:00:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch架构组件，读写原理，性能优化以及节点选举和选举流程源码。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-1462655_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="原理概述">原理概述</h2>
<h3 id="基础架构图">基础架构图</h3>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303025.png" alt="img" loading="lazy"></figure>
<p>1: Gateway是ES用来存储索引的文件系统。支持多种类型：包括本地文件系统(默认)，分片文件系统，HDFS，S3等。</p>
<p>2: Distributed Lucene Directory指的是Apach Lucene框架。</p>
<p>3: Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块以及River模块（river代表数据从其他存储框架（如：mysql）流入ES）。</p>
<p>4: ES模块之上是 Discovery、Scripting和第三方插件。</p>
<p>5: 再上层是ES的传输模块和JMX.传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX是java的管理框架，用来管理ES应用。</p>
<p>6: 最上层是ES提供给用户的接口，可以通过RESTful接口或定制的SDK和ES集群进行交互。</p>
<h2 id="读写原理">读写原理</h2>
<h3 id="术语介绍">术语介绍</h3>
<p>segment file: 类似于倒排索引，但其中包含的数据结构更丰富（Inverted Index, Stored Fields, Document Values, Cache等）；一组segment集合加上commit point便构成了Lucene中的index（动态索引，可类比Java中的动态数组概念，每个segment便是一个数组，commit point便是ArrayList；也类似于Java1.8的ConcurrentHashMap分段概念）。</p>
<p>commit point: 记录了当前所有可用的segment file文件。数据可被搜索到。</p>
<p>translog: 持久化地记录了所有还没被刷到磁盘的操作，避免宕机时，数据丢失。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。translog 会每隔 5 秒异步执行或者在每一个请求完成之后执行一次 fsync 操作，将 translog 从缓存刷入磁盘，这个操作比较耗时，如果对数据一致性要求不是很高时建议将索引改为 async ，如果节点宕机时会有 5 秒数据丢失;</p>
<p>In-memory buffer: ES中的内存缓存，每当索引数据时，都会将数据先存储到该buffer及translog中。</p>
<p>refresh: 打开或创建一个新的segment的过程，即将数据从内存刷入filesystem cache并清空当前buffer的过程(默认每隔一秒或者buffer满了便会执行该操作)。</p>
<p>merge: refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>flush&amp;commit: 默认每隔30分钟或者translog数据量达到512mb则会触发一次flush操作。此过程会将所有数据刷入硬盘中进行持久化存储。</p>
<h3 id="写操作原理">写操作原理</h3>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303026.png" alt="img" loading="lazy"></figure>
<p>具体步骤如下：</p>
<p>1、数据写入buffer及translog中，此时是搜索不到的。</p>
<p>2、默认每隔一秒或buffer已满，则执行一次refresh操作，将数据刷入filesystem cache生成segment file，此时数据可被搜索，并清空当前的buffer。</p>
<p>3、translog中的数据存储在os cache中，之后默认每隔5秒会持久化到磁盘中（时间可设置，长短将影响性能）。</p>
<p>4、重复上述步骤，直到抵达默认的30分钟或者translog达到512mb时（相关参数可配置），便会触发一次flush操作（commit操作）：该操作首先将buffer中现有的数据refresh到os cache中去，并清空buffer；然后将一个commit point写入磁盘文件，里面标识着这个commit point 对应的所有segment file，同时强行将os cache中目前所有的数据都fsync到磁盘文件中去；最后清空现有 translog日志文件，重启一个新的translog，此时flush操作完成。</p>
<p>额外补充：</p>
<p>5、删除操作，commit的时候会产生一个.del文件，里面将某个doc标记为delete状态（并非实时删除），搜索时会自动过滤掉标记为删除状态的数据。</p>
<p>6、更新操作，将原来的doc标识为delete状态，然后重新写入一条新数据即可。</p>
<p>7、refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似大小的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>8、数据一致性由translog保证（丢失数据取决于fsync的时间）；副本一致性则是采用的半同步机制，即主分片写成功后，只需一部分数量（quorum）的副本写入成功即可返回。相关配置wait_for_active_shards的默认值为int( (primary + number_of_replicas) / 2 ) + 1</p>
<h3 id="读操作原理">读操作原理</h3>
<p>读过程大体上分为查询与取回两个阶段。</p>
<ol>
<li>查询阶段</li>
<li>当一个搜索请求被发送到某个节点时，该节点就变成协调节点。这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。</li>
<li>首先将广播请求到索引中每一个节点的分片拷贝，查询请求可以被某个主分片或某个副分片处理（这就是为什么更多的副本（当结合更多的硬件）能够增加搜索吞吐率），协调节点将在之后的请求中轮训所有的分片拷贝来分摊负载。</li>
<li>每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列—也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。</li>
<li>协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。</li>
<li>取回阶段</li>
<li>查询过程得到的排序结果，标记出哪些文档是符合要求的，此时仍然需要获取这些文档返回给客户端。</li>
<li>协调节点会辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求；每个分片加载并修饰文档，如果有需要的话，接着返回文档给协调节点</li>
<li>一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
</ol>
<p>注意1：先查后取的过程支持用 from 和 size 参数分页，但是这是有限制的。要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 number_of_shards * (from + size) 排序文档，来找到被包含在 size 里的文档。</p>
<p>注意2：一般不建议使用深度搜索，这将会耗费大量额外的cpu，内存与带宽（ES默认深度分页限制为10000条，即from + size &lt;=10000）;如果有需要，可以使用scroll进行查询。</p>
<h2 id="性能优化">性能优化</h2>
<h3 id="filesystem-cache">filesystem cache</h3>
<p>由上述写过程原理可知，ES的数据在filesystem cache中便可被搜索到，那么对应的，如果给予filesystem cache更多的机器内存，让它足以容纳下所有的index segment file，相应的查询效率将会获得长足的提高（内存与磁盘查询效率相差巨大）。同时，如果数据量非常之大，那么ES中应该尽量存储doc_id之类的字段，减少大文本存储（大文本存入分布式文件系统中）。</p>
<h3 id="数据预热与冷热分离">数据预热与冷热分离</h3>
<p>某些热点数据，可通过缓存预热系统进行提前查询，让其流入filesystem cache中；同时，对冷热数据进行隔离存储，确保热数据一直在filesystem cache。</p>
<h3 id="合理的文档设计">合理的文档设计</h3>
<p>不要出现复杂性的查询操作，尽量在设计阶段就做一定的冗余，让相关数据在同一个文档中。</p>
<h3 id="避免深度分页">避免深度分页</h3>
<p>就像读过程原理中所描述，过度的深分页查询，会占用大量的cpu，内存与带宽；如果有对应的需求，可通过scroll api进行查询。</p>
<h2 id="节点发现与选举流程源码">节点发现与选举流程源码</h2>
<p>节点启动时，便会开始加入集群；启动函数：org.elasticsearch.node.Node.start()</p>
<pre><code>public Node start() throws NodeValidationException {
    // start after transport service so the local disco is known
    // start before cluster service so that it can set initial state on ClusterApplierService
    discovery.start(); 
    clusterService.start();
    // 服务发现函数
    discovery.startInitialJoin();
}

</code></pre>
<p>查询mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.findMaster()；此处选举id最小的节点是因为es沿用了bully算法。</p>
<pre><code>private DiscoveryNode findMaster() {
    logger.trace(&quot;starting to ping&quot;);
    // 开始ping操作，获取当前集群处于活跃状态的节点信息
    // pingAndWait函数实际上调用了org.elasticsearch.discovery.zen.UnicastZenPing.ping()
    // 它会主动从discovery.seed_hosts配置中读取信息（7.*之前的老版本配置为：discovery.zen.ping.unicast.hosts）
    // 最终返回的节点信息中，包含有master信息
    List&lt;ZenPing.PingResponse&gt; fullPingResponses = pingAndWait(pingTimeout).toList();

    // 将本节点也加入 fullPingResponses 中
    final DiscoveryNode localNode = transportService.getLocalNode();
    assert fullPingResponses.stream().map(ZenPing.PingResponse::node).filter(n -&gt; n.equals(localNode)).findAny().isPresent() == false;
    fullPingResponses.add(new ZenPing.PingResponse(localNode, null, this.clusterState()));

    // filter responses
    // 如果配置了discovery.zen.master_election.ignore_non_master_ping（即：masterElectionIgnoreNonMasters）为true将会过滤出所有的主节点信息
    // 默认为false
    final List&lt;ZenPing.PingResponse&gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);

    // 遍历列表，将节点认为的主节点信息存入activeMasters
    List&lt;DiscoveryNode&gt; activeMasters = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        // We can't include the local node in pingMasters list, otherwise we may up electing ourselves without
        // any check / verifications from other nodes in ZenDiscover#innerJoinCluster()
        if (pingResponse.master() != null &amp;&amp; localNode.equals(pingResponse.master()) == false) {
            activeMasters.add(pingResponse.master());
        }
    }

    // 如果ping过程中发现了具备资格成为master的节点，将其存入masterCandidates 
    List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        if (pingResponse.node().isMasterNode()) {
            masterCandidates.add(new ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));
        }
    }

    if (activeMasters.isEmpty()) {
        // 判断是否有足够的候选者，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.hasEnoughMasterNodes()
        if (electMaster.hasEnoughCandidates(masterCandidates)) {
            // 从候选者中选举新的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.electMaster()
            // 选举逻辑比较简单，直接按id排序，随后取出最小id的节点，即为主节点
            final ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);
            logger.trace(&quot;candidate {} won election&quot;, winner);
            return winner.getNode();
        } else {
            // if we don't have enough master nodes, we bail, because there are not enough master to elect from
            logger.warn(
                    &quot;not enough master nodes discovered during pinging (found [{}], but needed [{}]), pinging again&quot;,
                    masterCandidates,
                    electMaster.minimumMasterNodes()
            );
            return null;
        }
    } else {
        assert activeMasters.contains(localNode) == false
                : &quot;local node should never be elected as master when other nodes indicate an active master&quot;;
        // lets tie break between discovered nodes
        // 按id进行二级排序，并返回最小id的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.tieBreakActiveMasters()
        return electMaster.tieBreakActiveMasters(activeMasters);
    }
}

</code></pre>
<p>确认mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster()</p>
<pre><code>// 1.本节点是master
if (transportService.getLocalNode().equals(masterNode)) {
    // 等待足够多的节点加入本节点
    final int requiredJoins = Math.max(0, electMaster.minimumMasterNodes() - 1); // we count as one
    logger.debug(&quot;elected as master, waiting for incoming joins ([{}] needed)&quot;, requiredJoins);
    // masterElectionWaitForJoinsTimeout默认超时时间为30秒，如果超时则直接return
    // 对应函数：org.elasticsearch.discovery.zen.NodeJoinController.waitToBeElectedAsMaster()
    nodeJoinController.waitToBeElectedAsMaster(
        requiredJoins,
        masterElectionWaitForJoinsTimeout,
        new NodeJoinController.ElectionCallback() {
            // 进行master选举
            @Override
            public void onElectedAsMaster(ClusterState state) {
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDone(currentThread);
                }
            }

            // 失败则重新发起加入集群流程
            @Override
            public void onFailure(Throwable t) {
                logger.trace(&quot;failed while waiting for nodes to join, rejoining&quot;, t);
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
                }
            }
        }

    );
}

// NodeJoinController.waitToBeElectedAsMaster()
public void waitToBeElectedAsMaster(int requiredMasterJoins, TimeValue timeValue, final ElectionCallback callback) {
    try {
        // check what we have so far..
        // capture the context we add the callback to make sure we fail our own
        // 检查是否已有requiredMasterJoins的节点数
        synchronized (this) {
            assert electionContext != null : &quot;waitToBeElectedAsMaster is called we are not accumulating joins&quot;;
            myElectionContext = electionContext;
            electionContext.onAttemptToBeElected(requiredMasterJoins, wrapperCallback);
            // 如果节点数已达标，将该节点设置为master
            checkPendingJoinsAndElectIfNeeded();
        }

        try {
            // 超时直接return
            if (done.await(timeValue.millis(), TimeUnit.MILLISECONDS)) {
                // callback handles everything
                return;
            }
        } catch (InterruptedException e) {

        }
    } catch (Exception e) {
        logger.error(&quot;unexpected failure while waiting for incoming joins&quot;, e);
        if (myElectionContext != null) {
            failContextIfNeeded(myElectionContext, &quot;unexpected failure while waiting for pending joins [&quot; + e.getMessage() + &quot;]&quot;);
        }
    }
}

// NodeJoinController.checkPendingJoinsAndElectIfNeeded()
private synchronized void checkPendingJoinsAndElectIfNeeded() {
    // 发布clusterState
    electionContext.closeAndBecomeMaster();
}

// NodeJoinController.closeAndBecomeMaster
public synchronized void closeAndBecomeMaster() {
    innerClose();

    Map&lt;JoinTaskExecutor.Task, ClusterStateTaskListener&gt; tasks = getPendingAsTasks(&quot;become master&quot;);
    final String source = &quot;zen-disco-elected-as-master ([&quot; + tasks.size() + &quot;] nodes joined)&quot;;

    // noop listener, the election finished listener determines result
    tasks.put(JoinTaskExecutor.newBecomeMasterTask(), (source1, e) -&gt; {});
    tasks.put(JoinTaskExecutor.newFinishElectionTask(), electionFinishedListener);
    // 提交更新状态的任务
    masterService.submitStateUpdateTasks(source, tasks, ClusterStateTaskConfig.build(Priority.URGENT), joinTaskExecutor);
}

</code></pre>
<pre><code>// 本节点不是master
// process any incoming joins (they will fail because we are not the master)
// 拒绝其他节点加入，因为本节点不是master
nodeJoinController.stopElectionContext(masterNode + &quot; elected&quot;);

// send join request
// 发送加入master的请求
final boolean success = joinElectedMaster(masterNode);

synchronized (stateMutex) {
    if (success) {
        // currentMasterNode 为空，或者当选的master不是之前选择的节点，进行重试加入
        DiscoveryNode currentMasterNode = this.clusterState().getNodes().getMasterNode();
        if (currentMasterNode == null) {
            // Post 1.3.0, the master should publish a new cluster state before acking our join request. we now should have
            // a valid master.
            logger.debug(&quot;no master node is set, despite of join request completing. retrying pings.&quot;);
            joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
        } else if (currentMasterNode.equals(masterNode) == false) {
            // update cluster state
            joinThreadControl.stopRunningThreadAndRejoin(&quot;master_switched_while_finalizing_join&quot;);
        }

        joinThreadControl.markThreadAsDone(currentThread);
    } else {
        // failed to join. Try again...
        // 失败则重新发起加入集群流程
        joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
    }
}

private boolean joinElectedMaster(DiscoveryNode masterNode) {
    try {
        // first, make sure we can connect to the master
        transportService.connectToNode(masterNode);
    } catch (Exception e) {
        logger.warn(() -&gt; new ParameterizedMessage(&quot;failed to connect to master [{}], retrying...&quot;, masterNode), e);
        return false;
    }
    int joinAttempt = 0; // we retry on illegal state if the master is not yet ready
    while (true) {
        try {
            logger.trace(&quot;joining master {}&quot;, masterNode);
            // joinTimeout 默认超时时间60s，org.elasticsearch.discovery.zen.MembershipAction.MembershipAction()
            membership.sendJoinRequestBlocking(masterNode, transportService.getLocalNode(), joinTimeout);
            return true;
        } catch (Exception e) {
            final Throwable unwrap = ExceptionsHelper.unwrapCause(e);
            if (unwrap instanceof NotMasterException) {
                // joinRetryAttempts 重试次数，默认3次
                if (++joinAttempt == this.joinRetryAttempts) {
                    logger.info(
                        &quot;failed to send join request to master [{}], reason [{}], tried [{}] times&quot;,
                        masterNode,
                        ExceptionsHelper.detailedMessage(e),
                        joinAttempt
                    );
                    return false;
                }
            } else {
                return false;
            }
        }

        try {
            Thread.sleep(this.joinRetryDelay.millis());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}

</code></pre>
<p>由上述步骤总结如下：</p>
<p>1、服务启动后，开始进行加入集群操作；</p>
<p>2、调用ping命令，最终获取一个包含节点基本信息及其所认为的master信息的列表（包括本节点）；</p>
<p>3、过滤结果列表，将master节点汇总到activeMasters，将master候选者节点汇总到masterCandidates；</p>
<p>4、判断如果activeMasters不为空，则从activeMasters中选择最小ID的一个节点；否则从candidateMasters中选择，先判断是否有足够的候选者，之后再排序选择ID最小的一个节点作为新的master；</p>
<p>5、投票阶段，每个节点都向自己认为的master进行joinRequest请求,对应的会产生如下两种情形：</p>
<ul>
<li>本节点是master：该节点统计发送过来的joinRequest个数，如果在指定的时间（默认30s，可配置）内达到requiredJoins个数，则发布集群信息，并回复joinRequest请求，最后完成选举，否则选举失败；</li>
<li>本节点不是master：首先，拒绝其他节点的joinRequest，其次向该节点认为的master发送joinRequest请求，并等待，如果在指定的时间（60s，可配置）未收到回复或异常重试3次都失败了则选举失败，之后将重新发起加入集群流程；否则如果收到的回复中没有master信息或者master信息不是之前选择的临时master节点则选举失败，同样会进行重新加入操作。</li>
</ul>
<p>注意：es使用延迟选举解决了选举过程中不断出现master假死现象（即master由于负载过重而假死，随后第二小id的节点成为master，之后故障节点又恢复再次被选为master，接着又假死...如此循环）；同时，es增加了法定得票人数机制，解决了脑裂（split-brain）问题。</p>
<p>脑裂指的是集群中出现多个主节点，导致集群割裂的一种异常情况。</p>
<p>法定个数：有master资格的节点数（官方建议）：n/2 + 1；其中n为有资格成为主节点的节点数。</p>
<pre><code>// 7.*版本后，discovery.zen.minimum_master_node已不再提供配置，而是由内置的代码处理
private void commonNodeConfig(ElasticsearchNode node, String nodeNames, ElasticsearchNode firstNode) {
    if (node.getVersion().onOrAfter(&quot;7.0.0&quot;)) {
        node.defaultConfig.keySet()
            .stream()
            .filter(name -&gt; name.startsWith(&quot;discovery.zen.&quot;))
            .collect(Collectors.toList())
            .forEach(node.defaultConfig::remove);
        if (nodeNames != null &amp;&amp; node.settings.getOrDefault(&quot;discovery.type&quot;, &quot;anything&quot;).equals(&quot;single-node&quot;) == false) {
            node.defaultConfig.put(&quot;cluster.initial_master_nodes&quot;, &quot;[&quot; + nodeNames + &quot;]&quot;);
        }
        node.defaultConfig.put(&quot;discovery.seed_providers&quot;, &quot;file&quot;);
        node.defaultConfig.put(&quot;discovery.seed_hosts&quot;, &quot;[]&quot;);
    } else {
        node.defaultConfig.put(&quot;discovery.zen.master_election.wait_for_joins_timeout&quot;, &quot;5s&quot;);
        if (nodes.size() &gt; 1) {
            node.defaultConfig.put(&quot;discovery.zen.minimum_master_nodes&quot;, Integer.toString(nodes.size() / 2 + 1));
        }
        if (node.getVersion().onOrAfter(&quot;6.5.0&quot;)) {
            node.defaultConfig.put(&quot;discovery.zen.hosts_provider&quot;, &quot;file&quot;);
            node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
        } else {
            if (firstNode == null) {
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
            } else {
                firstNode.waitForAllConditions();
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[\&quot;&quot; + firstNode.getTransportPortURI() + &quot;\&quot;]&quot;);
            }
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES基本概念与集群]]></title>
        <id>https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/</id>
        <link href="https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/">
        </link>
        <updated>2022-02-19T06:27:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch基本结构，术语介绍以及路由算法，分片原理等。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/conifers-1850227_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="基本概念">基本概念</h2>
<h3 id="简介">简介</h3>
<p>ElasticSearch是一个基于Apach Lucene构建的搜索引擎，其天生便是分布式的，具备极强的可扩展性，除此之外，强大的实时分析特性以及分布式存储都是其不可忽视的优点。</p>
<p>ES的主旨在于随时可用以及按需扩容。垂直扩容（纵向扩容）：性能更强大的硬件机器；水平扩容（横向扩容）：数量更多的服务器。</p>
<p>由于硬件限制，现阶段的垂直扩容必然存在一个极限，所以对于ES而言，真正的扩容能力还是来自于水平扩容-为集群增加更多的机器（多节点负载与分布式容灾，同时可以进行PB级别的数据分析）。</p>
<h3 id="名词解释">名词解释</h3>
<h4 id="索引存储索引">索引（存储索引）</h4>
<p>索引（Index）是ElasticSearch存放数据的地方（为了区分搜索索引，暂且称其为存储索引）。以关系数据库类比的话，ES中的索引相当于数据库（es6之后等同于数据表，参见；1.2.2文档类型-重点注意）的概念。但是与关系数据库相比，ES可以更快速且高效的对索引中的数据进行全文检索。</p>
<p>究其根本是由于ES/Lucene使用的倒排索引相较于关系数据库中的b-tree，b+tree而言，多了一层内存索引概念（此处的索引指搜索索引，而非存储索引）。</p>
<p>内存索引是对磁盘索引的一层简化封装，例如：磁盘索引为Alex，Bob，Curl，Abnormal；那么内存索引则为：A，B，C，b，这些简化字段会组成一颗trie tree（前缀树，根据字典顺序升序排列），通过特定的压缩技术（Lucene Finite State Transducers <a href="https://cs.nyu.edu/~mohri/pub/fla.pdf">点击此处跳转文档页面</a>）可以将其尺寸缩小数十倍，使得用内存缓存trie tree变成可能。</p>
<p>正是基于内存索引的优化，ES/Lucene才能比关系数据库更快的检索出结果；因为其在内存中已经找到了对应的磁盘索引，可以直接根据磁盘索引查询对应的磁盘数据，而关系数据库则需要遍历查找出对应的磁盘索引，之后再根据磁盘索引查询磁盘数据，这中间便多了磁盘的random access次数（一次磁盘random access大概耗时10ms，耗时会随着磁盘硬件的优劣而产生一定的浮动）。</p>
<p>关于多字段查询，ES/Lucene有两种合并方式：1.skip list实现联合索引的；对跳表中的数据进行快速与运算。2.bitset实现快速合并，进行按位与运算。两种方式的比较可参考：<a href="https://www.elastic.co/cn/blog/frame-of-reference-and-roaring-bitmaps">点击此处跳转页面</a></p>
<p>综上所述，整体效果图如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303015.png" alt="img" loading="lazy"></figure>
<h4 id="文档类型">文档类型</h4>
<p>ES中的索引可以存储许多不同用途的对象，如：学生对象，课程对象等，为了更轻松地区分这些对象，文档类型这个概念便应运而生（可类比于关系数据库中的表）；在实际操作中，为文档划分不同的类型，可以更方便的操作数据。</p>
<p>注意：划分文档类型时存在一定的限制条件，其中之一便是不同的文档类型对同一字段不能设置为不同的字段类型。例如：学生对象中的课程id是Integer类型，而课程对象中的id是String，这是不行的。详情可参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping.html">点击此处跳转页面</a></p>
<p>重点注意：es6.0.0之前单个索引可以有多个文档类型，es6.0.0之后单个索引只能有一个文档类型，7.0.0之后文档类型字段已被设置为过期，8.0.0将会完全不支持文档类型字段。原因参见上述注意点。</p>
<h4 id="文档及字段">文档及字段</h4>
<p>文档（document）是ES中存储的主要实体（类比于关系数据库中的一行数据），而字段则是具体的一对KV组合（类比于关系数据库中的一列数据）。</p>
<p>需要额外注意的是：字段类型（字符串型，数值型，日期型）决定了ES该执行何种操作，如比较、排序等。</p>
<p>幸运的是ES可以自动确定字段类型，当然也可以通过模式映射（schema mapping）自定义文档结构。</p>
<h2 id="集群概念">集群概念</h2>
<h3 id="节点与集群">节点与集群</h3>
<p>ElasticSearch可以作为一个独立的搜索服务器工作。然而，为了能够处理大型数据集并实现高可用容灾功能，我们有必要在多台服务器上部署运行ES。</p>
<p>一个运行中的ES实例称为一个节点，而集群则是由一个或多个拥有相同cluster.name配置的节点组成，集群中的所有节点共享数据且分担负载。</p>
<p>一个集群存在一个主节点（选举生成），它负责管理集群范围内的所有变更，如节点的增删，索引的增删等（不涉及文档级别）。</p>
<p>查看集群健康状态：curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot;</p>
<p>其中status字段展示了集群的健康状况：green：所有主/副本分片都是正常的；yellow：所有主分片都正常，但并不是所有副本分片都正常；red：所有主/副本分片都不正常。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303016.png" alt="img" loading="lazy"></figure>
<h3 id="分片概述">分片概述</h3>
<p>一个分片是一个底层的工作单元，它只存储了全部数据的一部分。前文所说的索引（存储数据的地方），实际上也是指向一个或多个物理分片的逻辑命名空间。</p>
<p>每个分片都是一个完整的搜索引擎，也即是一个Lucene实例。应用程序并不需要关注分片的存在，只需跟索引进行交互即可（ES透明处理了分片数据合并的过程）。</p>
<p>所有的分片都可以存储在集群中的任一节点中，而文档数据则存储在各个分片内，这便是ES集群管理数据的方式。</p>
<p>一个分片既可以是主分片，也可以是副本分片。索引中的任意文档都归属于一个主分片，所以主分片的数量决定了索引能够保存的最大数据量（Integer.MAX_VALUE-128，这是理论最大值，实际中还与硬件设备、文档大小、文档复杂度，索引和查询文档的方式以及期待的响应时长有关）。</p>
<p>副本分片主要用于高可用容灾与备份，是对主分片数据的一个拷贝，同时提供搜索和返回文档等读操作。</p>
<p>注意：扩容时，我们可以通过增加副本分片来提高搜索性能，但如果节点不变的情况下，我们增大副本分片仅仅只能带来容灾备份；这是因为每个分片从节点上获取的资源会变少，所以想增加吞吐量唯有扩展机器资源了。</p>
<p>设置三个主分片以及一个副本分片（每个主分片都拥有一个副本分片）：</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303017.png" alt="" loading="lazy"></figure>
<p>修改一个副本分片为两个副本分片：</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303018.png" alt="img" loading="lazy"></figure>
<h3 id="路由算法">路由算法</h3>
<p>分布式存储少不了路由算法，在ES中是通过hash算法来确定数据该存储到哪一个节点/分片中的。</p>
<p>公式：shard = hash(routeKey) % number_of_primary_shards</p>
<p>其中routeKey是一个随机数，一般情况下默认是文档id，不过也可以直接指定对应的值。</p>
<p>该公式也表明了主分片数为何只能在创建索引的时候设置，并且不允许被修改（如果被更改，那么之前的数据将无法被查询到，因为路由值已经不同）。</p>
<h3 id="集群交互">集群交互</h3>
<p>以三节点集群为例，其中包含一个blogs的索引，它对应的设置为：主分片数：2，副本数：2。一般相同分片的副本不会存放在同一节点，如下图：</p>
<p>注意：</p>
<ol>
<li>ES中的每个节点都有能力处理任意操作请求。</li>
<li>如果某个节点被指定为接受请求的节点，那么该节点被称为协调节点（coordinating  node）</li>
<li>为了后续更好的扩展负载，一般使用轮询机制遍历集群中的所有节点。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303019.png" alt="img" loading="lazy"></figure>
<h4 id="新建删除文档">新建/删除文档</h4>
<p>新建与删除操作需要在主节点操作结束后，才能同步至副本分片中，如下所示：</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303020.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送新建，删除请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3上的请求执行成功后，它会将请求并行地转发至NODE1与NODE2上的副本分片。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>额外参数补充：</p>
<ul>
<li>consistency：一致性。此参数默认配置下进行写操作时，主分片会要求集群中的大部分（规定数量（quorum））分片副本处于活跃可用状态，否则将不会进行写操作。如此设置的目的是为了防止出现网络分区故障时，写操作出现数据不一致的现象。</li>
<li>规定数量公式：int((primary + number_of_replicas)/2) + 1；其中number_of_replicas指的是设置索引时对应的副本分片数，且只有该值大于1时，规定数量设置才会生效（因为单节点默认配置会影响写操作）。</li>
<li>consistency参数值：one 表示主分片状态ok即可执行写操作；all 表示主分片及所有副本分片都ok才能进行写操作；quorum 默认设置，表示副本分片达到规定数量即可执行写操作。</li>
</ul>
<h4 id="更新文档">更新文档</h4>
<p>更新操作相较于新建/删除多了一个额外的冲突重试步骤，如下图所示；</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303021.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3从主分片搜索对应的文档数据，修改_source中的内容，并重新存储至主分片上。如果此过程中，文档被另一个进程修改，那么步骤3将会重复执行，直到retry_on_conflict次后放弃。</li>
<li>NODE3上的请求执行成功后，它会将新版本的文档并行地转发至NODE1与NODE2上的副本分片，重新建立索引。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>注意：主分片并不会将更改请求转发至副本分片，而是将新版本的文档完整的转发过去，且不保证顺序。如果ES转发更改请求，那么由于顺序的不一致，可能导致文档更新有误，从而使错误的数据存储下来。</p>
<h4 id="检索文档">检索文档</h4>
<p>ES可以从主分片或者副本分片中得到需要搜素的文档，如下图所示：</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303022.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，分片P0的副本分片存在所有节点上，在这种情况下（轮询机制），它将请求转发至NODE2。</li>
<li>NODE2将文档返回给NODE1，NODE1再将文档返回给客户端。</li>
</ol>
<p>注意：在处理读请求时，协调节点在每次请求时都会通过轮询机制遍历所有节点来达到负载均衡。这也是步骤2会从NODE2获取数据的原因。</p>
<p>在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p>
<h4 id="批量操作文档">批量操作文档</h4>
<p>ES批量操作与单文档操作基本一致。区别在于协调节点会将整个文档分解为每个分片的多文档请求，并将这些请求转发至每个参与节点。</p>
<p>使用单个 mget 请求取回多个文档所需的步骤顺序：</p>
<ol>
<li>客户端向 Node 1 发送 mget 请求。</li>
<li>Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303023.png" alt="img" loading="lazy"></figure>
<p>bulk API 操作步骤：</p>
<ol>
<li>客户端向 Node 1 发送 bulk 请求。</li>
<li>Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303024.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CPU飙升问题排查]]></title>
        <id>https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/</id>
        <link href="https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/">
        </link>
        <updated>2022-02-05T03:13:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述运行中的Java程序导致的CPU飙升问题排查过程和方法。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hot-air-balloon-1756150_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="cpu飙升问题排查">CPU飙升问题排查</h2>
<h3 id="问题描述">问题描述</h3>
<p>线上系统突然运行缓慢，CPU飙升，甚至到100%，以及Full GC次数过多，接着就是各种报警：例如接口超时报警等。此时急需快速线上排查问题。</p>
<h3 id="问题排查">问题排查</h3>
<p>不管什么问题，既然是CPU飙升，肯定是查一下耗CPU的线程，然后看看GC。</p>
<h4 id="排查步骤">排查步骤</h4>
<ol>
<li>执行“top”命令：查看所有进程占系统CPU的排序。极大可能排第一个的就是咱们的java进程（COMMAND列，也可以直接使用top -p <code>pgrep -d,java</code>查看系统中JAVA进程的CPU占用情况）。PID那一列就是进程号。</li>
<li>执行“top -Hp 进程号”命令：查看java进程下的所有线程占CPU的情况。</li>
<li>执行“printf &quot;%x\n 10&quot;命令 ：后续查看线程堆栈信息展示的都是十六进制，为了找到咱们的线程堆栈信息，咱们需要把线程号转成16进制。例如,printf &quot;%x\n 10-》打印：a，那么在jstack中线程号就是0xa.</li>
<li>执行 “jstack 进程号 | grep 线程ID” 查找某进程下-》线程ID（jstack堆栈信息中的nid）=0xa的线程堆栈信息。如果“&quot;VM Thread&quot; os_prio=0 tid=0x00007f871806e000 nid=0xa runnable”，第一个双引号圈起来的就是线程名，如果是“VM Thread”这就是虚拟机GC回收线程了</li>
<li>执行“jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一次统计）”，查看某进程GC持续变化情况，如果发现返回中FGC很大且一直增大-》确认Full GC! 也可以使用“jmap -heap 进程ID”查看一下进程的堆内存是不是要溢出了，特别是老年代内存使用情况，一般是达到阈值(具体看垃圾回收器和启动时配置的阈值)进程就会Full GC。</li>
<li>执行“jmap -dump:format=b,file=filename 进程ID”，导出某进程下内存heap输出到文件中。可以通过jvisualvm查看（直接双击打开jvisualvm.exe，点击文件-&gt;装入，在文件类型那一栏选择堆，选择要分析的dump文件，打开）。</li>
</ol>
<p>注意：jmap会导致JVM的停止（您的应用程序已停止。获得准确的堆转储的唯一实用方法是在创建转储时停止所有应用程序活动。这是“简短”暂停还是“长时间”暂停取决于要转储多少。如果使用“ -dump”，则将转储整个堆，包括不可达的对象。如果使用“-dump：live”，则只会转储可访问的对象……但这（至少）需要标记堆以找出可访问的对象。但是，如果要转储千兆字节大小的堆，则期望暂停时间以分钟而不是秒为单位。）。</p>
<h4 id="原因分析">原因分析</h4>
<h5 id="内存消耗过大导致full-gc次数过多">内存消耗过大，导致Full GC次数过多</h5>
<p>执行步骤1-5：</p>
<ul>
<li>多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程-》上一节步骤2</li>
<li>通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。--》上一节步骤5</li>
</ul>
<p>确定是Full GC,接下来找到具体原因：</p>
<ul>
<li>生成大量的对象，导致内存溢出-》执行步骤6，查看具体内存对象占用情况。</li>
<li>内存占用不高，但是Full GC次数还是比较多，此时可能是代码中手动调用 System.gc()导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。</li>
</ul>
<h5 id="代码中有大量消耗cpu的操作导致cpu过高系统运行缓慢">代码中有大量消耗CPU的操作，导致CPU过高，系统运行缓慢；</h5>
<p>执行步骤1-4：在步骤4jstack，可直接定位到代码行。例如某些复杂算法，甚至算法BUG，无限循环递归等等。</p>
<h5 id="由于锁使用不当导致死锁">由于锁使用不当，导致死锁。</h5>
<p>执行步骤1-4： 如果有死锁，会直接提示。关键字：deadlock.步骤四，会打印出业务死锁的位置。</p>
<p>造成死锁的原因：最典型的就是2个线程互相等待对方持有的锁。</p>
<h5 id="随机出现大量线程访问接口缓慢">随机出现大量线程访问接口缓慢。</h5>
<p>代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；平时消耗的CPU不多，而且占用的内存也不高。</p>
<p>思路：首先找到该接口，通过压测工具不断加大访问力度，大量线程将阻塞于该阻塞点。</p>
<p>执行步骤1-4，如下，找到业务代码阻塞点，这里业务代码使用了TimeUnit.sleep()方法，使线程进入了TIMED_WAITING(期限等待)状态。</p>
<pre><code>&quot;http-nio-8080-exec-4&quot; #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)-》期限等待
 at java.lang.Thread.sleep(Native Method)
 at java.lang.Thread.sleep(Thread.java:340)
 at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
 at com.*.user.controller.UserController.detail(UserController.java:18)-》业务代码阻塞点
</code></pre>
<h5 id="某个线程由于某种原因而进入waiting状态此时该功能整体不可用但是无法复现">某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；</h5>
<p>执行步骤1-4：jstack多查询几次，每次间隔30秒，对比一直停留在parking 导致的WAITING状态的线程。例如CountDownLatch倒计时器，使得相关线程等待-&gt;AQS-&gt;LockSupport.park()。</p>
<pre><code>&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000]
java.lang.Thread.State: WAITING (parking) -&gt;无期限等待
at sun.misc.Unsafe.park(Native Method)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
at com.*.SyncTask.lambda$main$0(SyncTask.java:8)-》业务代码阻塞点
at com.*.SyncTask$$Lambda$1/1791741888.run(Unknown Source)
at java.lang.Thread.run(Thread.java:748)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zabbix5.4采集日志进行钉钉告警]]></title>
        <id>https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/</id>
        <link href="https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/">
        </link>
        <updated>2022-01-22T02:28:06.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述zabbix5.4采集日志进行钉钉告警</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/landscape-1192669_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="配置钉钉机器人">配置钉钉机器人</h2>
<p>电脑版钉钉，选中对应的钉钉群，点击群设置---&gt;智能群助手---&gt;添加机器人---&gt;自定义---&gt;添加。</p>
<p>安全设置根据需要自行选择（演示选择的是自定义关键词），需要记住对应的Webhook（用作python脚本调接口使用）</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302016.png" alt="img" loading="lazy"></figure>
<h2 id="配置zabbix">配置zabbix</h2>
<h3 id="zabbix-server配置">zabbix-server配置</h3>
<p>使用命令查找对应的告警配置文件目录。</p>
<pre><code>cat /etc/zabbix/zabbix_server.conf | grep AlertScripts
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303001.png" alt="" loading="lazy"></figure>
<pre><code>find / -name alertscripts
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303002.png" alt="" loading="lazy"></figure>
<p>找到告警目录后，使用cd命令，切入该目录，并执行vi dingding.py。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303003.png" alt="" loading="lazy"></figure>
<p>dingding.py内容如下（钉钉文档：<a href="https://developers.dingtalk.com/document/app/custom-robot-access">点击此处跳转页面</a>）</p>
<pre><code>#!/usr/bin/env python3.8
#coding:utf-8
#zabbix dingding alert
import requests,json,sys,os,datetime
webhook=&quot;https://oapi.dingtalk.com/robot/send?access_token=******&quot;
user=sys.argv[1]
text=sys.argv[3]
data={
    &quot;msgtype&quot;: &quot;text&quot;,
    &quot;text&quot;: {
        &quot;content&quot;: text
    },
    &quot;at&quot;: {
        &quot;atMobiles&quot;: [
            user
        ],
        &quot;isAtAll&quot;: False
    }
}
headers = {'Content-Type': 'application/json'}
x=requests.post(url=webhook,data=json.dumps(data),headers=headers)
print(x.status_code)
print(x.text)

</code></pre>
<p>注意：代码的第一句（#!/usr/bin/env python3.8）中的 python3.8取决于系统安装的python版本，使用whereis  python进行查看。</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303004.png" alt="" loading="lazy"></figure>
<p>随后使用如下命令进行权限设置（如若未设置，将无法执行脚本文件）</p>
<pre><code>[root@localhost alertscripts]# chmod 755 dingding.py 
[root@localhost alertscripts]# chown zabbix.zabbix dingding.py

</code></pre>
<p>测试时，前两个参数，随便填，最后的文本内容需要加上在钉钉机器人配置时设置的关键词。</p>
<pre><code>[root@localhost alertscripts]# ./dingding.py 123 wrq &quot;{monitor,test}&quot;
200
{&quot;errcode&quot;:0,&quot;errmsg&quot;:&quot;ok&quot;}
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303005.png" alt="" loading="lazy"></figure>
<p>问题：可能出现一些安装包不存在，比如requests，使用pip3 list 查看安装了哪些包。如果没有安装requests，可以执行pip3 install requests进行安装。</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303006.png" alt="img" loading="lazy"></figure>
<h3 id="zabbix-web配置">zabbix-web配置</h3>
<h4 id="在已添加的主机上在创建一个监控项">在已添加的主机上在创建一个监控项</h4>
<p>logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,]<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件进行日志信息采集。</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303007.png" alt="img" loading="lazy"></figure>
<h4 id="在已添加的主机上在创建一个触发器">在已添加的主机上在创建一个触发器</h4>
<p>find(/zabbix-agent/logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,],#10,,&quot;HIGH&quot;)=1<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件中的HIGH字段进行告警触发。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303008.png" alt="img" loading="lazy"></figure>
<h4 id="在管理界面添加一个媒体类型">在管理界面添加一个媒体类型</h4>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303009.png" alt="img" loading="lazy"></figure>
<h4 id="在配置界面的动作操作中添加一个触发器动作">在配置界面的动作操作中添加一个触发器动作</h4>
<p>条件选择触发器名称匹配。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303010.png" alt="" loading="lazy"></figure>
<p>随后点击操作</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303011.png" alt="" loading="lazy"></figure>
<pre><code>配置信息如下：
业务告警（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303012.png" alt="" loading="lazy"></figure>
<pre><code>故障恢复（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303013.png" alt="" loading="lazy"></figure>
<p>上述操作中，需要注意的是Send to users选项，该选项对应的值需与媒体类型关联。比如上面选择的用户是Admin，那么需要在管理界面选择用户Admin进行媒体类型的添加。</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303014.png" alt="" loading="lazy"></figure>
<h4 id="拼接地址调转zabbix指定界面">拼接地址调转zabbix指定界面</h4>
<pre><code>// 拼接地址调转zabbix指定界面
String t = &quot;http://localhost:8096/index.php?request=zabbix.php%3Faction%3Dhost.dashboard.view%26hostid%3D10435&amp;name=Admin&amp;password=zabbix&amp;autologin=1&amp;enter=Sign+in&quot;;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WSL2 & Docker & Zabbix]]></title>
        <id>https://philosopherzb.github.io/post/wsl2-and-docker-and-zabbix/</id>
        <link href="https://philosopherzb.github.io/post/wsl2-and-docker-and-zabbix/">
        </link>
        <updated>2022-01-08T07:31:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述如何安装wsl2，docker以及zabbix。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/forest-1072828_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="install-wsl-update-to-wsl2">Install WSL &amp; update to WSL2</h2>
<p>WSL，全名：Windows Subsystem for Linux，是一个运行在windows系统上的Linux子系统，它支持绝大部分的Linux功能，避免了安装虚拟机。</p>
<h3 id="安装前的一些必要项">安装前的一些必要项</h3>
<p>确保计算机开启了虚拟化技术这项配置，开机进入BIOS界面，选择configuration-》Intel Virtual Technology进行开启即可。</p>
<p>使用WSL2的系统版本必须为windows10，且对应的最低版本要求如下（win+R，输入winver回车即可查看本机系统版本）：</p>
<ul>
<li>For x64 systems: Version 1903 or higher, with Build 18362 or higher.</li>
<li>For ARM64 systems: Version 2004 or higher, with Build 19041 or higher</li>
<li>Builds版本低于 18362 是不支持 WSL 2的。 <a href="https://www.microsoft.com/zh-cn/software-download/windows10">点击此处可跳转下载地址</a> 下载最新的windows进行更新。</li>
</ul>
<h3 id="安装wsl">安装WSL</h3>
<p>以管理员的权限打开powershell（右击左下角的win logo选择即可），键入如下命令：</p>
<pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
</code></pre>
<p>命令执行之后，重启电脑即可完成WSL的安装。</p>
<p>下载WSL2最新的安装包进行更新。<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">点击此处可跳转下载地址</a></p>
<p>下载完成后，双击运行即可。</p>
<p>将wsl2设置为默认版本，输入命令：wsl --set-default-version 2</p>
<h3 id="安装liunx操作系统">安装Liunx操作系统</h3>
<p><a href="https://aka.ms/wslstore">点击此处可跳转下载地址</a>选择一款系统点击get进行安装。</p>
<p><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302008.png" alt="img" loading="lazy"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302009.png" alt="" loading="lazy"></p>
<p>等待计算机自动安装完成后，左击桌面左下角的win logo，选择刚刚安装的操作系统。第一次进入需要等待几分钟，随后创建一个用户即可登录使用了。</p>
<p>点击左下方任务栏上的搜索按钮，在搜索框中输入“终端”，选择虚拟机打开。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302010.png" alt="" loading="lazy"></figure>
<p>可以在powershell中的键入wsl --list --verbose查看版本信息</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302011.png" alt="img" loading="lazy"></figure>
<p>额外：可以安装Windows Terminal，便于多界面管理终端。<a href="https://docs.microsoft.com/en-us/windows/terminal/get-started">点击此处可跳转下载地址</a></p>
<p>wls官方地址：<a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">点击此处可跳转</a></p>
<p>启动报错时可参考：<a href="https://appuals.com/wsl-fails-to-start-error-4294967295/">点击此处可跳转</a></p>
<h2 id="docker-desktop-for-windows">Docker desktop for windows</h2>
<h3 id="安装docker">安装Docker</h3>
<p>安装完WSL2后，<a href="https://docs.docker.com/docker-for-windows/wsl/#download">点击此处可跳转下载地址</a>下载docker安装包，随后直接双击安装即可。</p>
<p>注意1：docker默认安装在C盘目录下，如果需要迁移，需要进行如下操作：</p>
<p>以管理员身份打开cmd窗口，然后运行命令：mklink /j &quot;C:\Program Files\Docker&quot; &quot;D:\Program Files\Docker&quot;，在此之前要先创建&quot;D:\Program Files\Docker&quot;目录。最后安装docker即可。（ mklink /j 表示创建一个链接）</p>
<p>注意2：docker镜像文件默认存储在wsl中，也就是系统盘，可以通过如下命令进行迁移（需要先创建对应的文件目录D:\Program Files\wsl\data）。</p>
<pre><code>-- 导出文件
wsl --export docker-desktop-data &quot;D:\Program Files\wsl\data\docker-desktop-data.tar&quot;
wsl --export docker-desktop &quot;D:\Program Files\wsl\data\docker-desktop.tar&quot;
-- 注销原来的文件
wsl --unregister docker-desktop
wsl --unregister docker-desktop-data
-- 数据导入新文件中
wsl --import docker-desktop-data &quot;D:\Program Files\wsl\data&quot; &quot;D:\Program Files\wsl\data\docker-desktop-data.tar&quot; --version 2
wsl --import docker-desktop &quot;D:\Program Files\wsl\data&quot; &quot;D:\Program Files\wsl\data\docker-desktop.tar&quot; --version 2
</code></pre>
<p>注意3：在docker的设置界面，需要开启与虚拟机的集成。</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302012.png" alt="img" loading="lazy"></figure>
<h2 id="zabbix54">Zabbix5.4</h2>
<h3 id="安装zabbix">安装zabbix</h3>
<p>在docker中安装监控工具zabbix，操作步骤如下（官网地址：<a href="https://www.zabbix.com/documentation/current/manual/installation/containers">点击此处可跳转</a>）：</p>
<h4 id="创建docker容器专用网关">创建docker容器专用网关</h4>
<pre><code>docker network create --subnet 172.20.0.0/16 --ip-range 172.20.240.0/20 zabbix-net
docker network create -d bridge zabbix-net
</code></pre>
<h4 id="运行一个空的mysql80服务实例">运行一个空的mysql8.0服务实例</h4>
<p>注意：` 符号为windows中powershell下的换行符，位于ESC键下方</p>
<pre><code>docker run --name mysql-server -t `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      --network=zabbix-net `
      -d mysql:8.0 `
      --character-set-server=utf8 --collation-server=utf8_bin
</code></pre>
<h4 id="运行zabbix-java-gateway实例版本为ubuntu-latest">运行zabbix-java-gateway实例，版本为ubuntu-latest</h4>
<p>版本标签含义如下：</p>
<p>latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本（如果docker pull的时候不输入TAG，将会默认使用该标签）</p>
<p>alpine-latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本</p>
<p>ubuntu-latest: 基于Ubuntu镜像的zabbix组件最终稳定版本</p>
<p>alpine-5.4-latest: 基于Alpine Linux镜像的zabbix5.4组件最终次要版本</p>
<p>ubuntu-5.4-latest: 基于Ubuntu镜像的zabbix5.4组件最终次要版本</p>
<p>alpine-5.4.*: 基于Alpine Linux镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2</p>
<p>ubuntu-5.4.*: 基于Ubuntu镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2</p>
<pre><code>docker run --name zabbix-java-gateway -t `
      --network=zabbix-net `
      --restart unless-stopped `
      -d zabbix/zabbix-java-gateway:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-server-mysql服务并将其与mysql服务关联">运行zabbix-server-mysql服务，并将其与mysql服务关联</h4>
<p>注意：zabbix服务实例向主机公开10051/TCP端口（Zabbix Trapper）</p>
<pre><code>docker run --name zabbix-server-mysql -t `
      -e DB_SERVER_HOST=&quot;mysql-server&quot; `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      -e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      -p 10051:10051 `
      --restart unless-stopped `
      -d zabbix/zabbix-server-mysql:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-web-nginx-mysql服务并将其与mysql及zabbix-server-mysql关联">运行zabbix-web-nginx-mysql服务，并将其与mysql及zabbix-server-mysql关联</h4>
<p>注意：至此zabbix服务已在本机的8096端口暴露。</p>
<p>在docker镜像中nginx的默认端口是8080而非80，可进入镜像的/etc/zabbix/nginx.conf查看，命令如下：</p>
<pre><code>docker ps
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat nginx.conf
</code></pre>
<pre><code>docker run --name zabbix-web-nginx-mysql -t `
      -e ZBX_SERVER_HOST=&quot;zabbix-server-mysql&quot; `
      -e DB_SERVER_HOST=&quot;mysql-server&quot; `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      --link zabbix-server-mysql:zabbix-server `
      -p 8096:8080 `
      --restart unless-stopped `
      -d zabbix/zabbix-web-nginx-mysql:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-agent服务并关联zabbix-server配置在同一个网桥下">运行zabbix-agent服务，并关联zabbix-server（配置在同一个网桥下）</h4>
<p>注意：web界面Configuration中的Hosts配置中的Name必须与/etc/zabbix/zabbix_agentd.conf中的hostName保持一致，命令如下：</p>
<pre><code>docker ps
# root权限进入
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat zabbix_agentd.conf

web界面Configuration中的Hosts配置中的IP address为zabbix-agent容器所在的地址，命令如下：
docker network ls
docker network inspect NETWORK ID（指第一步中创建zabbix-net对应的id值）
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302013.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302014.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302015.png" alt="" loading="lazy"></figure>
<pre><code>docker run --name zabbix-agent `
      -e ZBX_HOSTNAME=&quot;zabbix-agent&quot; `
      -e ZBX_SERVER_HOST=&quot;zabbix-server-mysql&quot; `
      -e ZBX_SERVER_PORT=10051 `
      --network=zabbix-net `
      --link zabbix-server-mysql:zabbix-server-mysql `
      -p 10050:10050 `
      -d zabbix/zabbix-agent:ubuntu-latest

显示所有ip地址
docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' $(docker ps -aq)
显示zabbix-agen ip地址
docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' zabbix-agent
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux常用命令]]></title>
        <id>https://philosopherzb.github.io/post/linux-chang-yong-ming-ling/</id>
        <link href="https://philosopherzb.github.io/post/linux-chang-yong-ming-ling/">
        </link>
        <updated>2021-12-18T03:25:34.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Linux中常用的一些操作命令。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-440520_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="scp传输文件">SCP（传输文件）</h2>
<p>将win10 D盘temp目录下的文件传输到199.199.199.199的root目录下。</p>
<pre><code>scp D:\temp\***.tar root@199.199.199.199:/root

</code></pre>
<p>将199.199.199.199的root目录下文件传输到win10 D盘temp目录</p>
<pre><code>scp root@199.199.199.199:/root/***.txt D:\temp\

</code></pre>
<h2 id="tar解压缩">TAR（解压缩）</h2>
<p>压缩指定目录下的文件（注意：win为 \，linux为 /）</p>
<pre><code>tar -cvzf  D:\temp\***.tar &quot;D:\temp\***&quot;
# -l   压 缩文件时，把LF字符 置换成LF+CR字 符。
# -ll   压 缩文件时，把LF+CR字 符置换成LF字符。
tar -cvzf -ll  D:\temp\***.tar &quot;D:\temp\***&quot;

</code></pre>
<p>解压指定目录下的文件到指定目录（注意：win为 \，linux为 /）</p>
<pre><code> tar -zxvf /root/***.tar -C /opt/temp/

</code></pre>
<h2 id="mv移动文件">MV（移动文件）</h2>
<p>移动目录下的所有文件至指定目录下</p>
<pre><code>mv  /root/temp/*       /opt/temp/

</code></pre>
<h2 id="find-whereis查询文件">FIND $ WHEREIS（查询文件）</h2>
<p>查询文件</p>
<pre><code>find / -name agent
whereis agent
</code></pre>
<h2 id="dos2unix转换格式">DOS2UNIX（转换格式）</h2>
<p>在win系统中写的shell脚本移动至linux执行时，会提示错误：line 2: $'\r': command not found，这是因为win系统下的换行符为\r\n，而linux系统的为\n，所以需要进行格式转换。</p>
<p>单个，或多个文件格式转换</p>
<pre><code>dos2unix filename1, filename2
</code></pre>
<p>将指定目录下的所有sh结尾的文件进行格式转换</p>
<p>注意：一定要有{}，标示参数；以“;”结尾； {} 和\之间一定要有一个空格</p>
<pre><code>find /apps/cws -name &quot;*.sh&quot; -exec dos2unix {} \;   

</code></pre>
<p>也可以使用xargs命令，不过xargs命令需要和管道符结合使用，并且xargs命令将所有的传入的数据当作一个参数处理。</p>
<pre><code>find /opt/temp/ -name &quot;*.sh&quot; | xargs dos2unix
</code></pre>
<h2 id="ps进程状态process-status">PS（进程状态process status）</h2>
<p>显示所有进程信息，连同命令行</p>
<pre><code>ps -ef
</code></pre>
<p>列出目前正在内存中的程序</p>
<pre><code>ps aux
</code></pre>
<p>通过指定名称列出当前正在内存中的程序的状态(grep命令用于查找符合条件的字符串)</p>
<pre><code>ps aux | grep name
</code></pre>
<h2 id="top任务管理器">TOP（任务管理器）</h2>
<p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。</p>
<pre><code>top
</code></pre>
<h2 id="sudo操作命令">SUDO（操作命令）</h2>
<p>用于切换用户</p>
<pre><code># 切换至root用户登录
sudo -i
</code></pre>
<h2 id="rz传输文件">RZ（传输文件）</h2>
<p>使用finalshell软件时，在命令窗口输入rz可以直接选择外部文件传入服务器。</p>
<pre><code>rz
</code></pre>
<h2 id="firewall防火墙">Firewall（防火墙）</h2>
<pre><code># 安装防火墙
yum install firewalld firewalld-config
</code></pre>
<pre><code>Firewall开启常见端口命令：

firewall-cmd --zone=public--add-port=80/tcp --permanent

firewall-cmd --zone=public--add-port=443/tcp --permanent

firewall-cmd --zone=public --add-port=22/tcp--permanent

firewall-cmd --zone=public --add-port=9000/tcp --permanent

firewall-cmd --zone=public--add-port=53/udp --permanent

Firewall关闭常见端口命令：

firewall-cmd --zone=public--remove-port=80/tcp --permanent

firewall-cmd --zone=public--remove-port=443/tcp --permanent

firewall-cmd --zone=public--remove-port=22/tcp --permanent

firewall-cmd --zone=public--remove-port=21/tcp --permanent

firewall-cmd --zone=public--remove-port=53/udp --permanent

批量添加区间端口：

firewall-cmd --zone=public--add-port=4400-4600/udp --permanent

firewall-cmd --zone=public--add-port=4400-4600/tcp --permanent

开启防火墙命令：

systemctl start firewalld.service

重启防火墙命令：

firewall-cmd --reload  或者   service firewalld restart

查看端口列表：

firewall-cmd --permanent --list-port
firewall-cmd --list-all

禁用防火墙：

systemctl stop firewalld

设置开机启动：

systemctl enable firewalld

停止并禁用开机启动：

sytemctl disable firewalld

查看状态：

systemctl status firewalld或者firewall-cmd --state

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Centos7基本知识]]></title>
        <id>https://philosopherzb.github.io/post/centos7-ji-ben-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/centos7-ji-ben-zhi-shi/">
        </link>
        <updated>2021-12-04T03:18:08.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Centos7系统相关的操作及命令介绍。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-1802337_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="图形命令切换">图形/命令切换</h2>
<h3 id="图形界面进入命令行">图形界面进入命令行</h3>
<p>右击或者在application中打开终端，输入：init 3，即可进入命令行；也可以直接ctrl+alt+f2，进入命令行。</p>
<h3 id="命令行进入图形界面">命令行进入图形界面</h3>
<p>输入：init 5或者：startx，即可进入图形界面。</p>
<p>不过由 startx 再进入命令行会无法进入，可以重新输入：init 5，</p>
<p>重启一下x window，然后再输入：init 3，便可进入命令行。</p>
<h3 id="设置开机进入x-window还是命令行">设置开机进入x window还是命令行</h3>
<p>命令行状态下，root管理员，键入：cat /etc/inittab，</p>
<p>根据提示输入：systemctl get-default，可查看当前进入为那种状态。</p>
<p>如若需要更改可以输入：systemctl set-default multi-user.target------命令行</p>
<p>systemctl set-default graphical.target------图形界面</p>
<h2 id="日期相关">日期相关</h2>
<p>1、指令太长的时候，可以使用反斜杠 () 来跳脱[Enter]符号，使指令连续到下一 行。注意！反斜杠后就立刻接回车，才能跳脱。</p>
<p>2、linux区分大小写！！！</p>
<p>3、ls -al 列出『自己家目录(~)』下的『所有隐藏档不相关的文件属性』</p>
<p>4、显示当前语系：echo $LANG</p>
<p>5、日期：date(正常显示)，date +%y/%m/%d(年月日显示)，date +%H:%M(时钟显示)</p>
<p>6、万年历：cal [month][year]</p>
<p>7、计算器：bc，如需显示小数，在键入bc之后，输入：scale=4,（数字4表示小数有4位）退出键入：quit</p>
<p>8、在指令列模式里面下达指令时，会有两种主要的情况：</p>
<ul>
<li>一种是该指令会直接显示结果然后回到命令提示字符等待下一个指令的输入；</li>
<li>一种是进入到该指令的环境，直到结束该指令才回到命令提示字符的环境。</li>
</ul>
<h2 id="常用快捷键">常用快捷键</h2>
<p>1、Tab键，可进行 [[命令补全]] 和 [[档案补齐]]</p>
<ul>
<li>比如在ca后面连续按两下  Tab，即可查看补全的命令。</li>
<li>而档案补齐可以在 ls -al /.bash后面连续按两下Tab，可进行查看。</li>
</ul>
<p>2、Ctrl+C组合键，即先按下Ctrl不放，再按下C键，便可终止运行的命令。</p>
<p>比如：键入：find / 之后会不停的搜寻，此时，可以使用Ctrl+C来终止运行；不过如果是在进行很重要的指令，则不要急着使用组合键终止命令。</p>
<p>3、Ctrl+D组合键，相当于exit，如果使用，可直接退出文字接口。</p>
<p>4、使用man（manual 操作说明的简写），当需要知道某一个命令的详细指令的时候可以使用。比如：man date，如需退出，按下q即可，翻页按空格键。</p>
<p>5、当使用man date之后，界面左上角会出现DATE(1)，其中的括号中的1的概念如下：</p>
<ul>
<li>1 用户在shell环境中可以操作的指令或可执行文件（重要）</li>
<li>2 系统核心可呼叫的函数与工具等</li>
<li>3 一些常用的函数(function)与函式库(library)，大部分为C的函式库(libc)</li>
<li>4 装置档案的说明，通常在/dev下的档案</li>
<li>5 配置文件或者是某些档案的格式 （重要）</li>
<li>6 游戏(games)</li>
<li>7 惯例与协议等，例如Linux文件系统、网络协议、ASCII code等等的说明</li>
<li>8 系统管理员可用的管理指令 （重要）</li>
<li>9 跟kernel有关的文件</li>
</ul>
<p>6、在man page页面可有如下快捷键操作：</p>
<pre><code>空格键              向下翻一页

[Page Down]    向下翻一页

[Page Up]         向上翻一页

[Home]            去到第一页

[End]                去到最后一页

/string              向『下』搜寻 string 这个字符串，如果要搜寻 date 的话，就输入 /date

?string              向『上』搜寻 string 这个字符串

n, N                  利用 / 或 ? 来搜寻字符串时，可以用 n 来继续下一个搜寻 (不论是 / 或?) ，

可以利用 N 来进行『反向』搜寻。举例来说，我以 /date 搜寻 date 字符串，

那么可以 n 继续往下查询，用 N 往上查询。 若以 ?date 向上查询 date 字符串，

那我可以用 n 继续『向上』 查询，用 N 反向查询。

q                      结束这次的 man page
</code></pre>
<p>7、查看与【man】这个指令相关的的说明文件：</p>
<p>命令行键入：man -f man   等同于whatis man</p>
<p>8、利用关键词将说明文件里面只要含有man那个字眼的(不见得是完整字符串) 就将他取出：命令行键入：man -k man  等同于apropos man</p>
<h2 id="infopage及nano">InfoPage及nano</h2>
<p>1、info page</p>
<pre><code>info与man的用途其实差不多，都是用来查询指令的用法或者是档案的格式。

但是与man page一口气输出一堆信息不同的是，info page则是将文件数据拆成

一个一个的段落，每个段落用自己的页面来撰写， 并且在各个页面中还有类似网

页的『超链接』来跳到各不同的页面中，每个独立的 页面也被称为一个节点(node)

命令行键入：info info
</code></pre>
<p>2、出现的第一行里面的数据意义为：</p>
<pre><code>File：代表这个info page的资料是来自info.info档案所提供的；

Node：代表目前的这个页面是属亍Top节点。 意思是info.info内

含有很多信息，而Top仅是 info.info档案内的一个节点内容而已；

Next：下一个节点的名称为Getting Started，你也可以按『N』到下个节点去；

Up：回到上一层的节点总揽画面，你也可以按下『U』回到上一层；

Prev：前一个节点。但由于Top是info.info的第一个节点，所以上面没有前一个节点的信息
</code></pre>
<p>3、info page页面快捷键操作：</p>
<pre><code>空格键                 向下翻一页

[Page Down]       向下翻一页

[Page Up]            向上翻一页

[tab]                    在 node 之间移劢，有 node 的地方，通常会以 * 显示。

[Enter]                 当光标在 node 上面时，按下 Enter 可以进入该 node 。

b                         移动光标到该 info 画面当中的第一个 node 处

e                         移动光标到该 info 画面当中的最后一个 node 处

n                         前往下一个 node 处

p                         前往上一个 node 处

u                         向上移动一层

s(/)                      在 info page 当中进行搜寻

h                         显示求助选单

?                         指令一览表

q                         结束这次的 info page
</code></pre>
<p>4、说明文档所在地。架设一些其他的服务，或想要利用一整组软件来达成某项功能时</p>
<pre><code>键入：cd /usr/share/doc

即可进入doc文件夹下方，有很多文档的说明。（实践中未找到？？？）
</code></pre>
<p>5、超简单文书编辑器： nano</p>
<pre><code>[ctrl]-G：   取得联机帮助(help)，很有用的！

[ctrl]-X：   离开naon软件，若有修改过档案会提示是否需要储存喔！

[ctrl]-O：   储存档案，若你有权限的话就能够储存档案了；

[ctrl]-R：   从其他档案读入资料，可以将某个档案的内容贴在本档案中；

[ctrl]-W：  搜寻字符串，这个也是径有帮助的指令喔！

[ctrl]-C：   说明目前光标所在处的行数与列数等信息；

[ctrl]-_：    可以直接输入行号，让光标快速移动到该行；

[alt]-Y：    校正语法功能开启或关闭(单击开、再单击关)

[alt]-M：   可以支持鼠标来移动光标的功能
</code></pre>
<p>6、关机</p>
<pre><code>重新启动，关机： reboot, halt, poweroff

键入：man shutdown  查看具体细节。

常用的是：shutdown -h now 立即关机

shutdown -r now  立即重启

init 0           立即关机

init 6           立即重启

reboot         立即重启
</code></pre>
<h2 id="linux文件属性">Linux文件属性</h2>
<p>root登陆后，键入ls -al</p>
<p>-rw-r--r--  1 root  root  2272  Jul  5 09:50  initial-setup-ks.cfg</p>
<p>[权限]  [连结数]  [拥有者]  [群组]  [档案容量]  [ 修改日期 ] [檔名]</p>
<p>1、 第一栏代表这个档案的类型与权限(permission)：</p>
<pre><code>-rw-r--r--    其中一共有十个字符。

第一个字符表示档案类型，第二，三，四表示档案拥有者权限

第五，六，七表示档案所属群组的权限，第八，九，十表示其他人的权限
</code></pre>
<p>2、第一个字符代表这个档案是『目录、档案或链接文件等等』：</p>
<pre><code>当为[ d ]则是目录；

当为[ - ]则是档案；

若是[ l ]则表示为连结档(link file)；

若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；

若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)
</code></pre>
<p>3、接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。其中，</p>
<pre><code>[ r ]代表可读 (read)、

[ w ]代表可写(write)、

[ x ]代表可执行(execute)。

要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已
</code></pre>
<p>4、第二栏表示有多少档名连结到此节点(i-node)</p>
<pre><code>每个档案都会将他的权限与属性记录到文件系统的i-node中，

不过，我们使用的目录树却是使用文件名来记录的， 因此每个档名

就会连结到一个i-node！这个属性记录的，就是有多少不同的档

名连结到相同的一个i-node了。
</code></pre>
<p>5、第三栏表示这个档案(或目录)的『拥有者账号』</p>
<p>6、第四栏表示这个档案的所属群组</p>
<p>7、第五栏为这个档案的容量大小，默认单位为bytes</p>
<p>8、第六栏为这个档案的建档日期或者是最近的修改日期</p>
<pre><code>这一栏的内容分别为日期(月/日)及时间。如果这个档案

被修改的时间距离现在太久了，那么时间部分会仅显示年份而已。

显示完整的时间格式，可以利用ls的选顷，

亦即：『ls -al --full-time』就能够显示出完整的时间格式
</code></pre>
<p>9、第七栏为这个档案的档名</p>
<pre><code>如果档名之前多一个『 . 』，则代表这个档案为『隐藏档』
</code></pre>
<h2 id="设置变更">设置变更</h2>
<p>1、改变所属群组, chgrp</p>
<pre><code>这个指令就是change group的缩写

chgrp [-R] dirname/filename ...

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案、目录

都更新成为这个群组之意。常常用在变更某一目录内所有的档案之情况

chgrp users initial-setup-ks.cfg

chgrp testing initial-setup-ks.cfg（错误信息：invalid group name `testing'）

只有当你要改变的那个文件或者目录中有要改变成的对应群组，才能改变，否则报错，找不到

比如此次实例中的群组就在/etc/group中存在root和users群组，但不存在testing群组
</code></pre>
<p>2、改变档案拥有者, chown</p>
<pre><code>这个指令就是change owner的缩写

跟概念群组一样，这里要注意的是， 用户必项是已经存在系统中的账号，

也就是在/etc/passwd 这个档案中有纪录的用户名称才能改变。

chown [-R] 账号名称 档案或目录

chown [-R] 账号名称:组名 档案或目录

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案都变更

chown bin initial-setup-ks.cfg

chown还可以顺便直接修改群组的名称，中间使用冒号(也可以使用点)，前面为拥有者，后面为群组

chown bin:users initial-setup-ks.cfg

chown bin.users initial-setup-ks.cfg

有时候需要变更档案的拥有者，最常见的例子就是在复制档案给你之外的其他人时

cp 来源档案 目标文件
</code></pre>
<p>（cp .bashrc .bashrc_test ）</p>
<pre><code>先复制一下，然后在更改复制了的使用者，群组。
</code></pre>
<p>3、改变权限, chmod</p>
<pre><code>权限的设定方法有两种， 分别可以使用数字或者是符号来进行权限的变更

数字类型改变档案权限。

Linux档案的基本权限就有九个，分别是owner/group/others三种身份各有自己的 read/write/execute权限

可以使用数字来代表各个权限，如下

r:4 ，w:2， x:1

每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，

例如当权限为： [rwxrwx---] 分数则是：

owner = rwx = 4+2+1 = 7

group = rwx = 4+2+1 = 7

others= --- = 0+0+0 = 0

符号类型改变档案权限

九个权限分别是(1)user (2)group (3)others三种身份啦！那么我们就可以藉由u, g, o来代表三种身份的权限！

此外， a 则代表 all 亦即全部的身份！那么读写的权限就可以写成r, w, x

其中+表示加入，-表示减去，=表示设定

chmod a+w initial-setup-ks.cfg   设定该档案u，g，o都具有w（写）权限

chmod a-w initial-setup-ks.cfg   设定该档案u，g，o都去掉w（写）权限

chmod u=rwx,go=rw initial-setup-ks.cfg   设定该档案u具有rwx权限，go都具有rw权限
</code></pre>
<p>4、『 su - yy 』这个指令来变换身份，只能进入普通账户，进入root需要重新输入密码</p>
<p>5、『 cat ~/.bashrc 』就可以看到该档案的内容。 (cat 是将一个档案内容读出来的指令)</p>
<p>6、Linux目录配置的依据--FHS（Filesystem Hierarchy Standard 文件系统阶层标准）</p>
<pre><code>主要有以下四个类型：

可分享的：可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据，是能够分享给网络上其他主机挂载用的目录。

不可分享的：自己机器上面运作的装置档案或者是与程序有关的socket档案等，由与仅与自身机器有关，所以当然就不适合分享给其他主机了。

不变的：有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等。

可变动的：经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等 。
</code></pre>
<p>7、FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义</p>
<pre><code>/ (root, 根目录)：与开机系统有关；

/usr (unix software resource)：与软件安装/执行有关；

/var (variable)：与系统运作过程有关
</code></pre>
<h2 id="目录及文件">目录及文件</h2>
<p>1、相对路径与绝对路径：</p>
<pre><code>绝对路径：路径的写法『一定由根目录 / 写起』，例如： /usr/share/doc 这个目录。

相对路径：路径的写法『不是由 / 写起』，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写：『cd ../man』这就是相对路径的写法啦！相对路径意指『相对于目前工作目录的路径！』
</code></pre>
<p>2、目录的相关操作：</p>
<pre><code>『.』                代表此层目录

『..』               代表上一层目录

『-』               代表前一个工作目录

『~』              代表『目前用户身份』所在的家目录

『~yy』           代表yy这个用户的家目录(yy是个账号名称)
</code></pre>
<p>常见处理目录的指令(可用man查看)：</p>
<pre><code>cd：变换目录              （Change Directory）

pwd：显示当前目录        （Print Working Directory）

-P(大写)  ：显示出确实的路径，而非使用链接 (link) 路径。

mkdir：建立一个新的目录

mkdir [-mp] 目录名

-m ：配置文件案的权限！直接设定，不需要看预设权限 (umask) 的脸色

-p ：帮助你直接将所需要的目录(包含上层目录)递归建立起来

rmdir： 删除一个空的目录

-p ：连同上层『空的』目录也一起删除
</code></pre>
<p>3、执行文件路径的变量： $PATH</p>
<pre><code>a、不同身份使用者预设的PATH不同，默认能够随意执行的指令也不同(如root与yy)

b、PATH是可以修改的，所以一般使用者还是可以通过修改PATH来执行某些位于/sbin或/usr/sbin下的指令来查询

c、使用绝对路径或相对路径直接指定某个指令的文件名来执行，会比搜寻PATH来的正确

d、指令应该要放置到正确的目录下，执行才会比较方便

e、本目录(.)最好不要放到PATH当中
</code></pre>
<p>4、复制、删除与移动： cp, rm, mv</p>
<pre><code>cp (复制档案或目录)

[root@localhost]# cp /.bashrc /tmp/bashrc  &lt;==将.bashrc复制到/tmp下，并更名为bashrc

[root@localhost tmp]# cp /var/log/wtmp .  &lt;==将wtmp复制到当前目录，最后的『.』不要忘了！

在不加任何选项的情况下，档案的某些属性/权限会改变

这是个很重要的特性！而且连档案建立的时间也不一样了！

如果想要将档案的所有特性都一起复制过来，加上 -a 便可以了

[root@localhost tmp]# cp -r /etc/ /tmp     &lt;==如果为目录，则不能直接复制，需加上-r，与此同时，档案与目录的权限也可能会被改变，这个时候可以用『 cp -a /etc /tmp 』来下达指令！尤其是在备份的情况下！
</code></pre>
<p>cp 有种种的文件属性与权限的特性，所以，在复制时，须了解到：</p>
<pre><code>a、是否需要完整的保留来源档案的信息？

b、来源档案是否为连结档 (symbolic link file)？

c、来源档是否为特殊的档案，例如 FIFO, socket 等？

d、来源文件是否为目录？

rm (移除档案或目录)

[root@localhost tmp]# rm -i bashrc  &lt;==加上 -i 选项便会主动询问，避免删除到错误的档名！

[root@localhost tmp]# rm -i bashrc* &lt;==通过通配符『*』的帮忙，将/tmp底下开头为bashrc的档名通通删除。通配符『*』代表的是 0 到无穷多个任意字符。</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[IDEA属性及插件配置]]></title>
        <id>https://philosopherzb.github.io/post/idea-shu-xing-ji-cha-jian-pei-zhi/</id>
        <link href="https://philosopherzb.github.io/post/idea-shu-xing-ji-cha-jian-pei-zhi/">
        </link>
        <updated>2021-04-10T11:34:42.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述IDEA常用的一些配置以及相关插件，搭配使用或可提升编码效率。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/valley-90388_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="idea统一设置">IDEA统一设置</h2>
<p>为保证大家有统一的代码规范和IDE行为，现对IDEA的设置进行统一说明。需要指出的是，下列的IDEA设置，均在默认设置的基础上进行个性化变更的。</p>
<p>使用IDEA的自动格式化，对所有源文件以及配置文件进行格式化后提交。（IDEA默认的快捷键为：Ctrl + Alt + L，mac系统为:command + option + L）。</p>
<p>使用IDEA的优化导入类和包进行import语句的合理排列。（IDEA的默认快捷键为：Ctrl + Alt + O，mac系统为:command + option + O）。</p>
<h3 id="配置类">配置类</h3>
<p>配置类的设置入口为File-&gt;Settings,下面所说的所有配置，都是在这个菜单下进行的。</p>
<h4 id="导包优化配置">导包优化配置</h4>
<p>进行优化导入包时，可能会出现几个通包路径下的类出现折叠成*的情况，这是违反通用编码规约的（存在导错包的情形）。因此，在进行导包优化之前，请设置IDEA的自动折叠功能为999，如下图所示：</p>
<p>依次进入Editor-&gt;Code Style-&gt;Java 将Class count to use import ‘*’这一项后面的数值改为999</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301031.png" alt="img" loading="lazy"></figure>
<h4 id="文件编码配置">文件编码配置</h4>
<p>依次进入Editor-&gt;File Encodings，将所有字符集设置，调整为UTF-8，并且将UTF-8的pom设置为no pom，如下图：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301032.png" alt="img" loading="lazy"></figure>
<h4 id="换行符统一配置">换行符统一配置</h4>
<p>统一使用Unix风格的换行符，找到Editor-&gt;Code Style-&gt;Line separator，设置成Unix and OS X(\n)</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301033.png" alt="img" loading="lazy"></figure>
<h4 id="个性化配置">个性化配置</h4>
<p>一些个性化的简单配置。</p>
<h5 id="字体配置如下editor-font">字体配置如下Editor-&gt;Font：</h5>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301034.png" alt="" loading="lazy"></figure>
<h5 id="git配置如下version-control-git需要事先安装git找到对应的bin目录即可">git配置如下Version Control-&gt;Git(需要事先安装git，找到对应的bin目录即可)：</h5>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301035.png" alt="" loading="lazy"></figure>
<h5 id="序列化时未引入序列化id报警配置如下editor-inspections">序列化时未引入序列化id报警配置如下Editor-&gt;Inspections：</h5>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301036.png" alt="" loading="lazy"></figure>
<p>类头自动加载注释配置如下Editor-&gt;File and Code Templates：</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301037.png" alt="img" loading="lazy"></figure>
<h3 id="插件类">插件类</h3>
<p>为简化开发步骤，并且让大家在沟通一些插件功能时，可以用统一的语言，现对开发时使用的基本插件进行下列约定，请开发前，在IDEA中安装下列插件。</p>
<h4 id="lombok插件">Lombok插件</h4>
<p>开发过程中，编写JavaBean，需要些大量的get set方法，虽然IDEA有快捷键可以生成这些方法，但是对于整体代码的整洁度，多多少少还是有一些影响。</p>
<p>所以，在开发过程中，我们会大量用到Lombok，在编译期自动生成get set方法，equals方法以及hashcode方法。</p>
<p>该插件，可以自动识别@Data等注解，让代码IDEA能够对自动生成的方法进行导航。并且在编写代码时，能够自动对get,set方法进行提示补全。</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301038.png" alt="img" loading="lazy"></figure>
<h4 id="maven-helper插件">Maven Helper插件</h4>
<p>编写pom过程中，总会遇到各种各样的依赖问题，Maven Helper插件，提供了一种mvn dependency:tree之外的解决方案。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301039.png" alt="" loading="lazy"></figure>
<p>安装插件后，在打开pom文件，可以看到多了Dependency Analyzer标签。</p>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301040.png" alt="" loading="lazy"></figure>
<p>可以方便地找到冲突的依赖,并且支持以图形化的形式查看依赖树。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301041.png" alt="img" loading="lazy"></figure>
<h4 id="free-mybatis-plugin插件">Free Mybatis plugin插件</h4>
<p>用于Mybatis接口与xml文件的快速跳转。安装插件后，可以在接口中直接跳转到对应mybatis xml配置文件的对应方法上。</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301042.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301043.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301044.png" alt="" loading="lazy"></figure>
<h4 id="alibaba-java-coding-guidelines插件">Alibaba Java Coding Guidelines插件</h4>
<p>使用“Alibaba Java Coding Guidelines”，插件，对工程下所有代码进行扫描。一期暂定消除所有Blocker与Critial的错误，同时Major的错误不得超过50个。</p>
<p>在有些情况下，必然会产生警告（比如无法避免的泛型转原始类型），在确认不会产生意外错误时，使用@SuppressWarning 来抑制警告。若如此做，代码评审时，会对此注解进行重点关注。所以务必确保该注解不被滥用。</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301045.png" alt="" loading="lazy"></figure>
<p>直接右击项目，选择编码规约扫描</p>
<figure data-type="image" tabindex="17"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301046.png" alt="img" loading="lazy"></figure>
<h4 id="findbugs插件">FindBugs插件</h4>
<p>对工程下所有代码进行扫描，检查存在的bug。<a href="https://plugins.jetbrains.com/plugin/3847-findbugs-idea/versions">点击此处跳转下载页面</a></p>
<figure data-type="image" tabindex="18"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301047.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301048.png" alt="" loading="lazy"></figure>
<p>find-sec-bugs为FindBugs-IDEA的扩展库，可以增加额外的扫描结果。<a href="https://find-sec-bugs.github.io/download.htm">点击此处跳转下载页面</a></p>
<figure data-type="image" tabindex="20"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301049.png" alt="img" loading="lazy"></figure>
<h4 id="visualvm-launcher插件">VisualVM Launcher插件</h4>
<p>运行java程序的时候启动visualvm，方便查看jvm的情况 比如堆内存大小的分配</p>
<p>某个对象占用了多大的内存，jvm调优必备工具。</p>
<figure data-type="image" tabindex="21"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301050.png" alt="" loading="lazy"></figure>
<p>配置如下：</p>
<figure data-type="image" tabindex="22"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301051.png" alt="" loading="lazy"></figure>
<p>使用如下：</p>
<figure data-type="image" tabindex="23"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301052.png" alt="img" loading="lazy"></figure>
<h4 id="jclasslib插件">jclasslib插件</h4>
<p>查看java字节码插件，相比于命令行的javap -v className更加方便。直接在idea的插件中搜索并下载即可。</p>
<figure data-type="image" tabindex="24"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301053.png" alt="" loading="lazy"></figure>
<p>使用时，先选择需要查看字节码的java类，之后选择View -&gt; Show Bytecode With jclasslib即可打开字节码视图。</p>
<figure data-type="image" tabindex="25"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301054.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="26"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301055.png" alt="img" loading="lazy"></figure>
<h4 id="bashsupport插件">bashsupport插件</h4>
<p>支持bash编码，智能提示。</p>
<figure data-type="image" tabindex="27"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301056.png" alt="" loading="lazy"></figure>
<p>配置启动项，选择git安装目录中的bash.exe即可。</p>
<figure data-type="image" tabindex="28"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301057.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301058.png" alt="" loading="lazy"></figure>
<p>编写完成后，直接右击run便可看到执行结果。</p>
<figure data-type="image" tabindex="30"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301059.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java中的常用排序算法]]></title>
        <id>https://philosopherzb.github.io/post/java-zhong-de-chang-yong-pai-xu-suan-fa/</id>
        <link href="https://philosopherzb.github.io/post/java-zhong-de-chang-yong-pai-xu-suan-fa/">
        </link>
        <updated>2021-03-13T02:46:59.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述java中常用的一些排序算法极其实现代码，如二分查找，快速排序，堆排，归并排序，冒泡排序等。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-192979_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="java中的常用算法">Java中的常用算法</h2>
<h3 id="术语说明及排序图表">术语说明及排序图表</h3>
<p>稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面（如果我们只对一串数字排序，那么稳定与否确实不重要，因为一串数字的属性是单一的，就是数字值的大小。但是排序的元素往往不只有一个属性，例如我们对一群人按年龄排序，但是人除了年龄属性还有身高体重属性，在年龄相同时如果不想破坏原先身高体重的次序，就必须用稳定排序算法.）；</p>
<p>不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；</p>
<p>内排序：所有排序操作都在内存中完成；</p>
<p>外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；</p>
<p>时间复杂度： 一个算法执行所耗费的时间。</p>
<p>空间复杂度：运行完一个程序所需内存的大小。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302005.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302006.png" alt="img" loading="lazy"></figure>
<h3 id="二分查找">二分查找</h3>
<p>又称折半查找，要求待查找的列表有序，每次取中间位置的值与待查关键字比较，如果中间位置的值比关键字大，则在列表前半部分循环此查找过程，否则在列表后半部分循环此查找过程。</p>
<pre><code>public static void main(String[] args) {
    // 正常二分查找
    int[] array = {1, 2, 3, 4, 5, 6};
    int a = 3;
    System.out.println(binarySerach(array, a));

    // 寻找左侧边界的二分查找
    int[] array_left = {1, 2, 2, 4, 4, 6};
    int a_left = 2;
    System.out.println(binarySerachForLeftBound(array_left, a_left));

    // 寻找右侧边界的二分查找
    int[] array_right = {1, 2, 2, 5, 5, 6};
    int a_right = 5;
    System.out.println(binarySerachForRightBound(array_right, a_right));
}

/**
 * 二分查找,如果存在，则输出待查找数据在数组中的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerach(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &lt;= high) {
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，返回其在数组中所在的下标
        if (numbers[middle] == target) {
            return middle;
        } else if (numbers[middle] &gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &lt; target) {
            low = middle + 1;
        }
    }
    return -1;
}

/**
 * 寻找左侧边界的二分查找,如果存在，则输出待查找数据在数组中最左侧的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerachForLeftBound(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &lt;= high) {
        // 匹配返回下标
        if (numbers[low] == target) {
            return low;
        }
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，将其下标赋给high，往左侧缩小边界
        if (numbers[middle] == target) {
            high = middle;
        } else if (numbers[middle] &gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &lt; target) {
            low = middle + 1;
        }
    }
    return -1;
}

/**
 * 寻找左侧边界的二分查找,如果存在，则输出待查找数据在数组中最右侧的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerachForRightBound(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &lt;= high) {
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，将其下标+1赋给low，往右侧边界缩小
        if (numbers[middle] == target) {
            low = middle + 1;
        } else if (numbers[middle] &gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &lt; target) {
            low = middle + 1;
        }
    }
    // 匹配返回下标
    return numbers[high] == target ? high : -1;
}

</code></pre>
<h3 id="冒泡排序">冒泡排序</h3>
<p>比较前后相邻的两个的数据，如果前面数据大于后面数据，则将两个数据所在位置交换。步骤如下（以从小到大为例）：</p>
<ul>
<li>比较相邻的元素。如果第一个比第二个大，就交换它们两个；</li>
<li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；</li>
<li>针对所有的元素重复以上的步骤，除了最后一个；</li>
<li>重复步骤1~3，直到排序完成。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] numbers = {4, 2, 5, 3, 7, 9, 1};
    bubbleSort3(numbers);
    for (int number : numbers) {
        System.out.println(number);
    }
}

// 从小到大
private static void bubbleSort(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = 0; i &lt; numbers.length; i++) {
        for (int j = 0; j &lt; numbers.length - 1 - i; j++) {
            if (numbers[j] &gt; numbers[j + 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j + 1];
                numbers[j + 1] = temp;
            }
        }
    }
}

// 优化，去掉多余排序
private static void bubbleSort2(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = 0; i &lt; numbers.length; i++) {
        // 排序标识
        boolean isSorted = true;
        for (int j = 0; j &lt; numbers.length - 1 - i; j++) {
            if (numbers[j] &gt; numbers[j + 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j + 1];
                numbers[j + 1] = temp;
                // 存在交换过程，继续排序
                isSorted = false;
            }
        }
        if (isSorted) {
            break;
        }
    }
}

//从大到小
private static void bubbleSort3(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = numbers.length - 1; i &gt; 0; i--) {
        for (int j = numbers.length - 1; j &gt; numbers.length - 1 - i; j--) {
            if (numbers[j] &gt; numbers[j - 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j - 1];
                numbers[j - 1] = temp;
            }
        }
    }
}

</code></pre>
<h3 id="选择排序">选择排序</h3>
<p>每一次从待排序的数据元素中选出最小（最大）的一个元素，存放在序列的起始（末尾）位置，直到全部待排序数据排完。</p>
<p>选择排序是不稳定的排序方法，比如序列[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面。步骤如下：</p>
<ul>
<li>初始状态：无序区为R[1..n]，有序区为空；</li>
<li>第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；</li>
<li>n-1趟结束，数组有序化了</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {2, 3, 1, 5, 4};
    selectSort(array);
    System.out.println(Arrays.toString(array));
}

private static void selectSort(int[] array) {
    if (array.length == 0) {
        return;
    }
    int minIndex;
    for (int i = 0; i &lt; array.length; i++) {
        minIndex = i;
        for (int j = i + 1; j &lt; array.length; j++) {
            if (array[minIndex] &gt; array[j]) {
                minIndex = j;
            }
        }
        if (minIndex != i) {
            int temp = array[minIndex];
            array[minIndex] = array[i];
            array[i] = temp;
        }
    }
}

</code></pre>
<h3 id="插入排序">插入排序</h3>
<p>通过构建有序序列，对于未排序的数据，在已排序的数据中从后向前扫描，找到相应的位置并插入。步骤如下：</p>
<ul>
<li>从第一个元素开始，该元素可以认为已经被排序；</li>
<li>取出下一个元素，在已经排序的元素序列中从后向前扫描；</li>
<li>如果该元素（已排序）大于新元素，将该元素移到下一位置；</li>
<li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；</li>
<li>将新元素插入到该位置后；</li>
<li>重复步骤2~5。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {3, 1, 2, 5, 4};
    binaryInsertSort(array);
    System.out.println(Arrays.toString(array));
}

// 直接插入
private static void insertSort(int[] array) {
    for (int i = 1; i &lt; array.length; i++) {
        // 待插入数据
        int insertVal = array[i];
        // 待插入数据的前一个数据
        int insertIndex = i - 1;
        // insertIndex &gt;= 0防止数组越界
        while (insertIndex &gt;= 0 &amp;&amp; insertVal &lt; array[insertIndex]) {
            // 如果插入数据比已排序数据要小，则将已排序数据向后移动一位
            array[insertIndex + 1] = array[insertIndex];
            // 同时，让insertIndex向前移动一位
            insertIndex--;
        }
        // 插入指定位置
        array[insertIndex + 1] = insertVal;
    }
}

// 折半插入
private static void binaryInsertSort(int[] array) {
    int temp;
    int low, high, middle;
    for (int i = 1; i &lt; array.length; i++) {
        // 待插入数据
        temp = array[i];
        // 二分查找合适的插入位置
        // 左边默认为已排序
        low = 0;
        // 右边终点取已排序数组的索引
        high = i - 1;
        while (low &lt;= high) {
            // 无符号右移一位，等同于/2
            middle = (low + high) &gt;&gt;&gt; 1;
            if (array[middle] &gt; temp) {
                high = middle - 1;
            } else {
                // 等于的情形包含在此，因为相等的话，插入数据在其左边，右边都是一致的
                low = middle + 1;
            }
        }
        // 已排序的所有数据向后移动
//        for (int j = i - 1; j &gt;= high + 1; j--) {
//            array[j + 1] = array[j];
//        }
        if (i - (high + 1) &gt;= 0) {
            System.arraycopy(array, high + 1, array, high + 1 + 1, i - (high + 1));
        }
        // 插入元素
        array[high + 1] = temp;
    }
}

</code></pre>
<h3 id="希尔排序">希尔排序</h3>
<p>又称缩小增量排序，它按一定的增量（gap=lengh/2 -&gt; gap=gap/2,也称希尔增量）进行分组，对每一组数据进行直接插入排序，直至增量减为1，所有分组再次合并为一个，接着对这个最终分组进行直接插入排序，即可得到排序结果。步骤如下：</p>
<ul>
<li>选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；</li>
<li>按增量序列个数k，对序列进行k 趟排序；</li>
<li>每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {2, 3, 1, 5, 4};
    shellSort(array);
    System.out.println(Arrays.toString(array));
}

// 希尔排序
private static void shellSort(int[] array) {
    if (array.length == 0) {
        return;
    }
    // 无符号右移1位，等同/2
    int gap = array.length &gt;&gt;&gt; 1;
    while (gap &gt; 0) {
        for (int i = gap; i &lt; array.length; i++) {
            // 待插入数据
            int insertVal = array[i];
            // 待插入数据的前一个数据
            int insertIndex = i - gap;
            // insertIndex &gt;= 0防止数组越界
            while (insertIndex &gt;= 0 &amp;&amp; insertVal &lt; array[insertIndex]) {
                // 如果插入数据比已排序数据要小，则将已排序数据向后移动一位
                array[insertIndex + gap] = array[insertIndex];
                // 同时，让insertIndex向前移动一位
                insertIndex -= gap;
            }
            // 插入指定位置
            array[insertIndex + gap] = insertVal;
        }
        // 无符号右移1位，等同/2
        gap &gt;&gt;&gt;= 1;
    }
}

</code></pre>
<h3 id="归并排序">归并排序</h3>
<p>归并排序（MERGE-SORT）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。步骤如下：</p>
<ul>
<li>把长度为n的输入序列分成两个长度为n/2的子序列；</li>
<li>对这两个子序列分别采用归并排序；</li>
<li>将两个排序好的子序列合并成一个最终的排序序列。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {2, 1, 3, 9, 5, 8, 4, 6};
    System.out.println(Arrays.toString(mergeSort(array)));
}

private static int[] mergeSort(int[] array) {
    // 只有一位或者没有数据时，直接返回原数组
    if (array.length &lt; 2) {
        return array;
    }
    // 无符号右移（此处必为正数，效果与右移一致），等同于/2
    int middle = array.length &gt;&gt;&gt; 1;
    int[] left = Arrays.copyOfRange(array, 0, middle);
    int[] right = Arrays.copyOfRange(array, middle, array.length);
    return merge(mergeSort(left), mergeSort(right));
}

private static int[] merge(int[] left, int[] right) {
    // 合并之后的数组
    int[] result = new int[left.length + right.length];
    for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) {
        // 左侧数组已经全部放入结果数组中,将右侧数组数据直接递增放入
        if (i &gt;= left.length) {
            result[index] = right[j++];
        } else if (j &gt;= right.length) {
            // 右侧数组已经全部放入结果数组中,将左侧数组数据直接递增放入
            result[index] = left[i++];
        } else if (left[i] &gt; right[j]) {
            // 左侧数组中的数据比右侧数组中的数据值大,将右侧数组数据直接放入，随后递增
            result[index] = right[j++];
        } else {
            // 左侧数组中的数据比右侧数组中的数据值小,将左侧数组数据直接放入，随后递增
            result[index] = left[i++];
        }
    }
    return result;
}

</code></pre>
<h3 id="快速排序">快速排序</h3>
<p>快速排序由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p>
<p>注意：在此过程中需要先选取一个关键值作为基准值，这样比基准值小的都在左边，大的都在右边。步骤如下：</p>
<ul>
<li>从数列中挑出一个元素，称为 “基准”（pivot）；</li>
<li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；</li>
<li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302007.png" alt="" loading="lazy"></figure>
<pre><code>public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    quickSort(array, 0, array.length - 1);
    System.out.println(Arrays.toString(array));
}

// 填坑法
private static void quickSort(int[] array, int start, int end) {
    if (array.length &lt; 1 || start &lt; 0 || end &gt;= array.length || start &gt; end) {
        return;
    }
    int i = start;
    int j = end;
    // 基准值
    int pivot = array[i];
    // 左右两边同时扫描，直到两者交错
    while (i &lt;= j) {
        // 从右边寻找比基准值小的数
        while (array[j] &gt; pivot) {
            j--;
        }
        // 从左边寻找比基准值大的数
        while (array[i] &lt; pivot) {
            i++;
        }
        // 此处已找到比基准值大的数（左边），比基准值小的数（右边），两者进行交换
        if (i &lt;= j) {
            swap(array, i, j);
            i++;
            j--;
        }
    }
    // 左边再做排序，直到只剩下一个数，则退出递归
    if (start &lt; j) {
        quickSort(array, start, j);
    }
    // 右边再做排序，直到只剩下一个数，则退出递归
    if (end &gt; i) {
        quickSort(array, i, end);
    }
}

private static void swap(int[] array, int i, int j) {
    if (i != j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
}

</code></pre>
<h3 id="堆排序">堆排序</h3>
<p>堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。步骤如下：</p>
<ul>
<li>将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；</li>
<li>将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]；</li>
<li>由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    heapSort(array);
    System.out.println(Arrays.toString(array));
}

private static void heapSort(int[] array) {
    int length = array.length;
    if (length &lt; 1) {
        return;
    }
    buildMaxHeap(array, length);
    while (length &gt; 0) {
        swap(array, 0, length - 1);
        length--;
        adjustHeap(array, 0, length);
    }
}

private static void buildMaxHeap(int[] array, int length) {
    // 从最后一个非叶子节点开始向上构建最大堆
    for (int i = (length / 2 - 1); i &gt;= 0; i--) {
        adjustHeap(array, i, length);
    }
}

private static void adjustHeap(int[] array, int i, int length) {
    int maxIndex = i;
    // 如果有左子树，且左子树大于父节点，则将最大指针指向左子树
    if (i * 2 &lt; length &amp;&amp; array[i * 2] &gt; array[maxIndex]) {
        maxIndex = i * 2;
    }
    // 如果有右子树，且右子树大于父节点，则将最大指针指向右子树
    if (i * 2 + 1 &lt; length &amp;&amp; array[i * 2 + 1] &gt; array[maxIndex]) {
        maxIndex = i * 2 + 1;
    }
    // 如果父节点不是最大值，则将父节点与最大值交换，并递归调整与父节点交换的位置
    if (maxIndex != i) {
        swap(array, maxIndex, i);
        adjustHeap(array, maxIndex, length);
    }
}

private static void swap(int[] array, int i, int j) {
    if (i != j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
}

</code></pre>
<h3 id="计数排序">计数排序</h3>
<p>计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。</p>
<p>计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序。步骤如下：</p>
<ul>
<li>找出待排序的数组中最大和最小的元素；</li>
<li>统计数组中每个值为i的元素出现的次数，存入数组C的第i项；</li>
<li>对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；</li>
<li>反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    CountingSort(array);
    System.out.println(Arrays.toString(array));
}

private static void CountingSort(int[] array) {
    if (array.length &lt; 1) {
        return;
    }
    int bias, min = array[0], max = array[0];
    for (int i = 1; i &lt; array.length; i++) {
        if (array[i] &gt; max)
            max = array[i];
        if (array[i] &lt; min)
            min = array[i];
    }
    bias = 0 - min;
    int[] bucket = new int[max - min + 1];
    Arrays.fill(bucket, 0);
    for (int anArray : array) {
        bucket[anArray + bias]++;
    }
    int index = 0, i = 0;
    while (index &lt; array.length) {
        if (bucket[i] != 0) {
            array[index] = i - bias;
            bucket[i]--;
            index++;
        } else
            i++;
    }
}

</code></pre>
<h3 id="桶排序">桶排序</h3>
<p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。</p>
<p>桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序。</p>
<p>注意：如果递归使用桶排序为各个桶排序，则当桶数量为1时要手动减小BucketSize增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。步骤如下：</p>
<ul>
<li>人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize==5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）；</li>
<li>遍历输入数据，并且把数据一个一个放到对应的桶里去；</li>
<li>对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序；</li>
<li>从不是空的桶里把排好序的数据拼接起来。</li>
</ul>
<pre><code>public static void main(String[] args) {
    Integer[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(array.length);
    Collections.addAll(list, array);
    System.out.println(bucketSort(list, array.length));
}

private static ArrayList&lt;Integer&gt; bucketSort(ArrayList&lt;Integer&gt; array, int bucketSize) {
    if (array == null || array.size() &lt; 2)
        return array;
    int max = array.get(0), min = array.get(0);
    // 找到最大值最小值
    for (Integer i : array) {
        if (i &gt; max)
            max = i;
        if (i &lt; min)
            min = i;
    }
    int bucketCount = (max - min) / bucketSize + 1;
    ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketCount);
    ArrayList&lt;Integer&gt; resultArr = new ArrayList&lt;&gt;();
    for (int i = 0; i &lt; bucketCount; i++) {
        bucketArr.add(new ArrayList&lt;&gt;());
    }
    for (Integer i : array) {
        bucketArr.get((i - min) / bucketSize).add(i);
    }
    for (int i = 0; i &lt; bucketCount; i++) {
        if (bucketSize == 1) { // 如果带排序数组中有重复数字时
            resultArr.addAll(bucketArr.get(i));
        } else {
            if (bucketCount == 1) {
                bucketSize--;
            }
            ArrayList&lt;Integer&gt; temp = BucketSort(bucketArr.get(i), bucketSize);
            resultArr.addAll(temp);
        }
    }
    return resultArr;
}

</code></pre>
<h3 id="基数排序">基数排序</h3>
<p>基数排序(radix sort)属于&quot;分配式排序&quot;(distribution sort)，又称&quot;桶子法&quot;(bucket sort)或bin sort，顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些&quot;桶&quot;中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为O (nlog(r)m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。</p>
<p>基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。步骤如下：</p>
<ul>
<li>取得数组中的最大数，并取得位数；</li>
<li>arr为原始数组，从最低位开始取每个位组成radix数组；</li>
<li>对radix进行计数排序（利用计数排序适用于小范围数的特点）；</li>
</ul>
<pre><code>public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    radixSort(array);
    System.out.println(Arrays.toString(array));
}

private static void radixSort(int[] array) {
    if (array == null || array.length &lt; 2) {
        return;
    }
    // 1.先算出最大数的位数；
    int max = array[0];
    for (int i = 1; i &lt; array.length; i++) {
        max = Math.max(max, array[i]);
    }
    int maxDigit = 0;
    while (max != 0) {
        max /= 10;
        maxDigit++;
    }
    int mod = 10, div = 1;
    ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketList = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;();
    for (int i = 0; i &lt; 10; i++) {
        bucketList.add(new ArrayList&lt;&gt;());
    }
    for (int i = 0; i &lt; maxDigit; i++, mod *= 10, div *= 10) {
        for (int j : array) {
            int num = (j % mod) / div;
            bucketList.get(num).add(j);
        }
        int index = 0;
        for (ArrayList&lt;Integer&gt; buckets : bucketList) {
            for (Integer bucket : buckets) {
                array[index++] = bucket;
            }
            buckets.clear();
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java中引用&IO&类加载&对象创建过程]]></title>
        <id>https://philosopherzb.github.io/post/java-zhong-yin-yong-andioandlei-jia-zai-anddui-xiang-chuang-jian-guo-cheng/</id>
        <link href="https://philosopherzb.github.io/post/java-zhong-yin-yong-andioandlei-jia-zai-anddui-xiang-chuang-jian-guo-cheng/">
        </link>
        <updated>2021-03-06T08:10:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Java中的四种引用类型，JavaIO类型（BIO，NIO，AIO），Java类加载机制以及Hotspot JVM虚拟机对象的探究。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/boat-1014711_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="四种引用">四种引用</h2>
<h3 id="强引用">强引用</h3>
<p>把一个对象复制给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，这时，GC不会对其进行回收（造成OOM的主要原因之一）。</p>
<pre><code>// 强引用
String str = &quot;test&quot;;
// 取消强引用
str = null;

</code></pre>
<h3 id="软引用">软引用</h3>
<p>软引用需要使用SoftReference类来实现，对于软引用对象来说，当系统内存足够时不会对其进行回收，反之则进行回收。通常应用在对内存敏感的程序中。</p>
<pre><code>// 软引用
SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(&quot;test&quot;);

</code></pre>
<h3 id="弱引用">弱引用</h3>
<p>弱引用需要使用WeakReference类来实现，它比软引用生存周期更短，对于弱引用对象来说，只要垃圾回收机制一运行，不管JVM内存空间是否充足，都会对其进行回收。</p>
<pre><code>// 弱引用
WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(&quot;test&quot;);

</code></pre>
<h3 id="虚引用">虚引用</h3>
<p>虚引用需要使用PhantomReference类来实现，它不能单独使用，必须与引用队列联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。</p>
<pre><code>// 虚引用
ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;&gt;();
PhantomReference&lt;String&gt; pr = new PhantomReference&lt;&gt;(&quot;test&quot;, queue);

</code></pre>
<h2 id="java中的io">Java中的I/O</h2>
<h3 id="bioblock-io">BIO（Block IO）</h3>
<ul>
<li>同步阻塞式IO，一般指平常所用的IO类。</li>
<li>一个请求对应一个响应，为了合理的利用资源，可以使用多线程（线程池）。</li>
<li>此IO一般针对并发量较小的场景（&lt;1000）。</li>
<li>BIO操作的对象是流（Stream）。</li>
<li>比如：在ATM机上取钱，只能一个一个的取，前面有人的时候，需要等待；取钱的时候，需要本人进行相关取钱操作（取出之后拿到钱才走）。</li>
</ul>
<h3 id="nionew-io">NIO（New IO）</h3>
<ul>
<li>同步非阻塞式IO。</li>
<li>利用Channel（通道）通讯，实现了多路复用。</li>
<li>核心组件：Buffer（缓冲区），Channel（通道），Selector（选择器）</li>
<li>NIO操作的对象是缓存区（Buffer）。</li>
<li>基本运行流程：当Channel发生新连接、就绪读，就绪写的时候，首先会在Selector上注册相应的事件，生成一个与Channel绑定的selectKey；其次由一个线程轮询selectKey集合，利用操作系统底层的函数select() 或者 epoll（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是iocp）去操作系统查询IO是否就绪，如果就绪则执行相应的事件处理器（通过selectKey找到Channel，然后利用与Channel绑定的buffer进行实际读写）。</li>
<li>比如：在银行大厅取钱，对于前面是否有人等候，只需要隔一段时间去问一下大堂经理是否可以取钱就可以了，不需要一直去排队（这段时间可以做其他事）；取钱的时候，需要柜员进行相关操作，同时也需要保证你也在柜员面前（不能离开，不然柜员可能会找不到你，然后钱就没有实际拿到手里了）。</li>
</ul>
<h3 id="aioasynchronous-io">AIO（Asynchronous IO）</h3>
<ul>
<li>异步非阻塞式IO。</li>
<li>其实现是基于事件以及回调机制。</li>
<li>AIO与NIO有点相似，不过对于实际读写而言，AIO是交给操作系统底层自己去完成的，完成之后会返回一个IO完成的回调消息。</li>
<li>比如：同样是去银行取钱，不过这次你是让朋友去帮忙取的，你朋友会帮你排队，然后取钱，接着把钱给你，并告诉你已经取好了。</li>
</ul>
<h3 id="io阶段">IO阶段</h3>
<ul>
<li>IO中对于读写一般分为两个阶段：就绪读写（准备数据）以及实际读写（真正读写数据）。</li>
<li>对应上面取钱例子而言，就绪读写指的是排队，实际读写指的是取钱操作。</li>
</ul>
<h3 id="同步异步">同步，异步</h3>
<ul>
<li>同步指的是操作的时候，需要等待当前任务返回结果；异步则相反，它不需要等待当前任务返回，通常情况下是依赖于事件，回调机制来实现任务间的次序关系。</li>
<li>同步，异步对于IO而言指的是实际读写阶段；对应取钱例子而言，就是真正取钱操作（同步，自己取钱；异步，朋友帮忙取钱）。</li>
</ul>
<h3 id="阻塞非阻塞">阻塞，非阻塞</h3>
<ul>
<li>阻塞指的是如果任务在执行，当前线程会阻塞，需要等待任务执行完，这期间该线程不能执行其他任务；非阻塞则是说在一个任务执行期间，线程不会阻塞，可以执行其他任务。</li>
<li>阻塞，非阻塞对于IO而言指的是就绪读写阶段；对应取钱例子而言，就是排队等候（阻塞，排队没带手机，只能干等着；非阻塞，排队带了手机，可以一边玩手机一边排队）。</li>
</ul>
<h2 id="jvm类加载">JVM类加载</h2>
<h3 id="类加载机制">类加载机制</h3>
<p>JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301027.png" alt="img" loading="lazy"></figure>
<p>1、加载：在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口（注意：不一定非得从Class文件中获取，也可以从ZIP（如jar，war）中读取，或者在运行时计算生成（动态代理），或者由其他文件转换而来（如JSP转换为Class））。</p>
<p>2、验证：确保Class文件字节流中所包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<p>3、准备：正式为类变量分配内存并为其设置初始值，即在方法区中分配这些变量所使用的内存空间。需要注意这里所说的初始值概念，比如说一个类变量定义为：</p>
<pre><code>public static int port = 8080;
</code></pre>
<p>那么此变量在准备阶段所谓的设置初始值，是设置其为0，而不是8080。将port赋值为8080的put static 指令是程序被编译后，存放于类构造器<code>&lt;Client&gt;</code>方法中的。</p>
<p>但如果变量声明如下：</p>
<pre><code>public static final int port = 8080;
</code></pre>
<p>那么在编译期间，会为port生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将port赋值为8080.</p>
<p>4、解析：此阶段指虚拟机将常量池中的符号引用替换为直接引用的过程。</p>
<p>符号引用：与虚拟机实现的布局无关，引用的目标不一定要已经加载至内存中。各种虚拟机的内存布局可以不一致，但它们能接受的符号引用必须一致，因为符号引用的字面量形式明确的定义在java虚拟机规范的Class文件格式中。、</p>
<p>直接引用：是可以直接指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄，如果存在直接引用，那么引用的目标必定已经在内存中存在。</p>
<p>5、初始化：此阶段开始真正执行类中定义的java程序代码，即开始开始执行类构造器<code>&lt;client&gt;</code>方法。</p>
<p><code>&lt;client&gt;</code>方法是由编译器自动收集类中的类静态变量赋值以及静态语句块中的语句合并而成的。虚拟机会保证子<code>&lt;client&gt;</code>执行之前，父<code>&lt;client&gt;</code>已经执行完毕（如果一个类中既没有类静态变量赋值，也没有静态语句块，那虚拟机可以不为其生成<code>&lt;client&gt;</code>方法）。</p>
<p>注意以下几种情形不会执行类初始化：</p>
<ul>
<li>通过子类引用父类的静态字段，只会触发父类的初始化。</li>
<li>定义对象数组，不会触发该类的初始化。</li>
<li>常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在类的初始化。</li>
<li>通过类名获取Class对象，不会触发初始化。</li>
<li>通过Class.forName加载指定类时，如果指定参数initialize为false（initialize是告诉虚拟机是否要对该类进行初始化），也不会触发类的初始化。</li>
<li>通过ClassLoader默认的loadClass方法，不会触发类初始化。</li>
</ul>
<h3 id="类加载器">类加载器</h3>
<p>类的加载并没有发生在JVM中，而是由应用程序来确定如何获取所需要的类。为此JVM提供了三种类加载器，如下：</p>
<p>1、启动类加载器（Bootstrap ClassLoader）：负责加载JAVA_HOME\lib目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可的类（按文件名识别，如：rt.jar）。</p>
<p>2、扩展类加载器（Extension ClassLoader）：负责加载JAVA_HOME\lib\ext目录中的，或通过java.ext.dirs系统变量指定路径中的类库。</p>
<p>3、应用程序类加载器（Application ClassLoader）：负责加载用户路径（classpath）上的类库。</p>
<h3 id="双亲委派模型">双亲委派模型</h3>
<p>JVM通过双亲委派模型进行类的加载，当然，开发者也可以通过集成java.lang.ClassLoader实现自定义的类加载器。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301028.png" alt="" loading="lazy"></figure>
<p>双亲委派过程：当一个类收到类加载请求时，它首先不会尝试自己去加载这个类，而是将这个请求委派给父类去完成，每一层次的类加载器都是如此操作，因此所有的类加载请求都应该会传送到启动类加载器中，只有当父加载器无法加载此类时（在它的加载路径下没有找到所需加载的Class），子加载器才会尝试自己去加载。</p>
<p>双亲委派解决了java基础类统一加载的问题，但某些情况下父类加载器需要委托子类加载器去加载Class文件，例如SPI（Service Provider Interface）代码（spi是一种服务发现机制：即为某个接口寻找服务实现的机制。）。</p>
<h3 id="以jdbc为例谈双亲委派模型的破坏">以JDBC为例谈双亲委派模型的破坏</h3>
<p>Java本身有一套资源管理服务JNDI（Java Naming and Directory Interface，根据名称可以在其中查找对应的方法或者其他参数），其放置于rt.jar中，由启动类加载器进行加载。</p>
<p>以数据库管理JDBC为例，java给数据库操作提供了一个Driver（java.sql.Driver）接口，并提供了一个DriverManager（java.sql.DriverManager）来管理Driver的具体实现。</p>
<h4 id="不破坏双亲委派模型不使用jdni">不破坏双亲委派模型（不使用JDNI）</h4>
<pre><code>// 加载数据库驱动
Class.forName(&quot;com.mysql.jdbc.Driver&quot;);
// 连接到数据库上去
Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;serverTimezone=Asia/Shanghai&quot;,&quot;root&quot;,&quot;root&quot;);

</code></pre>
<p>Class.forName()触发了mysql驱动类的加载，通过源码可以发现，mysql的驱动类已经在静态块中被注册到了DriverManager中，所以后续使用时可以直接建立连接。其核心实现如下：</p>
<pre><code>public class Driver extends NonRegisteringDriver implements java.sql.Driver {
    public Driver() throws SQLException {
    }

    static {
        try {
            DriverManager.registerDriver(new Driver());
        } catch (SQLException var1) {
            throw new RuntimeException(&quot;Can't register driver!&quot;);
        }
    }
}
</code></pre>
<pre><code>public static synchronized void registerDriver(java.sql.Driver driver,
        DriverAction da)
    throws SQLException {

    /* Register the driver if it has not already been added to our list */
    if(driver != null) {
        registeredDrivers.addIfAbsent(new DriverInfo(driver, da));
    } else {
        // This is for compatibility with the original DriverManager
        throw new NullPointerException();
    }

    println(&quot;registerDriver: &quot; + driver);

}

</code></pre>
<h4 id="破坏双亲委派模型使用jdni">破坏双亲委派模型（使用JDNI）</h4>
<p>JDBC4.0以后，开始支持spi注册Driver，具体做法便是在mysql的jar中的META-INF/services/java.sql.Driver文件中指明当前的Driver，然后通过下列方式即可使用。</p>
<pre><code>// 连接到数据库上去
Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true&amp;serverTimezone=Asia/Shanghai&quot;,&quot;root&quot;,&quot;root&quot;);

</code></pre>
<p>此处相比于不破坏双亲委派模型，少了一句Class.forName()，即加载驱动类的步骤。其对应的Driver是配置在META-INF/services/java.sql.Drive文件中的，由此可以知道其操作为：先从配置文件中读取Driver，随后再进行加载（使用Class.forName()）</p>
<p>需要注意的是，Class.forName()加载的是调用者的ClassLoader，这个调用者DriverManager是在rt.jar中，ClassLoader是启动类加载器，而com.mysql.cj.jdbc.Driver并没有位于&lt;JAVA_HOME&gt;/lib下，所以肯定是无法直接加载到mysql的这个类的。这边是双亲委派的局限性，父类加载器无法加载子类加载器路径中的类（父对子透明，子对父不透明）。</p>
<p>为了让父类加载器加载子类加载器路径中的类，可以通过线程上下文加载器去加载第三方jar包中的Driver，这便打破了双亲委派模型。</p>
<p>以DriverManager为例，当调用其getConnection()方法时，会先执行器静态块中的初始化代码，如下：</p>
<pre><code>/**
 * Load the initial JDBC drivers by checking the System property
 * jdbc.properties and then use the {@code ServiceLoader} mechanism
 */
static {
    loadInitialDrivers();
    println(&quot;JDBC DriverManager initialized&quot;);
}

</code></pre>
<pre><code>AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() {
    public Void run() {
        // 各个sql厂商在自己的jar包中通过spi注册的驱动
        ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);
        Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();

        /* Load these drivers, so that they can be instantiated.
         * It may be the case that the driver class may not be there
         * i.e. there may be a packaged driver with the service class
         * as implementation of java.sql.Driver but the actual class
         * may be missing. In that case a java.util.ServiceConfigurationError
         * will be thrown at runtime by the VM trying to locate
         * and load the service.
         *
         * Adding a try catch block to catch those runtime errors
         * if driver not available in classpath but it's
         * packaged as service and that service is there in classpath.
         */
        try{
            while(driversIterator.hasNext()) {
                driversIterator.next();
            }
        } catch(Throwable t) {
        // Do nothing
        }
        return null;
    }
});

</code></pre>
<p>其中ServiceLoader.load()便是拿到线程上下文加载器，并构造了一个ServiceLoader进行返回，如下：</p>
<pre><code>public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) {
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    return ServiceLoader.load(service, cl);
}

public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service,
                                        ClassLoader loader)
{
    return new ServiceLoader&lt;&gt;(service, loader);
}

</code></pre>
<p>DriverManager中的doPrivileged()中还有一句driversIterator.next()，其中实现了类加载过程，具体实现如下：</p>
<pre><code>private S nextService() {
    if (!hasNextService())
        throw new NoSuchElementException();
    String cn = nextName;
    nextName = null;
    Class&lt;?&gt; c = null;
    try {
        // 此处的cn便是便是厂商在META-INF/services/java.sql.Drive文件中配置的全限定驱动类名
        // loader则是上文中ServiceLoader.load()返回的线程上下文加载器。
        c = Class.forName(cn, false, loader);
    } catch (ClassNotFoundException x) {
        fail(service,
             &quot;Provider &quot; + cn + &quot; not found&quot;);
    }
    if (!service.isAssignableFrom(c)) {
        fail(service,
             &quot;Provider &quot; + cn  + &quot; not a subtype&quot;);
    }
    try {
        S p = service.cast(c.newInstance());
        providers.put(cn, p);
        return p;
    } catch (Throwable x) {
        fail(service,
             &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;,
             x);
    }
    throw new Error();          // This cannot happen
}

</code></pre>
<h2 id="hotspot-jvm虚拟机对象探究">Hotspot JVM虚拟机对象探究</h2>
<h3 id="对象的创建以普通java对象new指令为例">对象的创建（以普通Java对象new指令为例）</h3>
<ul>
<li>当虚拟机遇到一条new指令时，首先会去常量池中检查是否存在这个对象的引用，并且检查该引用所代表的类是否已经被加载，解析和初始化过，如果没有，则先执行类加载。</li>
<li>当类加载检查通过之后，虚拟机将会为新生对象分配内存（对象所需的内存大小在类加载完成之后就已经确认了，为对象分配空间就是在Java堆上划分出一块内存来。一般有两种分配方式，根据内存规整程度分为：指针碰撞（规整）以及空闲列表（不规整））。</li>
<li>针对并发情况下对象内存分配冲突解决方案有：一是同步处理，二是使用本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）（虚拟机是否使用本地线程分配缓冲可通过-XX:+/-UseTLAB参数来设定）。</li>
<li>内存分配完毕之后，虚拟机会将对应的内存空间初始化为零值（不包括对象头）。接着会对这个对象进行必要的设置，例如此对象是哪个类的实例，如何查找类的元数据信息，对象的哈希码，对象的GC分代年龄等等，这些信息都放在了对象头中。</li>
<li>执行完new指令之后还需要执行<code>&lt;init&gt;</code>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算是完全创建好了。</li>
</ul>
<h3 id="对象的内存布局">对象的内存布局</h3>
<ul>
<li>在HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header），实例数据（Instance Data）以及对齐填充（Padding）。</li>
<li>对象头（Header）主要包含两部分信息：第一部分用于存储对象自身的运行时数据（如哈希码（HashCode），GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据长度在32位或者64位的虚拟机中分别为32bit以及64bit，官方称之为“Mark Word”）；第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机可以通过这个指针来确定该对象属于哪个类的实例（并不是所有的虚拟机实现都需要在对象数据上保留类型指针，即查找对象的元数据信息并不一定要经过对象本身），如果对象是一个Java数组，那么对象头还需要记录该数组长度，因为普通的Java对象可以通过元数据信息确认对象大小，而数组却不行。</li>
<li>实例数据（Instance Data）存储着对象真正有效的信息，即各种类型的字段，无论是继承父类还是子类自定义。</li>
<li>对齐填充（Padding）不是必然存在的，也没有特殊的含义，仅仅起到占位符的作用，保证对象大小是某个字节的整数倍（HotSpot VM 的自动内存管理系统要求对象起始地址必须为8字节的整数倍）。</li>
</ul>
<h3 id="对象的访问定位">对象的访问定位</h3>
<ul>
<li>建立对象的目的是为了使用该对象，Java程序是通过栈上的reference指针来操作堆上的具体对象的。</li>
<li>目前主流的访问方式有句柄和直接指针两种。</li>
</ul>
<h4 id="句柄访问定位">句柄访问定位</h4>
<ul>
<li>使用句柄的话，Java堆将会划分出一块内存来作为句柄池，reference中存放的也就是对象的句柄地址（句柄中包含了对象实例数据和类型数据各自的地址）。</li>
<li>句柄的优势在于其稳定性更高，如果对象频繁的发生移动（GC操作时移动对象），那么只会改变句柄中的实例数据的指针，reference本身不需要改变。</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301029.png" alt="img" loading="lazy"></figure>
<h4 id="直接访问定位">直接访问定位</h4>
<ul>
<li>使用直接指针，那么reference将直接指向对象对应的地址（Java堆布局时需要考虑如何存放访问类型数据的相关信息）。</li>
<li>直接指针的优势在于其速度更快，因为减少了一次指针定位的操作。如果对象访问频繁，那么使用直接访问将会提高相当不错的效率。</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301030.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
</feed>