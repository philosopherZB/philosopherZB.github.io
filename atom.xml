<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://philosopherzb.github.io</id>
    <title>Philosopher</title>
    <updated>2023-03-08T09:22:05.176Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://philosopherzb.github.io"/>
    <link rel="self" href="https://philosopherzb.github.io/atom.xml"/>
    <subtitle>WORLD AS CODE</subtitle>
    <logo>https://philosopherzb.github.io/images/avatar.png</logo>
    <icon>https://philosopherzb.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Philosopher</rights>
    <entry>
        <title type="html"><![CDATA[Bash条件判断详解]]></title>
        <id>https://philosopherzb.github.io/post/bash-tiao-jian-pan-duan-xiang-jie/</id>
        <link href="https://philosopherzb.github.io/post/bash-tiao-jian-pan-duan-xiang-jie/">
        </link>
        <updated>2022-05-13T09:20:29.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述bash条件判断规则语法。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/rocks-1757593_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="条件判断">条件判断</h2>
<h3 id="if结构">if结构</h3>
<p>if是最常用的条件判断结构，只有符合给定条件时，才会执行指定的命令。它的语法如下。</p>
<p>注意：如果写在同一行，关键字之间需要使用分号隔离。分号是 Bash 的命令分隔符</p>
<pre><code>if commands; then
  commands
[elif commands; then
  commands...]
[else
  commands]
fi

# 例子 判断环境变量$USER是否等于root
if test $USER = &quot;root&quot;; then
  echo &quot;Hello root.&quot;
else
  echo &quot;You are not root.&quot;
fi

# 单行书写例子
if true; then echo 'hello world'; fi

</code></pre>
<p>if后面可以跟任意数量的命令。这时，所有命令都会执行，但是判断真伪只看最后一个命令，即使前面所有命令都失败，只要最后一个命令返回0，就会执行then的部分。</p>
<pre><code>if false; i=3; true; then echo 'hello world'; fi
echo ${i}

</code></pre>
<h3 id="test命令">test命令</h3>
<p>if结构的判断条件，一般使用test命令，有三种形式。</p>
<pre><code># 写法一
test expression
# 写法二
[ expression ]
# 写法三
[[ expression ]]

</code></pre>
<p>三种形式是等价的，但是第三种形式还支持正则判断，前两种不支持。</p>
<p>expression是一个表达式。这个表达式为真，test命令执行成功（返回值为0）；表达式为伪，test命令执行失败（返回值为1）。</p>
<p>注意：第二种和第三种写法，[ ]与内部的表达式之间必须有空格。</p>
<pre><code>read i
# 写法一
if test ${i} == 1 ; then
  echo &quot;input param: ${i}&quot;
fi
# 写法二
if [ ${i} == 1 ] ; then
   echo &quot;input param: ${i}&quot;
fi
# 写法三
if [[ ${i} == 1 ]] ; then
   echo &quot;input param: ${i}&quot;
fi

</code></pre>
<h2 id="判断表达式">判断表达式</h2>
<p>[[ ]]使用在条件判断中，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt; 和 &gt; 操作符能够正常存在于 [[ ]] 条件判断结构中，但是如果出现在 [ ] 结构中的话，会报错。</p>
<p>执行的时候，需要用bash test.sh；因为[[]]是bash脚本中的命令（bash是sh的增强版本）。</p>
<p>注意：[[  ]]中操作符与变量之间需要有空格，否则会被当做一个变量处理。</p>
<h3 id="文件判断">文件判断</h3>
<ul>
<li>[ -a file ]：如果 file 存在，则为true。</li>
<li>[ -b file ]：如果 file 存在并且是一个块（设备）文件，则为true。</li>
<li>[ -c file ]：如果 file 存在并且是一个字符（设备）文件，则为true。</li>
<li>[ -d file ]：如果 file 存在并且是一个目录，则为true。</li>
<li>[ -e file ]：如果 file 存在，则为true。</li>
<li>[ -f file ]：如果 file 存在并且是一个普通文件，则为true。</li>
<li>[ -g file ]：如果 file 存在并且设置了组 ID，则为true。</li>
<li>[ -G file ]：如果 file 存在并且属于有效的组 ID，则为true。</li>
<li>[ -h file ]：如果 file 存在并且是符号链接，则为true。</li>
<li>[ -k file ]：如果 file 存在并且设置了它的“sticky bit”，则为true。</li>
<li>[ -L file ]：如果 file 存在并且是一个符号链接，则为true。</li>
<li>[ -N file ]：如果 file 存在并且自上次读取后已被修改，则为true。</li>
<li>[ -O file ]：如果 file 存在并且属于有效的用户 ID，则为true。</li>
<li>[ -p file ]：如果 file 存在并且是一个命名管道，则为true。</li>
<li>[ -r file ]：如果 file 存在并且可读（当前用户有可读权限），则为true。</li>
<li>[ -s file ]：如果 file 存在且其长度大于零，则为true。</li>
<li>[ -S file ]：如果 file 存在且是一个网络 socket，则为true。</li>
<li>[ -t fd ]：如果 fd 是一个文件描述符，并且重定向到终端，则为true。 这可以用来判断是否重定向了标准输入／输出错误。</li>
<li>[ -u file ]：如果 file 存在并且设置了 setuid 位，则为true。</li>
<li>[ -w file ]：如果 file 存在并且可写（当前用户拥有可写权限），则为true。</li>
<li>[ -x file ]：如果 file 存在并且可执行（有效用户有执行／搜索权限），则为true。</li>
<li>[ file1 -nt file2 ]：如果 FILE1 比 FILE2 的更新时间最近，或者 FILE1 存在而 FILE2 不存在，则为true。</li>
<li>[ file1 -ot file2 ]：如果 FILE1 比 FILE2 的更新时间更旧，或者 FILE2 存在而 FILE1 不存在，则为true。</li>
<li>[ FILE1 -ef FILE2 ]：如果 FILE1 和 FILE2 引用相同的设备和 inode 编号，则为true。</li>
</ul>
<pre><code>file=/opt/shellScriptDir/test1.sh
if [[ -e ${file} &amp;&amp; -a ${file} ]]; then
    echo &quot;${file} exist&quot;
    if [[ -f ${file} ]]; then
        echo &quot;${file} is normal file&quot;
    fi
    if [[ -d ${file} ]]; then
        echo &quot;${file} is directory&quot;
    fi
    if [[ -r ${file} ]]; then
        echo &quot;${file} is readable&quot;
    fi
    if [[ -w ${file} ]]; then
        echo &quot;${file} is writable&quot;
    fi
    if [[ -x ${file} ]]; then
        echo &quot;${file} is executable/searchable&quot;
    fi
else
    echo &quot;${file} not exist&quot;
fi

</code></pre>
<p>注意：上述判断中，如果使用的是单个中括号[]时，$file需要用双引号括起来，否则判断将会失误。因为当$file为空时，-e会判断为真，如果放在双引号中，返回的是空字符串，[ -e &quot;&quot; ]会判断为伪。</p>
<pre><code># 下面的例子会输出 not exist
file=
if [ -e &quot;${file}&quot; ]; then
    echo &quot;${file} exist&quot;
else
    echo &quot;${file} not exist&quot;
fi

# 下面的例子会输出 exist
file=
if [ -e ${file} ]; then
    echo &quot;${file} exist&quot;
else
    echo &quot;${file} not exist&quot;
fi

</code></pre>
<h3 id="字符串判断">字符串判断</h3>
<ul>
<li>[ string ]：如果string不为空（长度大于0），则判断为真。</li>
<li>[ -n string ]：如果字符串string的长度大于零，则判断为真。</li>
<li>[ -z string ]：如果字符串string的长度为零，则判断为真。</li>
<li>[ string1 = string2 ]：如果string1和string2相同，则判断为真。</li>
<li>[ string1 == string2 ] 等同于[ string1 = string2 ]。</li>
<li>[ string1 != string2 ]：如果string1和string2不相同，则判断为真。</li>
<li>[ string1 '&gt;' string2 ]：如果按照字典顺序string1排列在string2之后，则判断为真。</li>
<li>[ string1 '&lt;' string2 ]：如果按照字典顺序string1排列在string2之前，则判断为真。</li>
</ul>
<p>注意，test命令内部的&gt;和&lt;，必须用引号引起来（或者是用反斜杠转义，或者使用双中括号）。否则，它们会被 shell 解释为重定向操作符。</p>
<p>字符串判断时，变量要放在双引号之中，比如[ -n &quot;$COUNT&quot; ]，否则变量替换成字符串以后，test命令可能会报错，提示参数过多。另外，如果不放在双引号之中，变量为空时，命令会变成[ -n ]，这时会判断为真。如果放在双引号之中，[ -n &quot;&quot; ]就判断为伪。</p>
<p>如果不想使用双引号，也可以使用双括号。</p>
<pre><code>str=fwfw
if [[ -z ${str} ]]; then
    echo &quot;${str} length =0&quot;
elif [[ -n ${str} ]]; then
    echo &quot;${str} length &gt;0&quot;
    if [[ ${str} = &quot;fwfw&quot; ]]; then
        echo &quot;${str} exist&quot;
    fi
fi

</code></pre>
<h3 id="整数判断">整数判断</h3>
<ul>
<li>[ integer1 -eq integer2 ]：如果integer1等于integer2，则为true。</li>
<li>[ integer1 -ne integer2 ]：如果integer1不等于integer2，则为true。</li>
<li>[ integer1 -le integer2 ]：如果integer1小于或等于integer2，则为true。</li>
<li>[ integer1 -lt integer2 ]：如果integer1小于integer2，则为true。</li>
<li>[ integer1 -ge integer2 ]：如果integer1大于或等于integer2，则为true。</li>
<li>[ integer1 -gt integer2 ]：如果integer1大于integer2，则为true。</li>
</ul>
<pre><code>a=10
b=20
if [ ${a} -lt ${b} ]
then
    echo &quot;${a} &lt; ${b}&quot;
else
    echo &quot;${a} &gt;= ${b}&quot;
fi

# 使用双中括号，效果一致
if [[ ${a} &lt; ${b} ]]
then
    echo &quot;${a} &lt; ${b}&quot;
else
    echo &quot;${a} &gt;= ${b}&quot;
fi

</code></pre>
<h3 id="正则判断">正则判断</h3>
<p>[[ expression ]]这种判断形式，支持正则表达式。</p>
<pre><code># regex是一个正则表示式，=~是正则比较运算符。
[[ string =~ regex ]]
</code></pre>
<pre><code>read input
if [[ ${input} =~ [0-9] ]]; then
    echo &quot;match num value = ${input}&quot;
fi

</code></pre>
<h3 id="逻辑运算">逻辑运算</h3>
<ul>
<li>AND运算：符号&amp;&amp;，也可使用参数-a。</li>
<li>OR运算：符号||，也可使用参数-o。</li>
<li>NOT运算：符号!。</li>
</ul>
<pre><code>## 使用双中括号，可以直接在命令内容拼接逻辑运算符
read input
if [[ ${input} =~ [0-9] &amp;&amp; ${input} == 3 ]]; then
    echo &quot;match num value = ${input}&quot;
fi

</code></pre>
<p>&amp;&amp; 和 || 也被称作命令控制操作符，可以用来聚合多个逻辑运算命令。</p>
<pre><code>file=/opt/shellScriptDir/temp
[[ -d  ${file} ]] || echo &quot;${file} not exist&quot;
</code></pre>
<h3 id="算术判断">算术判断</h3>
<p>bash提供了(( ... ))作为算术条件，用于进行算术运算的判断。</p>
<p>注意，算术判断不需要使用test命令，而是直接使用((...))结构。这个结构的返回值，决定了判断的真伪。</p>
<p>如果算术计算的结果是非零值，则表示判断成立。这一点跟命令的返回值正好相反，需要小心。</p>
<pre><code># 输出match num value true
if [[ 0 ]]; then
    echo &quot;match num value true&quot;
else
    echo &quot;value false&quot;
fi

# 输出value false
if (( 0 )); then
    echo &quot;match num value true&quot;
else
    echo &quot;value false&quot;
fi

</code></pre>
<p>(( ... ))可以用作变量赋值，赋值完成后将会返回变量的值。</p>
<pre><code># 输出match num value: 1
if (( var=1 )); then
    echo &quot;match num value: ${var}&quot;
else
    echo &quot;value false&quot;
fi

</code></pre>
<h3 id="case结构判断">case结构判断</h3>
<p>case结构用于多值判断，可以为每个值指定对应的命令，跟包含多个elif的if结构等价，但是语义更好。</p>
<pre><code># 语法格式
# expression是一个表达式，pattern是表达式的值或者一个模式，可以有多条，
# 用来匹配多个值，每条以两个分号（;）结尾。
case expression in
  pattern )
    commands ;;
  pattern )
    commands ;;
  ...
esac

</code></pre>
<pre><code># 简单实例
echo &quot;input value[1-3]: &quot;
read input
case ${input} in
    1) echo &quot;read value is 1&quot;;;
    2) echo &quot;read value is 2&quot;;;
    3) echo &quot;read value is 3&quot;;;
    *) echo &quot;read value is not match: ${input}&quot;;;
esac

</code></pre>
<p>case的匹配模式可以使用各种通配符，类似于下方所示：</p>
<ul>
<li>a)：匹配a。</li>
<li>a|b)：匹配a或b。</li>
<li>[[:alpha:]])：匹配单个字母。</li>
<li>???)：匹配3个字符的单词。</li>
<li>*.txt)：匹配.txt结尾。</li>
<li>*)：匹配任意输入，通过作为case结构的最后一个模式。</li>
</ul>
<pre><code># 匹配数值，单个字符，两个字符
echo &quot;input value[number or character]: &quot;
read input
case ${input} in
    [0-9]) echo &quot;read number value is: ${input}&quot;;;
    [[:lower:]] | [[:upper:]]) echo &quot;read character value is: ${input}&quot;;;
    ??) echo &quot;read double input value is: ${input}&quot;;;
    *) echo &quot;read value is not match: ${input}&quot;;;
esac

</code></pre>
<p>Bash 4.0之前，case结构只能匹配一个条件，然后就会退出case结构。Bash 4.0之后，允许匹配多个条件，这时可以用;;&amp;终止每个条件块。</p>
<pre><code>echo &quot;input character value: &quot;
read input
case ${input} in
  [[:upper:]])    echo &quot;'${input}' is upper case.&quot; ;;&amp;
  [[:lower:]])    echo &quot;'${input}' is lower case.&quot; ;;&amp;
  [[:alpha:]])    echo &quot;'${input}' is alphabetic.&quot; ;;&amp;
  [[:digit:]])    echo &quot;'${input}' is a digit.&quot; ;;&amp;
  [[:graph:]])    echo &quot;'${input}' is a visible character.&quot; ;;&amp;
  [[:punct:]])    echo &quot;'${input}' is a punctuation symbol.&quot; ;;&amp;
  [[:space:]])    echo &quot;'${input}' is a whitespace character.&quot; ;;&amp;
  [[:xdigit:]])   echo &quot;'${input}' is a hexadecimal digit.&quot; ;;&amp;
esac

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shell基本知识]]></title>
        <id>https://philosopherzb.github.io/post/shell-ji-ben-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/shell-ji-ben-zhi-shi/">
        </link>
        <updated>2022-04-30T09:03:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述shell基本知识。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/nature-2147400_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="简介">简介</h2>
<h3 id="简介-2">简介</h3>
<p>Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。</p>
<p>Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。</p>
<p>Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本（故此处也沿用该说明），需要注意的是：shell 和 shell script 是两个不同的概念。</p>
<p>查看安装的shell信息，两种查看方式任选一种键入回车即可得到相关信息。</p>
<pre><code>ls -l /bin/*sh
cat /etc/shells

</code></pre>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230307001.png" alt="img" loading="lazy"></figure>
<h2 id="基本语法bash">基本语法（Bash）</h2>
<h3 id="变量">变量</h3>
<h4 id="基础变量">基础变量</h4>
<p>创建变量时，需遵循如下规则：</p>
<ul>
<li>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</li>
<li>不允许出现空格及标点符号。</li>
<li>不能使用bash里的关键字（可用help命令查看保留关键字）。</li>
</ul>
<p>变量声明的语法如下（注意：等号两边不能存在空格，读取时使用$符）：</p>
<pre><code>variable=vlaue
</code></pre>
<pre><code># 简单例子
# 变量 a 赋值为字符串 hello
a=hello
# $a 等效于 ${a}，加花括号是为了帮助解释器识别变量的边界
# 如：echo $a_world 将不会输出内容，因为变量a_world不存在
# 但是可以使用echo ${a}_world，将会输出hello_world
echo ${a}

# 变量值包含空格，就必须放在引号里面        
b=&quot;world shell&quot;
echo ${b}

# 变量值可以引用其他变量的值
c=&quot;${a} ${b} !&quot;
echo ${c}

# 变量值可以使用转义字符
d=&quot;\t content \n&quot;
echo ${d}

# 变量值可以是命令的执行结果
e=$(ls -l /bin/*sh)
echo ${e}

# 变量值可以是数学运算的结果
f=$((4 * 5))
echo ${f}

# 变量重复赋值，后面的赋值将会覆盖前面的赋值
foo=1
foo=2
echo ${foo}

# 变量的值是变量，如果需要输出，可以使用${!varname}愈发
myvar=USER
echo ${!myvar}

</code></pre>
<h4 id="特殊变量">特殊变量</h4>
<p>Bash（是shell的一个增强版本）提供了一些特殊变量，特殊变量的值由shell预定义，用户不用进行赋值。</p>
<ul>
<li>$?: 表示上一个命令的退出码，用来判断上一个命令是否执行成功，0表示成功，非0表示失败。</li>
<li>$$: 表示当前shell的进程id，也可以用来命名临时文件</li>
<li>$_: 表示上个命令的最后一个参数</li>
<li>$!: 表示最近一个后台执行的异步命令的进程id</li>
<li>$0: 表示当前shell的名称（在命令直接执行时）或者脚本名（在脚本中执行时）</li>
<li>$-: 表示当前shell的启动参数</li>
<li>$@ $#: 表示脚本中的参数数量（两者不同之处：在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 &quot; * &quot; 等价于 &quot;1 2 3&quot;（传递了一个参数），而 &quot;@&quot; 等价于 &quot;1&quot; &quot;2&quot; &quot;3&quot;（传递了三个参数）。）</li>
</ul>
<pre><code># $? 例子
ls -l /bin/bash
echo $?
ls -l notexistfile
echo $?
# 输出结果
-rwxr-xr-x 1 root root 1183448 Jun 18  2020 /bin/bash
0
ls: cannot access 'notexistfile': No such file or directory
2

</code></pre>
<h4 id="变量默认值">变量默认值</h4>
<p>Bash 提供四个特殊语法，跟变量的默认值有关，目的是保证变量不为空。</p>
<ul>
<li>${varname:-word} 语法含义：如果变量varname存在且不为空，则返回它的值，否则返回word。它的目的是返回一个默认值，比如${count:-0}表示变量count不存在时返回0。</li>
<li>${varname:=word} 语法含义：如果变量varname存在且不为空，则返回它的值，否则将它设为word，并且返回word。它的目的是设置变量的默认值，比如${count:=0}表示变量count不存在时返回0，且将count设为0。</li>
<li>${varname:+word} 语法含义：如果变量名存在且不为空，则返回word，否则返回空值。它的目的是测试变量是否存在，比如${count:+1}表示变量count存在时返回1（表示true），否则返回空值。</li>
<li>${varname:?message} 语法含义：如果变量varname存在且不为空，则返回它的值，否则打印出varname: message，并中断脚本的执行。如果省略了message，则输出默认的信息“parameter null or not set.”。它的目的是防止变量未定义，比如${count:?&quot;undefined!&quot;}表示变量count未定义时就中断执行，抛出错误，返回给定的报错信息undefined!。</li>
</ul>
<pre><code>echo ${a:-0}
echo ${a:=word}
echo ${a:+1}
echo ${b:?&quot;undefined!&quot;}
# 输出结果
0
word
1
./test1.sh: line 5: b: undefined!

</code></pre>
<h4 id="变量命令">变量命令</h4>
<p>declare命令可以声明一些特殊类型的变量，为变量设置一些限制，比如声明只读类型的变量和整数类型的变量。</p>
<p>declare语法格式：declare OPTION VARIABLE=value，命令的主要参数（OPTION）如下：</p>
<ul>
<li>-a：声明数组变量。</li>
<li>-f：输出所有函数定义。</li>
<li>-F：输出所有函数名。</li>
<li>-i：声明整数变量。</li>
<li>-l：声明变量为小写字母。</li>
<li>-p：查看变量信息。</li>
<li>-r：声明只读变量。</li>
<li>-u：声明变量为大写字母。</li>
<li>-x：该变量输出为环境变量。</li>
</ul>
<p>readonly命令等同于declare -r，用来声明只读变量，不能改变变量值，也不能unset变量。</p>
<p>let命令声明变量时，可以直接执行算术表达式。</p>
<h4 id="数组变量">数组变量</h4>
<p>数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小。</p>
<p>与大部分编程语言类似，数组元素的下标由 0 开始。</p>
<p>Shell 数组用括号来表示，元素用&quot;空格&quot;符号分割开，语法格式如下：</p>
<pre><code>array_name=(value1 value2 ... valuen)
</code></pre>
<pre><code># 数组例子
array_test=(&quot;hello&quot; &quot;world&quot; &quot;shell&quot;)
echo ${array_test[2]}
# 获取所有元素
echo ${array_test[@]}
echo ${array_test[*]}

</code></pre>
<h4 id="字符串变量进阶例子">字符串变量&lt;进阶例子&gt;</h4>
<pre><code>var=&quot;opt/temp/test.sh&quot;
# 字符串长度
echo ${#var}

# 截取字符串 ${varname:offset:length}: 从位置offset开始（从0开始计算），长度为length
echo ${var:0:3}
# 如果省略length，则从位置offset开始，一直返回到字符串的结尾。
echo ${var:0}
# 如果offset为负值，表示从字符串的末尾开始算起。
# 注意，负数前面必须有一个空格（如果不想写空格，可以填0），以防止与${variable:-word}的变量的设置默认值语法混淆。
# 这时，如果还指定length，则length不能小于零。
echo ${var: -16:3}
echo ${var: -13}
echo ${var:0-16:3}
echo ${var:0-13}

# 输出大写
echo ${var^^}
# 输出小写
echo ${var,,}

# 匹配删除字符串
# 匹配模式pattern可以使用*、?、[]等通配符。

# ${variable#pattern}
# 如果 pattern 匹配变量 variable 的开头，删除最短匹配（非贪婪匹配）的部分，返回剩余部分
# #*/ 表示从左边开始删除第一个 / 号及左边的所有字符，即删除opt/，结果为：temp/test.sh
echo ${var#*/}

# ${variable##pattern}
# 如果 pattern 匹配变量 variable 的开头，删除最长匹配（贪婪匹配）的部分，返回剩余部分
# ##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符，即删除opt/temp/，结果为：test.sh
echo ${var##*/}

# ${variable%pattern}
# 如果 pattern 匹配变量 variable 的结尾，删除最短匹配（非贪婪匹配）的部分，返回剩余部分
# %/* 表示从右边开始，删除第一个 / 号及右边的字符，即删除/test.sh，结果：opt/temp
echo ${var%/*}

# ${variable%%pattern}
# 如果 pattern 匹配变量 variable 的结尾，删除最长匹配（贪婪匹配）的部分，返回剩余部分
# %%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符，即删除/temp/test.sh，结果：opt
echo ${var%%/*}

</code></pre>
<h3 id="算术运算符">算术运算符</h3>
<h4 id="算术表达式">算术表达式</h4>
<p>((...))语法可以进行整数的算术运算。该表达式可以忽略内部的空格，在其内部可以使用()改变运算顺序。输出结果时，需要在前面加上$符。</p>
<pre><code>a=2
echo $(( ${a} + 2 ))
# 可以不使用$或者${}（花括号是为了确定边界）引用变量
echo $(( + 2))

# 赋值
i=$((a + 2))
echo &quot;i= ${i}&quot;

</code></pre>
<p>expr命令同样支持算是运算，其可以使用变量替换。</p>
<p>注意：表达式与运算符之间需要有空格，否则会被当做字符串输出。</p>
<pre><code>a=2
expr ${a} + 2

# 赋值，两种方式都可进行赋值，``符号位于esc键下方，并非单引号
b=$(expr ${a} + 2)
c=`expr ${a} + 2`
echo &quot;b= ${b}&quot;
echo &quot;c= ${c}&quot;

</code></pre>
<p>((...))语法支持的算术运算符如下。</p>
<ul>
<li>+：加法</li>
<li>-：减法</li>
<li>*：乘法</li>
<li>/：除法（整除）</li>
<li>%：余数</li>
<li>**：指数</li>
<li>++：自增运算（作为前缀是先运算后返回值，作为后缀是先返回值后运算）</li>
<li>--：自减运算（作为前缀是先运算后返回值，作为后缀是先返回值后运算）</li>
</ul>
<h4 id="进制数值">进制数值</h4>
<p>Bash 的数值默认都是十进制，但是在算术表达式中，也可以使用其他进制。</p>
<ul>
<li>number：没有任何特殊表示法的数字是十进制数（以10为底）。</li>
<li>0number：八进制数。</li>
<li>0xnumber：十六进制数。</li>
<li>base#number：base进制的数。</li>
</ul>
<pre><code>echo $((016))
echo $((0xee))
echo $((2#00000011))

</code></pre>
<h4 id="位运算">位运算</h4>
<p>Bash 支持二进制位运算符</p>
<ul>
<li>&lt;&lt;：位左移运算，把一个数字的所有位向左移动指定的位。</li>
<li>&gt;&gt;：位右移运算，把一个数字的所有位向右移动指定的位。</li>
<li>&amp;：位的“与”运算，对两个数字的所有位执行一个AND操作。</li>
<li>|：位的“或”运算，对两个数字的所有位执行一个OR操作。</li>
<li>~：位的“否”运算，对一个数字的所有位取反。</li>
<li>!：逻辑“否”运算</li>
<li>^：位的异或运算（exclusive or），对两个数字的所有位执行一个异或操作。</li>
</ul>
<h4 id="逻辑运算">逻辑运算</h4>
<p>Bash 支持逻辑运算符</p>
<ul>
<li>&lt;/-lt：小于</li>
<li>&gt;/-gt：大于</li>
<li>&lt;=/-le：小于或相等</li>
<li>&gt;=/ge：大于或相等</li>
<li>==/-eq：相等</li>
<li>!=/-ne：不相等</li>
<li>&amp;&amp;：逻辑与</li>
<li>||：逻辑或</li>
<li>expr1?expr2:expr3：三元条件运算符。若表达式expr1的计算结果为非零值（算术真），则执行表达式expr2，否则执行表达式expr3。</li>
</ul>
<h4 id="赋值与求值运算">赋值与求值运算</h4>
<p>逗号,在$((...))内部是求值运算符，执行前后两个表达式，并返回后一个表达式的值。</p>
<pre><code>echo $((foo = 1 + 2, 3 * 4))
echo ${foo}
# 输出
12
3

</code></pre>
<p>赋值运算如下：</p>
<ul>
<li>parameter = value：简单赋值。</li>
<li>parameter += value：等价于parameter = parameter + value。</li>
<li>parameter -= value：等价于parameter = parameter – value。</li>
<li>parameter *= value：等价于parameter = parameter * value。</li>
<li>parameter /= value：等价于parameter = parameter / value。</li>
<li>parameter %= value：等价于parameter = parameter % value。</li>
<li>parameter &lt;&lt;= value：等价于parameter = parameter &lt;&lt; value。</li>
<li>parameter &gt;&gt;= value：等价于parameter = parameter &gt;&gt; value。</li>
<li>parameter &amp;= value：等价于parameter = parameter &amp; value。</li>
<li>parameter |= value：等价于parameter = parameter | value。</li>
<li>parameter ^= value：等价于parameter = parameter ^ value。</li>
</ul>
<pre><code>echo $((foo = 3))
echo $((foo *= 2))
# 输出
3
6

</code></pre>
<h2 id="流程控制">流程控制</h2>
<h3 id="条件判断">条件判断</h3>
<p>1、简单if语句</p>
<pre><code># 简单if语句
if condition
then
    command
fi

</code></pre>
<p>2、if else语句</p>
<pre><code># if else语句
if condition
then
    command
else
    command
fi

</code></pre>
<p>3、if else-if else语句</p>
<pre><code># if else-if else语句
if condition1
then
    command1
elif condition2 
then 
    command2
else
    commandN
fi

</code></pre>
<pre><code># 例子
a=10
b=20
# [[ ]]使用在条件判断中，能够防止脚本中的许多逻辑错误。比如，&amp;&amp;、||、&lt; 和 &gt; 操作符能够正常存在于 [[ ]] 条件判断结构中，但是如果出现在 [ ] 结构中的话，会报错。
# 执行的时候，需要用bash test.sh；因为[[]]是bash脚本中的命令（bash是sh的增强版本）。
if [[ ${a} &lt; ${b} ]]
then
    echo &quot;a &lt; b&quot;
else
    echo &quot;a &gt;= b&quot;
fi

</code></pre>
<h3 id="循环语句">循环语句</h3>
<p>Bash 提供三种循环语法for、while和until。</p>
<p>while循环有一个判断条件，只要符合条件，就不断循环执行指定的语句。关键字do可以跟while不在同一行，这时两者之间不需要使用分号分隔。</p>
<pre><code>while condition; do
  commands
done

</code></pre>
<p>until循环与while循环恰好相反，只要不符合判断条件（判断条件失败），就不断循环执行指定的语句。一旦符合判断条件，就退出循环。关键字do可以与until不写在同一行，这时两者之间不需要分号分隔。</p>
<pre><code>until condition; do
  commands
done

</code></pre>
<p>for...in循环用于遍历列表中的每一项。关键词do可以跟for写在同一行，两者使用分号分隔。</p>
<pre><code>for variable in list
do
  commands
done

</code></pre>
<p>for循环支持C语言的循环语法。</p>
<pre><code># expression1用来初始化循环条件，expression2用来决定循环结束的条件，
# expression3在每次循环迭代的末尾执行，用于更新值。
# 注意，循环条件放在双重圆括号之中。另外，圆括号之中使用变量，不必加上美元符号$。
for (( expression1; expression2; expression3 )); do
  commands
done

# 等同于下述表达式
(( expression1 ))
while (( expression2 )); do
  commands
  (( expression3 ))
done

# 例子
for (( i=0; i&lt;5; i=i+1 )); do
  echo $i
done

</code></pre>
<p>Bash 提供了两个内部命令break和continue，用来在循环内部跳出循环。</p>
<p>break命令立即终止循环，程序继续执行循环块之后的语句，即不再执行剩下的循环。</p>
<p>continue命令立即终止本轮循环，开始执行下一轮循环。</p>
<pre><code># break
a=(first second third)
for i in ${a[*]}; do
    echo ${i}
    if [[ ${i} == &quot;first&quot; ]]; then break; fi
done

# continue
a=(first second third)
for i in ${a[*]}; do
    if [[ ${i} == &quot;second&quot; ]]; then continue; fi
    echo ${i}
done

</code></pre>
<h2 id="函数">函数</h2>
<p>函数（function）是可以重复使用的代码片段，有利于代码的复用。它与别名（alias）的区别是，别名只适合封装简单的单个命令，函数则可以封装复杂的多行命令。</p>
<p>函数总是在当前 Shell 执行，这是跟脚本的一个重大区别，Bash 会新建一个子 Shell 执行脚本。如果函数与脚本同名，函数会优先执行。但是，函数的优先级不如别名，即如果函数与别名同名，那么别名优先执行。</p>
<pre><code># 第一种
fn() {
  # codes
}
# 第二种
function fn() {
  # codes
}

</code></pre>
<p>$1~$9：函数的第一个到第9个的参数。如果函数的参数多于9个，那么第10个参数可以用${10}的形式引用，以此类推</p>
<pre><code>printParam(){
    echo &quot;first param is $1&quot;
}
printParam wqrwq

function log_msg(){
    echo &quot;[$(date '+%F %T')]: $@&quot;
}
log_msg this is sample log message

</code></pre>
<p>函数体内支持局部变量的声明。同时，也支持修改全局变量。</p>
<pre><code>function fn(){
    local str=paramValue
    echo &quot;local: str=${str}&quot;
}
fn
echo &quot;global: str=${str}&quot;

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[python3基本知识]]></title>
        <id>https://philosopherzb.github.io/post/python3-ji-ben-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/python3-ji-ben-zhi-shi/">
        </link>
        <updated>2022-04-16T07:52:59.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述python3脚本知识。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-209956_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="简介">简介</h2>
<h3 id="简介-2">简介</h3>
<p>Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言（计算机编程语言）。</p>
<p>Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色的语法结构。</p>
<p>注意：python3与python2具备较大的差别，他们之间并不完全兼容。</p>
<p>Python的优点：</p>
<ol>
<li>简单和明确，做一件事只有一种方法。</li>
<li>学习曲线低，跟其他很多语言相比，Python更容易上手。</li>
<li>开放源代码，拥有强大的社区和生态圈。</li>
<li>解释型语言，天生具有平台可移植性。</li>
<li>支持两种主流的编程范式（面向对象编程和函数式编程）都提供了支持。</li>
<li>可扩展性和可嵌入性，可以调用C/C++代码，也可以在C/C++中调用Python。</li>
<li>代码规范程度高，可读性强，适合有代码洁癖和强迫症的人群。</li>
</ol>
<p>Python的缺点主要集中在以下几点。</p>
<ol>
<li>执行效率稍低，因此计算密集型任务可以由C/C++编写。</li>
<li>代码无法加密，但是现在很多公司都不销售卖软件而是销售服务，这个问题会被淡化。</li>
<li>在开发时可以选择的框架太多（如Web框架就有100多个），有选择的地方就有错误。</li>
</ol>
<h2 id="基本语法">基本语法</h2>
<h3 id="变量">变量</h3>
<h4 id="基础变量">基础变量</h4>
<p>创建变量时，需遵循以下规则：</p>
<ul>
<li>第一个字符必须是字母表中字母或下划线 _ 。</li>
<li>标识符的其他的部分由字母、数字和下划线组成。</li>
<li>标识符对大小写敏感。</li>
<li>不能使用python保留字。</li>
<li>python3支持中文作为变量名，非 ASCII 标识符也是允许的。（不建议使用中文作为变量名）</li>
</ul>
<pre><code># 查看关键字
import keyword
var = keyword.kwlist
print(var)

</code></pre>
<h4 id="注释与编码">注释与编码</h4>
<p>单行注释使用#号，多行注释可以使用'''或者&quot;&quot;&quot;，python3编码默认为utf-8（可以修改）。</p>
<pre><code># 单行注释信息
&quot;&quot;&quot;
多行注释
&quot;&quot;&quot;

# 修改编码
# -*- coding: GBK -*-

</code></pre>
<h4 id="语法结构">语法结构</h4>
<p>python对于代码块需要使用缩进来表示，缩进的空格数是可变的，但是同一个代码块中的缩进需要保持一致，一般使用4个空格。</p>
<p>为了方便后期维护，在代码之间可以适当的使用空行进行代码功能隔离。</p>
<pre><code>a = &quot;12&quot;
if n := len(a) &gt; 1:
    print(&quot;True&quot;)
else:
    print(&quot;False&quot;)

</code></pre>
<p>python中关于一条语句过长需要换行的写法如下（使用反斜杠\）：</p>
<pre><code>var = &quot;var1&quot; \
    &quot;var2&quot; \
    &quot;var3&quot;
print(var)

</code></pre>
<p>python支持多行语句并做一行处理</p>
<pre><code>import sys; x = 'runoob'; sys.stdout.write(x + '\n')
</code></pre>
<h2 id="基本数据类型">基本数据类型</h2>
<p>Python3有六个标准的数据类型：Number，String，List，Tuple，Set，Dictionary。</p>
<p>其中不可变数据：Number，String，Tuple</p>
<p>可变数据：List，Set，Dictionary</p>
<h3 id="number数字">Number（数字）</h3>
<p>python3支持int(长整型，相当于python2的Long)，float，bool(python2没有布尔值；1等于True，0等于False，可用于算术运算)，complex(复数)。</p>
<pre><code># 可以使用type或者isinstance函数判断变量类型。
# type()不会认为子类是一种父类类型。即type事先不知道变量类型。
# isinstance()会认为子类是一种父类类型。即isinstance事先知道变量类型。
a, b, c, d = 1, 2.2, False, 4+1j
print(type(a), type(b), type(c), type(d))
print(isinstance(a, int))

# bool 算术运算
a = True
b, c, d = a + 1, a - 1, a * 10
print(a, b, c, d)

# 强制转换
a = &quot;1&quot;
print(a, int(a), bool(a), float(a))

</code></pre>
<h3 id="string字符串">String（字符串）</h3>
<p>python3使用''或者&quot;&quot;定义字符串，使用反斜杠\转义特殊字符，也可以使用r让反斜杠不转义；连接字符串用+号，重复字符串用*号。</p>
<pre><code>a = &quot;test\ncontent&quot;
b = r&quot;test\ncontent&quot;
print(a)
print(b)
print(b + b)
print(b*3)

</code></pre>
<p>字符串的截取语法：variable[头下标:尾下标]，规则为左闭右开区间；</p>
<p>从左往右，头下标从0开始（0可省略）；从右往左，尾下标从-1开始（注意：由于左闭右开原则，-1并不会取到最后一位字符，如需取最后一位字符，需将尾下标置空）。</p>
<pre><code>a = &quot;test content&quot;
print(a[:5])
print(a[0:5])
print(a[-12:-1])
print(a[-12:])

# 判断字符是否在目标字符串中
print(&quot;te&quot; in a)
print(&quot;t&quot; not in a)

# 字符串格式化
a = &quot;%s, %d&quot; % (&quot;weq&quot;, 2)
print(a)

# 使用f-string进行格式化，可以不用%s之类的转换符（python版本需要3.6及以上）
a = &quot;content&quot;
b = f&quot;test {a}&quot;
print(b)
print(f&quot;{1+2=}&quot;)

</code></pre>
<h3 id="tuple元组">Tuple（元组）</h3>
<p>元组使用()进行赋值，使用逗号分隔不同元素；()中可以存在不同类型的元素，如数字，字符串，嵌套元组等。</p>
<p>元组的索引与截取规则与字符串一致，可参考3.2节内容。</p>
<p>注意：元组中的元素是不能被修改的；只包含一个元素时，需要在元素后面添加逗号，否则括号会被当作运算符使用</p>
<pre><code>tup = (&quot;www&quot;, 12306, 99.99, 1, 2, 3)
tup2 = (&quot;test&quot;,)
print(tup)
print(tup[:2])
print(tup[-1:])
print(tup + tup2)
print(tup * 2)
print(&quot;www&quot; in tup)

# 元组截取时，支持第三个参数：步长
print(tup[0:6:2])

</code></pre>
<h3 id="list列表">List（列表）</h3>
<p>列表与元组规则基本一致，不过列表使用[]进行赋值，且其中的元素是可以被修改的。</p>
<pre><code>list1 = [&quot;www&quot;, 12306, 99.99, 1, 2, 3]
list2 = [&quot;test&quot;]
print(list1)
print(list1[:2])
print(list1[-1:])
print(list1 + list2)
print(list1 * 2)
print(&quot;www&quot; in list1)

# 截取时，支持第三个参数：步长
print(list1[0:6:2])

# 修改列表元素
list2[0] = &quot;update&quot;
print(list2)

</code></pre>
<p>借助内置函数，列表也可以被当做堆栈（后进先出）或者队列（先进先出）使用。</p>
<p>注意：列表用作队列时相对比较低效。因为在列表的末尾添加和弹出元素非常快，但是在列表的开头插入或弹出元素却很慢 (因为所有的其他元素都必须移动一位)。</p>
<pre><code># 列表作为堆栈，利用append函数添加一个元素到堆栈的顶端，利用pop函数从堆栈顶部取出一个元素
stack = [1, 2, 3]
stack.append(4)
stack.append(5)
print(stack)
stack.pop()
print(stack)

# 列表作为队列，需要借助collections.deque操作列表两端
from collections import deque

queue = deque([1, 2, 3])
queue.append(4)
queue.append(5)
print(queue)
queue.popleft()
print(queue)

</code></pre>
<p>python中的列表推导式：列表推导式提供了一个更简单的创建列表的方法。常见的用法是把某种操作应用于序列或可迭代对象的每个元素上，然后使用其结果来创建列表，或者通过满足某些特定条件元素来创建子序列。</p>
<p>列表推导式的结构是由一对方括号所包含的以下内容组成：一个表达式，后面跟一个 for 子句，然后是零个或多个 for 或 if 子句。 其结果将是一个新列表，由对表达式依据后面的 for 和 if 子句的内容进行求值计算而得出。</p>
<p>注意：如果表达式是一个元组，那么其必须加上括号。</p>
<pre><code># 简单列表推导式
t = [x * 2 for x in range(3)]
print(t)

list_x = [1, 3, 5]
list_y = [2, 4, 6]
print([x * y for x in list_x for y in list_y])

fresh_str = ['  f   ', '  r', 'w   ']
print([x.strip() for x in fresh_str])

# 组合两个列表中的不同元素，将返回一个列表，列表中的元素类型是元组
t = [(x, y) for x in [1, 2, 3] for y in [2, 1, 3] if x != y]
print(t)

# 嵌套列表推导式
list_1 = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]
t = [[row[i] for row in list_1] for i in range(4)]
print(t)

</code></pre>
<h3 id="set集合">Set（集合）</h3>
<p>集合是由不重复元素组成的无序的集。它的基本用法包括成员检测和消除重复元素。集合对象也支持像 联合，交集，差集，对称差分等数学运算。</p>
<p>使用{}花括号或<a href="https://docs.python.org/zh-cn/3.9/library/stdtypes.html#set">set()</a> 函数可以用来创建集合。注意：要创建一个空集合只能用 set() 而不能用 {}，因为后者是创建一个空字典。</p>
<pre><code># 去重
sites = {&quot;www&quot;, &quot;12306&quot;, &quot;com&quot;, &quot;www&quot;}
print(sites)
print(&quot;www&quot; in sites)

# 运算
a = set(&quot;abcd&quot;)
b = set(&quot;defg&quot;)
print(a &amp; b)
print(a | b)
print(a ^ b)
# a集合包含的元素而b集合不包含
print(a - b)

# 集合支持推导式
a = {x for x in 'abcdefg' if x not in 'abc'}
print(a)

</code></pre>
<h3 id="dictionary字典">Dictionary（字典）</h3>
<p>字典（dictionary）是Python中另一个非常有用的内置数据类型。</p>
<p>列表是有序的对象集合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。</p>
<p>字典是一种映射类型，字典用 { } 标识，它是一个无序的 键(key) : 值(value) 的集合。</p>
<p>键(key)必须使用不可变类型。</p>
<p>在同一个字典中，键(key)必须是唯一的。</p>
<pre><code># 字典，类比如json，或者map，是一个kv键值对的集合
dict_test = {'name': 'hello', 'age': 100}
# 获取字典的值
print(dict_test['name'])
print(dict_test.get('age'))
# 获取键值对
for k, v in dict_test.items():
    print(k, v)
  
# 使用dict函数构造字典
d = dict([('name', 'jack'), ('age', 100)])
print(d)
d2 = dict(name='tom', age=90)
print(d2)

# 字典支持推导式
a = {x: x * 2 for x in (1, 2, 3)}
print(a)

</code></pre>
<h2 id="流程控制">流程控制</h2>
<h3 id="条件判断">条件判断</h3>
<p>if 语法如下所示：</p>
<ul>
<li>每个条件后面要使用冒号 :，表示接下来是满足条件后要执行的语句块。</li>
<li>使用缩进来划分语句块，相同缩进数的语句在一起组成一个语句块。</li>
<li>在Python中没有switch – case语句。</li>
</ul>
<pre><code># 语法格式
if condition_1:
    statement_block_1
elif condition_2:
    statement_block_2
else:
    statement_block_3
  
# 简单实例
var = 10
if var &gt; 10:
    print(&quot;value(&quot; + str(var) + &quot;) grate than 10&quot;)
elif var == 10:
    print(&quot;value(&quot; + str(var) + &quot;) equals 10&quot;)
else:
    print(&quot;value(&quot; + str(var) + &quot;) less than 10&quot;)  
  
# := 赋值表达式运算符，又称海象运算符（python3.8）
a = &quot;12&quot;
if n := len(a) &gt; 1:
    print(&quot;True&quot;)
else:
    print(&quot;False&quot;)  

</code></pre>
<h3 id="循环语句">循环语句</h3>
<p>break（终止循环）及continue（跳过本次循环）用于流程控制。pass是空语句，是为了保持程序结构的完整性。</p>
<p>while语句</p>
<pre><code># 简单例子
var = 1
while var &lt; 3:
    print(&quot;value: &quot; + str(var))
    var += 1
  
# pass占位语句
while True:
    pass  

</code></pre>
<p>for语句（break（终止循环）及continue（跳过本次循环）用于流程控制）</p>
<pre><code># 简单例子
# 列表 for循环
list1 = [&quot;first&quot;, 'second', 123, 45.6]
print(len(list1))
for var in list1:
    print(var, end=&quot;; &quot;)
  
# 获取索引及其值
for i, v in enumerate(list1):
    print(i, v)   
  
# 多个list，使用zip函数聚合
list2 = ['map', 'json', 'session', 'cookie']
for q1, q2, in zip(list1, list2):
    print('param1={0}, param2={1}'.format(q1, q2))
  
# 内置的range函数可以遍历数字序列
# 简单range，
for i in range(3):
    print(i)
# 指定区间
for i in range(1, 3):
    print(i)
# 指定区间及步长
for i in range(1, 10, 2):
    print(i)
  
# 迭代器
list3 = [&quot;good&quot;, &quot;fire&quot;, &quot;hello&quot;]
it = iter(list2)
print(next(it))
for var in it:
    print(var)  

</code></pre>
<h2 id="函数">函数</h2>
<h3 id="函数-2">函数</h3>
<p>函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。函数能提高应用的模块性，和代码的重复利用率。</p>
<ul>
<li>函数代码块以 def 关键词开头，后接函数标识符名称和圆括号 ()。</li>
<li>任何传入参数和自变量必须放在圆括号中间，圆括号之间可以用于定义参数。</li>
<li>函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。</li>
<li>函数内容以冒号 : 起始，并且缩进。</li>
<li>return [表达式] 结束函数，选择性地返回一个值给调用方，不带表达式的 return 相当于返回 None。</li>
</ul>
<pre><code># 可变对象传递给函数，将会改变其中的值；不可变对象传递不会改变值（如果修改，则返回一个新的变量）
def test_n(var):
    var[0] = 3

test1 = [2, 3]
test_n(test1)
print(test1)

# 必需参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样。
def test_1(var):
    print(var)

test_1(1)

# 关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。
# 使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。
def test_2(var1, var2):
    print(var1, var2)

test_2(var2=2, var1=1)

# 默认参数：调用函数时，如果没有传递参数，则会使用默认参数
# 默认参数最好使用不可变数据类型，否则可能会出现超出预期的场景
def test_3(var1, var2=2):
    print(var1, var2)

test_3(1)

# 不定长参数: 当需要一个函数能处理比当初声明时更多的参数时，这些参数就叫做不定长参数
# *表示一个元组
def test_4(var1, *var2):
    print(var1)
    print(var2)

test_4(1, 10, 20, 30)

# **表示一个字典
def test_4(var1, **var2):
    print(var1)
    print(var2)

test_4(1, a=10, b=20, c=30)

# 文档字符串
# 第一行应该是对象目的的简要概述。为简洁起见，它不应显式声明对象的名称或类型，因为这些可通过其他方式获得（除非名称恰好是描述函数操作的动词）。这一行应以大写字母开头，以句点结尾。
# 如果文档字符串中有更多行，则第二行应为空白，从而在视觉上将摘要与其余描述分开。后面几行应该是一个或多个段落，描述对象的调用约定，它的副作用等。
def test_5():
    &quot;&quot;&quot;Do nothing, but document it.

    No, really, it doesn't do anything
    &quot;&quot;&quot;
    print(&quot;test&quot;)

print(test_5.__doc__)

</code></pre>
<h3 id="匿名函数">匿名函数</h3>
<p>python 使用 lambda 来创建匿名函数。</p>
<p>所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数。</p>
<ul>
<li>lambda 只是一个表达式，函数体比 def 简单很多。</li>
<li>lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。</li>
<li>lambda 函数拥有自己的命名空间，且不能访问自己参数列表之外或全局命名空间里的参数。</li>
<li>虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。</li>
</ul>
<pre><code># lambda函数
# 语法
lambda [arg1 [,arg2,.....argn]]:expression

# 简单例子
sum_result = lambda a1, a2: a1 + a2
print(sum_result(2, 3))

</code></pre>
<h2 id="错误与异常">错误与异常</h2>
<h3 id="异常">异常</h3>
<p>即使语句或表达式在语法上是正确的，但在尝试执行时，它仍可能会引发错误。在执行时检测到的错误被称为异常，异常不一定会导致严重后果。</p>
<pre><code># 简单异常
print(3 / 0)
# 输出
Traceback (most recent call last):
  File &quot;D:/knowledge/python/pycharm/pythonProject/learn/test.py&quot;, line 123, in &lt;module&gt;
    print(3 / 0)
ZeroDivisionError: division by zero

# 处理异常
def test_6(x, y):
    try:
        x / y
    except Exception as msg:
        print(msg)

test_6(3, 0)

# try finally， finally语句中的代码始终都会执行
def test_7(x, y):
    try:
        x / y
    except ZeroDivisionError as msg:
        print(msg)
    finally:
        print(&quot;finally exec&quot;)

test_7(3, 0)

# raise抛出异常
raise Exception(&quot;raise exception&quot;)

</code></pre>
<p>一个 <a href="https://docs.python.org/zh-cn/3.9/reference/compound_stmts.html#try">try</a> 语句可能有多个 except 子句，以指定不同异常的处理程序。 最多会执行一个处理程序。 处理程序只处理相应的 try 子句中发生的异常，而不处理同一 try 语句内其他处理程序中的异常。 一个 except 子句可以将多个异常命名为带括号的元组。</p>
<pre><code># 一个except多个异常
try:
    expression
except (RuntimeError, OSError, TypeError):
    pass
  
# 多个except
# 最后的 except 子句可以省略异常名，以用作通配符。但请谨慎使用，因为以这种方式很容易掩盖真正的编程错误！
# 它还可用于打印错误消息，然后重新引发异常（同样允许调用者处理异常）   
import sys
try:
    f = open('myfile.txt')
    s = f.readline()
    i = int(s.strip())
except OSError as err:
    print(&quot;OS error: {0}&quot;.format(err))
except ValueError:
    print(&quot;Could not convert data to an integer.&quot;)
except:
    print(&quot;Unexpected error:&quot;, sys.exc_info()[0])
    raise 

</code></pre>
<p>使用with语句可以自动关闭流</p>
<pre><code># with关键字会自动关闭文件,try捕获异常输出
try:
    with open('/opt/pythonDir/temp.txt', 'w+') as f:
        f.write(&quot;test content&quot;)
    print(f.close())
except IOError as err:
    print(&quot;exception: {0}&quot;.format(err))

</code></pre>
<h2 id="面向对象">面向对象</h2>
<h3 id="python中的类">python中的类</h3>
<p>类实例化后，可以使用其属性，实际上，创建一个类之后，可以通过类名访问其属性。</p>
<pre><code># 创建类
class FirstClass:
    name = &quot;python&quot;

    def fn(self):
        print(self.name)
        return &quot;hello world&quot;


# 实例化类
first_class = FirstClass()
# 调用变量
print(&quot;name: &quot;, first_class.name)
# 调用函数
print(&quot;function: &quot;, first_class.fn())

# 定义初始化函数
class People:
    # 基本属性
    name = &quot;&quot;
    age = 0
    # 使用双下划线定义私有属性，其无法被类外部所访问
    __private_attribute = &quot;private_attribute&quot;

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def speak(self):
        print(&quot;{0} speak: {1}, {2}&quot;.format(self.name, self.age, self.__private_attribute))

    def action(self):
        print(&quot;base class action&quot;)


# people = People(&quot;Jack&quot;, 100)
# people.speak()

# 继承类
class Employee(People):
    profession = &quot;&quot;

    def __init__(self, name, age, profession):
        People.__init__(self, name, age)
        self.profession = profession

    def speak(self):
        print(&quot;{0} speak: {1}, {2}&quot;.format(self.name, self.age, self.profession))

    # 重写toString方法
#   def __str__(self):
#       return &quot;Employee:{name: %s, age: %d, profession: %s}&quot; % (self.name, self.age, self.profession)

    # 重写toString方法（使用f-string格式化）
    def __str__(self):
        return f&quot;Employee:(name: {self.name}, age: {self.age}, profession: {self.profession})&quot;

teacher = Employee(&quot;Tom&quot;, 40, &quot;teacher&quot;)
teacher.speak()
teacher.action()
print(teacher.name)

json_str = json.dumps(teacher.__dict__)
print(json_str)
teacher2 = json.loads(json_str)
print(teacher2)

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lua基本知识]]></title>
        <id>https://philosopherzb.github.io/post/lua-ji-ben-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/lua-ji-ben-zhi-shi/">
        </link>
        <updated>2022-04-02T09:10:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Lua脚本知识。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/tianjin-2185510_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="简介与安装">简介与安装</h2>
<h3 id="简介">简介</h3>
<p>Lua是一个强大，高效且轻量化的嵌入式脚本语言，由 clean C（标准 C 和 C++ 间共通的子集）实现成一个库，支持过程编程，面向对象编程，函数编程以及数据驱动编程，以此来供任何需要的程序使用。</p>
<p>同时，作为一门扩展式语言，Lua 没有 &quot;main&quot; 程序的概念：它只能 嵌入 一个宿主程序中工作，该宿主程序被称为 被嵌入程序 或者简称 宿主 。 宿主程序可以调用函数执行一小段 Lua 代码，可以读写 Lua 变量，可以注册 C 函数让 Lua 代码调用。依靠 C 函数，Lua 可以共享相同的语法框架来定制编程语言，从而适用不同的领域。</p>
<p>这也是其设计目的：为了给应用程序提供灵活的可扩展及定制化功能。</p>
<h3 id="安装">安装</h3>
<p>linux/mac安装lua，命令如下，第四行根据系统自行选择，可在<a href="http://www.lua.org/ftp">官网地址</a>中获取最新的lua下载信息。</p>
<pre><code>curl -R -O http://www.lua.org/ftp/lua-5.*.*.tar.gz
tar zxf lua-5.*.*.tar.gz
cd lua-5.*.*
make linux/macosx test
make install

</code></pre>
<p>windows下载LuaForWindows（双击安装即可）：</p>
<ul>
<li>Github下载地址：<a href="https://github.com/rjpcomputing/luaforwindows/releases">点击此处跳转下载页面</a></li>
<li>Google下载地址 : <a href="https://code.google.com/p/luaforwindows/downloads/list">点击此处跳转下载页面</a></li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306010.png" alt="img" loading="lazy"></figure>
<h2 id="基本概念">基本概念</h2>
<h3 id="值与类型">值与类型</h3>
<p>Lua 是一门动态类型语言，这意味着变量没有类型，只有值才有类型；值可以存储在变量中，作为参数传递或者返回。</p>
<p>Lua 中有八种基本类型：nil、boolean、number、string、function、userdata、thread 和 table</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>nil</td>
<td>NIL是值nil的类型，用于与其他值区分；通常用来表示一个有意义的值不存在时的状态。如果用于条件判断，其等同于boolean中的false。</td>
</tr>
<tr>
<td>boolean</td>
<td>包含两个值：true和false</td>
</tr>
<tr>
<td>number</td>
<td>整数及实数(浮点数)：标准Lua使用64位整数及双精度(64位)浮点数；小型机器和嵌入式系统可以使用32位整数及单精度(32位)浮点数。</td>
</tr>
<tr>
<td>string</td>
<td>不可变的字节序列(字符串)，可以使用双引号(&quot;&quot;)，单引号('')，双中括号([[]])表示</td>
</tr>
<tr>
<td>function</td>
<td>由C或者Lua编写的函数</td>
</tr>
<tr>
<td>userdata</td>
<td>存储在变量中的C语言数据，用户数据类型的值是一个内存块，分为：完全用户数据：指一块由Lua管理的内存对应的对象；轻量用户数据：一个简单的C指针。Lua可使用元表(metatable)对userdata进行操作;如若需要修改用户数据中的值，只能通过C API进行处理，这保证了数据仅被宿主机所控制。</td>
</tr>
<tr>
<td>thread</td>
<td>一个独立的执行序列，主要用于实现协程(coroutine)。注意：Lua中的线程与操作系统没有任何关系，因此，它可以为那些不支持原生线程的系统提供协程支持。线程跟协程的区别：线程可以同时多个运行，而协程任意时刻只能运行一个，并且处于运行状态的协程只有被挂起（suspend）时才会暂停。</td>
</tr>
<tr>
<td>table</td>
<td>一个关联数组，是Lua中唯一的数据结构。它可被用于表示普通数组、序列、符号表、集合、记录、图、树等等。</td>
</tr>
</tbody>
</table>
<h3 id="错误处理">错误处理</h3>
<p>由于 Lua 是一门嵌入式扩展语言，其所有行为均源于宿主程序中代码对某个 Lua 库函数的调用（如果是单独使用 Lua 时，那么Lua 程序就是宿主程序）。因此，在编译或运行 Lua 代码块的过程中，无论何时发生错误，控制权都返回给宿主，由宿主负责采取恰当的措施（比如打印错误消息）。</p>
<p>在Lua中的可以通过asset函数或者error函数处理错误。</p>
<p>asset函数首先会检查第一个参数，如果没有问题则不做任何事情，否则输出第二个参数作为错误信息。使用样例：</p>
<pre><code>-- 错误处理
local function add(i, j)
    assert(type(i) == &quot;number&quot;, &quot;i 不是一个数字&quot;)
	assert(type(j) == &quot;number&quot;, &quot;j 不是一个数字&quot;)
	return i + j
end
print(add(rd, 1))
-- 输出
lua: demo.lua:3: i 不是一个数字
stack traceback:
	[C]: in function 'assert'
	demo.lua:3: in function 'add'
	demo.lua:7: in main chunk
	[C]: ?

</code></pre>
<p>error函数：error (message [, level])，显式地抛出一个错误，内容为参数message，</p>
<p>Level参数指示获得错误的位置: Level=1[默认]：为调用error位置(文件+行号)；Level=2：指出哪个调用error的函数的函数；Level=0:不添加错误位置信息。</p>
<pre><code>error('error msg..')
--输出
lua: demo.lua:1: error msg..
stack traceback:
	[C]: in function 'error'
	demo.lua:1: in main chunk
	[C]: ?

</code></pre>
<p>如果需要在 Lua 中捕获这些错误，可以使用 <a href="https://www.bookstack.cn/read/lua-5.3/2.md#pdf-pcall">pcall</a> 或<a href="https://www.bookstack.cn/read/lua-5.3/2.md#pdf-xpcall">xpcall</a>在 保护模式 下调用一个函数。</p>
<p>使用xpcall或pcall时，需要提供一个 消息处理函数 用于错误抛出时调用。该函数需接收原始的错误消息，并返回一个新的错误消息。</p>
<p>它在错误发生后栈尚未展开时调用，因此可以利用栈来收集更多的信息，比如通过探知栈来创建一组栈回溯信息。同时，该处理函数也处于保护模式下，所以该函数内发生的错误会再次触发它（递归）。如果递归太深，Lua 会终止调用并返回一个合适的消息。</p>
<h3 id="垃圾收集">垃圾收集</h3>
<p>Lua采用了自动内存管理（类似于Java）。这意味着使用者不用操心新创建的对象需要的内存如何分配出来，也不用考虑在对象不再被使用后怎样释放它们所占用的内存。</p>
<p>Lua 运行了一个 垃圾收集器 来收集所有 死对象（即在 Lua 中不可能再访问到的对象）来完成自动内存管理的工作。</p>
<p>Lua 中所有用到的内存，如：字符串、表、用户数据、函数、线程、内部结构等，都服从自动管理。</p>
<p>Lua 实现了一个增量标记-扫描收集器。它使用这两个数字来控制垃圾收集循环：垃圾收集器间歇率 和 垃圾收集器步进倍率。这两个数字都使用百分数为单位（例如：值 100 在内部表示 1 ）。</p>
<p>垃圾收集器间歇率控制着收集器需要在开启新的循环前要等待多久。增大这个值会减少收集器的积极性。当这个值比 100 小的时候，收集器在开启新的循环前不会有等待。设置这个值为 200 就会让收集器等到总内存使用量达到之前的两倍时才开始新的循环。</p>
<p>垃圾收集器步进倍率控制着收集器运作速度相对于内存分配速度的倍率。增大这个值不仅会让收集器更加积极，还会增加每个增量步骤的长度。不要把这个值设得小于 100 ，那样的话收集器就工作的太慢了以至于永远都干不完一个循环。默认值是 200 ，这表示收集器以内存分配的“两倍”速工作。</p>
<p>如果将步进倍率设为一个非常大的数字（比程序可能用到的字节数还大 10% ），收集器的行为就像一个 stop-the-world 收集器。接着若把间歇率设为 200 ，收集器的行为就和过去的 Lua 版本一样了：每次 Lua 使用的内存翻倍时，就做一次完整的收集。</p>
<p>通过在 C 中调用 lua_gc或在 Lua 中调用collectgarbage ([opt [, arg]])来控制自动内存管理。通过参数 opt 它提供了一组不同的功能：</p>
<ul>
<li>collectgarbage(&quot;collect&quot;): 做一次完整的垃圾收集循环。</li>
<li>collectgarbage(&quot;count&quot;): 以 K 字节数为单位返回 Lua 使用的总内存数。 这个值有小数部分，所以只需要乘上 1024 就能得到 Lua 使用的准确字节数（除非溢出）。</li>
<li>collectgarbage(&quot;restart&quot;): 重启垃圾收集器的自动运行。</li>
<li>collectgarbage(&quot;setpause&quot;): 将 arg 设为收集器的 间歇率。 返回 间歇率 的前一个值。</li>
<li>collectgarbage(&quot;setstepmul&quot;): 返回 步进倍率 的前一个值。</li>
<li>collectgarbage(&quot;step&quot;): 单步运行垃圾收集器。 步长&quot;大小&quot;由 arg 控制。 传入 0 时，收集器步进（不可分割的）一步。 传入非 0 值， 收集器收集相当于 Lua 分配这些多（K 字节）内存的工作。 如果收集器结束一个循环将返回 true 。</li>
<li>collectgarbage(&quot;stop&quot;): 停止垃圾收集器的运行。 在调用重启前，收集器只会因显式的调用运行。</li>
<li>collectgarbage(&quot;isrunning&quot;): 返回表示收集器是否工作的布尔值。</li>
</ul>
<pre><code>demoTable = {&quot;LUa&quot;, &quot;shell&quot;, &quot;python&quot;, &quot;Java&quot;, &quot;ruby&quot;}
print(collectgarbage(&quot;count&quot;))
demoTable = nil

print(collectgarbage(&quot;count&quot;))
print(collectgarbage(&quot;collect&quot;))
print(collectgarbage(&quot;count&quot;))
-- 输出
21.0859375
21.1123046875
0
19.498046875

</code></pre>
<h3 id="协程coroutine">协程（coroutine）</h3>
<p>Lua中的协程也被称作协同式多线程，代表了一段独立执行的线程。它与线程非常的类似：拥有独立的堆栈、局部变量、指令指针，同时又与其他协程共享全局变量。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>coroutine.create()</td>
<td>创建一个协程。其唯一的参数是该协程的主函数。create 函数只负责新建一个协程并返回其句柄（一个 thread 类型的对象）；而不会启动该协程。</td>
</tr>
<tr>
<td>coroutine.resume()</td>
<td>执行一个协程。第一次调用coroutine.resume时，第一个参数应传入coroutine.create返回的线程对象，然后协程从其主函数的第一行开始执行。传递给coroutine.resume的其他参数将作为协程主函数的参数传入。协程启动之后，将一直运行到它终止或调用coroutine.yield。</td>
</tr>
<tr>
<td>coroutine.yield()</td>
<td>挂起协程，让出执行权。一般与resume配合使用。协程挂起时，对应的最近coroutine.resume函数会立刻返回，即使该挂起操作发生在内嵌函数调用中（即不在主函数，但在主函数直接或间接调用的函数内部）。在协程挂起的情况下，coroutine.resume也会返回 true，并加上传给coroutine.yield的参数。当下次重启同一个协程时，协程会接着从挂起点继续执行。此时，此前挂起点处对coroutine.yield的调用会返回，返回值为传给coroutine.resume的第一个参数之外的其他参数。</td>
</tr>
<tr>
<td>coroutine.status()</td>
<td>查看线程状态：dead，suspended，running</td>
</tr>
<tr>
<td>coroutine.warp()</td>
<td>与create类似，也是创建一个协程。不同之处在于，它不返回协程本身，而是返回一个函数。调用这个函数将启动该协程。传递给该函数的任何参数均当作coroutine.resume的额外参数。</td>
</tr>
<tr>
<td>coroutine.running()</td>
<td>返回一个running协程的协程号。</td>
</tr>
</tbody>
</table>
<p>协程样例及步骤解释：</p>
<p>1、函数foo加载，协程co创建。</p>
<p>2、第15行print执行，由coroutine.resume触发执行co协程。</p>
<p>2.1、接着打印第7行数据，对应输出结果第28行。</p>
<p>2.2、随后第8行调用函数foo，开始执行第2行，打印结果为第29行</p>
<p>2.3、最后第3行执行，协程被挂起，打印结果对应第30行。</p>
<p>注意：yield调用后的返回值为下次resume同一协程时的输入参数。对应第8行的r。</p>
<p>3、第16行执行，打印协程状态，为suspended（挂起）。</p>
<p>4、第18行执行，resume同一协程，输入参数“r”对应第8行的local r，也即第3行yield挂起后的返回值。</p>
<p>4.1、第9行打印，对应结果为第32行。</p>
<p>4.2、第10行执行，协程挂起，返回r，s两个值，作为下次resume时可输入的值。</p>
<p>5、第21行执行，resume同一协程，输入参数“x”，“y”，对应第10行的local r，s。</p>
<p>5.1、第11行执行，打印协程内容，对接结果为第35行。</p>
<p>5.2、协程结束，打印结果为第36行。</p>
<p>6、第22执行，显示协程已dead（死亡），对应结果为第37行。</p>
<p>7、第24行执行，resume协程，开始提示，协程已经dead，对应结果为第38行。</p>
<pre><code>function foo (a)
  print(&quot;foo&quot;, a)
  return coroutine.yield(2*a)
end

co = coroutine.create(function (a,b)
      print(&quot;co-body&quot;, a, b)
      local r = foo(a+1)
      print(&quot;co-body&quot;, r)
      local r, s = coroutine.yield(a+b, a-b)
      print(&quot;co-body&quot;, r, s)
      return b, &quot;end&quot;
end)

print(&quot;main&quot;, coroutine.resume(co, 1, 10))
print(coroutine.status(co))

print(&quot;main&quot;, coroutine.resume(co, &quot;r&quot;))
print(coroutine.status(co))

print(&quot;main&quot;, coroutine.resume(co, &quot;x&quot;, &quot;y&quot;))
print(coroutine.status(co))

print(&quot;main&quot;, coroutine.resume(co, &quot;x&quot;, &quot;y&quot;))
print(coroutine.status(co))

-- 输出
co-body	1	10
foo	2
main	true	4
suspended
co-body	r
main	true	11	-9
suspended
co-body	x	y
main	true	10	end
dead
main	false	cannot resume dead coroutine
dead

</code></pre>
<h2 id="基本语法">基本语法</h2>
<h3 id="变量">变量</h3>
<p>在Lua中的进行赋值操作，是不需要指定类型的。如下：</p>
<pre><code>-- 简单赋值
z = 1
print(z)
-- 多重赋值，同时也支持多重返回值
a,b = 3,4
print(a)
print(b)
return a,b

-- 本地（局部）变量赋值
local x,y=5,6
print(x)
print(y)
-- 交换数据
x,y = y,x
print(x)
print(y)

-- 代码块
do
    local str = &quot;world&quot;
	print(str)
end

</code></pre>
<h3 id="表达式">表达式</h3>
<p>在Lua中的表达式基本与高级语言相差无几，如下：</p>
<p>操作符</p>
<ol>
<li>算术运算符：+ - * / ^ (加减乘除幂)</li>
<li>关系运算符：&lt; &gt; &lt;= &gt;= == ~=</li>
<li>逻辑运算符：and or not</li>
<li>连接运算符：..</li>
</ol>
<p>有几个操作符需要注意：</p>
<ul>
<li>a ~= b 即 a 不等于 b</li>
<li>a ^ b 即 a 的 b 次方</li>
<li>a .. b 将 a 和 b 作为字符串连接</li>
</ul>
<p>优先级：</p>
<ol>
<li>^</li>
<li>not -(负号)</li>
<li>*/</li>
<li>+-</li>
<li>..</li>
<li>&lt; &gt; &lt;= &gt;= ~= ==</li>
<li>and</li>
<li>or</li>
</ol>
<h3 id="控制流">控制流</h3>
<p>Lua以if for while等来进行流程控制，具体如下所示：</p>
<pre><code>-- if语句
local num = &quot;21&quot;
if (tonumber(num)~=nil) then
    print(&quot;tonumber result: &quot;..tonumber(num))
else
    print(&quot;tonumber result is not number&quot;)
end

-- for语句
-- 三个数字分别表示初始值，终止值，步长
for i = 2, 10, 2 do
    print(i)
end
-- i，v分别表示数组对应的索引及值，注意：Lua中的数组是从1开始排序
demoTable = {&quot;LUa&quot;, &quot;shell&quot;, &quot;python&quot;, &quot;Java&quot;, &quot;ruby&quot;}
for i,v in ipairs(demoTable) do
    print(i)
    print(v)
end

-- while语句
local i = 0
while i &lt; 2 do
    print(i)
	i = i + 1
	if (i == 1) then break end
end

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL日志系统]]></title>
        <id>https://philosopherzb.github.io/post/mysql-ri-zhi-xi-tong/</id>
        <link href="https://philosopherzb.github.io/post/mysql-ri-zhi-xi-tong/">
        </link>
        <updated>2022-03-19T08:07:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述MySQL日志系统，包括InnoDB引擎日志。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hd-wallpaper-2836301_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="日志系统">日志系统</h2>
<h3 id="概要">概要</h3>
<p>日志是mysql数据库的重要组成部分，记录着数据库运行期间的各种信息；其中包括错误日志，查询日志，慢查询日志，二进制日志等。</p>
<table>
<thead>
<tr>
<th>日志类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Error log</td>
<td>mysql启动、运行、停止期间发生的问题记录</td>
</tr>
<tr>
<td>General query log</td>
<td>客户端建立连接以及期间发生的所有sql操作</td>
</tr>
<tr>
<td>Slow query log</td>
<td>记录执行时间过长或没有使用索引的查询语句</td>
</tr>
<tr>
<td>Binary log</td>
<td>记录数据库的变动操作，如insert，create，alert等语句，所以该日志也可用于主从复制。</td>
</tr>
<tr>
<td>Relay log</td>
<td>中继日志一般用于接受复制源的数据变动（主从复制时会用到）</td>
</tr>
<tr>
<td>DDL log (metadata log)</td>
<td>记录了执行DDL语句的元数据操作</td>
</tr>
<tr>
<td>Engine log</td>
<td>引擎会有自己的额外日志</td>
</tr>
</tbody>
</table>
<h3 id="错误日志">错误日志</h3>
<p>错误日志包含了数据库启动和宕机时的记录；除此之外，它还包含服务启动、运行、宕机时的一些诊断性日志如errors,warnings和notes等。</p>
<p>一般情况下，错误日志有助于检查数据库运行状态，查看日志文件语句如下：</p>
<pre><code>show variables like '%log_error%';

</code></pre>
<h3 id="查询日志">查询日志</h3>
<p>查询日志记录了mysql服务实例的所有操作，如select,delete,insert等；一般情况，该日志不会被打开，避免造成mysql性能下降。查看该日志文件的语句如下：</p>
<pre><code>show variables like '%general_log%';
</code></pre>
<h3 id="慢查询日志">慢查询日志</h3>
<p>慢查询日志由执行时间超过long_query_time的sql语句组成，且必须有至少min_examined_row_limit行数据被检查过。</p>
<p>慢查询日志可以有效的跟踪执行时间过长或者没有使用索引的查询语句。查看语句如下：</p>
<pre><code>-- 查看日志文件
show variables like '%slow_query_log%';
-- 查看参数值
show variables like '%long_query_time%';
show variables like '%min_examined_row_limit%';

-- log_quries_not_using_indexes 是否将不使用索引的查询语句记录到慢查询日志中，无论查询速度有多快。
SET GLOBAL log_queries_not_using_indexes=ON;
show variables like 'log_queries_not_using_indexes';

-- 如果log_quries_not_using_indexes处于开启状态，那么mysql还提供了log_throttle_queries_not_using_indexes 用来控制每分钟写入多少条数据
show variables like 'log_throttle_queries_not_using_indexes';

-- 日志的输出格式，FILE或者table
show variables like 'log_output';

</code></pre>
<h3 id="中继日志">中继日志</h3>
<p>中继日志一般用于主从复制，基本结构与binlog一致。</p>
<h3 id="元数据日志">元数据日志</h3>
<p>元数据日志记录了通过数据库定义的能够影响表分区的语句操作，例如： ALTER TABLE t3 DROP PARTITION p2；mysql必须确保分区被完全移除，且该分区位于table t3的分区列表中的定义也被移除。为了防止在移除分区操作时机器宕机导致的移除失败，元数据日志便诞生了，因为其记录了具体的语句操作，mysql完全可以根据这些语句重新进行移除操作。</p>
<h3 id="二进制日志">二进制日志</h3>
<p>二进制日志记录了对mysql数据库执行更新的所有操作，需要注意的是不包括查询类操作，如select，show等；同时，某些操作本身可能并未对数据库进行修改，但这些操作仍然会被写入二进制日志，如update一条不存在的数据（update t set a=1 where a=2）。</p>
<pre><code>-- 查看二进制日志是否开启，默认情况下是关闭的
show variables like '%log_bin%';

</code></pre>
<h4 id="作用">作用</h4>
<p>二进制日志的具体用途如下：</p>
<ul>
<li>恢复(recovery)：二进制日志包含数据所有的更新操作，一旦数据库宕机，完全可以根据二进制日志进行备份恢复。如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。</li>
<li>复制(replication)：一般与relay log配合使用，进行主从复制操作。</li>
<li>审计(audit)：可以检查该日志来判断是否有注入攻击。</li>
</ul>
<h4 id="配置">配置</h4>
<p>二进制日志默认是关闭状态，需要手动配置才能开启。mysql配置文件为/etc/my.cnf，使用vim编辑该文件，键入如下内容：</p>
<pre><code># binlog
# 指明存储文件位置
log-bin=/temp/mysql-bin.log
# 设置binlog清理时间
expire-logs-days=14
# 每个文件的大小
max-binlog-size=512M
# mysql集群的服务id
server-id=1

</code></pre>
<pre><code># 参数说明
log_bin：设置此参数表示启用binlog功能，并指定路径名称

log_bin_index：设置此参数是指定二进制索引文件的路径与名称

expire-logs-days：设置binlog清理时间（手动清理：purge master logs before '2010-02-16 00:00:00';）

binlog_do_db：此参数表示只记录指定数据库的二进制日志

binlog_ignore_db：此参数表示不记录指定的数据库的二进制日志

max_binlog_cache_size：此参数表示binlog使用的内存最大的尺寸

binlog_cache_size：此参数表示binlog使用的内存大小，可以通过状态变量binlog_cache_use和binlog_cache_disk_use来帮助测试。
binlog_cache_use：使用二进制日志缓存的事务数量
binlog_cache_disk_use:使用二进制日志缓存但超过binlog_cache_size值并使用临时文件来保存事务中的语句的事务数量

max_binlog_size：Binlog最大值，最大和默认值是1GB，该设置并不能严格控制Binlog的大小，尤其是Binlog比较靠近最大值而又遇到一个比较大事务时，
为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的所有SQL都记录进当前日志，直到事务结束

</code></pre>
<pre><code># binlog刷盘策略参数配置
sync_binlog：这个参数直接影响mysql的性能和完整性
sync_binlog=0：当事务提交后，Mysql仅仅是将binlog_cache中的数据写入Binlog文件，但不执行fsync操作，而是让Filesystem自行决定什么时候来做同步。此模式相对来说性能最高，但不安全，宕机时容易丢失数据。
sync_binlog=1：每次事务提交时，都将binlog刷入磁盘。此模式最安全，但性能相对偏低。
sync_binlog=n：在进行n次事务提交以后，Mysql将执行一次fsync之类的磁盘同步指令，通知文件系统将Binlog文件缓存刷新到磁盘。如果容许出现数据丢失，可以适当的提高此设置值来获取更好的性能。

</code></pre>
<h4 id="格式">格式</h4>
<p>mysql5.1版本开始引入了额外的binlog格式参数，分别为：STATEMENT，ROW，MIXED。</p>
<pre><code>-- 查看binlog格式
show variables like '%binlog_format%';
</code></pre>
<ul>
<li>STATEMENT：记录的是逻辑SQL语句，即所有的数据库更新操作。该模式下日志量相对ROW会更少，节省了IO及存储资源，性能相对有所提高。注意：在RC(Read committed，读已提交)隔离级别下，此模式会导致主从复制数据不一致问题（例如：一条删除语句与一条新增语句在两个session中提交，最终master可能是先删除后新增，但slave库复制时可是先新增后删除，导致数据不一致）。解决方案便是RC选择ROW模式，RR（可重复读有间隙锁防止session执行顺序错乱）选择STATEMENT模式。</li>
<li>ROW：记录表行数据的变更情况，而非单纯的逻辑sql语句。如果binlog格式设置为ROW，那么隔离级别可以设置为RC，以提高并发度；当然随之而来的便是IO及存储资源的增加。</li>
<li>MIXED：默认依旧使用STATEMENT格式，只在某些情况下使用ROW格式；如：NDB引擎，insert delay语句，临时表，自定义函数等。</li>
</ul>
<h3 id="引擎日志">引擎日志</h3>
<p>事务一般都有ACID四个特性，其中隔离性可以通过锁来实现；原子性，一致性，持久性则需要通过日志系统进行保障。以InnoDB为例，redo log保证了持久性，undo log则保证了原子性。</p>
<p>InnoDB架构官网链接：<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html">点击此处跳转官网页面</a></p>
<h4 id="redo-log">redo log</h4>
<p>在mysql中，持久性作为事务四大特性之一，需要确保对数据的修改能够永久地保存下来；如果在每次更新数据时都简单地采用直接刷入磁盘的操作，将会导致整个服务性能变得低下。以InnoDB引擎为例，原因如下：</p>
<ul>
<li>InnoDB引擎与磁盘进行交互的基本单位是数据页，一次事务操作可能只修改了几个字节，这个时候将整个数据页刷入磁盘，将会浪费大量的资源。</li>
<li>一个事务操作可能涉及多个不同的数据页，且当这些数据页在磁盘上不连续时，写入性能也将变得很差（随机IO多了寻址(seek)步骤）</li>
</ul>
<p>于是，InnoDB引擎设计了redo log专门记录着事务操作引起的数据变化，确切地说是记录了事务操作对数据页做了哪些修改。</p>
<p>这个日志与磁盘配合的整个过程，在MySQL中被称之为WAL(Write-Ahead Logging，预写式技术)；WAL会先将记录写入日志，然后在系统空闲的时候或者按照设定的更新策略进行刷磁盘操作(刷脏页，fsync)。</p>
<h5 id="redo-log记录形式">redo log记录形式</h5>
<p>redo log本身只记录数据页的变更，且采用了大小固定，循环写入的实现方案进行log记录。为了实现循环写入，redo log中设置了两个标志位：checkpoint 和 write pos。</p>
<ul>
<li>write pos 表示redo log当前记录的LSN(log sequence number,日志序列号：日志空间中每条日志的结束点，用字节偏移量表示)，即记录写入位置。</li>
<li>checkpoint 表示脏页（缓存中的数据页被称为脏页）刷盘后对应的redo log所处的LSN，即记录擦除位置。</li>
</ul>
<p>在进行log记录时，如果write pos追上了checkpoint，那么就表示redo log已经写满了；此时需要停止写入，并运行checkpoint规则进行刷磁盘操作（先更新内存，再将buffer中的脏数据（缓存中的数据被称为脏数据）fsync到磁盘）。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306004.png" alt="img" loading="lazy"></figure>
<h5 id="redo-log刷磁盘">redo log刷磁盘</h5>
<p>redo log包含两个核心部分，分别是内存中的日志缓冲(redo log buffer)以及磁盘上的日志文件(redo log file)。当执行一条更新sql时，数据会先写入redo log buffer，之后再写入redo log file。</p>
<p>在计算机操作系统中，用户空间(user space)下的缓存区数据是无法直接写入磁盘的，一般都需要经过内核空间(kernel space)的缓存区(OS Buffer)，之后才能真正写入磁盘。具体流程图如下所示：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306005.png" alt="" loading="lazy"></figure>
<p>在InnoDB中有一个配置参数可以用来控制日志的刷新频率：innodb_flush_log_at_trx_commit。</p>
<table>
<thead>
<tr>
<th>参数值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>0（延时写）</td>
<td>事务提交之后，日志只记录到 log buffer 中，之后每秒写一次日志到缓存（OS Buffer）并刷新（fsync）到磁盘，尚未刷新的日志可能会丢失。</td>
</tr>
<tr>
<td>1（实时写，实时刷）</td>
<td>事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。</td>
</tr>
<tr>
<td>2（实时写，延时刷）</td>
<td>每次事务提交之后，日志写到 OS Buffer，每秒刷一次到磁盘，尚未刷新的日志可能会丢失。</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306007.png" alt="img" loading="lazy"></figure>
<h5 id="redo-log与binlog">redo log与binlog</h5>
<p>binlog是mysql服务共有的日志文件，而redo log则是InnoDB独有的日志文件。同时，redo log是基于crash recovery，保证MySQL宕机后的数据恢复（crash-safe）；而binlog是基于point-in-time recovery，保证服务器可以基于时间点对数据进行恢复，或者对数据进行备份。</p>
<p>注意：单纯的binlog日志系统是不具备crash-safe功能的，因为binlog一般只能提供归档功能（记录了对mysql数据库执行更新的所有操作）。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306008.png" alt="img" loading="lazy"></figure>
<p>以InnoDB引擎对update table set b = 2 where a = 1语句操作为例，其中都会涉及redo log日志和binlog日志，具体流程如下：</p>
<ol>
<li>查询 a=1 这一行。如果 a=1 这一行所在的数据页本来就在内存中，便直接返回；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>修改 a=1 这行的b为2，并写入新行。</li>
<li>引擎将这行新数据更新到内存（InnoDB Buffer Pool）中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。</li>
<li>sql语句写入 binlog，并把 binlog 刷入磁盘（依据配置的刷盘机制）。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306009.png" alt="img" loading="lazy"></figure>
<h4 id="undo-log">undo log</h4>
<p>回滚日志主要是为了保证数据库事务的原子性，当一个事务对数据库进行修改时，InnoDB引擎不仅会记录redo log，还会生成对应的undo log日志；当事务执行失败或者调用rollback时，便可以利用undo log将数据回滚到修改之前的样子。</p>
<p>关于 undo Log 的存储：InnoDB 中有回滚段(rollback segment)，每个回滚段记录 1024 个 undo log segment，在每个 undo log segment 段中进行申请 undo 页。系统表空间偏移量为 5 的页记录了所有的 rollback segment header 所在的页。</p>
<p>undo log有两个作用：一是提供回滚，二是实现MVCC；两种格式：insert undo log（记录插入对应的回滚日志） 和 update undo log（记录更新和删除对应的回滚日志）。</p>
<p>undo log详解可参考：<a href="http://mysql.taobao.org/monthly/2021/10/01/">点击此处跳转页面</a></p>
<h4 id="innodb故障恢复">InnoDB故障恢复</h4>
<p>由上小节可知，InnoDB事务处理采用的是二阶段提交，因此故障恢复也将依据二阶段进行。</p>
<p>注意1：binlog的完整性依据不同的日志格式而不同，STATEMENT格式为COMMIT，而ROW格式最后一行会有一个XID event，且5.6.2版本后，mysql还新增了binlog-checknum用于验证binlog的完整性。</p>
<p>注意2：redo log与binlog有一个共同的数据字段：XID。</p>
<ol>
<li>数据库启动后，InnoDB引擎会根据redo log寻找最近的一次checkpoint位置，随后根据checkpoint对应的LSN(log sequence number,日志序列号)获取需要重做的日志。</li>
<li>根据redo log回滚未prepared和commit的事务，但对于已经prepared，但未commit的事务，暂时挂起，将其保存到一个链表中。</li>
<li>mysql读取最后一个binlog文件。binlog文件通常是以固定的文件名加一组连续的编号来命名的，并且将其记录到一个binlog索引文件中，因此索引文件中的最后一个binlog文件即是MySQL将要读取的最后一个binlog文件。</li>
<li>如果binlog中记录了上次mysql为异常关闭（文件头是否存在标记LOG_EVENT_BINLOG_IN_USE_F），则依次读取binlog中所有的log event，并将所有已提交事务的xid取出归总到一个列表；同时，定位出最后一个完整事务的位置。</li>
<li>遍历第二步中的列表，判断其是否在第四步中的提交事务列表中，如果是，则提交此事务；否则回滚。</li>
<li>将最后一个完整事务位置之后的binlog清除，到此故障恢复便已全部完成。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL架构与EXPLAIN与锁]]></title>
        <id>https://philosopherzb.github.io/post/mysql-jia-gou-yu-explain-yu-suo/</id>
        <link href="https://philosopherzb.github.io/post/mysql-jia-gou-yu-explain-yu-suo/">
        </link>
        <updated>2022-03-05T02:51:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述MySQL架构组件，EXPLAIN语法分析以及各类锁细节。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sea-164989_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="mysql架构">MySQL架构</h2>
<h3 id="架构图">架构图</h3>
<h4 id="国外架构图">国外架构图</h4>
<p>图片文章链接：<a href="https://www.rathishkumar.com/2016/04/understanding-mysql-architecture.html">点击此处跳转页面</a></p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306001.png" alt="" loading="lazy"></figure>
<h4 id="国内架构图">国内架构图</h4>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306002.png" alt="img" loading="lazy"></figure>
<h3 id="架构层说明">架构层说明</h3>
<h4 id="客户端层">客户端层</h4>
<p>mysql是一个标准的cs(client-server)服务器，请求一般由客户主动发起，包括但不限于java，python，php等。</p>
<h4 id="服务端层">服务端层</h4>
<p>服务层包含了mysql所有的核心功能，具体可分为如下几种：</p>
<ul>
<li>连接器(Connection Pool)：维护客户端与服务端的连接，认证连接账号密码，确认连接账号的权限。</li>
<li>查询缓存(Query Cache)：缓存了select语法的结果集，如果命中了缓存则直接返回数据给客户端。注意：mysql8此功能已弃用。</li>
<li>分析器(Parser)：对即将执行的sql进行分析，包括词法分析(Lexical analysis，判断从字节流生成的单词或标识是否符合规范)和语法分析(Syntactic analys，确保语句符合sql规范)；同时，会创建一个内部的parse-tree结构。</li>
<li>优化器(Optimizer)：针对内部的parse-tree，mysql可以应用多种优化技术，如重写查询，扫描表的顺序以及选择合适的索引使用等。可以用explain查看分析优化结果。</li>
</ul>
<h4 id="引擎层">引擎层</h4>
<p>mysql提供给可插拔式的引擎技术，可根据不同的业务选择不同的引擎。</p>
<h4 id="存储层">存储层</h4>
<p>实际的物理存储介质。</p>
<h3 id="explain语句">EXPLAIN语句</h3>
<p>explain可以与select，delete，insert，replace以及update语句一同使用，结果会显示来自优化器（Optimizer）的有关语句执行计划的信息。</p>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html">点击此处跳转官网页面</a></p>
<p>explain输出格式参数如下所示：</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>JSON Name</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>select_id</td>
<td>select 标识符</td>
</tr>
<tr>
<td>select_type</td>
<td>None</td>
<td>select 类型</td>
</tr>
<tr>
<td>table</td>
<td>table_name</td>
<td>输出行对应的表名</td>
</tr>
<tr>
<td>partitions</td>
<td>partitions</td>
<td>匹配的分区</td>
</tr>
<tr>
<td>type</td>
<td>access_type</td>
<td>连接/访问类型</td>
</tr>
<tr>
<td>possible_keys</td>
<td>possible_keys</td>
<td>可供选择的匹配索引</td>
</tr>
<tr>
<td>key</td>
<td>key</td>
<td>实际匹配的索引</td>
</tr>
<tr>
<td>key_len</td>
<td>key_length</td>
<td>所选key的长度</td>
</tr>
<tr>
<td>ref</td>
<td>ref</td>
<td>与索引比较的列</td>
</tr>
<tr>
<td>rows</td>
<td>rows</td>
<td>预计要检查多少行</td>
</tr>
<tr>
<td>filtered</td>
<td>filtered</td>
<td>通过表条件过滤的行百分比</td>
</tr>
<tr>
<td>Extra</td>
<td>None</td>
<td>额外信息</td>
</tr>
</tbody>
</table>
<h4 id="idjson-name-select_id">id(JSON name: select_id)</h4>
<p>select 标识符，是一次查询中select的序列号。当行引用了另一行的联合结果时，此值可以为NULL。当然，它也可以显示联合行的结果，格式类似于：union M,N。其中M，N表示不同的行。</p>
<h4 id="select_typejson-name-none">select_type(JSON name: None)</h4>
<p>select类型，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>select_type Value</th>
<th>JSON Name</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIMPLE</td>
<td>None</td>
<td>简单查询（未使用联合查询及子查询）</td>
</tr>
<tr>
<td>PRIMARY</td>
<td>None</td>
<td>多层查询时，外层查询将被标记为primary（如两表做UNION或者存在子查询的外层的表操作为PRIMARY，内层的操作为UNION）</td>
</tr>
<tr>
<td>UNION</td>
<td>None</td>
<td>UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句没有依赖关系）</td>
</tr>
<tr>
<td>DEPENDENT UNION</td>
<td>dependent (true)</td>
<td>UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句有依赖关系）</td>
</tr>
<tr>
<td>UNION RESULT</td>
<td>union_result</td>
<td>union查询结果</td>
</tr>
<tr>
<td>SUBQUERY</td>
<td>None</td>
<td>子查询</td>
</tr>
<tr>
<td>DEPENDENT SUBQUERY</td>
<td>dependent (true)</td>
<td>依赖于外部查询的子查询</td>
</tr>
<tr>
<td>DERIVED</td>
<td>None</td>
<td>衍生表</td>
</tr>
<tr>
<td>DEPENDENT DERIVED</td>
<td>dependent (true)</td>
<td>依赖于另一张表的衍生表</td>
</tr>
<tr>
<td>MATERIALIZED</td>
<td>materialized_from_subquery</td>
<td>物化子查询</td>
</tr>
<tr>
<td>UNCACHEABLE SUBQUERY</td>
<td>cacheable (false)</td>
<td>对于外层的主表，子查询不可被物化，每次都需要计算（耗时操作）</td>
</tr>
<tr>
<td>UNCACHEABLE UNION</td>
<td>cacheable (false)</td>
<td>UNION操作中，内层的不可被物化的子查询（类似于UNCACHEABLE SUBQUERY）</td>
</tr>
</tbody>
</table>
<h4 id="tablejson-name-table_name">table(JSON name: table_name)</h4>
<p>输出行所引用的表。除此之外，它还包括联合查询：union M,N（表示连表查询）；衍生表：derived M（M表的衍生结果，例如子查询的from结果）；子查询：subquery M（M表的子查询结果）。</p>
<h4 id="typejson-name-access_type">type(JSON name: access_type)</h4>
<p>表的连接查询方式，性能从高到低如下表所示：</p>
<table>
<thead>
<tr>
<th>type value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>system</td>
<td>表中只有一行，算是一种特殊的const连接类型</td>
</tr>
<tr>
<td>const</td>
<td>单表中最多有一个匹配行，一般是primary key 或者 unique index的检索</td>
</tr>
<tr>
<td>eq_ref</td>
<td>多表连接中被驱动表的连接列上有primary key或者unique index的检索</td>
</tr>
<tr>
<td>ref</td>
<td>与eq_ref类似，但不是使用primary key或者unique index，而是普通索引。也可以是单表上non-unique索引检索</td>
</tr>
<tr>
<td>fulltext</td>
<td>使用FULLTEXT索引执行连接</td>
</tr>
<tr>
<td>ref_or_null</td>
<td>与ref类似，区别在于条件中包含对NULL的查询</td>
</tr>
<tr>
<td>index_merge</td>
<td>索引合并优化，利用一个表里的N个索引查询,key包含索引列表，key_len则表示这些索引键的最长长度。</td>
</tr>
<tr>
<td>unique_subquery</td>
<td>in的后面是一个查询primary key\unique字段的子查询，即子查询中使用eq_ref类型查询。</td>
</tr>
<tr>
<td>index_subquery</td>
<td>in的后面是一个查询普通index字段的子查询，即子查询中使用了ref类型查询。</td>
</tr>
<tr>
<td>range</td>
<td>单表索引中的范围查询,使用索引查询出单个表中的一些行数据。ref列会变为null</td>
</tr>
<tr>
<td>index</td>
<td>等于ALL。它有两种情况：(1)覆盖索引（Extra列会显示 Using index） (2)用索引的顺序做一个全表扫描。</td>
</tr>
<tr>
<td>all</td>
<td>全表扫描</td>
</tr>
</tbody>
</table>
<pre><code>-- 样例
-- const
SELECT * FROM tbl_name WHERE primary_key=1;
SELECT * FROM tbl_name
  WHERE primary_key_part1=1 AND primary_key_part2=2;

-- eq_ref
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref
SELECT * FROM ref_table WHERE key_column=expr;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref_or_null
SELECT * FROM ref_table
  WHERE key_column=expr OR key_column IS NULL;
  
-- unique_subquery
value IN (SELECT primary_key FROM single_table WHERE some_expr)  

-- index_subquery
value IN (SELECT key_column FROM single_table WHERE some_expr)

-- range
SELECT * FROM tbl_name
  WHERE key_column = 10;
SELECT * FROM tbl_name
  WHERE key_column BETWEEN 10 and 20;
SELECT * FROM tbl_name
  WHERE key_column IN (10,20,30);
SELECT * FROM tbl_name
  WHERE key_part1 = 10 AND key_part2 IN (10,20,30);

</code></pre>
<h4 id="extrajson-name-none">Extra(JSON name: None)</h4>
<p>包含了mysql解析查询的一些额外信息。</p>
<table>
<thead>
<tr>
<th>type value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backword index scan</td>
<td>优化器可以在InnoDB引擎中使用降序索引，一般与Using index一同出现</td>
</tr>
<tr>
<td>const row not found</td>
<td>所要查询的表为空</td>
</tr>
<tr>
<td>Distinct</td>
<td>mysql正在查询distinct值，因此当它查到匹配行后便会停止继续搜索更多行。</td>
</tr>
<tr>
<td>impossible HAVING</td>
<td>having条件总为false，且无法搜索到任何行</td>
</tr>
<tr>
<td>Impossible WHERE</td>
<td>where条件总为false，且无法搜索到任何行</td>
</tr>
<tr>
<td>Impossible WHERE noticed after reading const tables</td>
<td>mysql读取所有的const（及system）表之后，发现where条件均不满足（即where条件为false）</td>
</tr>
<tr>
<td>no matching row in const table</td>
<td>对于一个连接查询，结果是一个空表或者没有一条满足唯一索引条件的行。</td>
</tr>
<tr>
<td>Not exists</td>
<td>优化器发现内表记录不可能满足where条件（left join，如：SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL;）</td>
</tr>
<tr>
<td>Using filesort</td>
<td>MySQL 必须执行额外的检查以找出如何按排序顺序检索行。排序是通过根据连接类型遍历所有行并存储排序键和指向与WHERE子句匹配的所有行的指针来完成的。然后对键进行排序，并按排序顺序检索行</td>
</tr>
<tr>
<td>Using index</td>
<td>使用索引树中的信息从表中检索列信息，无须额外操作。（覆盖索引）</td>
</tr>
<tr>
<td>Using index for group-by</td>
<td>与Using index类似，对于group by列或者distinct列，可以利用索引检索出数据，而不需要去表里查数据、分组、排序、去重等等</td>
</tr>
<tr>
<td>Using join buffer</td>
<td>之前的表连接在nested loop之后放进join buffer，再来和本表进行join。</td>
</tr>
<tr>
<td>Using sort_union,using union,using intersect</td>
<td>index_merge的三种情况</td>
</tr>
<tr>
<td>Using temporary</td>
<td>使用了临时表来存储中间结果集，适用于group by，distinct，或order by列为不同表的列。</td>
</tr>
<tr>
<td>Using where</td>
<td>在存储引擎层检索出记录后，在server利用where条件进行过滤，并返回给客户端</td>
</tr>
</tbody>
</table>
<h2 id="mysql锁">MySQL锁</h2>
<h3 id="隔离级别">隔离级别</h3>
<table>
<thead>
<tr>
<th>Isolation Level（隔离级别）</th>
<th>Dirty Reads（脏读）</th>
<th>Non-Repeatable Reads（不可重复读）</th>
<th>Phantom Reads（幻读）</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read uncommitted（读未提交）</td>
<td>允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>Read committed(Sql server, Oracle)（读已提交）</td>
<td>不允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>Repeatable reads(Mysql)（可重复读）</td>
<td>不允许</td>
<td>不允许</td>
<td>允许</td>
</tr>
<tr>
<td>Serializable（串行化）</td>
<td>不允许</td>
<td>不允许</td>
<td>不允许</td>
</tr>
</tbody>
</table>
<ul>
<li>Dirty reads：脏读，A事务可以读到B事务还未提交的数据。</li>
<li>Non-repeatable read：不可重复读，A事务读取一行数据，B事务后续修改了这行数据，A事务再次读取这行数据，结果得到的数据不同。</li>
<li>Phantom reads：幻读，A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者删除已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次多/少了一些行。</li>
</ul>
<p>注意1：mysql默认使用RR隔离级别，这是由于binlog的格式问题（statement-记录修改的SQL语句,row-记录每行实际数据的变更,mixed-前面两种混合）所导致的，在5.0之前binlog只有statement一种格式，而主从复制时，这会导致数据的不一致。</p>
<p>注意2：其他数据库选用RC隔离级别，是由于RR隔离级别增加了间隙锁，会增加发生死锁的概率；同时，条件列未命中索引时，会锁全表，RC只会锁行。</p>
<p>注意3：RC隔离级别下，主从复制需要采用binlog的row格式，基于行的复制，这样不会出现主从不一致问题。</p>
<h3 id="锁分类">锁分类</h3>
<h4 id="按操作数据的类型">按操作数据的类型</h4>
<ul>
<li>共享锁(读锁，Shared Locks，S锁)：在事务要读取一条记录时，需要先获取该记录的S锁。S锁可以在同一时刻被多个事务同时持有；即多个读事务可以并发的进行，但不允许出现写事务。可以用select ...... lock in share mode;的方式手工加上一把S锁。</li>
<li>独占锁(写锁，排他锁，Exclusive Locks，X锁)：在事务要改动一条记录时，需要先获取该记录的X锁。X锁在同一时刻最多只能被一个事务持有；即当前写事务进行时，不允许其他读事务与写事务出现。X锁的加锁方式有两种，第一种是自动加锁，在对数据进行增删改的时候，都会默认加上一个X锁；还有一种是手工加锁，可以用一个FOR UPDATE给一行数据加上一个X锁。</li>
</ul>
<h4 id="按操作数据的粒度">按操作数据的粒度</h4>
<p>粒度：指数据仓库的数据单位中保存数据的细化或综合程度的级别。细化程度越高，粒度级就越小；相反，细化程度越低，粒度级就越大。</p>
<p>在数据库中为了获取更高的并发度，每次锁定的数据范围越小越好，即锁粒度越低越好。理论上来说，如果只锁定当前操作数据将会获得最大的并发度。</p>
<p>值得注意的是锁的管理也是需要耗费额外资源。</p>
<ul>
<li>表级锁(table-level locking)：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）。一般适合查询为主并带有少量更新（读多写少）的应用场景。</li>
<li>行级锁(row-level locking)：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）。一般适合大量并发更新并带有少量查询（写多读少）的应用场景。</li>
<li>页级锁(page-level locking)：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般（BDB存储引擎支持页级锁，也支持表级锁）。</li>
</ul>
<h4 id="按思想维度">按思想维度</h4>
<ul>
<li>乐观锁(Optimistic Lock)：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会根据版本号（一般情况是版本号，也可以使用时间戳等其他控制条件）判断一下在此期间别人有没有去更新这个数据。乐观锁适用于多读的应用类型，这样可以提高吞吐量。</li>
<li>悲观锁(Pessimistic Lock)：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，排他锁等，都是在做操作之前先上锁。</li>
</ul>
<h3 id="innodb引擎锁">InnoDB引擎锁</h3>
<p>作为mysql服务的默认引擎，其中的锁机制自然也是值得深究的。</p>
<p>查看表锁争用情况语句：show status like 'Table%';</p>
<p>查看引擎状态语句：SHOW ENGINE engine_name {STATUS | MUTEX}；例如：SHOW ENGINE INNODB STATUS</p>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html">点击此处跳转官网页面</a></p>
<h4 id="innodb表级锁">InnoDB表级锁</h4>
<ul>
<li>自增锁(AUTO-INC Locks)：是一种特殊的表级锁，它仅针对拥有AUTO_INCREMENT行的表。为了保证自增键数据的连续性，每次插入数据的时候，都会给该表加上一个自增锁，直到前一个事务执行成功，后一个事务才能执行。可以通过innodb_autoinc_lock_mode变量指定自增锁模式。</li>
<li>意向共享锁(intention shared lock，IS锁)：表明一个事务试图给表中的各个行设置共享锁；如果另一个事务要给数据行设置共享锁，则需先获取该行所在的表的IS锁；select ... for share可以设置IS锁。</li>
<li>意向独占锁(intention exclusive lock，IX锁)：表明一个事务试图给表中的各个行设置独占锁；如果另一个事务要给数据行设置独占锁，则需先获取该行所在的表的IX锁；select ... for update可以设置IX锁。</li>
</ul>
<p>关于各级别锁的兼容情形如下表所示（如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放）：</p>
<table>
<thead>
<tr>
<th></th>
<th>X</th>
<th>IX</th>
<th>S</th>
<th>IS</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>IX</td>
<td>冲突</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
</tr>
<tr>
<td>S</td>
<td>冲突</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>IS</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<h4 id="innodb行级锁">InnoDB行级锁</h4>
<p>InnoDB中的行级锁是通过锁定索引来实现的，这意味着只有通过索引条件进行检索的语句才会被施加行级锁，否则将使用表级锁。</p>
<p>注意：只有当执行计划真正使用了索引（用explain分析），才会施加行级锁；多个不同的session如果使用了同一个索引键，将会出现锁冲突场景。</p>
<p>聚集索引：一般是主键；如果主键不存在则使用不为空的唯一索引；如果主键和非空唯一索引都不存在，将会使用InnoDB引擎内置的6字节rowId（名称：GEN_CLUST_INDEX）。</p>
<h5 id="记录锁">记录锁</h5>
<p>记录锁(Record Locks)：使用精确匹配(=)锁定一个索引记录，例如：select c1 from t where c1 = 10 for update;锁定成功后，将不允许其他事务对该条记录进行修改删除操作。</p>
<p>值得注意的是，记录锁实际锁定的是索引（主键索引，唯一索引，普通索引，联合索引等），即使表并没有定义索引（对于这种情况，InnoDB会创建一个隐式的聚集索引并使用该索引来进行记录锁定）。</p>
<p>通过主键索引或唯一索引对数据进行update操作时，会自动对该行数据添加记录锁。例如：update t_test set test_name = 'demo_name' where id = 1;</p>
<h5 id="间隙锁">间隙锁</h5>
<p>间隙锁(Gap Locks)：使用范围匹配(&gt;,&lt;,between等)并请求共享或独占锁时将会锁定一个索引间隙，例如：select c1 from t where c1 between 10 and 30 for update;锁定成功后，在(10,30)之间的c1值将不允许插入。</p>
<p>间隙锁锁定的是一个不包括边界的区间，即左开右开区间。</p>
<p>语句：SELECT * FROM table_name WHERE id = 100 FOR UPDATE;如果id不是索引，则会触发间隙锁，将100之前的区间锁定(验证时更新id=100的数据同样会被阻塞)。</p>
<p>很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，应该尽量优化业务逻辑，使用相等条件来访问更新数据，避免使用范围条件。</p>
<p>注意：间隙锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，间隙锁可以预防幻读。</p>
<h5 id="临键锁">临键锁</h5>
<p>临键锁(Next-Key Locks)：临键锁是记录锁和间隙锁的组合。也可以称之为特殊的间隙锁，它的锁定范围是索引记录及之前的间隙，是一个左开右闭区间。</p>
<p>使用范围查询并命中了非唯一索引或非主键索引的record记录，此时锁住的就是临键区间。值得注意的是临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。</p>
<p>假设一个索引值包含10,11,13和20，那么该索引可能的临键锁区间有：(negative infinity, 10]，(10, 11]，(11, 13]，(13, 20]，(20, positive infinity)。</p>
<p>对于最后一个间隙区间，临键锁会锁定索引中最大值以上的间隙。</p>
<p>mysql默认行锁类型就是临键锁(Next-Key Locks)。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-Key Locks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。</p>
<p>注意：临键锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，临键锁可以预防幻读。</p>
<h3 id="innodb-mvcc">InnoDB MVCC</h3>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html">点击此处跳转官网页面</a></p>
<p>InnoDB multiversion concurrency control(MVCC，多版本并发控制)，主要是为了在RC(Read committed)，RR(Repeatable reads)隔离级别下提高数据库并发性能。</p>
<p>InnoDB是一个多版本存储引擎，它会将行变动的老版本信息存储下来用于回滚及并发控制。这种特性是基于undo log日志系统实现的；多版本的信息被存储在undo 表空间一个被称作回滚段(rollback segment)的数据结构中。</p>
<p>当进行并发读写时，InnoDB基于MVCC机制可以达到不加锁的一致性读效果，从而提高并发度；需要注意的是：基于MVCC的读可能会读到老数据，因为快照读会看到在该时间点之前提交的事务所做的更改，而不会看到稍后或未提交的事务所做的更改。</p>
<p>MVCC简单步骤：当一个读事务产生时，它会进行快照读并生成一个读视图(Read View)，随后根据read view中的记录(trx_ids)访问某个表索引上的记录，通过比较trx_id来确定事务可见性，如果不可见就沿着DB_ROLL_PTR往更老的版本寻找匹配数据。</p>
<p>如下图所示，事务R开始需要查询表t上的id为1的记录，R开始时事务I已经提交，事务J还在运行，事务K还没开始，这些信息都被记录在了事务R的ReadView中。事务R从索引中找到对应的这条Record[1, C]，对应的trx_id是K，不可见。沿着Rollptr找到Undo中的前一版本[1, B]，对应的trx_id是J，不可见。继续沿着Rollptr找到[1, A]，trx_id是I可见，返回结果。（此段及图片摘自：<a href="http://mysql.taobao.org/monthly/2021/10/01/">点击此处跳转文章</a>）</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306003.png" alt="img" loading="lazy"></figure>
<h4 id="当前读与快照读">当前读与快照读</h4>
<ul>
<li>当前读：返回的永远是最新的数据，一般通过加锁来实现，例如select ... for update；</li>
<li>快照读：基于MVCC，并由InnoDB多版本存储引擎实现，可以让一个读事务读取多版本中可见的版本数据。</li>
<li>RR级别下快照读：RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的（除了当前事务本身的更新操作），而早于Read View提交的事务所做的修改均是可见。</li>
<li>RC级别下快照读：每次快照读时都会生成一个快照和Read View，这也就是为何可以看到其他事务提交的更新的原因。</li>
</ul>
<h4 id="innodb行内部存储字段">InnoDB行内部存储字段</h4>
<ul>
<li>DB_TRX_ID：6字节，记录了最后一次行插入或更新事务的事务标识。此外，删除在内部也会被视作更新，即在行中的一个特定位上打上已删除标记。</li>
<li>DB_ROLL_PTR：7字节，一般被称作回滚指针，它指向回滚段(rollback segment中的回滚日志记录。</li>
<li>DB_ROW_ID：6字节，行id，随着行新增而自增；如果是由InnoDB自动生成的聚集索引，则索引即为该值；否则，该值不会出现在任何索引中。</li>
</ul>
<h4 id="read-view相关属性">Read View相关属性</h4>
<ul>
<li>m_ids：表示在生成READVIEW时当前系统中活跃的读写事务的事务id列表，活跃的是指当前系统中那些尚未提交的事务。</li>
<li>m_up_limit_id：表示在生成READVIEW时当前系统中活跃的读写事务中最小的事务id，也就是trx_ids中的最小值。</li>
<li>m_low_limit_id：表示生成READVIEW时系统中应该分配给下一个事务的事务id值，由于事务id一般是递增分配的，所以max_trx_id就是trx_ids中最大的那个id再加上1。</li>
<li>m_creator_trx_id：表示生成该READVIEW的事务id，由于只有在对表中记录做改动（增删改）时才会为事务分配事务id，所以在一个读取数据的事务中的事务id默认为0。</li>
</ul>
<h4 id="read-view-可见性判断具体可参见mysql源码">Read View 可见性判断（具体可参见mysql源码）</h4>
<ul>
<li>如果trx_id = m_creator_trx_id，表示当前读事务正在读取被自己修改过的记录，该版本可以被当前事务访问。</li>
<li>如果trx_id &lt; m_up_limit_id，表明生成该版本的事务在当前事务生成READVIEW前已经提交了，所以该版本可以被当前事务访问。</li>
<li>如果trx_id &gt;= m_low_limit_id，表明生成该版本的事务在当前事务生成READVIEW后提交，所以该版本不可被当前事务访问。</li>
<li>如果 trx_id在m_low_limit_id, m_up_limit_id之间，则需要判断trx_id是否在m_ids列表中；如果存在，则表明事务处于活跃状态，此时是不可见的；否则可见。</li>
</ul>
<pre><code>源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/read/read0read.cc
/**
ReadView constructor */
ReadView::ReadView()
    : m_low_limit_id(),
      m_up_limit_id(),
      m_creator_trx_id(),
      m_ids(),
      m_low_limit_no() {
  ut_d(::memset(&amp;m_view_list, 0x0, sizeof(m_view_list)));
  ut_d(m_view_low_limit_no = 0);
}

/**
Opens a read view where exactly the transactions serialized before this
point in time are seen in the view.
@param id		Creator transaction id */

void ReadView::prepare(trx_id_t id) {
  ut_ad(trx_sys_mutex_own());

  m_creator_trx_id = id;

  m_low_limit_no = trx_get_serialisation_min_trx_no();

  m_low_limit_id = trx_sys_get_next_trx_id_or_no();

  ut_a(m_low_limit_no &lt;= m_low_limit_id);

  if (!trx_sys-&gt;rw_trx_ids.empty()) {
    copy_trx_ids(trx_sys-&gt;rw_trx_ids);
  } else {
    m_ids.clear();
  }

  /* The first active transaction has the smallest id. */
  m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id;

  ut_a(m_up_limit_id &lt;= m_low_limit_id);

  ut_d(m_view_low_limit_no = m_low_limit_no);
  m_closed = false;
}

源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/include/read0types.h
/** Check whether the changes by id are visible.
@param[in]	id	transaction id to check against the view
@param[in]	name	table name
@return whether the view sees the modifications of id. */
[[nodiscard]] bool changes_visible(trx_id_t id,
                                 const table_name_t &amp;name) const {
ut_ad(id &gt; 0);

if (id &lt; m_up_limit_id || id == m_creator_trx_id) {
  return (true);
}

check_trx_id_sanity(id, name);

if (id &gt;= m_low_limit_id) {
  return (false);

} else if (m_ids.empty()) {
  return (true);
}

const ids_t::value_type *p = m_ids.data();

return (!std::binary_search(p, p + m_ids.size(), id));
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES7架构原理及选举源码]]></title>
        <id>https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/</id>
        <link href="https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/">
        </link>
        <updated>2022-02-28T07:00:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch架构组件，读写原理，性能优化以及节点选举和选举流程源码。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-1462655_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="原理概述">原理概述</h2>
<h3 id="基础架构图">基础架构图</h3>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303025.png" alt="img" loading="lazy"></figure>
<p>1: Gateway是ES用来存储索引的文件系统。支持多种类型：包括本地文件系统(默认)，分片文件系统，HDFS，S3等。</p>
<p>2: Distributed Lucene Directory指的是Apach Lucene框架。</p>
<p>3: Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块以及River模块（river代表数据从其他存储框架（如：mysql）流入ES）。</p>
<p>4: ES模块之上是 Discovery、Scripting和第三方插件。</p>
<p>5: 再上层是ES的传输模块和JMX.传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX是java的管理框架，用来管理ES应用。</p>
<p>6: 最上层是ES提供给用户的接口，可以通过RESTful接口或定制的SDK和ES集群进行交互。</p>
<h2 id="读写原理">读写原理</h2>
<h3 id="术语介绍">术语介绍</h3>
<p>segment file: 类似于倒排索引，但其中包含的数据结构更丰富（Inverted Index, Stored Fields, Document Values, Cache等）；一组segment集合加上commit point便构成了Lucene中的index（动态索引，可类比Java中的动态数组概念，每个segment便是一个数组，commit point便是ArrayList；也类似于Java1.8的ConcurrentHashMap分段概念）。</p>
<p>commit point: 记录了当前所有可用的segment file文件。数据可被搜索到。</p>
<p>translog: 持久化地记录了所有还没被刷到磁盘的操作，避免宕机时，数据丢失。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。translog 会每隔 5 秒异步执行或者在每一个请求完成之后执行一次 fsync 操作，将 translog 从缓存刷入磁盘，这个操作比较耗时，如果对数据一致性要求不是很高时建议将索引改为 async ，如果节点宕机时会有 5 秒数据丢失;</p>
<p>In-memory buffer: ES中的内存缓存，每当索引数据时，都会将数据先存储到该buffer及translog中。</p>
<p>refresh: 打开或创建一个新的segment的过程，即将数据从内存刷入filesystem cache并清空当前buffer的过程(默认每隔一秒或者buffer满了便会执行该操作)。</p>
<p>merge: refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>flush&amp;commit: 默认每隔30分钟或者translog数据量达到512mb则会触发一次flush操作。此过程会将所有数据刷入硬盘中进行持久化存储。</p>
<h3 id="写操作原理">写操作原理</h3>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303026.png" alt="img" loading="lazy"></figure>
<p>具体步骤如下：</p>
<p>1、数据写入buffer及translog中，此时是搜索不到的。</p>
<p>2、默认每隔一秒或buffer已满，则执行一次refresh操作，将数据刷入filesystem cache生成segment file，此时数据可被搜索，并清空当前的buffer。</p>
<p>3、translog中的数据存储在os cache中，之后默认每隔5秒会持久化到磁盘中（时间可设置，长短将影响性能）。</p>
<p>4、重复上述步骤，直到抵达默认的30分钟或者translog达到512mb时（相关参数可配置），便会触发一次flush操作（commit操作）：该操作首先将buffer中现有的数据refresh到os cache中去，并清空buffer；然后将一个commit point写入磁盘文件，里面标识着这个commit point 对应的所有segment file，同时强行将os cache中目前所有的数据都fsync到磁盘文件中去；最后清空现有 translog日志文件，重启一个新的translog，此时flush操作完成。</p>
<p>额外补充：</p>
<p>5、删除操作，commit的时候会产生一个.del文件，里面将某个doc标记为delete状态（并非实时删除），搜索时会自动过滤掉标记为删除状态的数据。</p>
<p>6、更新操作，将原来的doc标识为delete状态，然后重新写入一条新数据即可。</p>
<p>7、refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似大小的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>8、数据一致性由translog保证（丢失数据取决于fsync的时间）；副本一致性则是采用的半同步机制，即主分片写成功后，只需一部分数量（quorum）的副本写入成功即可返回。相关配置wait_for_active_shards的默认值为int( (primary + number_of_replicas) / 2 ) + 1</p>
<h3 id="读操作原理">读操作原理</h3>
<p>读过程大体上分为查询与取回两个阶段。</p>
<ol>
<li>查询阶段</li>
<li>当一个搜索请求被发送到某个节点时，该节点就变成协调节点。这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。</li>
<li>首先将广播请求到索引中每一个节点的分片拷贝，查询请求可以被某个主分片或某个副分片处理（这就是为什么更多的副本（当结合更多的硬件）能够增加搜索吞吐率），协调节点将在之后的请求中轮训所有的分片拷贝来分摊负载。</li>
<li>每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列—也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。</li>
<li>协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。</li>
<li>取回阶段</li>
<li>查询过程得到的排序结果，标记出哪些文档是符合要求的，此时仍然需要获取这些文档返回给客户端。</li>
<li>协调节点会辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求；每个分片加载并修饰文档，如果有需要的话，接着返回文档给协调节点</li>
<li>一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
</ol>
<p>注意1：先查后取的过程支持用 from 和 size 参数分页，但是这是有限制的。要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 number_of_shards * (from + size) 排序文档，来找到被包含在 size 里的文档。</p>
<p>注意2：一般不建议使用深度搜索，这将会耗费大量额外的cpu，内存与带宽（ES默认深度分页限制为10000条，即from + size &lt;=10000）;如果有需要，可以使用scroll进行查询。</p>
<h2 id="性能优化">性能优化</h2>
<h3 id="filesystem-cache">filesystem cache</h3>
<p>由上述写过程原理可知，ES的数据在filesystem cache中便可被搜索到，那么对应的，如果给予filesystem cache更多的机器内存，让它足以容纳下所有的index segment file，相应的查询效率将会获得长足的提高（内存与磁盘查询效率相差巨大）。同时，如果数据量非常之大，那么ES中应该尽量存储doc_id之类的字段，减少大文本存储（大文本存入分布式文件系统中）。</p>
<h3 id="数据预热与冷热分离">数据预热与冷热分离</h3>
<p>某些热点数据，可通过缓存预热系统进行提前查询，让其流入filesystem cache中；同时，对冷热数据进行隔离存储，确保热数据一直在filesystem cache。</p>
<h3 id="合理的文档设计">合理的文档设计</h3>
<p>不要出现复杂性的查询操作，尽量在设计阶段就做一定的冗余，让相关数据在同一个文档中。</p>
<h3 id="避免深度分页">避免深度分页</h3>
<p>就像读过程原理中所描述，过度的深分页查询，会占用大量的cpu，内存与带宽；如果有对应的需求，可通过scroll api进行查询。</p>
<h2 id="节点发现与选举流程源码">节点发现与选举流程源码</h2>
<p>节点启动时，便会开始加入集群；启动函数：org.elasticsearch.node.Node.start()</p>
<pre><code>public Node start() throws NodeValidationException {
    // start after transport service so the local disco is known
    // start before cluster service so that it can set initial state on ClusterApplierService
    discovery.start(); 
    clusterService.start();
    // 服务发现函数
    discovery.startInitialJoin();
}

</code></pre>
<p>查询mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.findMaster()；此处选举id最小的节点是因为es沿用了bully算法。</p>
<pre><code>private DiscoveryNode findMaster() {
    logger.trace(&quot;starting to ping&quot;);
    // 开始ping操作，获取当前集群处于活跃状态的节点信息
    // pingAndWait函数实际上调用了org.elasticsearch.discovery.zen.UnicastZenPing.ping()
    // 它会主动从discovery.seed_hosts配置中读取信息（7.*之前的老版本配置为：discovery.zen.ping.unicast.hosts）
    // 最终返回的节点信息中，包含有master信息
    List&lt;ZenPing.PingResponse&gt; fullPingResponses = pingAndWait(pingTimeout).toList();

    // 将本节点也加入 fullPingResponses 中
    final DiscoveryNode localNode = transportService.getLocalNode();
    assert fullPingResponses.stream().map(ZenPing.PingResponse::node).filter(n -&gt; n.equals(localNode)).findAny().isPresent() == false;
    fullPingResponses.add(new ZenPing.PingResponse(localNode, null, this.clusterState()));

    // filter responses
    // 如果配置了discovery.zen.master_election.ignore_non_master_ping（即：masterElectionIgnoreNonMasters）为true将会过滤出所有的主节点信息
    // 默认为false
    final List&lt;ZenPing.PingResponse&gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);

    // 遍历列表，将节点认为的主节点信息存入activeMasters
    List&lt;DiscoveryNode&gt; activeMasters = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        // We can't include the local node in pingMasters list, otherwise we may up electing ourselves without
        // any check / verifications from other nodes in ZenDiscover#innerJoinCluster()
        if (pingResponse.master() != null &amp;&amp; localNode.equals(pingResponse.master()) == false) {
            activeMasters.add(pingResponse.master());
        }
    }

    // 如果ping过程中发现了具备资格成为master的节点，将其存入masterCandidates 
    List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        if (pingResponse.node().isMasterNode()) {
            masterCandidates.add(new ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));
        }
    }

    if (activeMasters.isEmpty()) {
        // 判断是否有足够的候选者，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.hasEnoughMasterNodes()
        if (electMaster.hasEnoughCandidates(masterCandidates)) {
            // 从候选者中选举新的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.electMaster()
            // 选举逻辑比较简单，直接按id排序，随后取出最小id的节点，即为主节点
            final ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);
            logger.trace(&quot;candidate {} won election&quot;, winner);
            return winner.getNode();
        } else {
            // if we don't have enough master nodes, we bail, because there are not enough master to elect from
            logger.warn(
                    &quot;not enough master nodes discovered during pinging (found [{}], but needed [{}]), pinging again&quot;,
                    masterCandidates,
                    electMaster.minimumMasterNodes()
            );
            return null;
        }
    } else {
        assert activeMasters.contains(localNode) == false
                : &quot;local node should never be elected as master when other nodes indicate an active master&quot;;
        // lets tie break between discovered nodes
        // 按id进行二级排序，并返回最小id的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.tieBreakActiveMasters()
        return electMaster.tieBreakActiveMasters(activeMasters);
    }
}

</code></pre>
<p>确认mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster()</p>
<pre><code>// 1.本节点是master
if (transportService.getLocalNode().equals(masterNode)) {
    // 等待足够多的节点加入本节点
    final int requiredJoins = Math.max(0, electMaster.minimumMasterNodes() - 1); // we count as one
    logger.debug(&quot;elected as master, waiting for incoming joins ([{}] needed)&quot;, requiredJoins);
    // masterElectionWaitForJoinsTimeout默认超时时间为30秒，如果超时则直接return
    // 对应函数：org.elasticsearch.discovery.zen.NodeJoinController.waitToBeElectedAsMaster()
    nodeJoinController.waitToBeElectedAsMaster(
        requiredJoins,
        masterElectionWaitForJoinsTimeout,
        new NodeJoinController.ElectionCallback() {
            // 进行master选举
            @Override
            public void onElectedAsMaster(ClusterState state) {
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDone(currentThread);
                }
            }

            // 失败则重新发起加入集群流程
            @Override
            public void onFailure(Throwable t) {
                logger.trace(&quot;failed while waiting for nodes to join, rejoining&quot;, t);
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
                }
            }
        }

    );
}

// NodeJoinController.waitToBeElectedAsMaster()
public void waitToBeElectedAsMaster(int requiredMasterJoins, TimeValue timeValue, final ElectionCallback callback) {
    try {
        // check what we have so far..
        // capture the context we add the callback to make sure we fail our own
        // 检查是否已有requiredMasterJoins的节点数
        synchronized (this) {
            assert electionContext != null : &quot;waitToBeElectedAsMaster is called we are not accumulating joins&quot;;
            myElectionContext = electionContext;
            electionContext.onAttemptToBeElected(requiredMasterJoins, wrapperCallback);
            // 如果节点数已达标，将该节点设置为master
            checkPendingJoinsAndElectIfNeeded();
        }

        try {
            // 超时直接return
            if (done.await(timeValue.millis(), TimeUnit.MILLISECONDS)) {
                // callback handles everything
                return;
            }
        } catch (InterruptedException e) {

        }
    } catch (Exception e) {
        logger.error(&quot;unexpected failure while waiting for incoming joins&quot;, e);
        if (myElectionContext != null) {
            failContextIfNeeded(myElectionContext, &quot;unexpected failure while waiting for pending joins [&quot; + e.getMessage() + &quot;]&quot;);
        }
    }
}

// NodeJoinController.checkPendingJoinsAndElectIfNeeded()
private synchronized void checkPendingJoinsAndElectIfNeeded() {
    // 发布clusterState
    electionContext.closeAndBecomeMaster();
}

// NodeJoinController.closeAndBecomeMaster
public synchronized void closeAndBecomeMaster() {
    innerClose();

    Map&lt;JoinTaskExecutor.Task, ClusterStateTaskListener&gt; tasks = getPendingAsTasks(&quot;become master&quot;);
    final String source = &quot;zen-disco-elected-as-master ([&quot; + tasks.size() + &quot;] nodes joined)&quot;;

    // noop listener, the election finished listener determines result
    tasks.put(JoinTaskExecutor.newBecomeMasterTask(), (source1, e) -&gt; {});
    tasks.put(JoinTaskExecutor.newFinishElectionTask(), electionFinishedListener);
    // 提交更新状态的任务
    masterService.submitStateUpdateTasks(source, tasks, ClusterStateTaskConfig.build(Priority.URGENT), joinTaskExecutor);
}

</code></pre>
<pre><code>// 本节点不是master
// process any incoming joins (they will fail because we are not the master)
// 拒绝其他节点加入，因为本节点不是master
nodeJoinController.stopElectionContext(masterNode + &quot; elected&quot;);

// send join request
// 发送加入master的请求
final boolean success = joinElectedMaster(masterNode);

synchronized (stateMutex) {
    if (success) {
        // currentMasterNode 为空，或者当选的master不是之前选择的节点，进行重试加入
        DiscoveryNode currentMasterNode = this.clusterState().getNodes().getMasterNode();
        if (currentMasterNode == null) {
            // Post 1.3.0, the master should publish a new cluster state before acking our join request. we now should have
            // a valid master.
            logger.debug(&quot;no master node is set, despite of join request completing. retrying pings.&quot;);
            joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
        } else if (currentMasterNode.equals(masterNode) == false) {
            // update cluster state
            joinThreadControl.stopRunningThreadAndRejoin(&quot;master_switched_while_finalizing_join&quot;);
        }

        joinThreadControl.markThreadAsDone(currentThread);
    } else {
        // failed to join. Try again...
        // 失败则重新发起加入集群流程
        joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
    }
}

private boolean joinElectedMaster(DiscoveryNode masterNode) {
    try {
        // first, make sure we can connect to the master
        transportService.connectToNode(masterNode);
    } catch (Exception e) {
        logger.warn(() -&gt; new ParameterizedMessage(&quot;failed to connect to master [{}], retrying...&quot;, masterNode), e);
        return false;
    }
    int joinAttempt = 0; // we retry on illegal state if the master is not yet ready
    while (true) {
        try {
            logger.trace(&quot;joining master {}&quot;, masterNode);
            // joinTimeout 默认超时时间60s，org.elasticsearch.discovery.zen.MembershipAction.MembershipAction()
            membership.sendJoinRequestBlocking(masterNode, transportService.getLocalNode(), joinTimeout);
            return true;
        } catch (Exception e) {
            final Throwable unwrap = ExceptionsHelper.unwrapCause(e);
            if (unwrap instanceof NotMasterException) {
                // joinRetryAttempts 重试次数，默认3次
                if (++joinAttempt == this.joinRetryAttempts) {
                    logger.info(
                        &quot;failed to send join request to master [{}], reason [{}], tried [{}] times&quot;,
                        masterNode,
                        ExceptionsHelper.detailedMessage(e),
                        joinAttempt
                    );
                    return false;
                }
            } else {
                return false;
            }
        }

        try {
            Thread.sleep(this.joinRetryDelay.millis());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}

</code></pre>
<p>由上述步骤总结如下：</p>
<p>1、服务启动后，开始进行加入集群操作；</p>
<p>2、调用ping命令，最终获取一个包含节点基本信息及其所认为的master信息的列表（包括本节点）；</p>
<p>3、过滤结果列表，将master节点汇总到activeMasters，将master候选者节点汇总到masterCandidates；</p>
<p>4、判断如果activeMasters不为空，则从activeMasters中选择最小ID的一个节点；否则从candidateMasters中选择，先判断是否有足够的候选者，之后再排序选择ID最小的一个节点作为新的master；</p>
<p>5、投票阶段，每个节点都向自己认为的master进行joinRequest请求,对应的会产生如下两种情形：</p>
<ul>
<li>本节点是master：该节点统计发送过来的joinRequest个数，如果在指定的时间（默认30s，可配置）内达到requiredJoins个数，则发布集群信息，并回复joinRequest请求，最后完成选举，否则选举失败；</li>
<li>本节点不是master：首先，拒绝其他节点的joinRequest，其次向该节点认为的master发送joinRequest请求，并等待，如果在指定的时间（60s，可配置）未收到回复或异常重试3次都失败了则选举失败，之后将重新发起加入集群流程；否则如果收到的回复中没有master信息或者master信息不是之前选择的临时master节点则选举失败，同样会进行重新加入操作。</li>
</ul>
<p>注意：es使用延迟选举解决了选举过程中不断出现master假死现象（即master由于负载过重而假死，随后第二小id的节点成为master，之后故障节点又恢复再次被选为master，接着又假死...如此循环）；同时，es增加了法定得票人数机制，解决了脑裂（split-brain）问题。</p>
<p>脑裂指的是集群中出现多个主节点，导致集群割裂的一种异常情况。</p>
<p>法定个数：有master资格的节点数（官方建议）：n/2 + 1；其中n为有资格成为主节点的节点数。</p>
<pre><code>// 7.*版本后，discovery.zen.minimum_master_node已不再提供配置，而是由内置的代码处理
private void commonNodeConfig(ElasticsearchNode node, String nodeNames, ElasticsearchNode firstNode) {
    if (node.getVersion().onOrAfter(&quot;7.0.0&quot;)) {
        node.defaultConfig.keySet()
            .stream()
            .filter(name -&gt; name.startsWith(&quot;discovery.zen.&quot;))
            .collect(Collectors.toList())
            .forEach(node.defaultConfig::remove);
        if (nodeNames != null &amp;&amp; node.settings.getOrDefault(&quot;discovery.type&quot;, &quot;anything&quot;).equals(&quot;single-node&quot;) == false) {
            node.defaultConfig.put(&quot;cluster.initial_master_nodes&quot;, &quot;[&quot; + nodeNames + &quot;]&quot;);
        }
        node.defaultConfig.put(&quot;discovery.seed_providers&quot;, &quot;file&quot;);
        node.defaultConfig.put(&quot;discovery.seed_hosts&quot;, &quot;[]&quot;);
    } else {
        node.defaultConfig.put(&quot;discovery.zen.master_election.wait_for_joins_timeout&quot;, &quot;5s&quot;);
        if (nodes.size() &gt; 1) {
            node.defaultConfig.put(&quot;discovery.zen.minimum_master_nodes&quot;, Integer.toString(nodes.size() / 2 + 1));
        }
        if (node.getVersion().onOrAfter(&quot;6.5.0&quot;)) {
            node.defaultConfig.put(&quot;discovery.zen.hosts_provider&quot;, &quot;file&quot;);
            node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
        } else {
            if (firstNode == null) {
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
            } else {
                firstNode.waitForAllConditions();
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[\&quot;&quot; + firstNode.getTransportPortURI() + &quot;\&quot;]&quot;);
            }
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES基本概念与集群]]></title>
        <id>https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/</id>
        <link href="https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/">
        </link>
        <updated>2022-02-19T06:27:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch基本结构，术语介绍以及路由算法，分片原理等。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/conifers-1850227_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="基本概念">基本概念</h2>
<h3 id="简介">简介</h3>
<p>ElasticSearch是一个基于Apach Lucene构建的搜索引擎，其天生便是分布式的，具备极强的可扩展性，除此之外，强大的实时分析特性以及分布式存储都是其不可忽视的优点。</p>
<p>ES的主旨在于随时可用以及按需扩容。垂直扩容（纵向扩容）：性能更强大的硬件机器；水平扩容（横向扩容）：数量更多的服务器。</p>
<p>由于硬件限制，现阶段的垂直扩容必然存在一个极限，所以对于ES而言，真正的扩容能力还是来自于水平扩容-为集群增加更多的机器（多节点负载与分布式容灾，同时可以进行PB级别的数据分析）。</p>
<h3 id="名词解释">名词解释</h3>
<h4 id="索引存储索引">索引（存储索引）</h4>
<p>索引（Index）是ElasticSearch存放数据的地方（为了区分搜索索引，暂且称其为存储索引）。以关系数据库类比的话，ES中的索引相当于数据库（es6之后等同于数据表，参见；1.2.2文档类型-重点注意）的概念。但是与关系数据库相比，ES可以更快速且高效的对索引中的数据进行全文检索。</p>
<p>究其根本是由于ES/Lucene使用的倒排索引相较于关系数据库中的b-tree，b+tree而言，多了一层内存索引概念（此处的索引指搜索索引，而非存储索引）。</p>
<p>内存索引是对磁盘索引的一层简化封装，例如：磁盘索引为Alex，Bob，Curl，Abnormal；那么内存索引则为：A，B，C，b，这些简化字段会组成一颗trie tree（前缀树，根据字典顺序升序排列），通过特定的压缩技术（Lucene Finite State Transducers <a href="https://cs.nyu.edu/~mohri/pub/fla.pdf">点击此处跳转文档页面</a>）可以将其尺寸缩小数十倍，使得用内存缓存trie tree变成可能。</p>
<p>正是基于内存索引的优化，ES/Lucene才能比关系数据库更快的检索出结果；因为其在内存中已经找到了对应的磁盘索引，可以直接根据磁盘索引查询对应的磁盘数据，而关系数据库则需要遍历查找出对应的磁盘索引，之后再根据磁盘索引查询磁盘数据，这中间便多了磁盘的random access次数（一次磁盘random access大概耗时10ms，耗时会随着磁盘硬件的优劣而产生一定的浮动）。</p>
<p>关于多字段查询，ES/Lucene有两种合并方式：1.skip list实现联合索引的；对跳表中的数据进行快速与运算。2.bitset实现快速合并，进行按位与运算。两种方式的比较可参考：<a href="https://www.elastic.co/cn/blog/frame-of-reference-and-roaring-bitmaps">点击此处跳转页面</a></p>
<p>综上所述，整体效果图如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303015.png" alt="img" loading="lazy"></figure>
<h4 id="文档类型">文档类型</h4>
<p>ES中的索引可以存储许多不同用途的对象，如：学生对象，课程对象等，为了更轻松地区分这些对象，文档类型这个概念便应运而生（可类比于关系数据库中的表）；在实际操作中，为文档划分不同的类型，可以更方便的操作数据。</p>
<p>注意：划分文档类型时存在一定的限制条件，其中之一便是不同的文档类型对同一字段不能设置为不同的字段类型。例如：学生对象中的课程id是Integer类型，而课程对象中的id是String，这是不行的。详情可参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping.html">点击此处跳转页面</a></p>
<p>重点注意：es6.0.0之前单个索引可以有多个文档类型，es6.0.0之后单个索引只能有一个文档类型，7.0.0之后文档类型字段已被设置为过期，8.0.0将会完全不支持文档类型字段。原因参见上述注意点。</p>
<h4 id="文档及字段">文档及字段</h4>
<p>文档（document）是ES中存储的主要实体（类比于关系数据库中的一行数据），而字段则是具体的一对KV组合（类比于关系数据库中的一列数据）。</p>
<p>需要额外注意的是：字段类型（字符串型，数值型，日期型）决定了ES该执行何种操作，如比较、排序等。</p>
<p>幸运的是ES可以自动确定字段类型，当然也可以通过模式映射（schema mapping）自定义文档结构。</p>
<h2 id="集群概念">集群概念</h2>
<h3 id="节点与集群">节点与集群</h3>
<p>ElasticSearch可以作为一个独立的搜索服务器工作。然而，为了能够处理大型数据集并实现高可用容灾功能，我们有必要在多台服务器上部署运行ES。</p>
<p>一个运行中的ES实例称为一个节点，而集群则是由一个或多个拥有相同cluster.name配置的节点组成，集群中的所有节点共享数据且分担负载。</p>
<p>一个集群存在一个主节点（选举生成），它负责管理集群范围内的所有变更，如节点的增删，索引的增删等（不涉及文档级别）。</p>
<p>查看集群健康状态：curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot;</p>
<p>其中status字段展示了集群的健康状况：green：所有主/副本分片都是正常的；yellow：所有主分片都正常，但并不是所有副本分片都正常；red：所有主/副本分片都不正常。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303016.png" alt="img" loading="lazy"></figure>
<h3 id="分片概述">分片概述</h3>
<p>一个分片是一个底层的工作单元，它只存储了全部数据的一部分。前文所说的索引（存储数据的地方），实际上也是指向一个或多个物理分片的逻辑命名空间。</p>
<p>每个分片都是一个完整的搜索引擎，也即是一个Lucene实例。应用程序并不需要关注分片的存在，只需跟索引进行交互即可（ES透明处理了分片数据合并的过程）。</p>
<p>所有的分片都可以存储在集群中的任一节点中，而文档数据则存储在各个分片内，这便是ES集群管理数据的方式。</p>
<p>一个分片既可以是主分片，也可以是副本分片。索引中的任意文档都归属于一个主分片，所以主分片的数量决定了索引能够保存的最大数据量（Integer.MAX_VALUE-128，这是理论最大值，实际中还与硬件设备、文档大小、文档复杂度，索引和查询文档的方式以及期待的响应时长有关）。</p>
<p>副本分片主要用于高可用容灾与备份，是对主分片数据的一个拷贝，同时提供搜索和返回文档等读操作。</p>
<p>注意：扩容时，我们可以通过增加副本分片来提高搜索性能，但如果节点不变的情况下，我们增大副本分片仅仅只能带来容灾备份；这是因为每个分片从节点上获取的资源会变少，所以想增加吞吐量唯有扩展机器资源了。</p>
<p>设置三个主分片以及一个副本分片（每个主分片都拥有一个副本分片）：</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303017.png" alt="" loading="lazy"></figure>
<p>修改一个副本分片为两个副本分片：</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303018.png" alt="img" loading="lazy"></figure>
<h3 id="路由算法">路由算法</h3>
<p>分布式存储少不了路由算法，在ES中是通过hash算法来确定数据该存储到哪一个节点/分片中的。</p>
<p>公式：shard = hash(routeKey) % number_of_primary_shards</p>
<p>其中routeKey是一个随机数，一般情况下默认是文档id，不过也可以直接指定对应的值。</p>
<p>该公式也表明了主分片数为何只能在创建索引的时候设置，并且不允许被修改（如果被更改，那么之前的数据将无法被查询到，因为路由值已经不同）。</p>
<h3 id="集群交互">集群交互</h3>
<p>以三节点集群为例，其中包含一个blogs的索引，它对应的设置为：主分片数：2，副本数：2。一般相同分片的副本不会存放在同一节点，如下图：</p>
<p>注意：</p>
<ol>
<li>ES中的每个节点都有能力处理任意操作请求。</li>
<li>如果某个节点被指定为接受请求的节点，那么该节点被称为协调节点（coordinating  node）</li>
<li>为了后续更好的扩展负载，一般使用轮询机制遍历集群中的所有节点。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303019.png" alt="img" loading="lazy"></figure>
<h4 id="新建删除文档">新建/删除文档</h4>
<p>新建与删除操作需要在主节点操作结束后，才能同步至副本分片中，如下所示：</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303020.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送新建，删除请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3上的请求执行成功后，它会将请求并行地转发至NODE1与NODE2上的副本分片。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>额外参数补充：</p>
<ul>
<li>consistency：一致性。此参数默认配置下进行写操作时，主分片会要求集群中的大部分（规定数量（quorum））分片副本处于活跃可用状态，否则将不会进行写操作。如此设置的目的是为了防止出现网络分区故障时，写操作出现数据不一致的现象。</li>
<li>规定数量公式：int((primary + number_of_replicas)/2) + 1；其中number_of_replicas指的是设置索引时对应的副本分片数，且只有该值大于1时，规定数量设置才会生效（因为单节点默认配置会影响写操作）。</li>
<li>consistency参数值：one 表示主分片状态ok即可执行写操作；all 表示主分片及所有副本分片都ok才能进行写操作；quorum 默认设置，表示副本分片达到规定数量即可执行写操作。</li>
</ul>
<h4 id="更新文档">更新文档</h4>
<p>更新操作相较于新建/删除多了一个额外的冲突重试步骤，如下图所示；</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303021.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3从主分片搜索对应的文档数据，修改_source中的内容，并重新存储至主分片上。如果此过程中，文档被另一个进程修改，那么步骤3将会重复执行，直到retry_on_conflict次后放弃。</li>
<li>NODE3上的请求执行成功后，它会将新版本的文档并行地转发至NODE1与NODE2上的副本分片，重新建立索引。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>注意：主分片并不会将更改请求转发至副本分片，而是将新版本的文档完整的转发过去，且不保证顺序。如果ES转发更改请求，那么由于顺序的不一致，可能导致文档更新有误，从而使错误的数据存储下来。</p>
<h4 id="检索文档">检索文档</h4>
<p>ES可以从主分片或者副本分片中得到需要搜素的文档，如下图所示：</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303022.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，分片P0的副本分片存在所有节点上，在这种情况下（轮询机制），它将请求转发至NODE2。</li>
<li>NODE2将文档返回给NODE1，NODE1再将文档返回给客户端。</li>
</ol>
<p>注意：在处理读请求时，协调节点在每次请求时都会通过轮询机制遍历所有节点来达到负载均衡。这也是步骤2会从NODE2获取数据的原因。</p>
<p>在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p>
<h4 id="批量操作文档">批量操作文档</h4>
<p>ES批量操作与单文档操作基本一致。区别在于协调节点会将整个文档分解为每个分片的多文档请求，并将这些请求转发至每个参与节点。</p>
<p>使用单个 mget 请求取回多个文档所需的步骤顺序：</p>
<ol>
<li>客户端向 Node 1 发送 mget 请求。</li>
<li>Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303023.png" alt="img" loading="lazy"></figure>
<p>bulk API 操作步骤：</p>
<ol>
<li>客户端向 Node 1 发送 bulk 请求。</li>
<li>Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303024.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CPU飙升问题排查]]></title>
        <id>https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/</id>
        <link href="https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/">
        </link>
        <updated>2022-02-05T03:13:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述运行中的Java程序导致的CPU飙升问题排查过程和方法。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hot-air-balloon-1756150_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="cpu飙升问题排查">CPU飙升问题排查</h2>
<h3 id="问题描述">问题描述</h3>
<p>线上系统突然运行缓慢，CPU飙升，甚至到100%，以及Full GC次数过多，接着就是各种报警：例如接口超时报警等。此时急需快速线上排查问题。</p>
<h3 id="问题排查">问题排查</h3>
<p>不管什么问题，既然是CPU飙升，肯定是查一下耗CPU的线程，然后看看GC。</p>
<h4 id="排查步骤">排查步骤</h4>
<ol>
<li>执行“top”命令：查看所有进程占系统CPU的排序。极大可能排第一个的就是咱们的java进程（COMMAND列，也可以直接使用top -p <code>pgrep -d,java</code>查看系统中JAVA进程的CPU占用情况）。PID那一列就是进程号。</li>
<li>执行“top -Hp 进程号”命令：查看java进程下的所有线程占CPU的情况。</li>
<li>执行“printf &quot;%x\n 10&quot;命令 ：后续查看线程堆栈信息展示的都是十六进制，为了找到咱们的线程堆栈信息，咱们需要把线程号转成16进制。例如,printf &quot;%x\n 10-》打印：a，那么在jstack中线程号就是0xa.</li>
<li>执行 “jstack 进程号 | grep 线程ID” 查找某进程下-》线程ID（jstack堆栈信息中的nid）=0xa的线程堆栈信息。如果“&quot;VM Thread&quot; os_prio=0 tid=0x00007f871806e000 nid=0xa runnable”，第一个双引号圈起来的就是线程名，如果是“VM Thread”这就是虚拟机GC回收线程了</li>
<li>执行“jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一次统计）”，查看某进程GC持续变化情况，如果发现返回中FGC很大且一直增大-》确认Full GC! 也可以使用“jmap -heap 进程ID”查看一下进程的堆内存是不是要溢出了，特别是老年代内存使用情况，一般是达到阈值(具体看垃圾回收器和启动时配置的阈值)进程就会Full GC。</li>
<li>执行“jmap -dump:format=b,file=filename 进程ID”，导出某进程下内存heap输出到文件中。可以通过jvisualvm查看（直接双击打开jvisualvm.exe，点击文件-&gt;装入，在文件类型那一栏选择堆，选择要分析的dump文件，打开）。</li>
</ol>
<p>注意：jmap会导致JVM的停止（您的应用程序已停止。获得准确的堆转储的唯一实用方法是在创建转储时停止所有应用程序活动。这是“简短”暂停还是“长时间”暂停取决于要转储多少。如果使用“ -dump”，则将转储整个堆，包括不可达的对象。如果使用“-dump：live”，则只会转储可访问的对象……但这（至少）需要标记堆以找出可访问的对象。但是，如果要转储千兆字节大小的堆，则期望暂停时间以分钟而不是秒为单位。）。</p>
<h4 id="原因分析">原因分析</h4>
<h5 id="内存消耗过大导致full-gc次数过多">内存消耗过大，导致Full GC次数过多</h5>
<p>执行步骤1-5：</p>
<ul>
<li>多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程-》上一节步骤2</li>
<li>通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。--》上一节步骤5</li>
</ul>
<p>确定是Full GC,接下来找到具体原因：</p>
<ul>
<li>生成大量的对象，导致内存溢出-》执行步骤6，查看具体内存对象占用情况。</li>
<li>内存占用不高，但是Full GC次数还是比较多，此时可能是代码中手动调用 System.gc()导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。</li>
</ul>
<h5 id="代码中有大量消耗cpu的操作导致cpu过高系统运行缓慢">代码中有大量消耗CPU的操作，导致CPU过高，系统运行缓慢；</h5>
<p>执行步骤1-4：在步骤4jstack，可直接定位到代码行。例如某些复杂算法，甚至算法BUG，无限循环递归等等。</p>
<h5 id="由于锁使用不当导致死锁">由于锁使用不当，导致死锁。</h5>
<p>执行步骤1-4： 如果有死锁，会直接提示。关键字：deadlock.步骤四，会打印出业务死锁的位置。</p>
<p>造成死锁的原因：最典型的就是2个线程互相等待对方持有的锁。</p>
<h5 id="随机出现大量线程访问接口缓慢">随机出现大量线程访问接口缓慢。</h5>
<p>代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；平时消耗的CPU不多，而且占用的内存也不高。</p>
<p>思路：首先找到该接口，通过压测工具不断加大访问力度，大量线程将阻塞于该阻塞点。</p>
<p>执行步骤1-4，如下，找到业务代码阻塞点，这里业务代码使用了TimeUnit.sleep()方法，使线程进入了TIMED_WAITING(期限等待)状态。</p>
<pre><code>&quot;http-nio-8080-exec-4&quot; #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)-》期限等待
 at java.lang.Thread.sleep(Native Method)
 at java.lang.Thread.sleep(Thread.java:340)
 at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
 at com.*.user.controller.UserController.detail(UserController.java:18)-》业务代码阻塞点
</code></pre>
<h5 id="某个线程由于某种原因而进入waiting状态此时该功能整体不可用但是无法复现">某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；</h5>
<p>执行步骤1-4：jstack多查询几次，每次间隔30秒，对比一直停留在parking 导致的WAITING状态的线程。例如CountDownLatch倒计时器，使得相关线程等待-&gt;AQS-&gt;LockSupport.park()。</p>
<pre><code>&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000]
java.lang.Thread.State: WAITING (parking) -&gt;无期限等待
at sun.misc.Unsafe.park(Native Method)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
at com.*.SyncTask.lambda$main$0(SyncTask.java:8)-》业务代码阻塞点
at com.*.SyncTask$$Lambda$1/1791741888.run(Unknown Source)
at java.lang.Thread.run(Thread.java:748)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zabbix5.4采集日志进行钉钉告警]]></title>
        <id>https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/</id>
        <link href="https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/">
        </link>
        <updated>2022-01-22T02:28:06.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述zabbix5.4采集日志进行钉钉告警</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/landscape-1192669_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="配置钉钉机器人">配置钉钉机器人</h2>
<p>电脑版钉钉，选中对应的钉钉群，点击群设置---&gt;智能群助手---&gt;添加机器人---&gt;自定义---&gt;添加。</p>
<p>安全设置根据需要自行选择（演示选择的是自定义关键词），需要记住对应的Webhook（用作python脚本调接口使用）</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302016.png" alt="img" loading="lazy"></figure>
<h2 id="配置zabbix">配置zabbix</h2>
<h3 id="zabbix-server配置">zabbix-server配置</h3>
<p>使用命令查找对应的告警配置文件目录。</p>
<pre><code>cat /etc/zabbix/zabbix_server.conf | grep AlertScripts
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303001.png" alt="" loading="lazy"></figure>
<pre><code>find / -name alertscripts
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303002.png" alt="" loading="lazy"></figure>
<p>找到告警目录后，使用cd命令，切入该目录，并执行vi dingding.py。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303003.png" alt="" loading="lazy"></figure>
<p>dingding.py内容如下（钉钉文档：<a href="https://developers.dingtalk.com/document/app/custom-robot-access">点击此处跳转页面</a>）</p>
<pre><code>#!/usr/bin/env python3.8
#coding:utf-8
#zabbix dingding alert
import requests,json,sys,os,datetime
webhook=&quot;https://oapi.dingtalk.com/robot/send?access_token=******&quot;
user=sys.argv[1]
text=sys.argv[3]
data={
    &quot;msgtype&quot;: &quot;text&quot;,
    &quot;text&quot;: {
        &quot;content&quot;: text
    },
    &quot;at&quot;: {
        &quot;atMobiles&quot;: [
            user
        ],
        &quot;isAtAll&quot;: False
    }
}
headers = {'Content-Type': 'application/json'}
x=requests.post(url=webhook,data=json.dumps(data),headers=headers)
print(x.status_code)
print(x.text)

</code></pre>
<p>注意：代码的第一句（#!/usr/bin/env python3.8）中的 python3.8取决于系统安装的python版本，使用whereis  python进行查看。</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303004.png" alt="" loading="lazy"></figure>
<p>随后使用如下命令进行权限设置（如若未设置，将无法执行脚本文件）</p>
<pre><code>[root@localhost alertscripts]# chmod 755 dingding.py 
[root@localhost alertscripts]# chown zabbix.zabbix dingding.py

</code></pre>
<p>测试时，前两个参数，随便填，最后的文本内容需要加上在钉钉机器人配置时设置的关键词。</p>
<pre><code>[root@localhost alertscripts]# ./dingding.py 123 wrq &quot;{monitor,test}&quot;
200
{&quot;errcode&quot;:0,&quot;errmsg&quot;:&quot;ok&quot;}
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303005.png" alt="" loading="lazy"></figure>
<p>问题：可能出现一些安装包不存在，比如requests，使用pip3 list 查看安装了哪些包。如果没有安装requests，可以执行pip3 install requests进行安装。</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303006.png" alt="img" loading="lazy"></figure>
<h3 id="zabbix-web配置">zabbix-web配置</h3>
<h4 id="在已添加的主机上在创建一个监控项">在已添加的主机上在创建一个监控项</h4>
<p>logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,]<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件进行日志信息采集。</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303007.png" alt="img" loading="lazy"></figure>
<h4 id="在已添加的主机上在创建一个触发器">在已添加的主机上在创建一个触发器</h4>
<p>find(/zabbix-agent/logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,],#10,,&quot;HIGH&quot;)=1<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件中的HIGH字段进行告警触发。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303008.png" alt="img" loading="lazy"></figure>
<h4 id="在管理界面添加一个媒体类型">在管理界面添加一个媒体类型</h4>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303009.png" alt="img" loading="lazy"></figure>
<h4 id="在配置界面的动作操作中添加一个触发器动作">在配置界面的动作操作中添加一个触发器动作</h4>
<p>条件选择触发器名称匹配。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303010.png" alt="" loading="lazy"></figure>
<p>随后点击操作</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303011.png" alt="" loading="lazy"></figure>
<pre><code>配置信息如下：
业务告警（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303012.png" alt="" loading="lazy"></figure>
<pre><code>故障恢复（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303013.png" alt="" loading="lazy"></figure>
<p>上述操作中，需要注意的是Send to users选项，该选项对应的值需与媒体类型关联。比如上面选择的用户是Admin，那么需要在管理界面选择用户Admin进行媒体类型的添加。</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303014.png" alt="" loading="lazy"></figure>
<h4 id="拼接地址调转zabbix指定界面">拼接地址调转zabbix指定界面</h4>
<pre><code>// 拼接地址调转zabbix指定界面
String t = &quot;http://localhost:8096/index.php?request=zabbix.php%3Faction%3Dhost.dashboard.view%26hostid%3D10435&amp;name=Admin&amp;password=zabbix&amp;autologin=1&amp;enter=Sign+in&quot;;
</code></pre>
]]></content>
    </entry>
</feed>