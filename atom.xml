<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://philosopherzb.github.io</id>
    <title>Philosopher</title>
    <updated>2023-03-20T07:42:28.299Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://philosopherzb.github.io"/>
    <link rel="self" href="https://philosopherzb.github.io/atom.xml"/>
    <subtitle>WORLD AS CODE</subtitle>
    <logo>https://philosopherzb.github.io/images/avatar.png</logo>
    <icon>https://philosopherzb.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Philosopher</rights>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之主从机制]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-zhu-cong-ji-zhi/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-zhu-cong-ji-zhi/">
        </link>
        <updated>2022-11-19T05:55:18.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之主从机制。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/reservoir-50681_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="主从复制">主从复制</h2>
<h3 id="简介">简介</h3>
<p>为了提供消息消费的高可用性，避免broker单点故障导致其上的消息无法及时消费，rocketmq引入了broker主备机制，即消息到达主服务器后需要同步至从服务器；这样，如果主服务器broker宕机了，消费者依然可以从slave服务器拉取消息。</p>
<p>rocketmq高可用相关类如下所示：</p>
<ul>
<li>HAService: RocketMQ 主从同步核心实现类</li>
<li>HAService$AcceptSocketService : HA Master 端监听客户端连接实现类</li>
<li>HAService$GroupTransferService ：主从同步通知实现类。</li>
<li>HAService$HAClient: HA Client 端实现类。</li>
<li>HA Connection: HA Master 服务端 HA 连接对象的封装，与 Broker 从服务器的网络读写类</li>
<li>HAConnection$ReadSocketService: HA Master 网络读实现类</li>
<li>HAConnection$WriteSocketServicce: HA Master 网络写实现类</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320012.png" alt="img" loading="lazy"></figure>
<h3 id="haservice工作机制">HAService工作机制</h3>
<p>高可用的核心处理类HAService，本节主要介绍其启动加载内容。rocketmq HA 的大致实现原理如下：</p>
<ol>
<li>主服务器启动，并在特定端口监听从服务器的连接。</li>
<li>从服务器主动连接主服务器，主服务器接受客户端的连接，并建立相应的tcp连接。</li>
<li>从服务器主动向主服务器发送待拉取消息的偏移量，主服务器解析请求并返回消息给从服务器。</li>
<li>从服务器保存消息，并不断发送新的消息同步请求。</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320013.png" alt="" loading="lazy"></figure>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService
// ha 服务启动
public void start() throws Exception {
    this.acceptSocketService.beginAccept();
    this.acceptSocketService.start();
    this.groupTransferService.start();
    this.haClient.start();
}

</code></pre>
<h3 id="acceptsocketservice">AcceptSocketService</h3>
<p>AcceptSocketService 是 HAService的内部类，主要负责实现master端监听salve连接。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#AcceptSocketService 
public void beginAccept() throws Exception {
    // 创建服务端socket通道，基于NIO
    this.serverSocketChannel = ServerSocketChannel.open();
    // 创建selector--》事件选择器，基于NIO
    this.selector = RemotingUtil.openSelector();
    this.serverSocketChannel.socket().setReuseAddress(true);
    // 绑定监听端口
    this.serverSocketChannel.socket().bind(this.socketAddressListen);
    // 设置非阻塞
    this.serverSocketChannel.configureBlocking(false);
    // 以OP_ACCEPT（网络连接事件）进行注册
    this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#AcceptSocketService 
public void run() {
    log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        try {
            // 每隔1s处理一次连接就绪事件
            this.selector.select(1000);
            Set&lt;SelectionKey&gt; selected = this.selector.selectedKeys();

            if (selected != null) {
                for (SelectionKey k : selected) {
                    if ((k.readyOps() &amp; SelectionKey.OP_ACCEPT) != 0) {
                        // 创建一个SocketChannel
                        SocketChannel sc = ((ServerSocketChannel) k.channel()).accept();

                        if (sc != null) {
                            HAService.log.info(&quot;HAService receive new connection, &quot;
                                + sc.socket().getRemoteSocketAddress());

                            try {
                                // 同时为每个连接创建一个HAConnection ，主要负责M-S数据同步逻辑
                                HAConnection conn = new HAConnection(HAService.this, sc);
                                conn.start();
                                HAService.this.addConnection(conn);
                            } catch (Exception e) {
                                log.error(&quot;new HAConnection exception&quot;, e);
                                sc.close();
                            }
                        }
                    } else {
                        log.warn(&quot;Unexpected ops in select &quot; + k.readyOps());
                    }
                }

                selected.clear();
            }
        } catch (Exception e) {
            log.error(this.getServiceName() + &quot; service has exception.&quot;, e);
        }
    }

    log.info(this.getServiceName() + &quot; service end&quot;);
}

</code></pre>
<h3 id="grouptransferservice">GroupTransferService</h3>
<p>GroupTransferService是 HAService的内部类，主要负责主从同步阻塞。在主从同步中，消息发送者将消息刷盘后，需要继续等待新消息被传输到从服务器，即需要等待数据主从同步的结果。而在这个同步过程中便需要用到GroupTransferService进行阻塞处理。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#GroupTransferService
private void doWaitTransfer() {
    if (!this.requestsRead.isEmpty()) {
        for (CommitLog.GroupCommitRequest req : this.requestsRead) {
            boolean transferOK = HAService.this.push2SlaveMaxOffset.get() &gt;= req.getNextOffset();
            long deadLine = req.getDeadLine();
            while (!transferOK &amp;&amp; deadLine - System.nanoTime() &gt; 0) {
                this.notifyTransferObject.waitForRunning(1000);
                 // 同步完成的判断依据：salve中已复制的最大偏移量是否大于等于生产者发送消息后服务端返回的下一条消息的起始偏移量 
                transferOK = HAService.this.push2SlaveMaxOffset.get() &gt;= req.getNextOffset();
            }
            // 根据上述同步判断来决定是否唤醒发送者线程
            req.wakeupCustomer(transferOK ? PutMessageStatus.PUT_OK : PutMessageStatus.FLUSH_SLAVE_TIMEOUT);
        }

        this.requestsRead = new LinkedList&lt;&gt;();
    }
}

</code></pre>
<h3 id="haclient">HAClient</h3>
<p>HAClient是主从同步slave端的核心实现类。以下从其run函数开始分析其工作原理。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#HAClient
// 首先，salve服务器需要与master服务器进行连接
private boolean connectMaster() throws ClosedChannelException {
    // 当socketChannel为空时尝试连接master
    if (null == socketChannel) {
        // 获取master服务器地址
        String addr = this.masterAddress.get();
        if (addr != null) {
             // 将master地址转为socket地址  
            SocketAddress socketAddress = RemotingUtil.string2SocketAddress(addr);
            if (socketAddress != null) {
                // 创建socket通道
                this.socketChannel = RemotingUtil.connect(socketAddress);
                if (this.socketChannel != null) {
                    // 以OP_READ（网络读事件）注册
                    this.socketChannel.register(this.selector, SelectionKey.OP_READ);
                }
            }
        }
        // 初始化currentReportedOffset为commitlog文件的最大偏移量
        this.currentReportedOffset = HAService.this.defaultMessageStore.getMaxPhyOffset();
        // 上次写入时间戳的值设置为当前时间戳
        this.lastWriteTimestamp = System.currentTimeMillis();
    }

    return this.socketChannel != null;
}

// 是否将当前待拉取偏移量反馈给master，默认心跳间隔5s，可通过haSendHeartbeatInterval进行配置
private boolean isTimeToReportOffset() {
    long interval =
        HAService.this.defaultMessageStore.getSystemClock().now() - this.lastWriteTimestamp;
    boolean needHeart = interval &gt; HAService.this.defaultMessageStore.getMessageStoreConfig()
        .getHaSendHeartbeatInterval();

    return needHeart;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#HAClient
// 向master反馈待拉取偏移量
// 此函数包含两种含义：对于salve而言是发送下次待拉取偏移量；
// 对master而言既可以认为是salve本次请求的待拉取偏移量，也可以认为是salve消息同步的ACK确认消息
private boolean reportSlaveMaxOffset(final long maxOffset) {
    // 读写模式切换，或许可以使用ByteBuffer的flip函数来实现
    this.reportOffset.position(0);
    this.reportOffset.limit(8);
    this.reportOffset.putLong(maxOffset);
    this.reportOffset.position(0);
    this.reportOffset.limit(8);

    // 此处循环写入的原因是由于NIO是一个非阻塞IO，一次写入不一定会将ByteBuffer可读字节全部写入 
    for (int i = 0; i &lt; 3 &amp;&amp; this.reportOffset.hasRemaining(); i++) {
        try {
            this.socketChannel.write(this.reportOffset);
        } catch (IOException e) {
            log.error(this.getServiceName()
                + &quot;reportSlaveMaxOffset this.socketChannel.write exception&quot;, e);
            return false;
        }
    }

    lastWriteTimestamp = HAService.this.defaultMessageStore.getSystemClock().now();
    return !this.reportOffset.hasRemaining();
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAService#HAClient
// 处理网络读请求，即master返回的消息
private boolean processReadEvent() {
    int readSizeZeroTimes = 0;
    // 循环判断readByteBuffer是否还有剩余空间
    while (this.byteBufferRead.hasRemaining()) {
        try {
            // 获取读字节数
            int readSize = this.socketChannel.read(this.byteBufferRead);
            if (readSize &gt; 0) {
                // 重置读取到0字节的次数
                readSizeZeroTimes = 0;
                // 将读取到的所有消息追加到内存映射文件中
                boolean result = this.dispatchReadRequest();
                if (!result) {
                    log.error(&quot;HAClient, dispatchReadRequest error&quot;);
                    return false;
                }
            } else if (readSize == 0) {
                if (++readSizeZeroTimes &gt;= 3) {
                    break;
                }
            } else {
                log.info(&quot;HAClient, processReadEvent read socket &lt; 0&quot;);
                return false;
            }
        } catch (IOException e) {
            log.info(&quot;HAClient, processReadEvent read socket exception&quot;, e);
            return false;
        }
    }

    return true;
}

</code></pre>
<h3 id="haconnection">HAConnection</h3>
<p>Master服务器接收到Salve服务器的请求后，会将主从服务器的连接封装成 HAConnection 对象，以此来实现主从服务器之间的读写操作。下面主要分析其读写操作源码。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAConnection#ReadSocketService
// 读操作核心处理函数processReadEvent
private boolean processReadEvent() {
    int readSizeZeroTimes = 0;
    // 如果readByteBuffer没有剩余空间，说明position=limit=capacity
    if (!this.byteBufferRead.hasRemaining()) {
        // flip函数将会让position=0，limit=capacity
        this.byteBufferRead.flip();
        // 设置processPosition 为0，表示从头开始处理
        this.processPosition = 0;
    }
    // 循环读取 
    while (this.byteBufferRead.hasRemaining()) {
        try {
            int readSize = this.socketChannel.read(this.byteBufferRead);
            if (readSize &gt; 0) {
                readSizeZeroTimes = 0;
                this.lastReadTimestamp = HAConnection.this.haService.getDefaultMessageStore().getSystemClock().now();
                // 存在读数据且本次读取内容大于8，说明收到了从服务器的一条拉取消息请求
                if ((this.byteBufferRead.position() - this.processPosition) &gt;= 8) {
                    int pos = this.byteBufferRead.position() - (this.byteBufferRead.position() % 8);
                    long readOffset = this.byteBufferRead.getLong(pos - 8);
                    this.processPosition = pos;

                    HAConnection.this.slaveAckOffset = readOffset;
                    if (HAConnection.this.slaveRequestOffset &lt; 0) {
                        HAConnection.this.slaveRequestOffset = readOffset;
                        log.info(&quot;slave[&quot; + HAConnection.this.clientAddr + &quot;] request offset &quot; + readOffset);
                    } else if (HAConnection.this.slaveAckOffset &gt; HAConnection.this.haService.getDefaultMessageStore().getMaxPhyOffset()) {
                        log.warn(&quot;slave[{}] request offset={} greater than local commitLog offset={}. &quot;,
                                HAConnection.this.clientAddr,
                                HAConnection.this.slaveAckOffset,
                                HAConnection.this.haService.getDefaultMessageStore().getMaxPhyOffset());
                        return false;
                    }
                    // 通知由于同步等待HA复制结果而阻塞的消息发送线程
                    HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset);
                }
            } else if (readSize == 0) {
                // 读取字节数等于0，重复执行三次
                if (++readSizeZeroTimes &gt;= 3) {
                    break;
                }
            } else {
                // 结束本次循环，服务器将关闭该连接
                log.error(&quot;read socket[&quot; + HAConnection.this.clientAddr + &quot;] &lt; 0&quot;);
                return false;
            }
        } catch (IOException e) {
            log.error(&quot;processReadEvent exception&quot;, e);
            return false;
        }
    }

    return true;
}
</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.ha.HAConnection#WriteSocketService
// 写操作核心处理函数run
public void run() {
    HAConnection.log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        try {
            // 每1秒都会执行一次写操作
            this.selector.select(1000);
            // slaveRequestOffset=-1，表示master还未收到salve的请求，将跳过本次循环
            if (-1 == HAConnection.this.slaveRequestOffset) {
                Thread.sleep(10);
                continue;
            }
            // nextTransferFromWhere=-1，表示初次进行数据传输
            if (-1 == this.nextTransferFromWhere) {
                // 当slaveRequestOffset=0时，会从当前commitlog文件获取最大偏移量
                // nextTransferFromWhere 表示下次数据传输点
                if (0 == HAConnection.this.slaveRequestOffset) {
                    long masterOffset = HAConnection.this.haService.getDefaultMessageStore().getCommitLog().getMaxOffset();
                    masterOffset =
                        masterOffset
                            - (masterOffset % HAConnection.this.haService.getDefaultMessageStore().getMessageStoreConfig()
                            .getMappedFileSizeCommitLog());

                    if (masterOffset &lt; 0) {
                        masterOffset = 0;
                    }
                    // 赋值给nextTransferFromWhere 
                    this.nextTransferFromWhere = masterOffset;
                } else {
                    // 否则将从服务器拉取偏移量赋值给nextTransferFromWhere 
                    this.nextTransferFromWhere = HAConnection.this.slaveRequestOffset;
                }

                log.info(&quot;master transfer data from &quot; + this.nextTransferFromWhere + &quot; to slave[&quot; + HAConnection.this.clientAddr
                    + &quot;], and slave request &quot; + HAConnection.this.slaveRequestOffset);
            }
            // 判断上次写事件是否将消息全部写入客户端
            if (this.lastWriteOver) {
                // 获取当前系统时间与上次最后写入时间的差值
                long interval =
                    HAConnection.this.haService.getDefaultMessageStore().getSystemClock().now() - this.lastWriteTimestamp;
                // 如果该差值大于HA心跳间隔，HA心跳间隔由haSendHeartbeatInterval控制，默认5s
                if (interval &gt; HAConnection.this.haService.getDefaultMessageStore().getMessageStoreConfig()
                    .getHaSendHeartbeatInterval()) {

                    // Build Header
                    this.byteBufferHeader.position(0);
                    this.byteBufferHeader.limit(headerSize);
                    this.byteBufferHeader.putLong(this.nextTransferFromWhere);
                    this.byteBufferHeader.putInt(0);
                    this.byteBufferHeader.flip();
                    // 此处将发送一个心跳包，主要是为了避免长链接由于空闲而被关闭
                    this.lastWriteOver = this.transferData();
                    if (!this.lastWriteOver)
                        continue;
                }
            } else {
                // 未写入，则继续传输上一次数据
                this.lastWriteOver = this.transferData();
                // 如果消息仍未传输完成，则终止此次循环
                if (!this.lastWriteOver)
                    continue;
            }
            // 传输消息到从服务器
            // 根据从服务器请求的待拉取偏移量，查找该偏移量之后的所有可读数据
            SelectMappedBufferResult selectResult =
                HAConnection.this.haService.getDefaultMessageStore().getCommitLogData(this.nextTransferFromWhere);
            // 存在可读数据
            if (selectResult != null) {
                // 判断消息总长度是否大于HA配置的一次同步任务最大传输字节数，如果是的话，消息将会被截取，进行部分发送
                int size = selectResult.getSize();
                // HA一次同步任务最大字节数由haTransferBatchSize控制，默认32k
                if (size &gt; HAConnection.this.haService.getDefaultMessageStore().getMessageStoreConfig().getHaTransferBatchSize()) {
                    size = HAConnection.this.haService.getDefaultMessageStore().getMessageStoreConfig().getHaTransferBatchSize();
                }

                long thisOffset = this.nextTransferFromWhere;
                this.nextTransferFromWhere += size;
                // 限制传输大小
                selectResult.getByteBuffer().limit(size);
                this.selectMappedBufferResult = selectResult;

                // Build Header
                this.byteBufferHeader.position(0);
                this.byteBufferHeader.limit(headerSize);
                this.byteBufferHeader.putLong(thisOffset);
                this.byteBufferHeader.putInt(size);
                this.byteBufferHeader.flip();
                // 传输数据 
                this.lastWriteOver = this.transferData();
            } else {
                // 未匹配到数据时，通知所有线程等待100ms
                HAConnection.this.haService.getWaitNotifyObject().allWaitForRunning(100);
            }
        } catch (Exception e) {

            HAConnection.log.error(this.getServiceName() + &quot; service has exception.&quot;, e);
            break;
        }
    }
     // 将等待线程移除 
    HAConnection.this.haService.getWaitNotifyObject().removeFromWaitingThreadTable();
    if (this.selectMappedBufferResult != null) {
        this.selectMappedBufferResult.release();
    }
    this.makeStop();
    readSocketService.makeStop();
    haService.removeConnection(HAConnection.this);
    SelectionKey sk = this.socketChannel.keyFor(this.selector);
    if (sk != null) {
        sk.cancel();
    }
    try {
        // 关闭socket
        this.selector.close();
        this.socketChannel.close();
    } catch (IOException e) {
        HAConnection.log.error(&quot;&quot;, e);
    }

    HAConnection.log.info(this.getServiceName() + &quot; service end&quot;);
}

</code></pre>
<h2 id="读写分离">读写分离</h2>
<h3 id="简介-2">简介</h3>
<p>本节主要介绍消费者拉取消息时，从服务器如何参与负载，即主写从读机制。</p>
<p>RocketMQ根据MessageQueue查找broker地址的唯一依据时brokerName，从RocketMQ的的broker组织结构中得知同一组broker(M-S)服务器，它们的brokerName相同，但是brokerId不同，主服务器的brokerId为0，从服务器的则大于0。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.PullAPIWrapper#pullKernelImpl
// 提供基于brokeName获取broker信息的函数
FindBrokerResult findBrokerResult =
    this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(),
        this.recalculatePullFromWhichNode(mq), false);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.factory.MQClientInstance
public FindBrokerResult findBrokerAddressInSubscribe(
    final String brokerName,
    final long brokerId,
    // 是否仅返回broker信息
    final boolean onlyThisBroker
) {
    String brokerAddr = null;
    boolean slave = false;
    boolean found = false;
    // 从缓存表中获取broker信息
    HashMap&lt;Long/* brokerId */, String/* address */&gt; map = this.brokerAddrTable.get(brokerName);
    if (map != null &amp;&amp; !map.isEmpty()) {
        // 通过brokerId获取broker地址信息
        brokerAddr = map.get(brokerId);
        slave = brokerId != MixAll.MASTER_ID;
        found = brokerAddr != null;
        // 未找到且salve为true，则获取 brokerId + 1 的 brokerAddr 
        if (!found &amp;&amp; slave) {
            brokerAddr = map.get(brokerId + 1);
            found = brokerAddr != null;
        }
        // 未找到且onlyThisBroker设置为false，则从列表中随机选一个brokerAddr
        if (!found &amp;&amp; !onlyThisBroker) {
            Entry&lt;Long, String&gt; entry = map.entrySet().iterator().next();
            brokerAddr = entry.getValue();
            slave = entry.getKey() != MixAll.MASTER_ID;
            found = true;
        }
    }

    if (found) {
        // 组装返回FindBrokerResult，其中的salve表示是否从从服务求获取broker结果信息
        return new FindBrokerResult(brokerAddr, slave, findBrokerVersion(brokerName, brokerAddr));
    }

    return null;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#getMessage
// maxOffsetPy：当前主服务器存储文件的最大偏移量
// maxPhyOffsetPulling：此次拉取消息的最大偏移量
// diff：对于拉取线程而言，则是当前未被拉取到消费者端的消息长度
long diff = maxOffsetPy - maxPhyOffsetPulling;
// TOTAL_PHYSICAL_MEMORY_SIZE：rocketmq所在服务器的总内存大小
// AccessMessageInMemoryMaxRatio：rocketmq所能使用的最大内存比例，超过该比例，消息会被置换出内存
// memory：消息常驻内存的大小，超过该大小，rocketmq会将旧的消息置换回磁盘
// 如果diff &gt; memory，表示当前需要拉取的消息已经超过了常驻内存的大小，此时一般是主服务器繁忙，会建议从从服务器拉取消息
long memory = (long) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE
    * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0));
getResult.setSuggestPullingFromSlave(diff &gt; memory);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.broker.processor.PullMessageProcessor#processRequest
// 如果主服务器繁忙，则下次将从从服务器拉取消息。
if (getMessageResult.isSuggestPullingFromSlave()) {
    // 设值SuggestWhichBrokerId的值为配置文件中的whichBrokerWhenConsumeSlowly属性，默认为1
    // 一个master即使拥有多个salve，消息负载时也只会选择其中一个salve
    responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly());
} else {
    responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之消息消费(下)]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-xiao-fei-xia/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-xiao-fei-xia/">
        </link>
        <updated>2022-11-05T05:45:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之消息消费下篇。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-4810958_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="消息消费">消息消费</h2>
<h3 id="消费过程">消费过程</h3>
<p>在上篇文章中，PullMessageService负责消息拉取，并将其存入ProcessQueue队列中，随后便通过ConsumeMessageService#submitConsumeRequest将其提交至消费者线程池进行具体的消费处理。在整个消费过程中，消息拉取与消息消费实现了解耦。</p>
<p>ConsumeMessageService提供了两种实现，并发消费及顺序消费。两种实现大致上的流程一致，不过也存在一些细微的差别，主要在于顺序消息在创建消息队列拉取任务时需要在Broker端锁定消息队列。即在使用顺序消息时需指定MessageQueueSelector。</p>
<p>本节主要以并发消费的源码来简单介绍其中的实现。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.ConsumeMessageService
// 核心函数
void submitConsumeRequest(
    // 消息列表，默认一次从服务器最多拉取32条
    final List&lt;MessageExt&gt; msgs,
    // 消息处理队列
    final ProcessQueue processQueue,
    // 消息所属的消息队列
    final MessageQueue messageQueue,
    // 是否转发至消费线程池，并发消费时此参数可忽略
    final boolean dispathToConsume);

</code></pre>
<h4 id="消息消费-2">消息消费</h4>
<p>消费者并发消费的核心函数在ConsumeMessageConcurrentlyService#submitConsumeRequest，具体逻辑如下：</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService
public void submitConsumeRequest(
    final List&lt;MessageExt&gt; msgs,
    final ProcessQueue processQueue,
    final MessageQueue messageQueue,
    final boolean dispatchToConsume) {
    // 消息批次，默认为1  
    final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize();
     // msgs.size()默认为32条，受DefaultMQPushConsumer#pullBatchSize属性控制
    // 当 msgs.size()小于等于consumeBatchSize 
    if (msgs.size() &lt;= consumeBatchSize) {
        // 将提交消息放入ConsumeRequest 
        ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue);
        try {
            // 提交至消费者线程池
            this.consumeExecutor.submit(consumeRequest);
        } catch (RejectedExecutionException e) {
            // 提交过程中出现拒绝提交异常，则延迟5秒再提交。
            // consumeExecutor使用的是LinkedBlockingQueue，不设置大小的情况下LinkedBlockingQueue为无界队列，因此一般不会出现拒绝提交异常
            this.submitConsumeRequestLater(consumeRequest);
        }
    } else {
        // 当 msgs.size()大于consumeBatchSize 时，采用分页提交，每页页数为consumeBatchSize
        for (int total = 0; total &lt; msgs.size(); ) {
            List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize);
            for (int i = 0; i &lt; consumeBatchSize; i++, total++) {
                if (total &lt; msgs.size()) {
                    msgThis.add(msgs.get(total));
                } else {
                    break;
                }
            }
            // 将提交消息放入ConsumeRequest 
            ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue);
            try {
                // 提交至消费者线程池
                this.consumeExecutor.submit(consumeRequest);
            } catch (RejectedExecutionException e) {
                for (; total &lt; msgs.size(); total++) {
                    msgThis.add(msgs.get(total));
                }
                // 提交过程中出现拒绝提交异常，则延迟5秒再提交 
                this.submitConsumeRequestLater(consumeRequest);
            }
        }
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService#ConsumeRequest
// 具体的逻辑处理线程类
public void run() {
    // 如果processQueue的dropped设置为true，则停止对该队列的消费操作
    // 在消息队列重平衡期间，此值可能会被设置true
    if (this.processQueue.isDropped()) {
        log.info(&quot;the message queue not be able to consume, because it's dropped. group={} {}&quot;, ConsumeMessageConcurrentlyService.this.consumerGroup, this.messageQueue);
        return;
    }
    // 获取并发消费监听器
    MessageListenerConcurrently listener = ConsumeMessageConcurrentlyService.this.messageListener;
    // 通过messageQueue获取并发消费上下文
    ConsumeConcurrentlyContext context = new ConsumeConcurrentlyContext(messageQueue);
    ConsumeConcurrentlyStatus status = null;
    // 重置重试主题名，当存在重试主题（RETRY_TOPIC）或者namespace时，需要重置主题名
    defaultMQPushConsumerImpl.resetRetryAndNamespace(msgs, defaultMQPushConsumer.getConsumerGroup());

    ConsumeMessageContext consumeMessageContext = null;
    if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) {
        consumeMessageContext = new ConsumeMessageContext();
        consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace());
        consumeMessageContext.setConsumerGroup(defaultMQPushConsumer.getConsumerGroup());
        consumeMessageContext.setProps(new HashMap&lt;String, String&gt;());
        consumeMessageContext.setMq(messageQueue);
        consumeMessageContext.setMsgList(msgs);
        consumeMessageContext.setSuccess(false);
        // 在消息消费之前，执行增强处理逻辑
        ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext);
    }

    long beginTimestamp = System.currentTimeMillis();
    boolean hasException = false;
    ConsumeReturnType returnType = ConsumeReturnType.SUCCESS;
    try {
        if (msgs != null &amp;&amp; !msgs.isEmpty()) {
            for (MessageExt msg : msgs) {
                MessageAccessor.setConsumeStartTimeStamp(msg, String.valueOf(System.currentTimeMillis()));
            }
        }
        // 通过监听器的consumeMessage函数处理具体的消息消费
        status = listener.consumeMessage(Collections.unmodifiableList(msgs), context);
    } catch (Throwable e) {
        log.warn(String.format(&quot;consumeMessage exception: %s Group: %s Msgs: %s MQ: %s&quot;,
            RemotingHelper.exceptionSimpleDesc(e),
            ConsumeMessageConcurrentlyService.this.consumerGroup,
            msgs,
            messageQueue), e);
        hasException = true;
    }
    // 设置返回状态returnType 
    long consumeRT = System.currentTimeMillis() - beginTimestamp;
    if (null == status) {
        if (hasException) {
            returnType = ConsumeReturnType.EXCEPTION;
        } else {
            returnType = ConsumeReturnType.RETURNNULL;
        }
    } else if (consumeRT &gt;= defaultMQPushConsumer.getConsumeTimeout() * 60 * 1000) {
        returnType = ConsumeReturnType.TIME_OUT;
    } else if (ConsumeConcurrentlyStatus.RECONSUME_LATER == status) {
        returnType = ConsumeReturnType.FAILED;
    } else if (ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status) {
        returnType = ConsumeReturnType.SUCCESS;
    }

    if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) {
        consumeMessageContext.getProps().put(MixAll.CONSUME_CONTEXT_TYPE, returnType.name());
    }

    if (null == status) {
        log.warn(&quot;consumeMessage return null, Group: {} Msgs: {} MQ: {}&quot;,
            ConsumeMessageConcurrentlyService.this.consumerGroup,
            msgs,
            messageQueue);
        status = ConsumeConcurrentlyStatus.RECONSUME_LATER;
    }

    if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) {
        consumeMessageContext.setStatus(status.toString());
        consumeMessageContext.setSuccess(ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status);
        // 在消息消费之前，执行增强处理逻辑
        ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext);
    }

    ConsumeMessageConcurrentlyService.this.getConsumerStatsManager()
        .incConsumeRT(ConsumeMessageConcurrentlyService.this.consumerGroup, messageQueue.getTopic(), consumeRT);
    // 执行消息结果处理之前，校验processQueue是否被丢弃；
    // 因为在前述处理步骤中，如果出现消费队列重平衡或原先的消费者宕机而将该队列分配给新的消费者，那么应用程序认为此消息可能会重复消费
    if (!processQueue.isDropped()) {
        ConsumeMessageConcurrentlyService.this.processConsumeResult(status, context, this);
    } else {
        log.warn(&quot;processQueue is dropped without process consume result. messageQueue={}, msgs={}&quot;, messageQueue, msgs);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService
public void processConsumeResult(
    final ConsumeConcurrentlyStatus status,
    final ConsumeConcurrentlyContext context,
    final ConsumeRequest consumeRequest
) {
    // 定义ack返回值 
    int ackIndex = context.getAckIndex();

    if (consumeRequest.getMsgs().isEmpty())
        return;

    switch (status) {
        case CONSUME_SUCCESS:
            // 当ackIndex 大于消息数时，将其值设置为消息数
            if (ackIndex &gt;= consumeRequest.getMsgs().size()) {
                ackIndex = consumeRequest.getMsgs().size() - 1;
            }
            int ok = ackIndex + 1;
            int failed = consumeRequest.getMsgs().size() - ok;
            this.getConsumerStatsManager().incConsumeOKTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), ok);
            this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(), failed);
            break;
        case RECONSUME_LATER:
            // 重试时，需要将其设置为-1，主要是为了下次发送ACK做准备
            ackIndex = -1;
            this.getConsumerStatsManager().incConsumeFailedTPS(consumerGroup, consumeRequest.getMessageQueue().getTopic(),
                consumeRequest.getMsgs().size());
            break;
        default:
            break;
    }

    switch (this.defaultMQPushConsumer.getMessageModel()) {
        case BROADCASTING:
            // 广播模式中，无需发送ACK，并针对重试消息打印失败日志
            for (int i = ackIndex + 1; i &lt; consumeRequest.getMsgs().size(); i++) {
                MessageExt msg = consumeRequest.getMsgs().get(i);
                log.warn(&quot;BROADCASTING, the message consume failed, drop it, {}&quot;, msg.toString());
            }
            break;
        case CLUSTERING:
            // 集群模式
            List&lt;MessageExt&gt; msgBackFailed = new ArrayList&lt;MessageExt&gt;(consumeRequest.getMsgs().size());
            // 消费成功时，ackIndex + 1 = consumeRequest.getMsgs().size()，故不会发送ACK
            // 消息重试消费时，针对每批消息都需要发送ACK给客户端
            for (int i = ackIndex + 1; i &lt; consumeRequest.getMsgs().size(); i++) {
                MessageExt msg = consumeRequest.getMsgs().get(i);
                boolean result = this.sendMessageBack(msg, context);
                // 当ACK消息发送失败时，消息会统计进msgBackFailed
                if (!result) {
                    msg.setReconsumeTimes(msg.getReconsumeTimes() + 1);
                    msgBackFailed.add(msg);
                }
            }
            // 针对msgBackFailed数据，会延迟5s再次进行消费
            if (!msgBackFailed.isEmpty()) {
                consumeRequest.getMsgs().removeAll(msgBackFailed);
                this.submitConsumeRequestLater(msgBackFailed, consumeRequest.getProcessQueue(), consumeRequest.getMessageQueue());
            }
            break;
        default:
            break;
    }

    // 从ProcessQueue中移除该批消息，此处返回的offset为当前队列中的最小偏移量。
    long offset = consumeRequest.getProcessQueue().removeMessage(consumeRequest.getMsgs());
    if (offset &gt;= 0 &amp;&amp; !consumeRequest.getProcessQueue().isDropped()) {
        // 使用上述offset更新消息消费进度，以便消费者重启后能从上一次消费进度开始消费，防止重复消费。
        // 值得注意的是：监听器返回RECONSUME_LATER时，消息消费进度依然会向前推进；
        // 因为当返回RECONSUME_LATER时，rocketmq会创建一条与原先属性完全一致的消息，并生成一个新的msgId，该消息会存入commitlog，这相当于一条全新的消息，自然也拥有全新的offset。
        this.defaultMQPushConsumerImpl.getOffsetStore().updateOffset(consumeRequest.getMessageQueue(), offset, true);
    }
}

</code></pre>
<h4 id="消息确认ack">消息确认（ACK）</h4>
<p>当消息监听器返回的消费结果为RECONSUME_LATER，则需要将这些消息发送给Broker延迟消息。如果ACK发送失败，将延迟5s后提交至线程池继续进行消费。</p>
<pre><code>// 文件地址：org.apache.rocketmq.common.protocol.header.ConsumerSendMsgBackRequestHeader
// ConsumerSendMsgBackRequestHeader核心属性
// 消息物理偏移量
private Long offset;
// 消费组名
private String group;
// 延迟级别，固定为1-18
private Integer delayLevel;
// 原消息id
private String originMsgId;
// 原消息主题
private String originTopic;
// 单位模型
private boolean unitMode = false;
// 最大重消费次数，默认为16次
private Integer maxReconsumeTimes;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.common.subscription.SubscriptionGroupConfig
// 获取消费组的订阅信息，如果不存在将会返回错误 SUBSCRIPTION_GROUP_NOT_EXIST
// 核心属性如下
// 消费组名
private String groupName;
// 是否可消费，默认true
private boolean consumeEnable = true;
// 是否允许从最小offset开始消费，默认true
private boolean consumeFromMinEnable = true;
// 是否能以广播的形式消费，默认true
private boolean consumeBroadcastEnable = true;
// 重试队列数，默认1，即每个broker上一个重试队列
private int retryQueueNums = 1;
// 最大重试次数，默认为16次
private int retryMaxTimes = 16;
// masterId
private long brokerId = MixAll.MASTER_ID;
// 当（主broker）消息阻塞时，将转向该brokerId的服务器上拉取消息，默认为1
private long whichBrokerWhenConsumeSlowly = 1;
// 当消息发送变化时是否立即进行消息队列重平衡
private boolean notifyConsumerIdsChangedEnable = true;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.broker.processor.SendMessageProcessor#asyncConsumerSendMsgBack
// 创建重试主题，格式：%RETRY% + 消费组名
String newTopic = MixAll.getRetryTopic(requestHeader.getGroup());
// 从重试队列中随机选择一个
int queueIdInt = ThreadLocalRandom.current().nextInt(99999999) % subscriptionGroupConfig.getRetryQueueNums();

// 根据ConsumerSendMsgBackRequestHeader中的offset从commitlog中获取消息
MessageExt msgExt = this.brokerController.getMessageStore().lookMessageByOffset(requestHeader.getOffset());
if (null == msgExt) {
    response.setCode(ResponseCode.SYSTEM_ERROR);
    response.setRemark(&quot;look message by offset failed, &quot; + requestHeader.getOffset());
    return CompletableFuture.completedFuture(response);
}
// 获取重试主题
final String retryTopic = msgExt.getProperty(MessageConst.PROPERTY_RETRY_TOPIC);
if (null == retryTopic) {
    MessageAccessor.putProperty(msgExt, MessageConst.PROPERTY_RETRY_TOPIC, msgExt.getTopic());
}
msgExt.setWaitStoreMsgOK(false);

// 当消息次数超过maxReconsumeTimes时，主题名将再次改变，格式：%DLQ% + 消费组名；此主题权限为只写，如需再操作则需人工干预
newTopic = MixAll.getDLQTopic(requestHeader.getGroup());
queueIdInt = ThreadLocalRandom.current().nextInt(99999999) % DLQ_NUMS_PER_GROUP;

// 根据原来的消息创建一条新的内部消息进行存储，此处也对应了上小节的updateOffset操作
MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
msgInner.setTopic(newTopic);
msgInner.setBody(msgExt.getBody());
msgInner.setFlag(msgExt.getFlag());
MessageAccessor.setProperties(msgInner, msgExt.getProperties());
msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties()));
msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(null, msgExt.getTags()));

msgInner.setQueueId(queueIdInt);
msgInner.setSysFlag(msgExt.getSysFlag());
msgInner.setBornTimestamp(msgExt.getBornTimestamp());
msgInner.setBornHost(msgExt.getBornHost());
msgInner.setStoreHost(msgExt.getStoreHost());
msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1);

String originMsgId = MessageAccessor.getOriginMessageId(msgExt);
MessageAccessor.setOriginMessageId(msgInner, UtilAll.isBlank(originMsgId) ? msgExt.getMsgId() : originMsgId);
msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties()));
// 此处的消息重试主要依托于定时机制来实现。
CompletableFuture&lt;PutMessageResult&gt; putMessageResult = this.brokerController.getMessageStore().asyncPutMessage(msgInner);

</code></pre>
<h4 id="消费进度管理">消费进度管理</h4>
<p>当消息被消费完毕后，需要记录其已被消费，以防止出现重复消费。在RocketMQ中消费模式分为广播和集群，因此对应的消费进度也分两种情况。</p>
<ul>
<li>广播模式：同一个消费组下的消费者都需要消费主题下的所有消息，也就是说组内的消费者对于消息的消费行为是彼此独立，互不干扰的。在这种情况下消费进度最好与消费者绑定并独立存储。</li>
<li>集群模式：同一个消费组下的消费者共享主题下的所有消息，同一条消息在同一时间只能被组内的一个消费者消费，并且随着消息队列的动态变化而重新负载（重平衡）。在这种情况下消费进度最好存储在所有消费者都能访问到的地方（例如broker）。</li>
</ul>
<pre><code>// 文件地址：org.apache.rocketmq.client.consumer.store.OffsetStore
/**
 * 将消费进度从存储文件加载至内存中
 */
void load() throws MQClientException;

/**
 * 更新内存中的消费进度
 * 参数 increaseOnly 为true时表示offset必须大于内存中当前的消费进度才更新
 */
void updateOffset(final MessageQueue mq, final long offset, final boolean increaseOnly);

/**
 * 依据类型获取消费进度
 * ReadOffsetType: READ_FROM_MEMORY(内存),READ_FROM_STORE(存储),MEMORY_FIRST_THEN_STORE(先内存后存储)
 */
long readOffset(final MessageQueue mq, final ReadOffsetType type);

/**
 * Persist all offsets,may be in local storage or remote name server
 */
void persistAll(final Set&lt;MessageQueue&gt; mqs);

/**
 * 持久化消费进度---》本地（广播模式）或远程服务broker（集群模式）
 */
void persist(final MessageQueue mq);

/**
 * 移除消费进度
 */
void removeOffset(MessageQueue mq);

/**
 * 克隆主题下所有队列的消费进度
 */
Map&lt;MessageQueue, Long&gt; cloneOffsetTable(String topic);

/**
 * 更新存储在broker上的消费进度（集群模式）
 */
void updateConsumeOffsetToBroker(MessageQueue mq, long offset, boolean isOneway) throws RemotingException,
    MQBrokerException, InterruptedException, MQClientException;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.consumer.store.LocalFileOffsetStore
// 广播模式中，消费进度是存储在消费者本地，具体实现逻辑如下：
// 核心属性
// 消费进度存储目录，可通过 -Drocketmq.client.localOffsetStoreDir 指定存储目录，默认存储在主目录下
public final static String LOCAL_OFFSET_STORE_DIR = System.getProperty(
    &quot;rocketmq.client.localOffsetStoreDir&quot;,
    System.getProperty(&quot;user.home&quot;) + File.separator + &quot;.rocketmq_offsets&quot;);
// 消息客户端
private final MQClientInstance mQClientFactory;
// 消费组名
private final String groupName;
// 消费进度存储文件路径
private final String storePath;
// 消费进度存储在内存中的对象
private ConcurrentMap&lt;MessageQueue, AtomicLong&gt; offsetTable =
    new ConcurrentHashMap&lt;MessageQueue, AtomicLong&gt;();

// 此函数是由MQClientInstance#startScheduledTask定时任务开启，每5s会执行一次
// 持久化存储消费进度    
public void persistAll(Set&lt;MessageQueue&gt; mqs) {
    if (null == mqs || mqs.isEmpty())
        return;
    // 从内存中获取消费进度信息，并将其封装至OffsetSerializeWrapper 
    OffsetSerializeWrapper offsetSerializeWrapper = new OffsetSerializeWrapper();
    for (Map.Entry&lt;MessageQueue, AtomicLong&gt; entry : this.offsetTable.entrySet()) {
        if (mqs.contains(entry.getKey())) {
            AtomicLong offset = entry.getValue();
            offsetSerializeWrapper.getOffsetTable().put(entry.getKey(), offset);
        }
    }
    // 将其转为json
    String jsonString = offsetSerializeWrapper.toJson(true);
    if (jsonString != null) {
        try {
            // 持久化至文件中
            MixAll.string2File(jsonString, this.storePath);
        } catch (IOException e) {
            log.error(&quot;persistAll consumer offset Exception, &quot; + this.storePath, e);
        }
    }
} 

</code></pre>
<p>集群模式中，消费进度存储在消息服务端broker。无论是广播模式还是集群模式，消费进度的管理逻辑基本一致，只不过广播是操作本地存储，集群操作远程存储。集群模式大致实现原理图如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320010.png" alt="img" loading="lazy"></figure>
<h3 id="定时消息机制">定时消息机制</h3>
<p>定时消息是指消息发送到broker之后，并不会立刻被消费者所感知，而是等候特定时间后才能被消费。RocketMQ只支持固定的延迟级别：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 总共18个级别，使用时，可以通过设置msg.setDelayLevel(level)来发送延迟消息。对level设值时会出现以下是那种情形：</p>
<ul>
<li>level == 0，消息为非延迟消息</li>
<li>1&lt;=level&lt;=maxLevel，消息延迟特定时间，例如level==1，延迟1s</li>
<li>level &gt; maxLevel，则level== maxLevel，例如level==20，延迟2h</li>
</ul>
<p>定时任务设计的关键：单独创建一个主题 SCHEDULE_TOPIC_XXXX 作为定时任务专属，该主题下的队列数量等于 MessageStoreConfig#messageDelayLevel 配置的延迟级别数量，其对应关系为：消息队列id = 延迟级别 - 1。ScheduleMessageService 会为每个延迟级别创建一个定时Timer，并根据延迟级别对应的延迟时间进行任务调度。</p>
<p>在消息发送时，如果消息的延迟级别delayLevel大于0，那么便会将其发送至内部的延迟主题的延迟队列下，之后再根据上述步骤进行任务处理。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.schedule.ScheduleMessageService
public boolean load() {
    // 加载消费进度存储文件至内存中
    boolean result = super.load();
    // 将 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 映射为 1-18
    result = result &amp;&amp; this.parseDelayLevel();
    // 赋值 offsetTable---》用于在内存中管理延迟消费进度
    result = result &amp;&amp; this.correctDelayOffset();
    return result;
}

public void start() {
    // CAS加锁启动
    if (started.compareAndSet(false, true)) {
        super.load();
        this.deliverExecutorService = new ScheduledThreadPoolExecutor(this.maxDelayLevel, new ThreadFactoryImpl(&quot;ScheduleMessageTimerThread_&quot;));
        // 是否启用异步延迟
        if (this.enableAsyncDeliver) {
            this.handleExecutorService = new ScheduledThreadPoolExecutor(this.maxDelayLevel, new ThreadFactoryImpl(&quot;ScheduleMessageExecutorHandleThread_&quot;));
        }
        // 遍历所有的延迟级别
        for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) {
            Integer level = entry.getKey();
            Long timeDelay = entry.getValue();
            // 根据延迟级别从offsetTable中获取消费进度；这里说明了一个延迟级别对应一个消息队列
            Long offset = this.offsetTable.get(level);、
            // offsetTable 中不存在消费进度便直接使用0
            if (null == offset) {
                offset = 0L;
            }

            // 每个定时任务第一次启动时都默认延迟1s执行一次，随后才会使用对应的延迟时间执行
            if (timeDelay != null) {
                if (this.enableAsyncDeliver) {
                    this.handleExecutorService.schedule(new HandlePutResultTask(level), FIRST_DELAY_TIME, TimeUnit.MILLISECONDS);
                }
                this.deliverExecutorService.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME, TimeUnit.MILLISECONDS);
            }
        }

        // 创建定时任务，默认每10s持久化一次延迟队列的消费进度
        this.deliverExecutorService.scheduleAtFixedRate(new Runnable() {
            @Override
            public void run() {
                try {
                    if (started.get()) {
                        ScheduleMessageService.this.persist();
                    }
                } catch (Throwable e) {
                    log.error(&quot;scheduleAtFixedRate flush exception&quot;, e);
                }
            }
        }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval(), TimeUnit.MILLISECONDS);
    }
}

// 延迟级别与消息队列的映射关系：消息队列id = 延迟级别 - 1
public static int queueId2DelayLevel(final int queueId) {
    return queueId + 1;
}
public static int delayLevel2QueueId(final int delayLevel) {
    return delayLevel - 1;
}

</code></pre>
<h4 id="定时调度逻辑">定时调度逻辑</h4>
<p>在 ScheduleMessageService#start 函数启动时，会为每个延迟任务创建一个对应的调度任务，而调度任务的核心函数便是ScheduleMessageService$DeliverDelayedMessageTimerTask#executeOnTimeup。整体流程如下：</p>
<ol>
<li>在消息发送时，如果消息的延迟级别delayLevel大于0，则改变消息主题为 SCHEDULE_TOPIC_XXX，消息队列为延迟级别减1。</li>
<li>消息首先会经由commitlog转发至 SCHEDULE_TOPIC_XXX 的消费队列0。</li>
<li>定时任务Time每隔1s根据上次拉取偏移量从消费队列中拉取出所有的消息。</li>
<li>根据消息物理偏移量及消息大小从commitlog中取出对应的延迟消息。</li>
<li>根据取出的消息属性重建新的消息对象，并转发至真正的原主题及原消息队列，此过程会清除延迟级别，同时会再次存入commitlog。</li>
<li>订阅了原主题的消费者正常消费消息。</li>
</ol>
<pre><code>// 文件地址：org.apache.rocketmq.store.schedule.ScheduleMessageService#DeliverDelayedMessageTimerTask
public void executeOnTimeup() {
    // 根据延迟主题和队列id查询消费队列
    ConsumeQueue cq =
        ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(TopicValidator.RMQ_SYS_SCHEDULE_TOPIC,
            delayLevel2QueueId(delayLevel));
    // 消费队列不存在， 说明目前不存在该延迟级别的消息
    if (cq == null) {
         // 等待100ms后，再次执行该延迟级别的任务
        this.scheduleNextTimerTask(this.offset, DELAY_FOR_A_WHILE);
        return;
    }
    // 根据offset从消费队列中获取所有有效消息
    SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset);
    // 未找到有效消息
    if (bufferCQ == null) {
        long resetOffset;
        if ((resetOffset = cq.getMinOffsetInQueue()) &gt; this.offset) {
            log.error(&quot;schedule CQ offset invalid. offset={}, cqMinOffset={}, queueId={}&quot;,
                this.offset, resetOffset, cq.getQueueId());
        } else if ((resetOffset = cq.getMaxOffsetInQueue()) &lt; this.offset) {
            log.error(&quot;schedule CQ offset invalid. offset={}, cqMaxOffset={}, queueId={}&quot;,
                this.offset, resetOffset, cq.getQueueId());
        } else {
            resetOffset = this.offset;
        }
        // 等待100ms后，再次执行该延迟级别的任务
        this.scheduleNextTimerTask(resetOffset, DELAY_FOR_A_WHILE);
        return;
    }

    long nextOffset = this.offset;
    try {
        int i = 0;
        ConsumeQueueExt.CqExtUnit cqExtUnit = new ConsumeQueueExt.CqExtUnit();
        // 遍历消费队列，每个消费队列条目为20个字节。
        for (; i &lt; bufferCQ.getSize() &amp;&amp; isStarted(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) {
            // 解析偏移量
            long offsetPy = bufferCQ.getByteBuffer().getLong();
            // 解析消息大小
            int sizePy = bufferCQ.getByteBuffer().getInt();
            // 解析tag信息
            long tagsCode = bufferCQ.getByteBuffer().getLong();
            if (cq.isExtAddr(tagsCode)) {
                if (cq.getExt(tagsCode, cqExtUnit)) {
                    tagsCode = cqExtUnit.getTagsCode();
                } else {
                    //can't find ext content.So re compute tags code.
                    log.error(&quot;[BUG] can't find consume queue extend file content!addr={}, offsetPy={}, sizePy={}&quot;,
                        tagsCode, offsetPy, sizePy);
                    long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy);
                    tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime);
                }
            }

            long now = System.currentTimeMillis();
            long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode);
            nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
            // 比较延迟任务执行时间戳与当前时间戳，尽量保证在指定的延迟时间执行任务
            long countdown = deliverTimestamp - now;
            if (countdown &gt; 0) {
                // 等待100ms后，再次执行该延迟级别的任务
                this.scheduleNextTimerTask(nextOffset, DELAY_FOR_A_WHILE);
                return;
            }
            // 从commitlog中获取消息
            MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy);
            // 没有消息时，略过本次循环
            if (msgExt == null) {
                continue;
            }
            // 根据消息重建新的消息对象，清除消息的延迟级别，并恢复消息原先的消息主题和消费队列。
            MessageExtBrokerInner msgInner = ScheduleMessageService.this.messageTimeup(msgExt);
            // 判断是否为事务的半消息主题
            if (TopicValidator.RMQ_SYS_TRANS_HALF_TOPIC.equals(msgInner.getTopic())) {
                log.error(&quot;[BUG] the real topic of schedule msg is {}, discard the msg. msg={}&quot;,
                    msgInner.getTopic(), msgInner);
                continue;
            }
        
            // 开始投递消息，此过程中消息会再次存入commitlog中，并转发至对应的消息主题及消费队列以供消费者消费，同时也会更新延迟队列拉取进度。
            boolean deliverSuc;
            if (ScheduleMessageService.this.enableAsyncDeliver) {
                deliverSuc = this.asyncDeliver(msgInner, msgExt.getMsgId(), offset, offsetPy, sizePy);
            } else {
                deliverSuc = this.syncDeliver(msgInner, msgExt.getMsgId(), offset, offsetPy, sizePy);
            }

            if (!deliverSuc) {
                // 等待100ms后，再次执行该延迟级别的任务
                this.scheduleNextTimerTask(nextOffset, DELAY_FOR_A_WHILE);
                return;
            }
        }

        nextOffset = this.offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
    } catch (Exception e) {
        log.error(&quot;ScheduleMessageService, messageTimeup execute error, offset = {}&quot;, nextOffset, e);
    } finally {
        bufferCQ.release();
    }
    // 等待100ms后，再次执行该延迟级别的任务
    this.scheduleNextTimerTask(nextOffset, DELAY_FOR_A_WHILE);
}

// 延迟指定时间后，再次执行this.delayLevel延迟级别的任务
public void scheduleNextTimerTask(long offset, long delay) {
    ScheduleMessageService.this.deliverExecutorService.schedule(new DeliverDelayedMessageTimerTask(
        this.delayLevel, offset), delay, TimeUnit.MILLISECONDS);
}

</code></pre>
<h3 id="消息过滤机制">消息过滤机制</h3>
<p>RocketMQ支持两种过滤模式：表达式过滤和类过滤，其中表达式过滤又分为TAG和SQL92。表达式过滤中TAG实现最为简单，就是给消息定义一个标签，消费者会根据tag进行匹配；SQL92则是依据SQL条件过滤表达式来过滤对应的消息属性；类过滤模式中允许提交一个过滤类至filterServer，消费者将从filterServer拉取消息，此过程中当消息经过filterServer时会执行对应的过滤逻辑。</p>
<h4 id="表达式tag过滤">表达式TAG过滤</h4>
<p>消息发送者在发送消息时如果设置了tag属性，那么该字段值将会一同存储在commitlog中，但在消费队列中会用8字节来存储tag的hashcode，这是因为consumerQueue采用了定长的设计，以此来加快加载速度。</p>
<p>broker端拉取消息时，仅仅只会对比tag的hashcode，如果匹配则返回，否则忽略该消息。consumer收到消息后，会再次对比tag的实际值以进行二次过滤。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl
// 消费者订阅主题与消息过滤表达式
public void subscribe(String topic, String subExpression) throws MQClientException {
    try {
        // 根据主题及表达式构建订阅信息
        SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(topic, subExpression);
        // 将上述信息加入rebalanceImpl，以便后续进行消息重平衡
        this.rebalanceImpl.getSubscriptionInner().put(topic, subscriptionData);
        if (this.mQClientFactory != null) {
            // 发送心跳
            this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();
        }
    } catch (Exception e) {
        throw new MQClientException(&quot;subscription exception&quot;, e);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl#pullMessage
String subExpression = null;
boolean classFilter = false;
SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());
if (sd != null) {
    if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) {
        subExpression = sd.getSubString();
    }

    classFilter = sd.isClassFilterMode();
}
// 根据表达式过滤和了过滤构建系统拉取标签
int sysFlag = PullSysFlag.buildSysFlag(
    commitOffsetEnable, // commitOffset
    true, // suspend
    subExpression != null, // subscription
    classFilter // class filter
);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.broker.processor.PullMessageProcessor#processRequest
// 根据消息表达式构建订阅信息
subscriptionData = FilterAPI.build(
    requestHeader.getTopic(), requestHeader.getSubscription(), requestHeader.getExpressionType()
);
// 类过滤模式下，使用consumerFilterData 
if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) {
    consumerFilterData = ConsumerFilterManager.build(
        requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(),
        requestHeader.getExpressionType(), requestHeader.getSubVersion()
    );
    assert consumerFilterData != null;
}

// 初始化消息过滤对象
MessageFilter messageFilter;
if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) {
    // 支持对重试主题的过滤
    messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData,
        this.brokerController.getConsumerFilterManager());
} else {
    messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData,
        this.brokerController.getConsumerFilterManager());
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#getMessage
// 根据consumerQueue过滤消息
if (messageFilter != null
    &amp;&amp; !messageFilter.isMatchedByConsumeQueue(isTagsCodeLegal ? tagsCode : null, extRet ? cqExtUnit : null)) {
    if (getResult.getBufferTotalSize() == 0) {
        status = GetMessageStatus.NO_MATCHED_MESSAGE;
    }

    continue;
}

// 如果通过consumerQueue过滤成功，则从commitlog中加载整个消息体，根据消息属性进行过滤
if (messageFilter != null
    &amp;&amp; !messageFilter.isMatchedByCommitLog(selectResult.getByteBuffer().slice(), null)) {
    if (getResult.getBufferTotalSize() == 0) {
        status = GetMessageStatus.NO_MATCHED_MESSAGE;
    }
    // release...
    selectResult.release();
    continue;
}

</code></pre>
<h4 id="类过滤模式">类过滤模式</h4>
<p>类过滤模式是指在broker端运行一个或多个filterServer，rocketmq允许消费者自定义过滤实现类并将其上传至filterServer上；消费者向filterServer拉取消息，filterServer将消费者的拉取请求转发至broker，然后对返回的消息进行过滤操作，最终将过滤后的消息返回给消费者。大体流程如下：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320011.png" alt="" loading="lazy"></figure>
<p>filterServer注册至broker的流程与发送者或消费者的注册流程基本一致，都是定时向broker发送心跳包。broker端接收到心跳后，会维护filterServer的属性信息，并定时监控其状态。随后broker会与所有存活的nameServer进行通信，将filterServer信息存储至nameServer上，方便后续消费者从nameServer获取filterServer的相关信息。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.PullAPIWrapper#pullKernelImpl
// 消息拉取时，如果发现消息过滤模式为classFilter，那么便会变更brokerAddr地址为filterServer的地址
if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) {
    brokerAddr = computePullFromWhichFilterServer(mq.getTopic(), brokerAddr);
}

private String computePullFromWhichFilterServer(final String topic, final String brokerAddr)
    throws MQClientException {
     // 获取消息主题路由table  
    ConcurrentMap&lt;String, TopicRouteData&gt; topicRouteTable = this.mQClientFactory.getTopicRouteTable();
    if (topicRouteTable != null) {
        // 通过主题名获取对应的主题路由信息
        TopicRouteData topicRouteData = topicRouteTable.get(topic);
        // 从中获取所有的filterServer列表
        List&lt;String&gt; list = topicRouteData.getFilterServerTable().get(brokerAddr);
        // 随机选出一个filterServer返回
        if (list != null &amp;&amp; !list.isEmpty()) {
            return list.get(randomNum() % list.size());
        }
    }

    throw new MQClientException(&quot;Find Filter Server Failed, Broker Addr: &quot; + brokerAddr + &quot; topic: &quot;
        + topic, null);
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之消息消费(上)]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-xiao-fei-shang/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-xiao-fei-shang/">
        </link>
        <updated>2022-10-29T05:37:44.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之消息消费上篇。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/desert-74781_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="消息消费">消息消费</h2>
<h3 id="简介">简介</h3>
<p>RocketMQ中是以组的模式进行消息消费的，一个消费组内包含多个消费者，每个消费组可订阅多个主题，消费组之间有集群模式和广播模式两种消费方式。</p>
<ul>
<li>
<p>集群模式：主题下的同一条消息只允许被消费组中的一个消费者所消费。</p>
</li>
<li>
<p>广播模式：主题下的同一消息可被组内的所有消息消费一次。</p>
<p>RocketMQ中消息服务器与消费者之间的消息传递也有两种方式：推模式，拉模式。</p>
</li>
<li>
<p>拉模式（pull）：消费者主动从broker拉取消息进行消费。</p>
</li>
<li>
<p>推模式（push）：指消息到达broker后会推送至消费者，实际上是对拉模式的一个封装，本质上仍然是拉模式。</p>
</li>
</ul>
<h3 id="启动流程">启动流程</h3>
<p>以DefaultMQPushConsumerImpl#start为例，简单介绍消费者启动流程</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.consumer.DefaultMQPushConsumer
public synchronized void start() throws MQClientException {
    switch (this.serviceState) {
        case CREATE_JUST:
            log.info(&quot;the consumer [{}] start beginning. messageModel={}, isUnitMode={}&quot;, this.defaultMQPushConsumer.getConsumerGroup(),
                this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode());
            this.serviceState = ServiceState.START_FAILED;
            // 检查配置信息
            this.checkConfig();
            // 复制订阅信息
            this.copySubscription();

            // 集群模式下，改变消费者的instanceName为进程ID
            if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) {
                // 如果instanceName为“DEFAULT”时，此处改变函数将会将instanceName更改为进程id + 当前纳秒
                // this.instanceName = UtilAll.getPid() + &quot;#&quot; + System.nanoTime();
                this.defaultMQPushConsumer.changeInstanceNameToPID();
            }

            // 创建MQClientInstance实例，整个JVM中只存在一个MQClientManager实例，其中维护了一个factoryTable用于存储clientId与MQClientInstance
            // private ConcurrentMap&lt;String/* clientId */, MQClientInstance&gt; factoryTable 
            // 也就是说一个clientId只会存在一个至于对应的MQClientInstance
            this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook);
        
            // 设置rebalanceImpl属性
            this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup());
            this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel());
            this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy());
            this.rebalanceImpl.setmQClientFactory(this.mQClientFactory);

            // 封装拉模式API 
            this.pullAPIWrapper = new PullAPIWrapper(
                mQClientFactory,
                this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode());
            this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookList);

            // 初始化消息消费进度  
            if (this.defaultMQPushConsumer.getOffsetStore() != null) {
                this.offsetStore = this.defaultMQPushConsumer.getOffsetStore();
            } else {
                // 不存在storeOffset时，表示是第一次消费
                switch (this.defaultMQPushConsumer.getMessageModel()) {
                    case BROADCASTING:
                        // 广播模式中，offset存储在消费者端
                        this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());
                        break;
                    case CLUSTERING:
                        // 集群模式中，offset存储在broker
                        this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup());
                        break;
                    default:
                        break;
                }
                this.defaultMQPushConsumer.setOffsetStore(this.offsetStore);
            }
            this.offsetStore.load();

            // 判断是否顺序消息，来创建对应的consumeMessageService并启动---&gt;consumeMessageService内部维护了一个线程池用于消费消息
            if (this.getMessageListenerInner() instanceof MessageListenerOrderly) {
                this.consumeOrderly = true;
                this.consumeMessageService =
                    new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner());
            } else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) {
                this.consumeOrderly = false;
                this.consumeMessageService =
                    new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner());
            }

            this.consumeMessageService.start();
        
            // 将当前消费加入MQClientInstance中进行管理，方便后续调用网络请求，发送心跳包等
            boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this);
            if (!registerOK) {
                this.serviceState = ServiceState.CREATE_JUST;
                this.consumeMessageService.shutdown(defaultMQPushConsumer.getAwaitTerminationMillisWhenShutdown());
                throw new MQClientException(&quot;The consumer group[&quot; + this.defaultMQPushConsumer.getConsumerGroup()
                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),
                    null);
            }
            // 启动 MQClientInstance
            mQClientFactory.start();
            log.info(&quot;the consumer [{}] start OK.&quot;, this.defaultMQPushConsumer.getConsumerGroup());
            this.serviceState = ServiceState.RUNNING;
            break;
        case RUNNING:
        case START_FAILED:
        case SHUTDOWN_ALREADY:
            throw new MQClientException(&quot;The PushConsumer service state not OK, maybe started once, &quot;
                + this.serviceState
                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),
                null);
        default:
            break;
    }
    // 如果订阅改变了，便更新主题订阅信息
    this.updateTopicSubscribeInfoWhenSubscriptionChanged();
    // 检查broker中的客户端信息
    this.mQClientFactory.checkClientInBroker();
    // 发送心跳
    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();
    // 立刻进行重平衡操作
    this.mQClientFactory.rebalanceImmediately();
}

private void copySubscription() throws MQClientException {
    try {
        // 获取订阅内容
        Map&lt;String, String&gt; sub = this.defaultMQPushConsumer.getSubscription();
        if (sub != null) {
            for (final Map.Entry&lt;String, String&gt; entry : sub.entrySet()) {
                final String topic = entry.getKey();
                final String subString = entry.getValue();
                SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(topic, subString);
                // 按照主题分组存入rebalanceImpl---&gt;消费者负载均衡的核心类
                this.rebalanceImpl.getSubscriptionInner().put(topic, subscriptionData);
            }
        }
        // 配置内部监听器
        if (null == this.messageListenerInner) {
            this.messageListenerInner = this.defaultMQPushConsumer.getMessageListener();
        }

        switch (this.defaultMQPushConsumer.getMessageModel()) {
            case BROADCASTING:
                break;
            case CLUSTERING:
                // 集群模式下，订阅重试主题消息。RocketMQ消息重试是以组为单位的--&gt;重试主题格式：%RETRY% + 消费组名
                final String retryTopic = MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup());
                SubscriptionData subscriptionData = FilterAPI.buildSubscriptionData(retryTopic, SubscriptionData.SUB_ALL);
                // 按照重试主题消费组分组存入rebalanceImpl---&gt;消费者负载均衡的核心类
                this.rebalanceImpl.getSubscriptionInner().put(retryTopic, subscriptionData);
                break;
            default:
                break;
        }
    } catch (Exception e) {
        throw new MQClientException(&quot;subscription exception&quot;, e);
    }
}

</code></pre>
<h3 id="消息拉取">消息拉取</h3>
<p>消息消费有两种模式，此节将以集群模式来简单介绍push模式的消息消费。</p>
<p>需要注意的是，rocketmq并没有实现真正意义上的推模式，本质上仍然是消费者主动向服务器拉取消息，只不过整个拉取过程被封装在了后台处理。</p>
<p>在此过程中，如果消息还未到达消息队列且未开启长轮询机制，那么会在服务端等待shortPollingTimeMills=1000时间后（相当于挂起）再去判断消息是否已到达消息队列；如果开启了长轮询机制longPollingEnable=true，rocketmq会每隔5s轮询检查一次消息是否到达，在消息到达时便会立即通知挂起线程验证该消息是否为可消费消息，如果是则从commitlog中提取消息并返回给客户端，否则便一直挂起直到超时（push模式默认15s；pull模式可通过设置DefaultMQPullConsumer#brokerSuspendMaxTimeMillis，该值默认20s不建议修改）。</p>
<p>长轮询核心源码：org.apache.rocketmq.broker.longpolling.PullRequestHoldService</p>
<p>整个消息拉取过程为分三步：客户端封装消息拉取请求，消息服务器查找并返回消息，客户端处理返回消息。大体流程如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320009.png" alt="" loading="lazy"></figure>
<h4 id="客户端封装消息拉取请求">客户端封装消息拉取请求</h4>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl
public void pullMessage(final PullRequest pullRequest) {
    // 获取ProcessQueue ---&gt; ProcessQueue 本质上是对messageQueue的封装
    final ProcessQueue processQueue = pullRequest.getProcessQueue();
    // 当前处理队列已被丢弃则直接终止拉取操作
    if (processQueue.isDropped()) {
        log.info(&quot;the pull request[{}] is dropped.&quot;, pullRequest.toString());
        return;
    }
    // 更新最后一次拉取时间戳为当前时间戳
    pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis());

    try {
        // 检查服务状态是否处于RUNNING
        this.makeSureStateOK();
    } catch (MQClientException e) {
        log.warn(&quot;pullMessage exception, consumer state not ok&quot;, e);
        this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
        return;
    }
    // 如果当前消费者被挂起，则将拉取任务延迟1s再放入PullMessageService的拉取任务队列中，之后结束拉取操作
    if (this.isPause()) {
        log.warn(&quot;consumer was paused, execute pull request later. instanceName={}, group={}&quot;, this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup());
        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND);
        return;
    }
  
    // 获取已缓存的消息数 
    long cachedMessageCount = processQueue.getMsgCount().get();
    // 获取已缓存的消息大小--》单位MB
    long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);
  
    // 如果processQueue当前处理的消息条数超过了pullThresholdForQueue=1000时，将触发流控
    // 将拉取任务延迟50ms再放入PullMessageService的拉取任务队列中，并终止拉取操作
    if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) {
        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);
        if ((queueFlowControlTimes++ % 1000) == 0) {
            log.warn(
                &quot;the cached message count exceeds the threshold {}, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}&quot;,
                this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);
        }
        return;
    }
    // 如果processQueue当前处理的消息大小超过了pullThresholdForQueue=100MB时，将触发流控
    // 将拉取任务延迟50ms再放入PullMessageService的拉取任务队列中，并终止拉取操作
    if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) {
        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);
        if ((queueFlowControlTimes++ % 1000) == 0) {
            log.warn(
                &quot;the cached message size exceeds the threshold {} MiB, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}&quot;,
                this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);
        }
        return;
    }
  
    // 非顺序消费
    if (!this.consumeOrderly) {
        // 如果processQueue当前处理的消息最大偏移量与最小偏移量的间距超过了consumeConcurrentlyMaxSpan=2000时，将触发流控
        // 将拉取任务延迟50ms再放入PullMessageService的拉取任务队列中，并终止拉取操作
        if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) {
            this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);
            if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) {
                log.warn(
                    &quot;the queue's messages, span too long, so do flow control, minOffset={}, maxOffset={}, maxSpan={}, pullRequest={}, flowControlTimes={}&quot;,
                    processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(),
                    pullRequest, queueMaxSpanFlowControlTimes);
            }
            return;
        }
    } else {
        // 顺序消息，需要判断是否已加锁
        if (processQueue.isLocked()) {
            // 是否上次加锁的数据
            if (!pullRequest.isPreviouslyLocked()) {
                long offset = -1L;
                try {
                    // 获取偏移量
                    offset = this.rebalanceImpl.computePullFromWhereWithException(pullRequest.getMessageQueue());
                } catch (Exception e) {
                    this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
                    log.error(&quot;Failed to compute pull offset, pullResult: {}&quot;, pullRequest, e);
                    return;
                }
                boolean brokerBusy = offset &lt; pullRequest.getNextOffset();
                log.info(&quot;the first time to pull message, so fix offset from broker. pullRequest: {} NewOffset: {} brokerBusy: {}&quot;,
                    pullRequest, offset, brokerBusy);
                if (brokerBusy) {
                    log.info(&quot;[NOTIFYME]the first time to pull message, but pull request offset larger than broker consume offset. pullRequest: {} NewOffset: {}&quot;,
                        pullRequest, offset);
                }
                // 重置前锁与下一次offset 
                pullRequest.setPreviouslyLocked(true);
                pullRequest.setNextOffset(offset);
            }
        } else {
            // 未加锁顺序消息不允许消费----》为了保证顺序
            // 将拉取任务延迟3s再放入PullMessageService的拉取任务队列中，并终止拉取操作
            this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
            log.info(&quot;pull message later because not locked in broker, {}&quot;, pullRequest);
            return;
        }
    }
    // 获取订阅信息
    final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());
    // 订阅信息为空
    if (null == subscriptionData) {
        // 将拉取任务延迟3s再放入PullMessageService的拉取任务队列中，并终止拉取操作
        this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
        log.warn(&quot;find the consumer's subscription failed, {}&quot;, pullRequest);
        return;
    }

    final long beginTimestamp = System.currentTimeMillis();
    // 针对pull回调处理 ----》在后续 客户端处理返回消息 小节中详细介绍，此处暂且省略
    PullCallback pullCallback = new PullCallback() {};

    // 判断 commitOffsetEnable 是否启用
    boolean commitOffsetEnable = false;
    long commitOffsetValue = 0L;
    // 集群模式下，从broker读取commitOffset，如果大于0表示commitOffset可用
    if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) {
        commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY);
        if (commitOffsetValue &gt; 0) {
            commitOffsetEnable = true;
        }
    }
    // 消息过滤模式---》subExpression（TAG，SQL92） 和 classFilter 
    String subExpression = null;
    boolean classFilter = false;
    SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());
    if (sd != null) {
        if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) {
            subExpression = sd.getSubString();
        }

        classFilter = sd.isClassFilterMode();
    }
    // 构建系统标记
    int sysFlag = PullSysFlag.buildSysFlag(
        commitOffsetEnable, // commitOffset
        true, // suspend
        subExpression != null, // subscription
        classFilter // class filter
    );
    try {
        // 与服务端进行交互拉取消息
        this.pullAPIWrapper.pullKernelImpl(
            pullRequest.getMessageQueue(),
            subExpression,
            subscriptionData.getExpressionType(),
            subscriptionData.getSubVersion(),
            pullRequest.getNextOffset(),
            this.defaultMQPushConsumer.getPullBatchSize(),
            sysFlag,
            commitOffsetValue,
            BROKER_SUSPEND_MAX_TIME_MILLIS,
            CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND,
            CommunicationMode.ASYNC,
            pullCallback
        );
    } catch (Exception e) {
        log.error(&quot;pullKernelImpl exception&quot;, e);
        // 将拉取任务延迟3s再放入PullMessageService的拉取任务队列中
        this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.PullAPIWrapper
public PullResult pullKernelImpl(
    // 从哪个消息队列拉取消息
    final MessageQueue mq,
    // 消息过滤表达式
    final String subExpression,
    // 消息表达式类型--》TAG 和 SQL92
    final String expressionType,
    // 订阅版本号
    final long subVersion,
    // 拉取偏移量 
    final long offset,
    // 本次拉取最大消息条数，默认32条
    final int maxNums,
    // 系统标记
    final int sysFlag,
    // 当前MessageQueue的消费进度
    final long commitOffset,
    // 消息拉取过程中允许broker挂起时间，默认15s
    final long brokerSuspendMaxTimeMillis,
    // 消息拉取超时时间，默认30s
    final long timeoutMillis,
    // 消息拉取模式，默认异步拉取
    final CommunicationMode communicationMode,
    // 从broker拉取消息后的回调函数
    final PullCallback pullCallback
) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    // 获取broker地址，主要是为了下面进行远程通讯
    FindBrokerResult findBrokerResult =
        this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(),
            this.recalculatePullFromWhichNode(mq), false);
    if (null == findBrokerResult) {
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(mq.getTopic());
        findBrokerResult =
            this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(),
                this.recalculatePullFromWhichNode(mq), false);
    }

    if (findBrokerResult != null) {
        {
            // check version
            if (!ExpressionType.isTagType(expressionType)
                &amp;&amp; findBrokerResult.getBrokerVersion() &lt; MQVersion.Version.V4_1_0_SNAPSHOT.ordinal()) {
                throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;, &quot;
                    + findBrokerResult.getBrokerVersion() + &quot;] does not upgrade to support for filter message by &quot; + expressionType, null);
            }
        }
        int sysFlagInner = sysFlag;

        if (findBrokerResult.isSlave()) {
            sysFlagInner = PullSysFlag.clearCommitOffsetFlag(sysFlagInner);
        }
        // 拼接请求数据
        PullMessageRequestHeader requestHeader = new PullMessageRequestHeader();
        requestHeader.setConsumerGroup(this.consumerGroup);
        requestHeader.setTopic(mq.getTopic());
        requestHeader.setQueueId(mq.getQueueId());
        requestHeader.setQueueOffset(offset);
        requestHeader.setMaxMsgNums(maxNums);
        requestHeader.setSysFlag(sysFlagInner);
        requestHeader.setCommitOffset(commitOffset);
        requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis);
        requestHeader.setSubscription(subExpression);
        requestHeader.setSubVersion(subVersion);
        requestHeader.setExpressionType(expressionType);
    
        String brokerAddr = findBrokerResult.getBrokerAddr();
        // 如果为类过滤模式，则需要根据主题名称和broker地址找到注册在Broker上的filterServer地址，随后将从filterServer上拉取消息
        if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) {
            brokerAddr = computePullFromWhichFilterServer(mq.getTopic(), brokerAddr);
        }
        // 拉取数据
        PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(
            brokerAddr,
            requestHeader,
            timeoutMillis,
            communicationMode,
            pullCallback);

        return pullResult;
    }

    throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null);
}

</code></pre>
<h4 id="消息服务器组装消息并返回">消息服务器组装消息并返回</h4>
<p>根据消息拉取命令code: RequestCode.PULL_MESSAGE，可以从broker端找到对应的处理函数。</p>
<pre><code>// 文件地址：org.apache.rocketmq.broker.processor.PullMessageProcessor#processRequest
// 查找消息
final GetMessageResult getMessageResult =
    this.brokerController.getMessageStore().getMessage(requestHeader.getConsumerGroup(), requestHeader.getTopic(),
        requestHeader.getQueueId(), requestHeader.getQueueOffset(), requestHeader.getMaxMsgNums(), messageFilter);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#getMessage
// 消息获取状态，默认NO_MESSAGE_IN_QUEUE
GetMessageStatus status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;
// 待查找的起始偏移量
long nextBeginOffset = offset;
// 最小偏移量
long minOffset = 0;
// 最大偏移量
long maxOffset = 0;
// 消息获取结果，当查找到消息时再初始化
GetMessageResult getResult = null;
// 当前文件最大的偏移量
final long maxOffsetPy = this.commitLog.getMaxOffset();
// 根据主题及queueId寻找对应的ConsumeQueue 
ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId);

// 当前消费队列中没有消息
if (maxOffset == 0) {
    status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;
    nextBeginOffset = nextOffsetCorrection(offset, 0);
} 
// 待拉取消息偏移量小于队列的最小偏移量
else if (offset &lt; minOffset) {
    status = GetMessageStatus.OFFSET_TOO_SMALL;
    nextBeginOffset = nextOffsetCorrection(offset, minOffset);
} 
// 待拉取消息偏移量等于队列的最大偏移量--》直接从待拉取消息偏移量开始拉取
else if (offset == maxOffset) {
    status = GetMessageStatus.OFFSET_OVERFLOW_ONE;
    nextBeginOffset = nextOffsetCorrection(offset, offset);
} 
// 待拉取消息偏移量大于队列的最大偏移量
else if (offset &gt; maxOffset) {
    status = GetMessageStatus.OFFSET_OVERFLOW_BADLY;
    if (0 == minOffset) {
        nextBeginOffset = nextOffsetCorrection(offset, minOffset);
    } else {
        nextBeginOffset = nextOffsetCorrection(offset, maxOffset);
    }
}

// 填充获取消息的结果信息
getResult.setStatus(status);
getResult.setNextBeginOffset(nextBeginOffset);
getResult.setMaxOffset(maxOffset);
getResult.setMinOffset(minOffset);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
// 修正下次拉取offset
private long nextOffsetCorrection(long oldOffset, long newOffset) {
    // 默认使用传入的oldOffset作为下一次拉取偏移量
    long nextOffset = oldOffset;
    // 如果broker不会从节点或者OffsetCheckInSlave为true，则使用传入的newOffset最为下一次拉取偏移量
    if (this.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE || this.getMessageStoreConfig().isOffsetCheckInSlave()) {
        nextOffset = newOffset;
    }
    return nextOffset;
}

</code></pre>
<h4 id="客户端处理返回消息">客户端处理返回消息</h4>
<p>核心在于回调函数的处理，其中包括成功与失败。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl#pullMessage
PullCallback pullCallback = new PullCallback() {
    @Override
    public void onSuccess(PullResult pullResult) {
        if (pullResult != null) {
            // 获取拉取消息的结果信息
            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult,
                subscriptionData);

            switch (pullResult.getPullStatus()) {
                case FOUND:
                    // 更新下次拉取偏移量
                    long prevRequestOffset = pullRequest.getNextOffset();
                    pullRequest.setNextOffset(pullResult.getNextBeginOffset());
                    // 更新拉取间隔时间
                    long pullRT = System.currentTimeMillis() - beginTimestamp;
                    DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(),
                        pullRequest.getMessageQueue().getTopic(), pullRT);

                    long firstMsgOffset = Long.MAX_VALUE;
                    // 当MsgFoundList为空时----》由于TAG模式过滤，可能会导致MsgFoundList为空
                    if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) {
                        // 立即将拉取任务放入PullMessageService的拉取任务队列中，以便PullMessageService及时唤醒并再次执行拉取任务
                        DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
                    } else {
                        firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset();

                        DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(),
                            pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size());
                        // 将拉取到的消息存入processQueue
                        boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());
                        // 提交至consumeMessageService，以便消费者进行消费---》此函数异步执行
                        DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(
                            pullResult.getMsgFoundList(),
                            processQueue,
                            pullRequest.getMessageQueue(),
                            dispatchToConsume);

                        // 判断PullInterval是否大于0，如果是，则等待该时间间隔再执行下次拉取，否则立即执行拉取操作
                        // 此逻辑主要是为了实现持续拉取，以达到准实时拉取消息的效果
                        if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) {
                            DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest,
                                DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());
                        } else {
                            DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
                        }
                    }

                    if (pullResult.getNextBeginOffset() &lt; prevRequestOffset
                        || firstMsgOffset &lt; prevRequestOffset) {
                        log.warn(
                            &quot;[BUG] pull message result maybe data wrong, nextBeginOffset: {} firstMsgOffset: {} prevRequestOffset: {}&quot;,
                            pullResult.getNextBeginOffset(),
                            firstMsgOffset,
                            prevRequestOffset);
                    }

                    break;
                case NO_NEW_MSG:
                case NO_MATCHED_MSG:
                    // 消息不匹配的情况下，纠正偏移量然后立即执行下次拉取操作
                    pullRequest.setNextOffset(pullResult.getNextBeginOffset());

                    DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest);

                    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
                    break;
                case OFFSET_ILLEGAL:
                    log.warn(&quot;the pull request offset illegal, {} {}&quot;,
                        pullRequest.toString(), pullResult.toString());
                    pullRequest.setNextOffset(pullResult.getNextBeginOffset());
                    // 当offset非法时，丢弃该ProcessQueue---&gt;即该ProcessQueue中的消息将停止被消费
                    pullRequest.getProcessQueue().setDropped(true);
                    // 延迟执行任务
                    DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() {

                        @Override
                        public void run() {
                            try {
                                // 依据服务端下次校验的偏移量NextOffset去更新内存中的消息消费进度
                                DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(),
                                    pullRequest.getNextOffset(), false);
                                // 尝试持久化该消息队列
                                DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue());
                                // 从rebalanceImpl的处理队列中将其移除---&gt;这意味着不再从该消息队列拉取消息，直到下次队列重平衡为止
                                DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue());

                                log.warn(&quot;fix the pull request offset, {}&quot;, pullRequest);
                            } catch (Throwable e) {
                                log.error(&quot;executeTaskLater Exception&quot;, e);
                            }
                        }
                    }, 10000);
                    break;
                default:
                    break;
            }
        }
    }

    @Override
    public void onException(Throwable e) {
        if (!pullRequest.getMessageQueue().getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
            log.warn(&quot;execute the pull request exception&quot;, e);
        }
        // 将拉取任务延迟3s再放入PullMessageService的拉取任务队列中
        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, pullTimeDelayMillsWhenException);
    }
};

</code></pre>
<h3 id="重平衡分配算法">重平衡分配算法</h3>
<p>重平衡过程源码可参见《RocketMQ架构与设计》文章中的 2.4.2小节 Consumer负载均衡，此处主要简单介绍重平衡的一些算法。</p>
<p>rocketmq默认使用的是平均分配：AllocateMessageQueueAveragely</p>
<ul>
<li>AllocateMachineRoomNearby：就近机房分配策略</li>
<li>AllocateMessageQueueAveragely：平均散列队列算法--》默认分配算法</li>
<li>AllocateMessageQueueAveragelyByCircle：轮询平均散列队列算法----》常用分配算法</li>
<li>AllocateMessageQueueByConfig：通过配置进行分配，相当于手动指定消费者的消息队列</li>
<li>AllocateMessageQueueByMachineRoom：通过机房分配</li>
<li>AllocateMessageQueueConsistentHash：通过一致性哈希分配</li>
</ul>
<pre><code>// 文件地址：org.apache.rocketmq.client.consumer.AllocateMessageQueueStrategy
// 重平衡消息队列分配算法的核心接口，如果默认的分配算法不满足业务，可以实现该接口自定义分配算法
public interface AllocateMessageQueueStrategy {

    /**
     * 分配算法核心函数
     *
     * @param consumerGroup current consumer group
     * @param currentCID current consumer id
     * @param mqAll message queue set in current topic
     * @param cidAll consumer set in current consumer group
     * @return The allocate result of given strategy
     */
    List&lt;MessageQueue&gt; allocate(
        final String consumerGroup,
        final String currentCID,
        final List&lt;MessageQueue&gt; mqAll,
        final List&lt;String&gt; cidAll
    );

    /**
     * Algorithm name
     *
     * @return The strategy name
     */
    String getName();
}

</code></pre>
<h4 id="allocatemachineroomnearby">AllocateMachineRoomNearby</h4>
<p>就近机房分配策略，仍需指定实际的分配策略。</p>
<p>基本逻辑：如果有任何消费者在机房中活着，部署在同一台机器上的broker的消息队列应该只分配给这些存活的消费者。否则，这些消息队列可以与所有消费者共享，因为没有活着的消费者来独享它们。</p>
<pre><code>public class AllocateMachineRoomNearby implements AllocateMessageQueueStrategy {
    private final InternalLogger log = ClientLogger.getLog();

    private final AllocateMessageQueueStrategy allocateMessageQueueStrategy;//actual allocate strategy
    private final MachineRoomResolver machineRoomResolver;
    // 指定实际的分配策略以及机房解析器 
    public AllocateMachineRoomNearby(AllocateMessageQueueStrategy allocateMessageQueueStrategy,
        MachineRoomResolver machineRoomResolver) throws NullPointerException {
        if (allocateMessageQueueStrategy == null) {
            throw new NullPointerException(&quot;allocateMessageQueueStrategy is null&quot;);
        }

        if (machineRoomResolver == null) {
            throw new NullPointerException(&quot;machineRoomResolver is null&quot;);
        }

        this.allocateMessageQueueStrategy = allocateMessageQueueStrategy;
        this.machineRoomResolver = machineRoomResolver;
    }

    @Override
    public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll,
        List&lt;String&gt; cidAll) {
        // 省略校验
        List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;();
        // 以机房名对消息队列进行分组
        Map&lt;String/*machine room */, List&lt;MessageQueue&gt;&gt; mr2Mq = new TreeMap&lt;String, List&lt;MessageQueue&gt;&gt;();
        for (MessageQueue mq : mqAll) {
            String brokerMachineRoom = machineRoomResolver.brokerDeployIn(mq);
            if (StringUtils.isNoneEmpty(brokerMachineRoom)) {
                if (mr2Mq.get(brokerMachineRoom) == null) {
                    mr2Mq.put(brokerMachineRoom, new ArrayList&lt;MessageQueue&gt;());
                }
                mr2Mq.get(brokerMachineRoom).add(mq);
            } else {
                throw new IllegalArgumentException(&quot;Machine room is null for mq &quot; + mq);
            }
        }

        // 以机房名对消费者进行分组
        Map&lt;String/*machine room */, List&lt;String/*clientId*/&gt;&gt; mr2c = new TreeMap&lt;String, List&lt;String&gt;&gt;();
        for (String cid : cidAll) {
            String consumerMachineRoom = machineRoomResolver.consumerDeployIn(cid);
            if (StringUtils.isNoneEmpty(consumerMachineRoom)) {
                if (mr2c.get(consumerMachineRoom) == null) {
                    mr2c.put(consumerMachineRoom, new ArrayList&lt;String&gt;());
                }
                mr2c.get(consumerMachineRoom).add(cid);
            } else {
                throw new IllegalArgumentException(&quot;Machine room is null for consumer id &quot; + cid);
            }
        }

        List&lt;MessageQueue&gt; allocateResults = new ArrayList&lt;MessageQueue&gt;();

        // 分配消息队列至同一机房的当前消费者
        String currentMachineRoom = machineRoomResolver.consumerDeployIn(currentCID);
        List&lt;MessageQueue&gt; mqInThisMachineRoom = mr2Mq.remove(currentMachineRoom);
        List&lt;String&gt; consumerInThisMachineRoom = mr2c.get(currentMachineRoom);
        if (mqInThisMachineRoom != null &amp;&amp; !mqInThisMachineRoom.isEmpty()) {
            // 使用实际上指定的分配策略进行再分配
            allocateResults.addAll(allocateMessageQueueStrategy.allocate(consumerGroup, currentCID, mqInThisMachineRoom, consumerInThisMachineRoom));
        }

        // 如果当前机房没有存活的消费者，那么便将剩余的消息队列分配给每个机房
        for (Entry&lt;String, List&lt;MessageQueue&gt;&gt; machineRoomEntry : mr2Mq.entrySet()) {
            if (!mr2c.containsKey(machineRoomEntry.getKey())) { 
                // 在相应的机房中没有存活的消费者，因此所有消费者都可共享这些消息队列
                allocateResults.addAll(allocateMessageQueueStrategy.allocate(consumerGroup, currentCID, machineRoomEntry.getValue(), cidAll));
            }
        }

        return allocateResults;
    }

    @Override
    public String getName() {
        return &quot;MACHINE_ROOM_NEARBY&quot; + &quot;-&quot; + allocateMessageQueueStrategy.getName();
    }

    /**
     * 一个解析器对象，用于确定消息队列或客户端部署在哪个机房。
     * AllocateMachineRoomNearby 会利用结果将消息队列和客户端按机房进行分组。
     * 注意：实现的方法返回的结果不能为空。 
     */
    public interface MachineRoomResolver {
        String brokerDeployIn(MessageQueue messageQueue);

        String consumerDeployIn(String clientID);
    }
}

</code></pre>
<h4 id="allocatemessagequeueaveragely">AllocateMessageQueueAveragely</h4>
<p>平均散列队列算法：消息队列数除以消费者总数，以确定分配给每个消费者的队列数。如果无法整除，那么额外的队列将会分配给排序靠前的消费者。</p>
<p>数学模型：设主题队列数为x，消费者数为y，设队列数除以消费者数的商为n、余数为m。那么在一个消费组中，前m个消费者将分配到n+1个队列，剩余的消费者分配n个队列。</p>
<p>例如：存在两个消费者C0，C1，两个主题t0，t1，且每个主题拥有三个队列，那么队列结果为：t0q0，t0q1，t0q2，t1q0，t1q1，t1q2。最终分配结果如下所示：</p>
<pre><code>// 依据上述数学模型，此处x=3，y=2，算出n=1，m=1，最终结果如下所示：
C0: [t0q0, t0q1, t1q0, t1q1]
C1: [t0q2, t1q2]

</code></pre>
<p>使用这种分配器的优势在于每个消费者都可以为每个主题获得一个队列，这对于某些负载均衡场景很有利。当然劣势也很明显，比如当遇到某个消费组订阅了多个Topic，那么可能会导致前几个消费者负载过重；又或者消费者数多于队列数时，将会有部分消费者处于空闲状态；且针对消费者进行扩缩容时，分配可能会发生较大的变化。</p>
<pre><code>public class AllocateMessageQueueAveragely implements AllocateMessageQueueStrategy {
    private final InternalLogger log = ClientLogger.getLog();

    @Override
    public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll,
        List&lt;String&gt; cidAll) {
        // 省略校验
        List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;();
        int index = cidAll.indexOf(currentCID);
        // 取模获取余数
        int mod = mqAll.size() % cidAll.size();
        // 获取平均大小
        int averageSize =
            mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size()
                + 1 : mqAll.size() / cidAll.size());
        // 获取起始索引
        int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod;
        // 获取遍历范围
        int range = Math.min(averageSize, mqAll.size() - startIndex);
        for (int i = 0; i &lt; range; i++) {
            result.add(mqAll.get((startIndex + i) % mqAll.size()));
        }
        return result;
    }

    @Override
    public String getName() {
        return &quot;AVG&quot;;
    }
}

</code></pre>
<h4 id="allocatemessagequeueaveragelybycircle">AllocateMessageQueueAveragelyByCircle</h4>
<p>轮询平均散列队列算法：直接轮询给每个消费者分配消息队列。算法实现整体上比较简单，源码如下：</p>
<pre><code>public class AllocateMessageQueueAveragelyByCircle implements AllocateMessageQueueStrategy {
    private final InternalLogger log = ClientLogger.getLog();

    @Override
    public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll,
        List&lt;String&gt; cidAll) {
        // 省略校验
        List&lt;MessageQueue&gt; result = new ArrayList&lt;MessageQueue&gt;();
        // 获取当前消费者在消费者列表中的索引 
        int index = cidAll.indexOf(currentCID);
        // 遍历消息队列表
        for (int i = index; i &lt; mqAll.size(); i++) {
            // 取模运算如果等于消费者索引，则进行分配
            if (i % cidAll.size() == index) {
                result.add(mqAll.get(i));
            }
        }
        return result;
    }

    @Override
    public String getName() {
        return &quot;AVG_BY_CIRCLE&quot;;
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之消息存储(下)]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-cun-chu-xia/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-cun-chu-xia/">
        </link>
        <updated>2022-10-22T03:23:23.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之消息存储下篇。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/peak-190053_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="消息存储">消息存储</h2>
<h3 id="文件恢复">文件恢复</h3>
<p>RocketMQ所有消息都会先存储在commitLog中，随后再异步生成转发任务更新consumerQueue，indexFile文件。在此异步过程中，如果broker宕机，那么可能会出现数据不一致的问题。比如消息未同步至consumerQueue中，那么消费者将永远都消费不到该消息。此时便需要一种方案能够异步宕机导致的数据不一致问题。以下从源码角度分析rocketmq是如何实现数据同步操作的。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
// 文件加载
public boolean load() {
    boolean result = true;

    try {
        // 判断上一次退出是否正常
        boolean lastExitOK = !this.isTempFileExist();
        log.info(&quot;last shutdown {}&quot;, lastExitOK ? &quot;normally&quot; : &quot;abnormally&quot;);

        // 加载 CommitLog文件
        result = result &amp;&amp; this.commitLog.load();

        // 加载 ConsumeQueue文件---&gt;遍历消费队列根目录，获取所有主题文件，随后遍历每个主题文件，将其中的内容加载至ConsumeQueue对象中
        result = result &amp;&amp; this.loadConsumeQueue();

        if (result) {
            // 加载存储检查点，即文件对应的刷盘点
            this.storeCheckpoint =
                new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));
            // 加载索引文件---&gt;如果上次异常退出，且索引文件最后刷盘时间小于该文件最大的消息时间戳，那么该文件将被销毁
            this.indexService.load(lastExitOK);
            // 根据broker是否正常退出进行文件恢复
            this.recover(lastExitOK);

            log.info(&quot;load over, and the max phy offset = {}&quot;, this.getMaxPhyOffset());
            // 加载延迟消息相关的服务 
            if (null != scheduleMessageService) {
                result =  this.scheduleMessageService.load();
            }
        }

    } catch (Exception e) {
        log.error(&quot;load exception&quot;, e);
        result = false;
    }

    if (!result) {
        this.allocateMappedFileService.shutdown();
    }

    return result;
}

// 判断存储根目录下是否存在abort文件，存在说明为异常退出
// 正常退出时，abort文件将会被删除--&gt;可参见: org.apache.rocketmq.store.DefaultMessageStore#shutdown
private boolean isTempFileExist() {
    String fileName = StorePathConfigHelper.getAbortFile(this.messageStoreConfig.getStorePathRootDir());
    File file = new File(fileName);
    return file.exists();
}

// 加载commitLog文件
public boolean doLoad(List&lt;File&gt; files) {
    // ascending order
    // 按照文件名进行排序
    files.sort(Comparator.comparing(File::getName));

    for (File file : files) {
        // 如果文件大小与预先配置的不一致，将被忽略。
        if (file.length() != this.mappedFileSize) {
            log.warn(file + &quot;\t&quot; + file.length()
                    + &quot; length not matched message store config value, please check it manually&quot;);
            return false;
        }

        try {
            // 创建一个新的MappedFile 
            MappedFile mappedFile = new MappedFile(file.getPath(), mappedFileSize);
            // 设置三个指针为文件大小
            mappedFile.setWrotePosition(this.mappedFileSize);
            mappedFile.setFlushedPosition(this.mappedFileSize);
            mappedFile.setCommittedPosition(this.mappedFileSize);
            this.mappedFiles.add(mappedFile);
            log.info(&quot;load &quot; + file.getPath() + &quot; OK&quot;);
        } catch (IOException e) {
            log.error(&quot;load file &quot; + file + &quot; error&quot;, e);
            return false;
        }
    }
    return true;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
// 文件恢复
private void recover(final boolean lastExitOK) {
    long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue();

    if (lastExitOK) {
        // 正常退出恢复
        this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue);
    } else {
        // 异常退出恢复
        this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue);
    }
    // 恢复TopicQueueTable
    this.recoverTopicQueueTable();
}

// 此函数表示消息中不仅存储了主题，队列id，还存储了消息队列的偏移量
public void recoverTopicQueueTable() {
    HashMap&lt;String/* topic-queueid */, Long/* offset */&gt; table = new HashMap&lt;String, Long&gt;(1024);
    // 获取commitLog的最小偏移量
    long minPhyOffset = this.commitLog.getMinOffset();
    for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) {
        for (ConsumeQueue logic : maps.values()) {
            String key = logic.getTopic() + &quot;-&quot; + logic.getQueueId();
            // 将队列中最大的偏移量存储table中
            table.put(key, logic.getMaxOffsetInQueue());
            logic.correctMinOffset(minPhyOffset);
        }
    }
    // 将table设置进commitLog的TopicQueueTable
    this.commitLog.setTopicQueueTable(table);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog
// broker正常退出，所有的文件都将恢复，内存数据也将被刷盘
public void recoverNormally(long maxPhyOffsetOfConsumeQueue) {
    // checkCRCOnRecover 表示文件恢复过程中查找消息时是否需要验证CRC
    boolean checkCRCOnRecover = this.defaultMessageStore.getMessageStoreConfig().isCheckCRCOnRecover();
    final List&lt;MappedFile&gt; mappedFiles = this.mappedFileQueue.getMappedFiles();
    if (!mappedFiles.isEmpty()) {
        // 从倒数第三个文件开始进行恢复
        int index = mappedFiles.size() - 3;
        // 如果不足三个文件，则从第一个文件开始
        if (index &lt; 0)
            index = 0;
        // 通过index获取MappedFile 
        MappedFile mappedFile = mappedFiles.get(index);
        // 获取共享ByteBuffer
        ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();
        // commitLog已确认的物理偏移量
        long processOffset = mappedFile.getFileFromOffset();
        // 当前文件已校验通过offset
        long mappedFileOffset = 0;
        while (true) {
            // 检查消息是否合规，并返回消息大小
            DispatchRequest dispatchRequest = this.checkMessageAndReturnSize(byteBuffer, checkCRCOnRecover);
            int size = dispatchRequest.getMsgSize();
            // 消息合规，且消息大小大于0：mappedFileOffset 向前移动本条消息的长度
            if (dispatchRequest.isSuccess() &amp;&amp; size &gt; 0) {
                mappedFileOffset += size;
            }
            // Come the end of the file, switch to the next file Since the
            // return 0 representatives met last hole,
            // this can not be included in truncate offset
            // 消息合规，且消息大小等于0，表示已抵达文件末尾
            else if (dispatchRequest.isSuccess() &amp;&amp; size == 0) {
                index++;
                // 是否还有下一个文件，没有则直接跳出循环
                if (index &gt;= mappedFiles.size()) {
                    // Current branch can not happen
                    log.info(&quot;recover last 3 physics file over, last mapped file &quot; + mappedFile.getFileName());
                    break;
                } else {
                    // 否则重置processOffset，processOffset，并重复上述步骤
                    mappedFile = mappedFiles.get(index);
                    byteBuffer = mappedFile.sliceByteBuffer();
                    processOffset = mappedFile.getFileFromOffset();
                    processOffset = 0;
                    log.info(&quot;recover next physics file, &quot; + mappedFile.getFileName());
                }
            }
            // Intermediate file read error
            // 消息不合规，直接跳出循环
            else if (!dispatchRequest.isSuccess()) {
                log.info(&quot;recover physics file end, &quot; + mappedFile.getFileName());
                break;
            }
        }
        // processOffset 为 mappedFile.getFileFromOffset() + mappedFileOffset
        processOffset += mappedFileOffset;
        // 更新FlushedWhere，CommittedWhere指针
        this.mappedFileQueue.setFlushedWhere(processOffset);
        this.mappedFileQueue.setCommittedWhere(processOffset);
        // 删除processOffset之后的所有文件
        this.mappedFileQueue.truncateDirtyFiles(processOffset);

        // Clear ConsumeQueue redundant data
        // 清除processOffset之后的所有逻辑文件 
        if (maxPhyOffsetOfConsumeQueue &gt;= processOffset) {
            log.warn(&quot;maxPhyOffsetOfConsumeQueue({}) &gt;= processOffset({}), truncate dirty logic files&quot;, maxPhyOffsetOfConsumeQueue, processOffset);
            this.defaultMessageStore.truncateDirtyLogicFiles(processOffset);
        }
    } else {
        // Commitlog case files are deleted
        // commitlog 文件已被删除
        log.warn(&quot;The commitlog files are deleted, and delete the consume queue files&quot;);
        this.mappedFileQueue.setFlushedWhere(0);
        this.mappedFileQueue.setCommittedWhere(0);
        this.defaultMessageStore.destroyLogics();
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog
// broker异常退出，文件恢复过程与正常退出基本一致。
// 主要差别在于：异常退出会从最后一个文件开始往前遍历，找到第一个消息存储正常的文件进行恢复；
// 从此处也可看出rocketmq可能会存在重复消费的问题，消费幂等还是需要靠客户端自己保证。
// 判断MappedFile文件是否正常
private boolean isMappedFileMatchedRecover(final MappedFile mappedFile) {
    ByteBuffer byteBuffer = mappedFile.sliceByteBuffer();

     // 判断文件魔数是否等于 MESSAGE_MAGIC_CODE，如果不等于则表示该文件不符合commitLog存储格式
    int magicCode = byteBuffer.getInt(MessageDecoder.MESSAGE_MAGIC_CODE_POSTION);
    if (magicCode != MESSAGE_MAGIC_CODE) {
        return false;
    }
  
    int sysFlag = byteBuffer.getInt(MessageDecoder.SYSFLAG_POSITION);
    int bornhostLength = (sysFlag &amp; MessageSysFlag.BORNHOST_V6_FLAG) == 0 ? 8 : 20;
    int msgStoreTimePos = 4 + 4 + 4 + 4 + 4 + 8 + 8 + 4 + 8 + bornhostLength;
    // 如果文件中第一条消息的存储时间等于0，等于0表示该文件中未存储消息
    long storeTimestamp = byteBuffer.getLong(msgStoreTimePos);
    if (0 == storeTimestamp) {
        return false;
    }

    // 如果启用了消息索引，那么判断文件中第一条消息的存储时间是否小于等于存储检查点的最小索引时间戳 
    if (this.defaultMessageStore.getMessageStoreConfig().isMessageIndexEnable()
        &amp;&amp; this.defaultMessageStore.getMessageStoreConfig().isMessageIndexSafe()) {
        if (storeTimestamp &lt;= this.defaultMessageStore.getStoreCheckpoint().getMinTimestampIndex()) {
            log.info(&quot;find check timestamp, {} {}&quot;,
                storeTimestamp,
                UtilAll.timeMillisToHumanString(storeTimestamp));
            return true;
        }
    } else {
        // 否则判断文件中第一条消息的存储时间是否小于等于存储检查点的最小时间戳 
        if (storeTimestamp &lt;= this.defaultMessageStore.getStoreCheckpoint().getMinTimestamp()) {
            log.info(&quot;find check timestamp, {} {}&quot;,
                storeTimestamp,
                UtilAll.timeMillisToHumanString(storeTimestamp));
            return true;
        }
    }

    return false;
}

</code></pre>
<h3 id="文件刷盘机制">文件刷盘机制</h3>
<p>RocketMQ的读写是基于JDK NIO的内存映射机制（MappedByteBuffer），消息存储时首先将消息追加至内存，再根据配置的刷盘策略在不同时间进行刷盘。</p>
<ul>
<li>同步刷盘（SYNC_FLUSH）：消息追加至内存后，将同步调用MappedByteBuffer的force函数进行刷盘操作。</li>
<li>异步刷盘（ASYNC_FLUSH）：在消息追加至内存后将立刻返回给消息发送端，rocketmq后端会起一个独立线程按照配置的频率进行刷盘。</li>
</ul>
<h4 id="同步刷盘">同步刷盘</h4>
<p>同步刷盘主要是构建GroupCommitRequest 参数提交至GroupCommitService 进行处理，源码如下：</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog#submitFlushRequest
if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {
    // 设置GroupCommitService 
    final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;
    if (messageExt.isWaitStoreMsgOK()) {
        // 构建GroupCommitRequest 对象
        GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes(),
                this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());
         // 将请求提交至刷盘监听器   
        flushDiskWatcher.add(request);
        service.putRequest(request);
        // 等待返回结果
        return request.future();
    } else {
        // 唤醒GroupCommitService 
        service.wakeup();
        return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog#GroupCommitService

public void run() {
    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);

    // 每处理一批请求后会休眠10秒 
    while (!this.isStopped()) {
        try {
            this.waitForRunning(10);
            // 核心处理函数
            this.doCommit();
        } catch (Exception e) {
            CommitLog.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
        }
    }

    // 正常情况下宕机，会等待请求的到来，并进行刷盘操作
    try {
        Thread.sleep(10);
    } catch (InterruptedException e) {
        CommitLog.log.warn(this.getServiceName() + &quot; Exception, &quot;, e);
    }
    synchronized (this) {
        this.swapRequests();
    }
    this.doCommit();

    CommitLog.log.info(this.getServiceName() + &quot; service end&quot;);
}

private void doCommit() {
    if (!this.requestsRead.isEmpty()) {
        // 遍历请求，依次进行刷盘操作
        for (GroupCommitRequest req : this.requestsRead) {
            // There may be a message in the next file, so a maximum of
            // two times the flush
            boolean flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset();
            for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) {
                // 实际上是调用了MappedByteBuffer.force函数进行了刷盘操作
                // 
                CommitLog.this.mappedFileQueue.flush(0);
                flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset();
            }
            // 唤醒线程通知发送客户端刷盘结果--&gt;执行flushOKFuture.complete函数
            req.wakeupCustomer(flushOK ? PutMessageStatus.PUT_OK : PutMessageStatus.FLUSH_DISK_TIMEOUT);
        }
    
        // 刷盘完成后，需要更新存储检查点的时间戳。此处仅在内存中更新了该属性，并未落地到磁盘
        long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();
        if (storeTimestamp &gt; 0) {
            CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);
        }

        this.requestsRead = new LinkedList&lt;&gt;();
    } else {
        // Because of individual messages is set to not sync flush, it
        // will come to this process
        CommitLog.this.mappedFileQueue.flush(0);
    }
}

</code></pre>
<h4 id="异步刷盘">异步刷盘</h4>
<p>异步刷盘根据是否开启了transientStorePoolEnable机制，刷盘实现会有些许区别。</p>
<p>如果transientStorePoolEnable为true，rocketmq会单独申请一块与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存会使用内存锁定，确保不会被置换到虚拟内存中，消息首先提交至堆外内存，然后提交至物理文件对应的映射内存中，最后再flush到磁盘。</p>
<p>如果transientStorePoolEnable为false，消息是直接追加到内存映射文件中，然后flush到磁盘。</p>
<p>当transientStorePoolEnable为true时，消息刷盘流程如下所示：</p>
<ol>
<li>首先将消息追加至ByteBuffer（堆外内存DirectByteBuffer），writePosition随着消息不断向后移动。</li>
<li>CommitRealTimeService 线程默认每200ms将ByteBuffer新追加的内容数据提交至MappedFileBuffer中。</li>
<li>FlushRealTimeService 线程默认每500ms调用MappedByteBuffer#force函数将新追加的内存数据刷写到磁盘。</li>
</ol>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog#submitFlushRequest
// Asynchronous flush
else {
    if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {
        // 唤醒FlushRealTimeService 线程
        flushCommitLogService.wakeup();
    } else  {
        // 唤醒CommitRealTimeService 线程
        commitLogService.wakeup();
    }
    // 异步刷盘时直接返回ok
    return CompletableFuture.completedFuture(PutMessageStatus.PUT_OK);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog#CommitRealTimeService
public void run() {
    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);
    while (!this.isStopped()) {
        // 获取配置的提交间隔时间，默认200ms
        int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();
        // 一次提交任务中最少待提交页数，默认4，如果小于该值，将忽略本次提交
        int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();
         // 两次提交任务间隔，默认200ms
        int commitDataThoroughInterval =
            CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();

        // 如果距上次提交时间超过 commitDataThoroughInterval，那么忽略commitDataLeastPages 参数
        long begin = System.currentTimeMillis();
        if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) {
            this.lastCommitTimestamp = begin;
            commitDataLeastPages = 0;
        }

        try {
            // 提交数据值映射内存中，提交操作返回false，不代表提交失败，而是只提交了部分数据
            boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);
            long end = System.currentTimeMillis();
            if (!result) {
                this.lastCommitTimestamp = end; // result = false means some data committed.
                //now wake up flush thread.
                // 唤醒FlushRealTimeService 线程，进行刷盘操作
                flushCommitLogService.wakeup();
            }

            if (end - begin &gt; 500) {
                log.info(&quot;Commit data to file costs {} ms&quot;, end - begin);
            }
            this.waitForRunning(interval);
        } catch (Throwable e) {
            CommitLog.log.error(this.getServiceName() + &quot; service has exception. &quot;, e);
        }
    }
    // 针对commit失败的情况进行重试提交
    boolean result = false;
    for (int i = 0; i &lt; RETRY_TIMES_OVER &amp;&amp; !result; i++) {
        result = CommitLog.this.mappedFileQueue.commit(0);
        CommitLog.log.info(this.getServiceName() + &quot; service shutdown, retry &quot; + (i + 1) + &quot; times &quot; + (result ? &quot;OK&quot; : &quot;Not OK&quot;));
    }
    CommitLog.log.info(this.getServiceName() + &quot; service end&quot;);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog#FlushRealTimeService
public void run() {
    CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        // 是否定时刷新，默认true
        boolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();
        // 刷盘间隔，默认500ms
        int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();
        // 一次刷盘任务中最少待刷盘页数，默认4，如果小于该值，将忽略本次刷盘
        int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();
        // 两次刷盘任务间隔，默认10s 
        int flushPhysicQueueThoroughInterval =
            CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();
        // 是否打印刷盘过程信息，默认false 
        boolean printFlushProgress = false;

        // 如果距上次刷盘时间超过 flushPhysicQueueThoroughInterval，那么忽略flushPhysicQueueThoroughInterval参数
        // Print flush progress
        long currentTimeMillis = System.currentTimeMillis();
        if (currentTimeMillis &gt;= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) {
            this.lastFlushTimestamp = currentTimeMillis;
            flushPhysicQueueLeastPages = 0;
            printFlushProgress = (printTimes++ % 10) == 0;
        }

        try {
            // 延迟刷盘
            if (flushCommitLogTimed) {
                Thread.sleep(interval);
            } else {
                this.waitForRunning(interval);
            }
            // 打印刷盘过程信息
            if (printFlushProgress) {
                this.printFlushProgress();
            }

            // 数据刷盘，刷盘操作返回false，不代表fush失败，而是只flush了部分数据
            // 刷盘操作过程还会更新flushedPosition指针
            long begin = System.currentTimeMillis();
            CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);
            long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();
            if (storeTimestamp &gt; 0) {
                CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);
            }
            long past = System.currentTimeMillis() - begin;
            if (past &gt; 500) {
                log.info(&quot;Flush data to disk costs {} ms&quot;, past);
            }
        } catch (Throwable e) {
            CommitLog.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
            this.printFlushProgress();
        }
    }

    // 针对flush失败的情况进行重试刷盘
    // Normal shutdown, to ensure that all the flush before exit
    boolean result = false;
    for (int i = 0; i &lt; RETRY_TIMES_OVER &amp;&amp; !result; i++) {
        result = CommitLog.this.mappedFileQueue.flush(0);
        CommitLog.log.info(this.getServiceName() + &quot; service shutdown, retry &quot; + (i + 1) + &quot; times &quot; + (result ? &quot;OK&quot; : &quot;Not OK&quot;));
    }

    this.printFlushProgress();

    CommitLog.log.info(this.getServiceName() + &quot; service end&quot;);
}

</code></pre>
<h3 id="过期文件删除机制">过期文件删除机制</h3>
<p>为了避免内存（内存映射机制）与磁盘资源的浪费，rocketmq中的文件不可能永远存储在消息服务器上，这时便需要一种文件过期清除策略来删除已过期的文件。</p>
<p>RocketMQ顺序写文件，也就是说所有的写操作都将落在最后一个文件，之前的文件在下一个文件创建后将不会再被更新。这样便可以引入一种过期策略：如果非当前写文件在一定时间间隔内没有再被更新，则认为该文件过期，可被删除。</p>
<p>RocketMQ不会关注文件上的消息是否已被全部消费，当抵达指定的过期时间时（默认72小时，可以通过在broker配置文件中设置fileReservedTime来更改，单位：小时）便会执行清除操作。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#addScheduleTask
this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {
    @Override
    public void run() {
        DefaultMessageStore.this.cleanFilesPeriodically();
    }
   // 默认每隔10秒执行一次清除任务，可以设置cleanResourceInterval来控制执行频率
}, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS);

private void cleanFilesPeriodically() {
    // 清除commitLog文件
    this.cleanCommitLogService.run();
    // 清除consumerQueue文件
    this.cleanConsumeQueueService.run();
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#CleanCommitLogService
// 清除commitLog文件
public void run() {
    try {
        this.deleteExpiredFiles();

        this.redeleteHangedFile();
    } catch (Throwable e) {
        DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
    }
}

private void deleteExpiredFiles() {
    int deleteCount = 0;
    // 文件保留时间，即最后一次更新到现在的时间，如果超过了该时间，则认为是过期文件，可以被删除
    // 默认72小时，可以通过在broker配置文件中设置fileReservedTime来更改，单位：小时
    long fileReservedTime = DefaultMessageStore.this.getMessageStoreConfig().getFileReservedTime();
    // 两次文件删除间隔，默认100ms；在一次清除过程中，可能需要删除的文件不止一个，该属性指定了两次删除文件的间隔
    int deletePhysicFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteCommitLogFilesInterval();
    // 在清除文件过程中，如果该文件被其他线程所占用（引用次数大于0，例如读消息），此时会阻止本次删除操作，
    // 同时在第一次试图删除该文件时记录当前时间戳，destroyMapedFileIntervalForcibly 表示第一次拒绝删除后能保留的最大时间，默认120s
    // 在此时间内，删除操作将会被拒绝，同时引用次数减1000，超过该时间后，文件会被强制删除
    int destroyMapedFileIntervalForcibly = DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();
  
    // 指定删除文件的时间点，可以通过设置deleteWhen来指定在一天的哪个时间点进行删除，默认凌晨4点
    boolean timeup = this.isTimeToDelete();
    // 磁盘空间是否充足，如果不足则应该执行删除操作
    boolean spacefull = this.isSpaceToDelete();
    // 手动删除
    boolean manualDelete = this.manualDeleteFileSeveralTimes &gt; 0;

    if (timeup || spacefull || manualDelete) {

        if (manualDelete)
            this.manualDeleteFileSeveralTimes--;

        boolean cleanAtOnce = DefaultMessageStore.this.getMessageStoreConfig().isCleanFileForciblyEnable() &amp;&amp; this.cleanImmediately;

        log.info(&quot;begin to delete before {} hours file. timeup: {} spacefull: {} manualDeleteFileSeveralTimes: {} cleanAtOnce: {}&quot;,
            fileReservedTime,
            timeup,
            spacefull,
            manualDeleteFileSeveralTimes,
            cleanAtOnce);

        fileReservedTime *= 60 * 60 * 1000;
        // 删除文件
        deleteCount = DefaultMessageStore.this.commitLog.deleteExpiredFile(fileReservedTime, deletePhysicFilesInterval,
            destroyMapedFileIntervalForcibly, cleanAtOnce);
        if (deleteCount &gt; 0) {
        } else if (spacefull) {
            log.warn(&quot;disk space will be full soon, but delete file failed.&quot;);
        }
    }
}
// 针对挂起的文件，重新删除
private void redeleteHangedFile() {
    int interval = DefaultMessageStore.this.getMessageStoreConfig().getRedeleteHangedFileInterval();
    long currentTimestamp = System.currentTimeMillis();
    if ((currentTimestamp - this.lastRedeleteTimestamp) &gt; interval) {
        this.lastRedeleteTimestamp = currentTimestamp;
        int destroyMapedFileIntervalForcibly =
            DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();
        if (DefaultMessageStore.this.commitLog.retryDeleteFirstFile(destroyMapedFileIntervalForcibly)) {
        }
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore#CleanConsumeQueueService
// 清除consumerQueue文件
public void run() {
    try {
        this.deleteExpiredFiles();
    } catch (Throwable e) {
        DefaultMessageStore.log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
    }
}

private void deleteExpiredFiles() {
    // 两次文件删除间隔，默认100ms
    int deleteLogicsFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteConsumeQueueFilesInterval();
    // 获取最小偏移量
    long minOffset = DefaultMessageStore.this.commitLog.getMinOffset();
    // 当前最小偏移量大于上次最小偏移量才进行删除操纵，说明存在需要删除的内容
    if (minOffset &gt; this.lastPhysicalMinOffset) {
        // 重新设置lastPhysicalMinOffset 
        this.lastPhysicalMinOffset = minOffset;

        ConcurrentMap&lt;String, ConcurrentMap&lt;Integer, ConsumeQueue&gt;&gt; tables = DefaultMessageStore.this.consumeQueueTable;

        for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : tables.values()) {
            for (ConsumeQueue logic : maps.values()) {
                // 删除minOffset之前的所有ConsumeQueue 文件
                int deleteCount = logic.deleteExpiredFile(minOffset);

                if (deleteCount &gt; 0 &amp;&amp; deleteLogicsFilesInterval &gt; 0) {
                    try {
                        Thread.sleep(deleteLogicsFilesInterval);
                    } catch (InterruptedException ignored) {
                    }
                }
            }
        }
        // 删除minOffset之前的所有索引文件
        DefaultMessageStore.this.indexService.deleteExpiredFile(minOffset);
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之消息存储(上)]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-cun-chu-shang/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-cun-chu-shang/">
        </link>
        <updated>2022-10-15T03:19:15.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之消息存储上篇。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/bow-lake-5854210_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="消息存储">消息存储</h2>
<h3 id="简介">简介</h3>
<p>RocketMQ主要存储文件包括commitLog，consumerQueue，indexFile。发送的所有消息都将存储在commitLog文件中，以确保消息顺序写入磁盘。consumerQueue文件相当于commitLog的索引文件，主要记录对应的消息offset，方便消费者对其进行订阅操作。indexFile则是主要用来进行快速检索。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320007.png" alt="" loading="lazy"></figure>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
// 消息存储的部分核心属性信息
// 存储配置
private final MessageStoreConfig messageStoreConfig;
// CommitLog
private final CommitLog commitLog;
// 消息队列存储缓存表，按消息主题分组
private final ConcurrentMap&lt;String/* topic */, ConcurrentMap&lt;Integer/* queueId */, ConsumeQueue&gt;&gt; consumeQueueTable;
// 消息队列文件consumerQueue的刷盘服务
private final FlushConsumeQueueService flushConsumeQueueService;
// commitLog 文件清除服务
private final CleanCommitLogService cleanCommitLogService;
// consumerQueue 文件清除服务
private final CleanConsumeQueueService cleanConsumeQueueService;
// 索引文件实现服务
private final IndexService indexService;
// mappedFile分配服务
private final AllocateMappedFileService allocateMappedFileService;
// commitLog 消息分发，可以根据commitLog文件构建对应的consumerQueue及indexFile文件
private final ReputMessageService reputMessageService;
// 存储高可用服务
private final HAService haService;
// 定时消息服务
private final ScheduleMessageService scheduleMessageService;
// 存储状态服务
private final StoreStatsService storeStatsService;
// 消息堆内存缓存
private final TransientStorePool transientStorePool;
// broker状态管理器
private final BrokerStatsManager brokerStatsManager;
// 消息拉取长轮询模式中消息到达时的监听器
private final MessageArrivingListener messageArrivingListener;
// broker配置信息
private final BrokerConfig brokerConfig;
// 文件刷盘检查点
private StoreCheckpoint storeCheckpoint;
// commitLog文件转发请求
private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList;

</code></pre>
<h3 id="消息发送时存储">消息发送时存储</h3>
<p>以消息发送时持久化操作为例。<br>
核心入口函数：org.apache.rocketmq.store.DefaultMessageStore#putMessage,通过源码可以发现同步消息存储实际上也是调用了异步存储的函数。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
public PutMessageResult putMessage(MessageExtBrokerInner msg) {
    return waitForPutResult(asyncPutMessage(msg));
}

// 等待异步写入操作的结果
private PutMessageResult waitForPutResult(CompletableFuture&lt;PutMessageResult&gt; putMessageResultFuture) {
    try {
        // 获取CompletableFuture等待超时时间
        int putMessageTimeout =
                Math.max(this.messageStoreConfig.getSyncFlushTimeout(),
                        this.messageStoreConfig.getSlaveTimeout()) + 5000;
        // 获取异步操作结果            
        return putMessageResultFuture.get(putMessageTimeout, TimeUnit.MILLISECONDS);
    } catch (ExecutionException | InterruptedException e) {
        return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, null);
    } catch (TimeoutException e) {
        log.error(&quot;usually it will never timeout, putMessageTimeout is much bigger than slaveTimeout and &quot;
                + &quot;flushTimeout so the result can be got anyway, but in some situations timeout will happen like full gc &quot;
                + &quot;process hangs or other unexpected situations.&quot;);
        // 超时将返回未知错误    
        return new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, null);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.DefaultMessageStore
public CompletableFuture&lt;PutMessageResult&gt; asyncPutMessage(MessageExtBrokerInner msg) {
    // 检查存储状态是否可用，可能存在服务不可用及操作系统页缓存繁忙状态
    PutMessageStatus checkStoreStatus = this.checkStoreStatus();
    if (checkStoreStatus != PutMessageStatus.PUT_OK) {
        return CompletableFuture.completedFuture(new PutMessageResult(checkStoreStatus, null));
    }

     // 消息主题长度超过127，或消息内容长度超过2^15-1(即32767)，将不允许写入
    PutMessageStatus msgCheckStatus = this.checkMessage(msg);
    if (msgCheckStatus == PutMessageStatus.MESSAGE_ILLEGAL) {
        return CompletableFuture.completedFuture(new PutMessageResult(msgCheckStatus, null));
    }

    // 检查微消息队列数
    PutMessageStatus lmqMsgCheckStatus = this.checkLmqMessage(msg);
    if (msgCheckStatus == PutMessageStatus.LMQ_CONSUME_QUEUE_NUM_EXCEEDED) {
        return CompletableFuture.completedFuture(new PutMessageResult(lmqMsgCheckStatus, null));
    }


    long beginTime = this.getSystemClock().now();
    // 异步存储消息
    CompletableFuture&lt;PutMessageResult&gt; putResultFuture = this.commitLog.asyncPutMessage(msg);

    // 处理异步结果
    putResultFuture.thenAccept((result) -&gt; {
        long elapsedTime = this.getSystemClock().now() - beginTime;
        if (elapsedTime &gt; 500) {
            log.warn(&quot;putMessage not in lock elapsed time(ms)={}, bodyLength={}&quot;, elapsedTime, msg.getBody().length);
        }
        // 设置消息存储处理的最大时间
        this.storeStatsService.setPutMessageEntireTimeMax(elapsedTime);

        // 失败时，增加失败次数
        if (null == result || !result.isOk()) {
            this.storeStatsService.getPutMessageFailedTimes().add(1);
        }
    });

    return putResultFuture;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.CommitLog
public CompletableFuture&lt;PutMessageResult&gt; asyncPutMessage(final MessageExtBrokerInner msg) {
    // Set the storage time
    msg.setStoreTimestamp(System.currentTimeMillis());
    // Set the message body BODY CRC (consider the most appropriate setting
    // on the client)
    msg.setBodyCRC(UtilAll.crc32(msg.getBody()));
    // Back to Results
    AppendMessageResult result = null;

    StoreStatsService storeStatsService = this.defaultMessageStore.getStoreStatsService();

    String topic = msg.getTopic();
    // int queueId msg.getQueueId();
    final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());
    if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE
            || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) {
        // Delay Delivery
        // 延迟消息将发往内部的延迟topic中
        if (msg.getDelayTimeLevel() &gt; 0) {
            if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) {
                msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel());
            }
            // 内部延迟主题
            topic = TopicValidator.RMQ_SYS_SCHEDULE_TOPIC;
            // 不同的延迟级别对应不同的consumerQueue
            int queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel());

            // Backup real topic, queueId
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic());
            MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId()));
            msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties()));

            msg.setTopic(topic);
            msg.setQueueId(queueId);
        }
    }

    // 设置socket 
    InetSocketAddress bornSocketAddress = (InetSocketAddress) msg.getBornHost();
    if (bornSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setBornHostV6Flag();
    }
    InetSocketAddress storeSocketAddress = (InetSocketAddress) msg.getStoreHost();
    if (storeSocketAddress.getAddress() instanceof Inet6Address) {
        msg.setStoreHostAddressV6Flag();
    }

    // 翻转buffer
    PutMessageThreadLocal putMessageThreadLocal = this.putMessageThreadLocal.get();
    PutMessageResult encodeResult = putMessageThreadLocal.getEncoder().encode(msg);
    if (encodeResult != null) {
        return CompletableFuture.completedFuture(encodeResult);
    }
    msg.setEncodedBuff(putMessageThreadLocal.getEncoder().encoderBuffer);
    PutMessageContext putMessageContext = new PutMessageContext(generateKey(putMessageThreadLocal.getKeyBuilder(), msg));

    long elapsedTimeInLock = 0;
    MappedFile unlockMappedFile = null;

    // 加锁串行写入；根据存储配置有两种锁可供选择：spin or ReentrantLock
    putMessageLock.lock(); 
    try {
        // 获取最后一个mappedFile
        MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();
        long beginLockTimestamp = this.defaultMessageStore.getSystemClock().now();
        this.beginTimeInLock = beginLockTimestamp;

        // 设置全局存储时间，主要为了确保有序
        msg.setStoreTimestamp(beginLockTimestamp);

        // 如果mappedFile 为空或者已经满了，则新建一个mappedFile 
        if (null == mappedFile || mappedFile.isFull()) {
            mappedFile = this.mappedFileQueue.getLastMappedFile(0); // Mark: NewFile may be cause noise
        }
        // 创建失败时可能是因为磁盘空间不足或权限不够等原因
        if (null == mappedFile) {
            log.error(&quot;create mapped file1 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());
            return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null));
        }

        // 在文件末尾追加消息，如果超过了文件配置大小则抛出异常
        // 此处追加消息操作仅仅只是将其放入缓存，并未进行刷盘
        result = mappedFile.appendMessage(msg, this.appendMessageCallback, putMessageContext);
        switch (result.getStatus()) {
            case PUT_OK:
                break;
            // 抵达文件末尾，便新增一个文件进行写入操作  
            case END_OF_FILE:
                unlockMappedFile = mappedFile;
                // Create a new file, re-write the message
                mappedFile = this.mappedFileQueue.getLastMappedFile(0);
                if (null == mappedFile) {
                    // XXX: warn and notify me
                    log.error(&quot;create mapped file2 error, topic: &quot; + msg.getTopic() + &quot; clientAddr: &quot; + msg.getBornHostString());
                    return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, result));
                }
                result = mappedFile.appendMessage(msg, this.appendMessageCallback, putMessageContext);
                break;
            case MESSAGE_SIZE_EXCEEDED:
            case PROPERTIES_SIZE_EXCEEDED:
                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result));
            case UNKNOWN_ERROR:
                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
            default:
                return CompletableFuture.completedFuture(new PutMessageResult(PutMessageStatus.UNKNOWN_ERROR, result));
        }

        elapsedTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginLockTimestamp;
    } finally {
        beginTimeInLock = 0;
        putMessageLock.unlock();
    }

    if (elapsedTimeInLock &gt; 500) {
        log.warn(&quot;[NOTIFYME]putMessage in lock cost time(ms)={}, bodyLength={} AppendMessageResult={}&quot;, elapsedTimeInLock, msg.getBody().length, result);
    }

    if (null != unlockMappedFile &amp;&amp; this.defaultMessageStore.getMessageStoreConfig().isWarmMapedFileEnable()) {
        this.defaultMessageStore.unlockMappedFile(unlockMappedFile);
    }

    PutMessageResult putMessageResult = new PutMessageResult(PutMessageStatus.PUT_OK, result);

    // Statistics
    storeStatsService.getSinglePutMessageTopicTimesTotal(msg.getTopic()).add(1);
    storeStatsService.getSinglePutMessageTopicSizeTotal(topic).add(result.getWroteBytes());
  
    // 提交刷盘请求，同步刷盘和异步刷盘
    CompletableFuture&lt;PutMessageStatus&gt; flushResultFuture = submitFlushRequest(result, msg);
    // 数据同步至副本
    CompletableFuture&lt;PutMessageStatus&gt; replicaResultFuture = submitReplicaRequest(result, msg);
    return flushResultFuture.thenCombine(replicaResultFuture, (flushStatus, replicaStatus) -&gt; {
        if (flushStatus != PutMessageStatus.PUT_OK) {
            putMessageResult.setPutMessageStatus(flushStatus);
        }
        if (replicaStatus != PutMessageStatus.PUT_OK) {
            putMessageResult.setPutMessageStatus(replicaStatus);
        }
        return putMessageResult;
    });
}

</code></pre>
<h3 id="内存映射">内存映射</h3>
<p>RocketMQ通过使用内存映射文件来提高IO访问性能，并且使用顺序写磁盘来提高写入效率。RocketMQ中的存储文件都采用了定长设计，每当一个文件达到指定长度后便会新增一个文件进行写操作。</p>
<p>Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后用户对物理内存的操作会被同步到硬盘上。</p>
<p>RocketMQ使用MappedFIle 及 MappedFileQueue来管理存储文件，关系如下所示：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320008.png" alt="img" loading="lazy"></figure>
<h4 id="mappedfilequeue">MappedFileQueue</h4>
<p>MappedFileQueue(映射文件队列)是MappedFIle 的管理器，实际上是对存储目录的管理，因为一般情况下，commitlog目录下会存在多个MappedFIle 文件。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFileQueue
// 核心属性
// 存储目录
private final String storePath;
// 单个MappedFIle 文件的大小
protected final int mappedFileSize;
// MappedFIle 文件集合，使用写时复制容器存储
protected final CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles = new CopyOnWriteArrayList&lt;MappedFile&gt;();
// 分配MappedFIle 的服务
private final AllocateMappedFileService allocateMappedFileService;
// 当前刷盘指针，表示该指针之前的所有数据都已持久化到磁盘
protected long flushedWhere = 0;
// 当前数据提交指针，内存中ByteBuffer当前的写指针，此值大于等于flushedWhere 
private long committedWhere = 0;
// 存储时间戳
private volatile long storeTimestamp = 0;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFileQueue
// 根据消息存储时间戳查询MappedFile
public MappedFile getMappedFileByTime(final long timestamp) {
    Object[] mfs = this.copyMappedFiles(0);

    if (null == mfs)
        return null;

     // 遍历列表，直到存在最后修改时间大于指定时间戳的MappedFile，返回该MappedFile
    for (int i = 0; i &lt; mfs.length; i++) {
        MappedFile mappedFile = (MappedFile) mfs[i];
        if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) {
            return mappedFile;
        }
    }
    // 如果不存在，那么便返回最后一个MappedFile文件 
    return (MappedFile) mfs[mfs.length - 1];
}

// 通过指定offset获取MappedFile，其中returnFirstOnNotFound参数表示如果未找到指定MappedFile便返回第一个MappedFile文件
public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) {
    try {
        // 获取第一个MappedFile 
        MappedFile firstMappedFile = this.getFirstMappedFile();
        // 获取最后一个MappedFile 
        MappedFile lastMappedFile = this.getLastMappedFile();
        if (firstMappedFile != null &amp;&amp; lastMappedFile != null) {
            if (offset &lt; firstMappedFile.getFileFromOffset() || offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) {
                LOG_ERROR.warn(&quot;Offset not matched. Request offset: {}, firstOffset: {}, lastOffset: {}, mappedFileSize: {}, mappedFiles count: {}&quot;,
                    offset,
                    firstMappedFile.getFileFromOffset(),
                    lastMappedFile.getFileFromOffset() + this.mappedFileSize,
                    this.mappedFileSize,
                    this.mappedFiles.size());
            } else {
                // 此处不直接使用offset % this.mappedFileSize，是因为内存映射文件可能会被删除
                // 为了防止出现内存压力与资源浪费，rocketmq会定时删除存储文件。
                int index = (int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize));
                MappedFile targetFile = null;
                try {
                    targetFile = this.mappedFiles.get(index);
                } catch (Exception ignored) {
                }

                if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset()
                    &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) {
                    return targetFile;
                }

                // 如果通过上述算法未找到MappedFile ，则遍历MappedFile 列表，从中找出一个契合offset的MappedFile 文件
                for (MappedFile tmpMappedFile : this.mappedFiles) {
                    if (offset &gt;= tmpMappedFile.getFileFromOffset()
                        &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) {
                        return tmpMappedFile;
                    }
                }
            }
            // 通过offset未找到MappedFile，那么便返回第一个MappedFile 
            if (returnFirstOnNotFound) {
                return firstMappedFile;
            }
        }
    } catch (Exception e) {
        log.error(&quot;findMappedFileByOffset Exception&quot;, e);
    }

    return null;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFileQueue
// 获取最小偏移量
public long getMinOffset() {

    if (!this.mappedFiles.isEmpty()) {
        try {
            // 并非直接返回0，而是返回了fileFromOffset 
            // 其中 this.fileFromOffset = Long.parseLong(this.file.getName());
            return this.mappedFiles.get(0).getFileFromOffset();
        } catch (IndexOutOfBoundsException e) {
            //continue;
        } catch (Exception e) {
            log.error(&quot;getMinOffset has exception.&quot;, e);
        }
    }
    return -1;
}
// 获取最大偏移量
public long getMaxOffset() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        // 返回最后一个文件的fileFromOffset + MappedFile的当前读指针
        return mappedFile.getFileFromOffset() + mappedFile.getReadPosition();
    }
    return 0;
}
// 获取最大写指针
public long getMaxWrotePosition() {
    MappedFile mappedFile = getLastMappedFile();
    if (mappedFile != null) {
        // 返回最后一个文件的fileFromOffset + MappedFile的当前写指针
        return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();
    }
    return 0;
}

</code></pre>
<h4 id="mappedfile">MappedFile</h4>
<p>MappedFile是rocketmq内存映射文件的具体实现。</p>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFile
// 核心属性
// 操作系统每页的大小，默认4k
public static final int OS_PAGE_SIZE = 1024 * 4;
// 当前JVM中MappedFile虚拟内存
private static final AtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0);
// 当前JVM中MappedFile对象个数
private static final AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0);
// 写指针，从0开始
protected final AtomicInteger wrotePosition = new AtomicInteger(0);
// 提交指针
protected final AtomicInteger committedPosition = new AtomicInteger(0);
// 刷盘指针，该指针之前的数据都已持久化至磁盘
private final AtomicInteger flushedPosition = new AtomicInteger(0);
// 文件大小
protected int fileSize;
// 文件通道
protected FileChannel fileChannel;
/**
 * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.
 * 堆内存ByteBuffer，如果不为空，数据会先存在该缓存中
 */
protected ByteBuffer writeBuffer = null;
// 堆内存池
protected TransientStorePool transientStorePool = null;
private String fileName;
// 文件起始偏移量
private long fileFromOffset;
private File file;
// 物理文件对应的内存映射buffer
private MappedByteBuffer mappedByteBuffer;
// 存储时间戳，一般是文件最后一次写入时间
private volatile long storeTimestamp = 0;
// 是否为MappedFileQueue中的第一个文件
private boolean firstCreateInQueue = false;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFile
// 初始化MappedFile
// 其中transientStorePool表示一个短暂的存储池，主要提供了内存锁定的功能，防止其被置换至磁盘，用于提高存储性能
public void init(final String fileName, final int fileSize,
    final TransientStorePool transientStorePool) throws IOException {
    init(fileName, fileSize);
    // 如果transientStorePoolEnable为true，那么writeBuffer 使用堆外内存。
    // 之后commit线程会将其内容提交至内存映射buffer，最后再进行刷盘操作
    this.writeBuffer = transientStorePool.borrowBuffer();
    this.transientStorePool = transientStorePool;
}

private void init(final String fileName, final int fileSize) throws IOException {
    this.fileName = fileName;
    this.fileSize = fileSize;
    this.file = new File(fileName);
    // 初始化文件名为该文件的起始偏移量
    this.fileFromOffset = Long.parseLong(this.file.getName());
    boolean ok = false;

    ensureDirOK(this.file.getParent());

    try {
        // 使用RandomAccessFile创建文件读写通道
        this.fileChannel = new RandomAccessFile(this.file, &quot;rw&quot;).getChannel();
        // 将文件内容映射至内存中---&gt;内存映射机制
        this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize);
        TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize);
        TOTAL_MAPPED_FILES.incrementAndGet();
        ok = true;
    } catch (FileNotFoundException e) {
        log.error(&quot;Failed to create file &quot; + this.fileName, e);
        throw e;
    } catch (IOException e) {
        log.error(&quot;Failed to map file &quot; + this.fileName, e);
        throw e;
    } finally {
        if (!ok &amp;&amp; this.fileChannel != null) {
            this.fileChannel.close();
        }
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFile
// MappedFile 提交
// commitLeastPages为本次提交的最小页数
public int commit(final int commitLeastPages) {
    // writeBuffer 为空不会进行提交操作
    if (writeBuffer == null) {
        //no need to commit data to file channel, so just regard wrotePosition as committedPosition.
        return this.wrotePosition.get();
    }
  
    // 判断commitLeastPages是否符合提交要求
    if (this.isAbleToCommit(commitLeastPages)) {
        if (this.hold()) {
            // 提交数据
            commit0();
            this.release();
        } else {
            log.warn(&quot;in commit, hold failed, commit offset = &quot; + this.committedPosition.get());
        }
    }

    // All dirty data has been committed to FileChannel.
    if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == this.committedPosition.get()) {
        this.transientStorePool.returnBuffer(writeBuffer);
        this.writeBuffer = null;
    }
    // 返回已提交指针
    return this.committedPosition.get();
}

// 判断是否可提交
protected boolean isAbleToCommit(final int commitLeastPages) {
    // 获取已提交指针
    int flush = this.committedPosition.get();
    // 获取当前写指针
    int write = this.wrotePosition.get();
  
    // 页数已满的情况下，直接返回可提交操作
    if (this.isFull()) {
        return true;
    }
    // 如果commitLeastPages 大于0，将当前写指针与已提交指针的差值与commitLeastPages进行比较。其中除以OS_PAGE_SIZE得到的是脏页数
    if (commitLeastPages &gt; 0) {
        return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= commitLeastPages;
    }
    // 当commitLeastPages小于0时，只要存在脏页便允许提交
    return write &gt; flush;
}

// 将writeBuffer中的数据写入fileChannel
protected void commit0() {
    // 获取写指针
    int writePos = this.wrotePosition.get();
    // 获取上次提交指针
    int lastCommittedPosition = this.committedPosition.get();
    // 存在可提交数据
    if (writePos - lastCommittedPosition &gt; 0) {
        try {
            // 创建writeBuffer共享区，slice()方法与原有的ByteBuffer共享内存，但维护了一套独立的指针(position，mark，limit)
            ByteBuffer byteBuffer = writeBuffer.slice();
            // 设置pos为上次提交指针
            byteBuffer.position(lastCommittedPosition);
            // 设置最大有效pos为当前写指针
            byteBuffer.limit(writePos);
            // 设置pos为上次提交指针
            this.fileChannel.position(lastCommittedPosition);
            // 将上次提交pos与本次写pos之间的数据写入fileChannel
            this.fileChannel.write(byteBuffer);
            // 更新已提交指针为当前写指针
            this.committedPosition.set(writePos);
        } catch (Throwable e) {
            log.error(&quot;Error occurred when commit data to FileChannel.&quot;, e);
        }
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFile
// MappedFile 刷盘，将数据持久化到磁盘
public int flush(final int flushLeastPages) {
    // 判断flushLeastPages是否符合提交要求
    if (this.isAbleToFlush(flushLeastPages)) {
        if (this.hold()) {
            // 获取当前读指针
            int value = getReadPosition();

            try {
                //We only append data to fileChannel or mappedByteBuffer, never both.
                if (writeBuffer != null || this.fileChannel.position() != 0) {
                    // 追加数据至fileChannel，并持久化至磁盘
                    this.fileChannel.force(false);
                } else {
                    // 追加数据至mappedByteBuffer，并持久化至磁盘
                    this.mappedByteBuffer.force();
                }
            } catch (Throwable e) {
                log.error(&quot;Error occurred when force data to disk.&quot;, e);
            }
            // 设置刷盘指针为当前文件最大可读指针
            this.flushedPosition.set(value);
            this.release();
        } else {
            log.warn(&quot;in flush, hold failed, flush offset = &quot; + this.flushedPosition.get());
            this.flushedPosition.set(getReadPosition());
        }
    }
    return this.getFlushedPosition();
}

private boolean isAbleToFlush(final int flushLeastPages) {
    // 获取已刷盘指针
    int flush = this.flushedPosition.get();
    // 获取当前读指针
    int write = getReadPosition();
    // 页数已满的情况下，直接返回可刷盘操作
    if (this.isFull()) {
        return true;
    }
    // 如果flushLeastPages 大于0，将当前读指针与已刷盘指针的差值与flushLeastPages进行比较。其中除以OS_PAGE_SIZE得到的是脏页数
    if (flushLeastPages &gt; 0) {
        return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= flushLeastPages;
    }
    // 当flushLeastPages 小于0时，只要存在脏页便允许刷盘
    return write &gt; flush;
}

// 获取当前文件最大可读指针
public int getReadPosition() {
    // 如果writeBuffer为空，直接返回当前写指针，否则返回上次已提交指针
    return this.writeBuffer == null ? this.wrotePosition.get() : this.committedPosition.get();
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.MappedFile
// MappedFile 销毁
// intervalForcibly 表示拒绝销毁的最大存活时间
public boolean destroy(final long intervalForcibly) {
    // 释放资源
    this.shutdown(intervalForcibly);
    // 判断资源是否已清理完毕 
    if (this.isCleanupOver()) {
        try {
            // 关闭fileChannel
            this.fileChannel.close();
            log.info(&quot;close file channel &quot; + this.fileName + &quot; OK&quot;);

            long beginTime = System.currentTimeMillis();、
            // 删除物理文件
            boolean result = this.file.delete();
            log.info(&quot;delete file[REF:&quot; + this.getRefCount() + &quot;] &quot; + this.fileName
                + (result ? &quot; OK, &quot; : &quot; Failed, &quot;) + &quot;W:&quot; + this.getWrotePosition() + &quot; M:&quot;
                + this.getFlushedPosition() + &quot;, &quot;
                + UtilAll.computeElapsedTimeMilliseconds(beginTime));
        } catch (Exception e) {
            log.warn(&quot;close file channel &quot; + this.fileName + &quot; Failed. &quot;, e);
        }

        return true;
    } else {
        log.warn(&quot;destroy mapped file[REF:&quot; + this.getRefCount() + &quot;] &quot; + this.fileName
            + &quot; Failed. cleanupOver: &quot; + this.cleanupOver);
    }

    return false;
}

public void shutdown(final long intervalForcibly) {
    // 判断是否可用，available初始值为true
    if (this.available) {
        this.available = false;
        // 设置首次关闭时间戳
        this.firstShutdownTimestamp = System.currentTimeMillis();
        // 释放资源，只有引用次数小于1的情况下才会执行释放操作
        this.release();
    } else if (this.getRefCount() &gt; 0) {
        // 非首次销毁，判断当前时间与firstShutdownTimestamp的差值是否大于intervalForcibly
        if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) {
            // 将引用次数减少1000
            this.refCount.set(-1000 - this.getRefCount());
            // 释放资源，只有引用次数小于1的情况下才会执行释放操作
            this.release();
        }
    }
}

public void release() {
    // 引用次数减1
    long value = this.refCount.decrementAndGet();
    // 大于0的情况下，不进行释放操作
    if (value &gt; 0)
        return;

    synchronized (this) {
        // 清理资源
        this.cleanupOver = this.cleanup(value);
    }
}

public boolean cleanup(final long currentRef) {
    // 如果available为true，表明当前MappedFile可用，无需清理
    if (this.isAvailable()) {
        log.error(&quot;this file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName
            + &quot; have not shutdown, stop unmapping.&quot;);
        return false;
    }
    // 如果已经清理完毕，则直接返回true 
    if (this.isCleanupOver()) {
        log.error(&quot;this file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName
            + &quot; have cleanup, do not do it again.&quot;);
        return true;
    }
    // 清理mappedByteBuffer
    clean(this.mappedByteBuffer);
    // 维护TOTAL_MAPPED_VIRTUAL_MEMORY及TOTAL_MAPPED_FILES值
    TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(this.fileSize * (-1));
    TOTAL_MAPPED_FILES.decrementAndGet();
    log.info(&quot;unmap file[REF:&quot; + currentRef + &quot;] &quot; + this.fileName + &quot; OK&quot;);
    return true;
}

// 清理完成的判断：是引用次数已经归零且cleanupOver为true
public boolean isCleanupOver() {
    return this.refCount.get() &lt;= 0 &amp;&amp; this.cleanupOver;
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之消息发送]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-fa-song/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-xiao-xi-fa-song/">
        </link>
        <updated>2022-10-05T03:12:44.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之消息发送。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/coast-192981_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="消息发送">消息发送</h2>
<h3 id="简介">简介</h3>
<p>RocketMQ支持3种消息发送方式：同步（sync），异步（async），单向（oneway）。</p>
<ul>
<li>同步（sync）：producer发送消息时，同步等待，直到服务器返回发送结果。</li>
<li>异步（async）：producer发送消息时，指定消息发送成功后的回调函数，而无需等待发送结果。整个发送过程为非阻塞状态。</li>
<li>单向（oneway）：producer发送消息后，不等待返回结果；即只管发送，不在乎消息是否成功存储在消息服务器上。</li>
</ul>
<p>RocketMQ中的主要消息属性如下：</p>
<pre><code>// 文件地址：org.apache.rocketmq.common.message.Message
private String topic;
private int flag;
// 扩展属性中用的比较多的如：tag，keys，waitStoreMsgOK，delayTimeLevel等
private Map&lt;String, String&gt; properties;
private byte[] body;
private String transactionId;

</code></pre>
<p>RocketMQ中的消息扩展属性介绍：</p>
<ul>
<li>tag：标签，主要用于过滤同一topic中的消息。消费多个tag时，以 &quot;||&quot; 作为分隔符。</li>
<li>keys：message索引键，多个以空格分隔。该属性可用于快速检索消息（例如消费失败时查询对应的消息）。</li>
<li>waitStoreMsgOK：消息发送时是否等待消息存储完成后再返回。</li>
<li>delayTimeLevel：消息延迟级别（1-18），主要用于消息重试和延迟消息。</li>
</ul>
<h3 id="启动流程">启动流程</h3>
<p>RocketMQ启动的核心代码在org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl中，如下所示：</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl
public void start(final boolean startFactory) throws MQClientException {
    switch (this.serviceState) {
        case CREATE_JUST:
            this.serviceState = ServiceState.START_FAILED;
            // 检查producerGroup是否合法
            this.checkConfig();

             // 当默认的producerGroup跟MixAll.CLIENT_INNER_PRODUCER_GROUP不相等时，改变生产者的instanceName为进程ID
            if (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) {
                // 如果instanceName为“DEFAULT”时，此处改变函数将会将instanceName更改为进程id + 当前纳秒
                // this.instanceName = UtilAll.getPid() + &quot;#&quot; + System.nanoTime();
                this.defaultMQProducer.changeInstanceNameToPID();
            }
        
            // 创建MQClientInstance实例，整个JVM中只存在一个MQClientManager实例，其中维护了一个factoryTable用于存储clientId与MQClientInstance
            // private ConcurrentMap&lt;String/* clientId */, MQClientInstance&gt; factoryTable 
            // 也就是说一个clientId只会存在一个至于对应的MQClientInstance
            this.mQClientFactory = MQClientManager.getInstance().getOrCreateMQClientInstance(this.defaultMQProducer, rpcHook);

            // 将当前生产者加入MQClientInstance中进行管理，方便后续调用网络请求，发送心跳包等
            boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);
            if (!registerOK) {
                this.serviceState = ServiceState.CREATE_JUST;
                throw new MQClientException(&quot;The producer group[&quot; + this.defaultMQProducer.getProducerGroup()
                    + &quot;] has been created before, specify another name please.&quot; + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL),
                    null);
            }

            //  将topicKey存入topicPublishInfoTable中，value暂时为无属性值的TopicPublishInfo对象
            this.topicPublishInfoTable.put(this.defaultMQProducer.getCreateTopicKey(), new TopicPublishInfo());

            // 启动 MQClientInstance，如果已启动，则本次操作不做处理
            if (startFactory) {
                mQClientFactory.start();
            }

            log.info(&quot;the producer [{}] start OK. sendMessageWithVIPChannel={}&quot;, this.defaultMQProducer.getProducerGroup(),
                this.defaultMQProducer.isSendMessageWithVIPChannel());
            this.serviceState = ServiceState.RUNNING;
            break;
        case RUNNING:
        case START_FAILED:
        case SHUTDOWN_ALREADY:
            throw new MQClientException(&quot;The producer service state not OK, maybe started once, &quot;
                + this.serviceState
                + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),
                null);
        default:
            break;
    }
    // 发送心跳 
    this.mQClientFactory.sendHeartbeatToAllBrokerWithLock();

    RequestFutureHolder.getInstance().startScheduledTask(this);

}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.MQClientManager
public MQClientInstance getOrCreateMQClientInstance(final ClientConfig clientConfig, RPCHook rpcHook) {
    // 创建clientId
    String clientId = clientConfig.buildMQClientId();
    // 一个clientId只对应一个MQClientInstance
    MQClientInstance instance = this.factoryTable.get(clientId);
    // 不存在就直接创建一个，否则便返回已创建的MQClientInstance
    if (null == instance) {
        instance =
            new MQClientInstance(clientConfig.cloneClientConfig(),
                this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook);
        MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance);
        if (prev != null) {
            instance = prev;
            log.warn(&quot;Returned Previous MQClientInstance for clientId:[{}]&quot;, clientId);
        } else {
            log.info(&quot;Created new MQClientInstance for clientId:[{}]&quot;, clientId);
        }
    }

    return instance;
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.ClientConfig
// clientId格式为：clientIP + instanceName + （unitName 可选值）
// 即使在同一台机器上部署了两个应用程序，clientId也会不同。详情可参见changeInstanceNameToPID函数
public String buildMQClientId() {
    StringBuilder sb = new StringBuilder();
    sb.append(this.getClientIP());
    sb.append(&quot;@&quot;);
    sb.append(this.getInstanceName());
    if (!UtilAll.isBlank(this.unitName)) {
        sb.append(&quot;@&quot;);
        sb.append(this.unitName);
    }
    return sb.toString();
}

// 如果instanceName为“DEFAULT”的情况下，instanceName将会赋值为进程id + 当前纳秒
public void changeInstanceNameToPID() {
    if (this.instanceName.equals(&quot;DEFAULT&quot;)) {
        this.instanceName = UtilAll.getPid() + &quot;#&quot; + System.nanoTime();
    }
}

</code></pre>
<h3 id="消息发送流程">消息发送流程</h3>
<p>消息发送主要分为验证消息，寻找路由，选择消息队列，发送消息四个步骤。此处分析以同步发送的源码为例。</p>
<h4 id="验证消息">验证消息</h4>
<p>消息发送之前，需要校验消息的合法性，包括主题是否规范，消息内容是否不为空等。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.producer.DefaultMQProducer
public SendResult send(
    Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    msg.setTopic(withNamespace(msg.getTopic()));
    // 同步发送，默认超时时间为3秒
    return this.defaultMQProducerImpl.send(msg);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl
// 确保服务状态是可运行的
private void makeSureStateOK() throws MQClientException {
    if (this.serviceState != ServiceState.RUNNING) {
        throw new MQClientException(&quot;The producer service state not OK, &quot;
            + this.serviceState
            + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK),
            null);
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.Validators
public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer) throws MQClientException {
    if (null == msg) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message is null&quot;);
    }
    // topic
    // 校验topic不能为空，且长度不能超过127
    Validators.checkTopic(msg.getTopic());
    // 校验topic是否允许发送消息
    Validators.isNotAllowedSendTopic(msg.getTopic());

    // body 不能为空
    if (null == msg.getBody()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body is null&quot;);
    }

    // body 内容长度不能等于0
    if (0 == msg.getBody().length) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, &quot;the message body length is zero&quot;);
    }

    // 校验消息体，默认不能超过4M 
    if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) {
        throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL,
            &quot;the message body size over max value, MAX: &quot; + defaultMQProducer.getMaxMessageSize());
    }
}

</code></pre>
<h4 id="寻找主题路由信息">寻找主题路由信息</h4>
<p>消息发送之前，需要先获取主题的路由信息，通过主题路由信息才能知道消息该发往哪个broker节点。</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.TopicPublishInfo
// TopicPublishInfo 属性信息
// 是否为顺序主题
private boolean orderTopic = false;
// 是否已有主题路由信息
private boolean haveTopicRouterInfo = false;
// 该主题的消息队列列表
private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;();
// 每次发送消息时，此值会递增1（为空时将随机选出一个值），主要用于队列选择
private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex();
// 主题路由数据--》包括orderTopicConf，queueDatas，brokerDatas，filterServerTable等属性信息
private TopicRouteData topicRouteData;

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl
private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) {
    // 从本地缓存中获取路由信息
    TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic);
    // 如果不存在，那么便从nameServer中获取对应的路由信息，并将其放入本地缓存中
    if (null == topicPublishInfo || !topicPublishInfo.ok()) {
        this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo());
        // 通过指定的topic获取对应的路由信息
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
    }

    if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) {
        return topicPublishInfo;
    } else {
        // 尝试使用默认主题去获取路由信息
        this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer);
        topicPublishInfo = this.topicPublishInfoTable.get(topic);
        return topicPublishInfo;
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.factory.MQClientInstance
public boolean updateTopicRouteInfoFromNameServer(final String topic, boolean isDefault,
    DefaultMQProducer defaultMQProducer) {
    try {
        if (this.lockNamesrv.tryLock(LOCK_TIMEOUT_MILLIS, TimeUnit.MILLISECONDS)) {
            try {
                TopicRouteData topicRouteData;
                // 使用默认主题去获取路由信息
                if (isDefault &amp;&amp; defaultMQProducer != null) {
                    // 注意：获取路由信息时，如果autoCreateTopicEnable为false，将会返回异常
                    topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(),
                        clientConfig.getMqClientApiTimeout());
                    if (topicRouteData != null) {
                        for (QueueData data : topicRouteData.getQueueDatas()) {
                            // 比较默认的主题队列数与数据的读队列数，选择其中更小的一个替换数据的读写队列数
                            int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());
                            data.setReadQueueNums(queueNums);
                            data.setWriteQueueNums(queueNums);
                        }
                    }
                } else {
                    // 否则通过指定的topic去获取对应的路由信息
                    topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, clientConfig.getMqClientApiTimeout());
                }
                // 如果从nameServer中获取到了topicRouteData 
                if (topicRouteData != null) {
                    // 获取本地缓存的路由信息
                    TopicRouteData old = this.topicRouteTable.get(topic);
                    // 将刚获取的topicRouteData 与本地缓存中的数据进行比较，如果未改变的话将直接返回false
                    boolean changed = topicRouteDataIsChange(old, topicRouteData);
                    if (!changed) {
                        changed = this.isNeedUpdateTopicRouteInfo(topic);
                    } else {
                        log.info(&quot;the topic[{}] route info changed, old[{}] ,new[{}]&quot;, topic, old, topicRouteData);
                    }
                    // 如果发生了改变
                    if (changed) {
                        TopicRouteData cloneTopicRouteData = topicRouteData.cloneTopicRouteData();

                        for (BrokerData bd : topicRouteData.getBrokerDatas()) {
                            this.brokerAddrTable.put(bd.getBrokerName(), bd.getBrokerAddrs());
                        }

                        // 更新所有需要进行发送的主题路由信息
                        if (!producerTable.isEmpty()) {
                            // 获取需要进行更改的发布信息
                            TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData);
                            publishInfo.setHaveTopicRouterInfo(true);
                            Iterator&lt;Entry&lt;String, MQProducerInner&gt;&gt; it = this.producerTable.entrySet().iterator();
                            // 迭代更改
                            while (it.hasNext()) {
                                Entry&lt;String, MQProducerInner&gt; entry = it.next();
                                MQProducerInner impl = entry.getValue();
                                if (impl != null) {
                                    // 所有信息都会存入topicPublishInfoTable
                                    impl.updateTopicPublishInfo(topic, publishInfo);
                                }
                            }
                        }

                        // 更新所有需要进行订阅的主题路由信息
                        if (!consumerTable.isEmpty()) {
                            // 获取需要进行更改的订阅信息
                            Set&lt;MessageQueue&gt; subscribeInfo = topicRouteData2TopicSubscribeInfo(topic, topicRouteData);
                            Iterator&lt;Entry&lt;String, MQConsumerInner&gt;&gt; it = this.consumerTable.entrySet().iterator();
                            // 迭代更改
                            while (it.hasNext()) {
                                Entry&lt;String, MQConsumerInner&gt; entry = it.next();
                                MQConsumerInner impl = entry.getValue();
                                if (impl != null) {
                                    // 所有信息都会存入topicSubscribeInfoTable
                                    impl.updateTopicSubscribeInfo(topic, subscribeInfo);
                                }
                            }
                        }
                        log.info(&quot;topicRouteTable.put. Topic = {}, TopicRouteData[{}]&quot;, topic, cloneTopicRouteData);
                        this.topicRouteTable.put(topic, cloneTopicRouteData);
                        return true;
                    }
                } else {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer, getTopicRouteInfoFromNameServer return null, Topic: {}. [{}]&quot;, topic, this.clientId);
                }
            } catch (MQClientException e) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX) &amp;&amp; !topic.equals(TopicValidator.AUTO_CREATE_TOPIC_KEY_TOPIC)) {
                    log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                }
            } catch (RemotingException e) {
                log.error(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
                throw new IllegalStateException(e);
            } finally {
                this.lockNamesrv.unlock();
            }
        } else {
            log.warn(&quot;updateTopicRouteInfoFromNameServer tryLock timeout {}ms. [{}]&quot;, LOCK_TIMEOUT_MILLIS, this.clientId);
        }
    } catch (InterruptedException e) {
        log.warn(&quot;updateTopicRouteInfoFromNameServer Exception&quot;, e);
    }

    return false;
}

</code></pre>
<h4 id="选择消息队列">选择消息队列</h4>
<p>发送消息时，可以通过指定MessageQueueSelector选择队列路由算法（默认有取hash，随机，指定机房(此类型实现暂时为空)）；未指定MessageQueueSelector 时，rocketmq 将使用默认的规则选择一个message queue。</p>
<pre><code>// 自带的消息路由规则
// 取arg参数的hashcode的绝对值，然后对mqs.size()取余，得到目标队列在mqs的下标
public class SelectMessageQueueByHash implements MessageQueueSelector {

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        int value = arg.hashCode() % mqs.size();
        if (value &lt; 0) {
            value = Math.abs(value);
        }
        return mqs.get(value);
    }
}

// 直接根据mqs.size()随机一个值作为目标队列在mqs的下标
public class SelectMessageQueueByRandom implements MessageQueueSelector {
    private Random random = new Random(System.currentTimeMillis());

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        int value = random.nextInt(mqs.size());
        return mqs.get(value);
    }
}

// 指定机房，目前return null，暂无实现逻辑
public class SelectMessageQueueByMachineRoom implements MessageQueueSelector {
    private Set&lt;String&gt; consumeridcs;

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        return null;
    }

    public Set&lt;String&gt; getConsumeridcs() {
        return consumeridcs;
    }

    public void setConsumeridcs(Set&lt;String&gt; consumeridcs) {
        this.consumeridcs = consumeridcs;
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.latency.MQFaultStrategy
// 未指定MessageQueueSelector，将使用自带的算法选择一个消息队列。
public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) {
    // 是否启用了broker故障延迟机制，默认为false
    // 为了producer的高可用，可以将此开关开启
    if (this.sendLatencyFaultEnable) {
        try {
            int index = tpInfo.getSendWhichQueue().incrementAndGet();
            // 遍历当前broker的队列列表
            for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) {
                 // 取模运算获取pos值
                int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();
                if (pos &lt; 0)
                    pos = 0;
                MessageQueue mq = tpInfo.getMessageQueueList().get(pos);
                // 验证该broker是否可用，可用便直接返回
                if (latencyFaultTolerance.isAvailable(mq.getBrokerName()))
                    return mq;
            }

            // 选择一个broker，可能并非最好的  
            final String notBestBroker = latencyFaultTolerance.pickOneAtLeast();
            int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker);
            // 如果存在可写的队列，便返回该broker对应的queue
            if (writeQueueNums &gt; 0) {
                final MessageQueue mq = tpInfo.selectOneMessageQueue();
                if (notBestBroker != null) {
                    mq.setBrokerName(notBestBroker);
                    mq.setQueueId(tpInfo.getSendWhichQueue().incrementAndGet() % writeQueueNums);
                }
                return mq;
            } else {
                // 否则便从faultItemTable中移除该broker
                latencyFaultTolerance.remove(notBestBroker);
            }
        } catch (Exception e) {
            log.error(&quot;Error occurred when selecting message queue&quot;, e);
        }

        return tpInfo.selectOneMessageQueue();
    }

    // 未启用broker故障延迟机制时，使用如下函数选择一个队列
    return tpInfo.selectOneMessageQueue(lastBrokerName);
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.TopicPublishInfo
// 此处lastBrokerName 表示上次发送消息的broker
public MessageQueue selectOneMessageQueue(final String lastBrokerName) {
    if (lastBrokerName == null) {
        return selectOneMessageQueue();
    } else {
        for (int i = 0; i &lt; this.messageQueueList.size(); i++) {
            int index = this.sendWhichQueue.incrementAndGet();
            int pos = Math.abs(index) % this.messageQueueList.size();
            if (pos &lt; 0)
                pos = 0;
            MessageQueue mq = this.messageQueueList.get(pos);
            if (!mq.getBrokerName().equals(lastBrokerName)) {
                return mq;
            }
        }
        return selectOneMessageQueue();
    }
}
// 递增取模获取发送队列
public MessageQueue selectOneMessageQueue() {
    int index = this.sendWhichQueue.incrementAndGet();
    int pos = Math.abs(index) % this.messageQueueList.size();
    if (pos &lt; 0)
        pos = 0;
    return this.messageQueueList.get(pos);
}

</code></pre>
<h4 id="发送消息">发送消息</h4>
<p>发送消息的核心函数为：sendDefaultImpl</p>
<pre><code>// 文件地址：org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl
private SendResult sendKernelImpl(
    // 待发送的消息
    final Message msg,
    // 消息发往的消息队列
    final MessageQueue mq,
    // 消息发送模式，即同步（SYNC），异步（ASYNC），单向（ONEWAY）
    final CommunicationMode communicationMode,
    // 发送异步消息时需要设置的回调函数
    final SendCallback sendCallback,
    // 主题路由信息
    final TopicPublishInfo topicPublishInfo,
    // 超时时间
    final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException {
    long beginStartTime = System.currentTimeMillis();
  
    // 根据messageQueue对应的brokerName获取broker的网络地址。
    String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());
    // 如果本地brokerAddrTable未缓存该信息，那么便与nameServer进行通信，获取broker信息
    if (null == brokerAddr) {
        // 从nameServer获取信息主动更新一下topic在本地的路由信息
        tryToFindTopicPublishInfo(mq.getTopic());
        // 从缓存中再次获取broker网络地址，如果未获取到，将抛出broker不存在异常
        brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());
    }

    SendMessageContext context = null;
    if (brokerAddr != null) {
        brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr);

        byte[] prevBody = msg.getBody();
        try {
            // 对于非批量消息给其设置唯一id（因为批量消息在其生成过程中已经设置好了）
            if (!(msg instanceof MessageBatch)) {
                MessageClientIDSetter.setUniqID(msg);
            }

            boolean topicWithNamespace = false;
            if (null != this.mQClientFactory.getClientConfig().getNamespace()) {
                msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace());
                topicWithNamespace = true;
            }

            // 设置系统标签
            int sysFlag = 0;
            boolean msgBodyCompressed = false;
            // 消息内容大于4K将会被压缩（批量消息会被忽略）
            if (this.tryToCompressMessage(msg)) {
                sysFlag |= MessageSysFlag.COMPRESSED_FLAG;
                msgBodyCompressed = true;
            }

            // 是否为事务消息，如果是则设置sysFlag 为TRANSACTION_PREPARED_TYPE（整型数值：4）
            final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
            if (Boolean.parseBoolean(tranMsg)) {
                sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;
            }

            // 在消息发送之前，判断是否有检查禁止项的钩子函数
            if (hasCheckForbiddenHook()) {
                CheckForbiddenContext checkForbiddenContext = new CheckForbiddenContext();
                checkForbiddenContext.setNameSrvAddr(this.defaultMQProducer.getNamesrvAddr());
                checkForbiddenContext.setGroup(this.defaultMQProducer.getProducerGroup());
                checkForbiddenContext.setCommunicationMode(communicationMode);
                checkForbiddenContext.setBrokerAddr(brokerAddr);
                checkForbiddenContext.setMessage(msg);
                checkForbiddenContext.setMq(mq);
                checkForbiddenContext.setUnitMode(this.isUnitMode());
                this.executeCheckForbiddenHook(checkForbiddenContext);
            }

            // 在消息发送之前，判断是否有发送消息增强的钩子函数
            if (this.hasSendMessageHook()) {
                context = new SendMessageContext();
                context.setProducer(this);
                context.setProducerGroup(this.defaultMQProducer.getProducerGroup());
                context.setCommunicationMode(communicationMode);
                context.setBornHost(this.defaultMQProducer.getClientIP());
                context.setBrokerAddr(brokerAddr);
                context.setMessage(msg);
                context.setMq(mq);
                context.setNamespace(this.defaultMQProducer.getNamespace());
                String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
                if (isTrans != null &amp;&amp; isTrans.equals(&quot;true&quot;)) {
                    context.setMsgType(MessageType.Trans_Msg_Half);
                }

                if (msg.getProperty(&quot;__STARTDELIVERTIME&quot;) != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) {
                    context.setMsgType(MessageType.Delay_Msg);
                }
                this.executeSendMessageHookBefore(context);
            }

            // 构建发送请求 
            SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();
            requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());
            requestHeader.setTopic(msg.getTopic());
            requestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());
            requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());
            requestHeader.setQueueId(mq.getQueueId());
            requestHeader.setSysFlag(sysFlag);
            requestHeader.setBornTimestamp(System.currentTimeMillis());
            requestHeader.setFlag(msg.getFlag());
            requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));
            requestHeader.setReconsumeTimes(0);
            requestHeader.setUnitMode(this.isUnitMode());
            requestHeader.setBatch(msg instanceof MessageBatch);
            if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                String reconsumeTimes = MessageAccessor.getReconsumeTime(msg);
                if (reconsumeTimes != null) {
                    requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes));
                    MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME);
                }

                String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg);
                if (maxReconsumeTimes != null) {
                    requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes));
                    MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES);
                }
            }

            SendResult sendResult = null;
            // 根据消息发送模式路由发送方式：同步，异步，单向
            switch (communicationMode) {
                case ASYNC:
                    Message tmpMessage = msg;
                    boolean messageCloned = false;
                    if (msgBodyCompressed) {
                        //If msg body was compressed, msgbody should be reset using prevBody.
                        //Clone new message using commpressed message body and recover origin massage.
                        //Fix bug:https://github.com/apache/rocketmq-externals/issues/66
                        tmpMessage = MessageAccessor.cloneMessage(msg);
                        messageCloned = true;
                        msg.setBody(prevBody);
                    }

                    if (topicWithNamespace) {
                        if (!messageCloned) {
                            tmpMessage = MessageAccessor.cloneMessage(msg);
                            messageCloned = true;
                        }
                        msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace()));
                    }

                    long costTimeAsync = System.currentTimeMillis() - beginStartTime;
                    if (timeout &lt; costTimeAsync) {
                        throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);
                    }
                    sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(
                        brokerAddr,
                        mq.getBrokerName(),
                        tmpMessage,
                        requestHeader,
                        timeout - costTimeAsync,
                        communicationMode,
                        sendCallback,
                        topicPublishInfo,
                        this.mQClientFactory,
                        this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(),
                        context,
                        this);
                    break;
                case ONEWAY:
                case SYNC:
                    long costTimeSync = System.currentTimeMillis() - beginStartTime;
                    if (timeout &lt; costTimeSync) {
                        throw new RemotingTooMuchRequestException(&quot;sendKernelImpl call timeout&quot;);
                    }
                    sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage(
                        brokerAddr,
                        mq.getBrokerName(),
                        msg,
                        requestHeader,
                        timeout - costTimeSync,
                        communicationMode,
                        context,
                        this);
                    break;
                default:
                    assert false;
                    break;
            }

            // 消息发送之后，判断是否有对应的消息增强处理钩子函数
            if (this.hasSendMessageHook()) {
                context.setSendResult(sendResult);
                this.executeSendMessageHookAfter(context);
            }

            return sendResult;
        } catch (RemotingException e) {
            // 消息发送之后，判断是否有对应的消息增强处理钩子函数
            if (this.hasSendMessageHook()) {
                context.setException(e);
                this.executeSendMessageHookAfter(context);
            }
            throw e;
        } catch (MQBrokerException e) {
            // 消息发送之后，判断是否有对应的消息增强处理钩子函数
            if (this.hasSendMessageHook()) {
                context.setException(e);
                this.executeSendMessageHookAfter(context);
            }
            throw e;
        } catch (InterruptedException e) {
            // 消息发送之后，判断是否有对应的消息增强处理钩子函数
            if (this.hasSendMessageHook()) {
                context.setException(e);
                this.executeSendMessageHookAfter(context);
            }
            throw e;
        } finally {
            msg.setBody(prevBody);
            msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace()));
        }
    }

    throw new MQClientException(&quot;The broker[&quot; + mq.getBrokerName() + &quot;] not exist&quot;, null);
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ源码解读之NameServer]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-nameserver/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-yuan-ma-jie-du-zhi-nameserver/">
        </link>
        <updated>2022-09-24T03:07:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq源码之NameService。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sea-6331772_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="路由中心">路由中心</h2>
<h3 id="简介">简介</h3>
<p>Broker启动时向所有的NameServer发送注册请求，并与所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。</p>
<p>Producer启动时会先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，之后便会与该broker建立长链接并发送消息。</p>
<p>NameServer可以通过部署多台NameServer服务器来实现高可用，且每台服务器之间并不会进行通信，也就是说某些时候NameServer服务器之间的数据会不一致，但这不会对消息的发送造成任何影响。如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320006.png" alt="img" loading="lazy"></figure>
<h3 id="启动流程">启动流程</h3>
<p>通过脚本启动NameServer时，实际上是调用了org.apache.rocketmq.namesr.NamesrvStartup进行启动操作。</p>
<p>启动时首先会加载配置信息，将指定的配置文件或命令中的选项值填充至NamesrvConfig及NettyServerConfig。参数来源方式主要有两种：</p>
<ol>
<li>-c configFile 通过-c命令指定配置文件的路径。</li>
<li>在启动命令时使用 &quot;--属性名 属性值&quot;，例如：--listenPort 9876</li>
</ol>
<pre><code>// 文件地址: org.apache.rocketmq.common.namesrv.NamesrvConfig
// NamesrvConfig 属性信息
// rocketmq主目录，可通过-Drocketmq.home.dir=path或通过设置环境变量ROCKETMQ_HOME来配置rocketmq的主目录
private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));
// NameServer存储KV配置属性的持久化文件
private String kvConfigPath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;kvConfig.json&quot;;
// nameServer默认的配置文件路径，不生效。如果要指定配置文件，可以通过 -c 参数来指定
private String configStorePath = System.getProperty(&quot;user.home&quot;) + File.separator + &quot;namesrv&quot; + File.separator + &quot;namesrv.properties&quot;;
private String productEnvName = &quot;center&quot;;
private boolean clusterTest = false;
// 默认关闭顺序消息
private boolean orderMessageEnable = false;

</code></pre>
<pre><code>// 文件地址: org.apache.rocketmq.remoting.netty.NettyServerConfig
// NettyServerConfig 属性信息
// NameServer监听端口，默认为9876，此处的值将会被覆盖
private int listenPort = 8888;
// netty 业务线程池线程数，用于处理具体的逻辑业务
private int serverWorkerThreads = 8;
// Netty public 任务线程池线程数，Netty网络设计会根据业务类型创建不同的线程池。例如发送消息，消费消息，心跳检测等。
private int serverCallbackExecutorThreads = 0;
// IO线程池线程数。主要用于解析请求，并转发值具体的业务线程执行具体的逻辑。
private int serverSelectorThreads = 3;
// send oneWay 消息请求并发度（broker端参数）
private int serverOnewaySemaphoreValue = 256;
// 异步消息发送的最大并发度（broker端参数）
private int serverAsyncSemaphoreValue = 64;
// 网络连接最大空闲时间，默认120s，如果超过此时间，连接将关闭。
private int serverChannelMaxIdleTimeSeconds = 120;

// socket发送缓冲区大小
private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;
// socket接受缓冲区大小
private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;
// 写缓冲区高水位值
private int writeBufferHighWaterMark = NettySystemConfig.writeBufferHighWaterMark;
// 写缓冲区低水位值
private int writeBufferLowWaterMark = NettySystemConfig.writeBufferLowWaterMark;
// socket 日志
private int serverSocketBacklog = NettySystemConfig.socketBacklog;
// 是否开启byteBuffer缓存，默认开启
private boolean serverPooledByteBufAllocatorEnable = true;
// 是否启用epoll io模型，默认关闭
private boolean useEpollNativeSelector = false;

</code></pre>
<p>通过启动属性创建NamesrvController并实例化，该类为NameServer的核心控制器。在初始化该控制器时，会开启两个定时任务。</p>
<ol>
<li>scanNotActiveBroker：延迟5秒启动，每隔10秒扫描一次broker，将其中不活跃的移除。</li>
<li>printAllPeriodically：延迟1分钟启动，每隔10分钟打印一次KV配置信息。</li>
</ol>
<pre><code>// 文件地址: org.apache.rocketmq.namesrv.NamesrvController
public boolean initialize() {

    this.kvConfigManager.load();
    this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService);
    this.remotingExecutor =
        Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(&quot;RemotingExecutorThread_&quot;));
    this.registerProcessor();

    // 定时移除不活跃的broker（2分钟内未收到心跳包，则该broker将被移除）
    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {

        @Override
        public void run() {
            NamesrvController.this.routeInfoManager.scanNotActiveBroker();
        }
    }, 5, 10, TimeUnit.SECONDS);

    // 定时打印KV配置信息
    this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {

        @Override
        public void run() {
            NamesrvController.this.kvConfigManager.printAllPeriodically();
        }
    }, 1, 10, TimeUnit.MINUTES);
    ......
    return true;
}

</code></pre>
<h3 id="路由注册">路由注册</h3>
<p>NameServer主要作用便是给发送者及消费者提供关于Topic的路由信息。</p>
<p>rocketmq的路由注册主要通过Broker与NameServer的心跳机制来实现的。Broker启动时会向集群中所有的NameServer发送心跳包，之后每隔30秒会再次发送。</p>
<p>NameServer收到Broker心跳包时会更新brokerLiveTable中的BrokerLiveInfo信息。与此同时，NameServer每隔10秒会去扫描brokerLiveTable，如果两分钟内未收到心跳包，那么该Broker将会被移除，且socket也将被关闭。</p>
<p>核心类：org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager</p>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager
// Topic消息队列路由信息，消息发送时会根据路由表进行负载均衡。
private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;
// Broker基础信息，例如：brokerName，clusterName，主备broker地址等
private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;
// Broker集群信息，存储集群中所有Broker名称
private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;
// Broker状态信息，NameServer每次收到心跳包时会替换该信息
private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;
// Broker上的filterServer列表，主要用于类模式消息过滤。
private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;

// 容器初始化大小
public RouteInfoManager() {
    this.topicQueueTable = new HashMap&lt;String, List&lt;QueueData&gt;&gt;(1024);
    this.brokerAddrTable = new HashMap&lt;String, BrokerData&gt;(128);
    this.clusterAddrTable = new HashMap&lt;String, Set&lt;String&gt;&gt;(32);
    this.brokerLiveTable = new HashMap&lt;String, BrokerLiveInfo&gt;(256);
    this.filterServerTable = new HashMap&lt;String, List&lt;String&gt;&gt;(256);
}

</code></pre>
<h4 id="broker发送心跳包">Broker发送心跳包</h4>
<p>Broker封装对应的请求头及请求体信息，并发送注册请求至NameServer。</p>
<pre><code>// 文件地址：org.apache.rocketmq.broker.BrokerController#start
this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {
    @Override
    public void run() {
        try {
            BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister());
        } catch (Throwable e) {
            log.error(&quot;registerBrokerAll Exception&quot;, e);
        }
    }
}, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.broker.out.BrokerOuterAPI#registerBrokerAll
public List&lt;RegisterBrokerResult&gt; registerBrokerAll(
    final String clusterName,
    final String brokerAddr,
    final String brokerName,
    final long brokerId,
    final String haServerAddr,
    final TopicConfigSerializeWrapper topicConfigWrapper,
    final List&lt;String&gt; filterServerList,
    final boolean oneway,
    final int timeoutMills,
    final boolean compressed) {

    final List&lt;RegisterBrokerResult&gt; registerBrokerResultList = new CopyOnWriteArrayList&lt;&gt;();
    List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList();
    if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) {

        // 设置请求头信息
        final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader();
        requestHeader.setBrokerAddr(brokerAddr);
        // brokerId：0表示master，大于0表示slave
        requestHeader.setBrokerId(brokerId);
        requestHeader.setBrokerName(brokerName);
        requestHeader.setClusterName(clusterName);
        // master地址
        requestHeader.setHaServerAddr(haServerAddr);
        requestHeader.setCompressed(compressed);

        // 设置请求体
        RegisterBrokerBody requestBody = new RegisterBrokerBody();
        // 主题配置信息
        requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper);
        // 消息过滤服务列表
        requestBody.setFilterServerList(filterServerList);
        final byte[] body = requestBody.encode(compressed);
        final int bodyCrc32 = UtilAll.crc32(body);
        requestHeader.setBodyCrc32(bodyCrc32);
        final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size());
        // 遍历NameServer列表，逐个发送心跳请求。
        for (final String namesrvAddr : nameServerAddressList) {
            brokerOuterExecutor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        RegisterBrokerResult result = registerBroker(namesrvAddr, oneway, timeoutMills, requestHeader, body);
                        if (result != null) {
                            registerBrokerResultList.add(result);
                        }

                        log.info(&quot;register broker[{}]to name server {} OK&quot;, brokerId, namesrvAddr);
                    } catch (Exception e) {
                        log.warn(&quot;registerBroker Exception, {}&quot;, namesrvAddr, e);
                    } finally {
                        countDownLatch.countDown();
                    }
                }
            });
        }

        try {
            countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
        }
    }

    return registerBrokerResultList;
}

</code></pre>
<h4 id="nameserver-处理心跳包">NameServer 处理心跳包</h4>
<p>org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor接受网络请求，并根据类型路由请求。如果请求类型为REGISTER_BROKER，则表示为注册请求，最终将路由至RouteInfoManager#registerBroker进行处理。</p>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor#processRequest
// 接受类型为REGISTER_BROKER的请求，并路由至RouteInfoManager#registerBroker进行处理
case RequestCode.REGISTER_BROKER:
    Version brokerVersion = MQVersion.value2Version(request.getVersion());
    if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) {
        return this.registerBrokerWithFilterServer(ctx, request);
    } else {
        return this.registerBroker(ctx, request);
    }

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager
public RegisterBrokerResult registerBroker(
    final String clusterName,
    final String brokerAddr,
    final String brokerName,
    final long brokerId,
    final String haServerAddr,
    final TopicConfigSerializeWrapper topicConfigWrapper,
    final List&lt;String&gt; filterServerList,
    final Channel channel) {
    RegisterBrokerResult result = new RegisterBrokerResult();
    try {
        try {
            // 加写锁，防止并发修改路由表
            this.lock.writeLock().lockInterruptibly();

            // 获取brokerName集s
            Set&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName);
            // 如果不存在则创建
            if (null == brokerNames) {
                brokerNames = new HashSet&lt;String&gt;();
                this.clusterAddrTable.put(clusterName, brokerNames);
            }
            // 将新加入的brokerName添加至brokerNames中
            brokerNames.add(brokerName);

            // 为false表示为非第一次注册  
            boolean registerFirst = false;

            // 获取brokerData 信息
            BrokerData brokerData = this.brokerAddrTable.get(brokerName);
            // 如果不存在则创建并将registerFirst 设置为true（表示第一次注册）
            if (null == brokerData) {
                registerFirst = true;
                brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;());
                this.brokerAddrTable.put(brokerName, brokerData);
            }
            Map&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs();
            //Switch slave to master: first remove &lt;1, IP:PORT&gt; in namesrv, then add &lt;0, IP:PORT&gt;
            //The same IP:PORT must only have one record in brokerAddrTable
            // 移除brokerAddr相同的数据
            Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator();
            while (it.hasNext()) {
                Entry&lt;Long, String&gt; item = it.next();
                if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) {
                    it.remove();
                }
            }

            String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr);
            registerFirst = registerFirst || (null == oldAddr);

            // 如果broker为master
            if (null != topicConfigWrapper
                &amp;&amp; MixAll.MASTER_ID == brokerId) {
                // 如果broker配置信息发生变化或者第一次注册  
                if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion())
                    || registerFirst) {
                    ConcurrentMap&lt;String, TopicConfig&gt; tcTable =
                        topicConfigWrapper.getTopicConfigTable();
                    if (tcTable != null) {
                        for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) {
                            // 创建或更新queueData，填充topicQueueTable--》一般是为默认主题自动注册路由信息
                            this.createAndUpdateQueueData(brokerName, entry.getValue());
                        }
                    }
                }
            }

            // 更新prevBrokerLiveInfo 信息，BrokerLiveInfo 是执行路由删除的重要依据
            BrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr,
                new BrokerLiveInfo(
                    System.currentTimeMillis(),
                    topicConfigWrapper.getDataVersion(),
                    channel,
                    haServerAddr));
            if (null == prevBrokerLiveInfo) {
                log.info(&quot;new broker registered, {} HAServer: {}&quot;, brokerAddr, haServerAddr);
            }

            // 注册Broker的过滤器server地址列表，一个broker上会关联多个filterServer消息过滤服务
            if (filterServerList != null) {
                if (filterServerList.isEmpty()) {
                    this.filterServerTable.remove(brokerAddr);
                } else {
                    this.filterServerTable.put(brokerAddr, filterServerList);
                }
            }

            // 如果broker为从节点，则需要寻找对应的materAddr，并更新该值
            if (MixAll.MASTER_ID != brokerId) {
                String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID);
                if (masterAddr != null) {
                    BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr);
                    if (brokerLiveInfo != null) {
                        result.setHaServerAddr(brokerLiveInfo.getHaServerAddr());
                        result.setMasterAddr(masterAddr);
                    }
                }
            }
        } finally {
            this.lock.writeLock().unlock();
        }
    } catch (Exception e) {
        log.error(&quot;registerBroker Exception&quot;, e);
    }

    return result;
}

</code></pre>
<h3 id="路由删除">路由删除</h3>
<p>NameServer每隔10秒会去扫描brokerLiveTable，如果brokerLive的lastUpdateTimestamp距离当前时间戳超过两分钟，则认为该broker已失效，将移除该broker并断开socket连接。除了定时删除不活跃broker之外，当broker正常退出时（shutdown），也会发送unregisterBrokerAll请求。</p>
<p>其中unregisterBrokerAll请求触发的注销操作与上述注册请求类似，只不过是将对应的信息从容器中删除；相关操作与定时移除相似，此处以定时删除为例进行说明。</p>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager
public void scanNotActiveBroker() {
    Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator();
    while (it.hasNext()) {
        Entry&lt;String, BrokerLiveInfo&gt; next = it.next();
        long last = next.getValue().getLastUpdateTimestamp();
        // 判断是否超过两分钟
        if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) {
             // 关闭通道
            RemotingUtil.closeChannel(next.getValue().getChannel());
            it.remove();
            log.warn(&quot;The broker channel expired, {} {}ms&quot;, next.getKey(), BROKER_CHANNEL_EXPIRED_TIME);
            // 删除与该broker相关的路由信息
            this.onChannelDestroy(next.getKey(), next.getValue().getChannel());
        }
    }
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager
public void onChannelDestroy(String remoteAddr, Channel channel) {
    String brokerAddrFound = null;
    if (channel != null) {
        try {
            try {
                // 寻找与已关闭通道相同的broker---》说明该broker需要被移除
                this.lock.readLock().lockInterruptibly();
                Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; itBrokerLiveTable =
                    this.brokerLiveTable.entrySet().iterator();
                while (itBrokerLiveTable.hasNext()) {
                    Entry&lt;String, BrokerLiveInfo&gt; entry = itBrokerLiveTable.next();
                    if (entry.getValue().getChannel() == channel) {
                        brokerAddrFound = entry.getKey();
                        break;
                    }
                }
            } finally {
                this.lock.readLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;onChannelDestroy Exception&quot;, e);
        }
    }

    // 如果未找到，便直接使用remoteAddr
    if (null == brokerAddrFound) {
        brokerAddrFound = remoteAddr;
    } else {
        log.info(&quot;the broker's channel destroyed, {}, clean it's data structure at once&quot;, brokerAddrFound);
    }

    if (brokerAddrFound != null &amp;&amp; brokerAddrFound.length() &gt; 0) {

        try {
            try {
                // 加写锁，从brokerLiveTable，filterServerTable中移除对应的数据
                this.lock.writeLock().lockInterruptibly();
                this.brokerLiveTable.remove(brokerAddrFound);
                this.filterServerTable.remove(brokerAddrFound);
            
                String brokerNameFound = null;
                boolean removeBrokerName = false;
                Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable =
                    this.brokerAddrTable.entrySet().iterator();
                while (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) {
                    BrokerData brokerData = itBrokerAddrTable.next().getValue();

                    // 移除brokerData
                    Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator();
                    while (it.hasNext()) {
                        Entry&lt;Long, String&gt; entry = it.next();
                        Long brokerId = entry.getKey();
                        String brokerAddr = entry.getValue();
                        if (brokerAddr.equals(brokerAddrFound)) {
                            brokerNameFound = brokerData.getBrokerName();
                            it.remove();
                            log.info(&quot;remove brokerAddr[{}, {}] from brokerAddrTable, because channel destroyed&quot;,
                                brokerId, brokerAddr);
                            break;
                        }
                    }
                    // 如果brokerData的BrokerAddrs数据为空，那么将对应的BrokerAddrTable一同移除
                    if (brokerData.getBrokerAddrs().isEmpty()) {
                        removeBrokerName = true;
                        itBrokerAddrTable.remove();
                        log.info(&quot;remove brokerName[{}] from brokerAddrTable, because channel destroyed&quot;,
                            brokerData.getBrokerName());
                    }
                }

                // 从clusterAddrTable中移除broker
                if (brokerNameFound != null &amp;&amp; removeBrokerName) {
                    Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator();
                    while (it.hasNext()) {
                        Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next();
                        String clusterName = entry.getKey();
                        Set&lt;String&gt; brokerNames = entry.getValue();
                        boolean removed = brokerNames.remove(brokerNameFound);
                        if (removed) {
                            log.info(&quot;remove brokerName[{}], clusterName[{}] from clusterAddrTable, because channel destroyed&quot;,
                                brokerNameFound, clusterName);
                            // 如果该broker信心不存在了，那么将对应的clusterAddrTable一同移除
                            if (brokerNames.isEmpty()) {
                                log.info(&quot;remove the clusterName[{}] from clusterAddrTable, because channel destroyed and no broker in this cluster&quot;,
                                    clusterName);
                                it.remove();
                            }

                            break;
                        }
                    }
                }

                if (removeBrokerName) {
                    Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable =
                        this.topicQueueTable.entrySet().iterator();
                    // 遍历所有的主题队列  
                    while (itTopicQueueTable.hasNext()) {
                        Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next();
                        String topic = entry.getKey();
                        List&lt;QueueData&gt; queueDataList = entry.getValue();

                        Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator();
                        while (itQueueData.hasNext()) {
                            QueueData queueData = itQueueData.next();
                            // 如果包含当前broker的队列，就将其移除
                            if (queueData.getBrokerName().equals(brokerNameFound)) {
                                itQueueData.remove();
                                log.info(&quot;remove topic[{} {}], from topicQueueTable, because channel destroyed&quot;,
                                    topic, queueData);
                            }
                        }
                        // 如果队列数据为空，那么将其对应的TopicQueueTable一同移除
                        if (queueDataList.isEmpty()) {
                            itTopicQueueTable.remove();
                            log.info(&quot;remove topic[{}] all queue, from topicQueueTable, because channel destroyed&quot;,
                                topic);
                        }
                    }
                }
            } finally {
                this.lock.writeLock().unlock();
            }
        } catch (Exception e) {
            log.error(&quot;onChannelDestroy Exception&quot;, e);
        }
    }
}

</code></pre>
<h3 id="路由发现">路由发现</h3>
<p>RocketMQ路由发现并非实时的，当Topic路由发生变化后，NameServer不主动推送给客户端，而是由客户端定时拉取主题最新的路由。对应的路由请求类型为：GET_ROUTEINFO_BY_TOPIC</p>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor#processRequest
case RequestCode.GET_ROUTEINFO_BY_TOPIC:
    return this.getRouteInfoByTopic(ctx, request);

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor
public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx,
    RemotingCommand request) throws RemotingCommandException {
    final RemotingCommand response = RemotingCommand.createResponseCommand(null);
    final GetRouteInfoRequestHeader requestHeader =
        (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class);

    // 通过RouteInfoManager获取主题对应的路由信息
    TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic());

    if (topicRouteData != null) {
        // 如果为顺序消息
        if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) {
            // 获取对应的顺序主题配置，并将其填充至topicRouteData中
            String orderTopicConf =
                this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG,
                    requestHeader.getTopic());
            topicRouteData.setOrderTopicConf(orderTopicConf);
        }

        byte[] content = topicRouteData.encode();
        response.setBody(content);
        response.setCode(ResponseCode.SUCCESS);
        response.setRemark(null);
        return response;
    }

    // 如果未找到，则返回主题不存在错误码
    response.setCode(ResponseCode.TOPIC_NOT_EXIST);
    response.setRemark(&quot;No topic route info in name server for the topic: &quot; + requestHeader.getTopic()
        + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL));
    return response;
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ架构与设计]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-jia-gou-yu-she-ji/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-jia-gou-yu-she-ji/">
        </link>
        <updated>2022-09-17T02:54:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq架构与设计。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/bagan-1137015_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="架构">架构</h2>
<h3 id="简介">简介</h3>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320001.png" alt="img" loading="lazy"></figure>
<p>Apache RocketMQ 是一个分布式消息流平台，具有低延迟、高性能、可靠性以及万亿级容量和灵活的可扩展性。它由四个部分组成：nameServer、broker、producer和consumer。它们中的每一个都可以水平扩展而没有单点故障。如上图所示。</p>
<ul>
<li>Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</li>
<li>Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推（实际上也是pull模式），pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。</li>
<li>NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer和Consumer仍然可以动态感知Broker的路由的信息。</li>
<li>BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了几个重要子模块：Remoting Module，Client Manager，Store Service，HA Service，Index Service。</li>
</ul>
<table>
<thead>
<tr>
<th>模块名称</th>
<th>功能简述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Remoting Module</td>
<td>整个Broker的实体，负责处理来自Client端的请求</td>
</tr>
<tr>
<td>Client Manager</td>
<td>负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息</td>
</tr>
<tr>
<td>Store Service</td>
<td>提供方便简单的API接口处理消息的存储与查询</td>
</tr>
<tr>
<td>HA Service</td>
<td>高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能</td>
</tr>
<tr>
<td>Index Service</td>
<td>根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询</td>
</tr>
</tbody>
</table>
<h3 id="集群工作流程">集群工作流程</h3>
<p>结合上述的架构图可以总结出如下的集群工作流程：</p>
<ul>
<li>启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。（心跳时间默认30s）</li>
<li>Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。</li>
<li>收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。</li>
<li>Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，默认情况下会轮询从队列列表中选择一个队列（简单代码（index为空时随机选取，否则会递增）：Math.abs(index) % this.messageQueueList.size()），然后与队列所在的Broker建立长连接从而向Broker发消息。</li>
<li>Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。</li>
</ul>
<h2 id="设计">设计</h2>
<h3 id="设计理念">设计理念</h3>
<p>Apache RocketMQ 设计基于主题的发布与订阅模式，核心功能为发送消息，存储消息，消费消息，整体上的设计要求简单与性能第一，主要体现在如下方面：</p>
<p>首先，rocketmq摒弃了传统的zookeeper之类的注册中心，而是自研了一套nameServer；为了降低实现的复杂性，nameServer彼此独立并不进行通信，这极大的降低了集群间的一致性保证难度，同时也对网络的要求降低了不少。</p>
<p>其次，是对IO存储的性能改造。为了实现发送消息的低延迟与高吞吐，rocketmq将消息存储文件设计成文件组的模型(Topic)，组内单个文件大小固定(CommitLog)，方便引入内存映射机制。同时所有的消息都是顺序读写的，并引入了页缓存及零拷贝实现高效率读写。为了兼顾消费者消费及查询操作，rocketmq还引入了消息队列文件（ConsumerQueue）和索引文件（支持按messageKey或时间区间查询）。</p>
<p>最后，rocketmq允许存在设计缺陷，可以将部分工作交由RocketMQ使用者来处理。例如重复消费的问题，rocketmq只保证消息一定会被消费者消费，但是不保证重复消费的问题。最终的幂等操作将由消费者自行处理。这极大地简化了中间件的内核设计，使得发送高可用消息更加简单与高效。</p>
<h3 id="消息存储">消息存储</h3>
<p>消息存储是Apache RocketMQ中最为复杂和最为重要的一部分，其中主要介绍RocketMQ的消息存储整体架构、PageCache、ZeroCopy和Mmap内存映射以及RocketMQ中两种不同的刷盘方式。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320002.png" alt="img" loading="lazy"></figure>
<h4 id="消息存储组件">消息存储组件</h4>
<p>消息存储架构图中主要有下面三个跟消息存储相关的文件构成。</p>
<p>CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G, 文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。类似于kafka中的logSegment文件。</p>
<p>ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</p>
<p>IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \store\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。</p>
<p>在上面的RocketMQ的消息存储整体架构图中可以看出，RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。</p>
<p>RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。这里，RocketMQ的具体做法是，使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。</p>
<h4 id="页缓存零拷贝内存映射">页缓存&amp;零拷贝&amp;内存映射</h4>
<p>页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。</p>
<p>在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。</p>
<p>零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。零拷贝技术变相地提高了rocketmq发送消息和消费消息的性能。</p>
<p>另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。</p>
<h4 id="刷盘方式">刷盘方式</h4>
<p>同步刷盘：如下图所示，只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般金融业务应用该模式较多。</p>
<p>异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320003.png" alt="img" loading="lazy"></figure>
<h4 id="通信机制">通信机制</h4>
<p>RocketMQ的RPC通信采用Netty组件作为底层通信库，同样也遵循了Reactor多线程模型，同时又在这之上做了一些扩展和优化。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320004.png" alt="img" loading="lazy"></figure>
<p>上面的框图中可以大致了解RocketMQ中NettyRemotingServer的Reactor多线程模型。一个 Reactor 主线程（eventLoopGroupBoss，即为上面的1）负责监听 TCP网络连接请求，建立好连接，创建SocketChannel，并注册到selector上。RocketMQ的源码中会自动根据OS的类型选择NIO和Epoll，也可以通过参数配置）,然后监听真正的网络数据。拿到网络数据后，再丢给Worker线程池（eventLoopGroupSelector，即为上面的“N”，源码中默认设置为3），在真正执行业务逻辑之前需要进行SSL验证、编解码、空闲检查、网络连接管理，这些工作给defaultEventExecutorGroup（即为上面的“M1”，源码中默认设置为8）去做。</p>
<p>处理业务操作将放在业务线程池中执行，根据 RomotingCommand 的业务请求码code去processorTable这个本地缓存变量中找到对应的 processor，然后封装成task任务后，提交给对应的业务processor处理线程池来执行（sendMessageExecutor，以发送消息为例，即为上面的 “M2”）。从入口到业务逻辑的几个步骤中线程池一直再增加，这跟每一步逻辑复杂性相关，越复杂，需要的并发通道越宽。</p>
<h3 id="负载均衡">负载均衡</h3>
<p>RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p>
<h4 id="producer负载均衡">Producer负载均衡</h4>
<p>Producer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，在获取了TopicPublishInfo路由信息后，RocketMQ的客户端在默认方式下selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列（MessageQueue）进行发送消息。（简单代码（index为空时随机选取，否则会递增）：Math.abs(index) % this.messageQueueList.size()）</p>
<p>具体的容错策略均在MQFaultStrategy这个类中定义。这里有一个sendLatencyFaultEnable开关变量，如果开启，在随机递增取模的基础上，再过滤掉not available的Broker代理。所谓的&quot;latencyFaultTolerance&quot;，是指对之前失败的，按一定的时间做退避。例如，如果上次请求的latency超过550Lms，就退避3000Lms；超过1000L，就退避60000L；如果关闭，采用随机递增取模的方式选择一个队列（MessageQueue）来发送消息，latencyFaultTolerance机制是实现消息发送高可用的核心关键所在。</p>
<pre><code>// 文件地址:rocketmq-client/org.apache.rocketmq.client.latency.LatencyFaultTolerance
public interface LatencyFaultTolerance&lt;T&gt; {
    void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration);

    boolean isAvailable(final T name);

    void remove(final T name);

    T pickOneAtLeast();
}

// 文件地址:rocketmq-client org.apache.rocketmq.client.latency.LatencyFaultToleranceImpl
public class LatencyFaultToleranceImpl implements LatencyFaultTolerance&lt;String&gt; {
    private final ConcurrentHashMap&lt;String, FaultItem&gt; faultItemTable = new ConcurrentHashMap&lt;String, FaultItem&gt;(16);

    private final ThreadLocalIndex whichItemWorst = new ThreadLocalIndex();

    // 它维护了一个faultItemTable，其key为name，value为FaultItem；
    // 其updateFaultItem方法会将对应name的currentLatency及notAvailableDuration更新到对应的FaultItem中，没有则创建
    @Override
    public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) {
        FaultItem old = this.faultItemTable.get(name);
        if (null == old) {
            // 没有则创建faultItem 
            final FaultItem faultItem = new FaultItem(name);
            faultItem.setCurrentLatency(currentLatency);
            faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);

            old = this.faultItemTable.putIfAbsent(name, faultItem);
            if (old != null) {
                old.setCurrentLatency(currentLatency);
                old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
            }
        } else {
            old.setCurrentLatency(currentLatency);
            old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration);
        }
    }

    // 从faultItemTable获取faultItem，不为null则返回faultItem.isAvailable()，为null则返回true；
    @Override
    public boolean isAvailable(final String name) {
        final FaultItem faultItem = this.faultItemTable.get(name);
        if (faultItem != null) {
            return faultItem.isAvailable();
        }
        return true;
    }

    // 直接移除faultItem
    @Override
    public void remove(final String name) {
        this.faultItemTable.remove(name);
    }

    @Override
    public String pickOneAtLeast() {
        final Enumeration&lt;FaultItem&gt; elements = this.faultItemTable.elements();
        List&lt;FaultItem&gt; tmpList = new LinkedList&lt;FaultItem&gt;();
        // 拷贝一份faultItemTable的FaultItem的列表
        while (elements.hasMoreElements()) {
            final FaultItem faultItem = elements.nextElement();
            tmpList.add(faultItem);
        }
  
        if (!tmpList.isEmpty()) {
            Collections.shuffle(tmpList);

            Collections.sort(tmpList);

            // 取half值
            final int half = tmpList.size() / 2;
            if (half &lt;= 0) {
                // 如果half小于等于0，便取第一条---》相当于只有一条
                return tmpList.get(0).getName();
            } else {
                // 否则根据递增index对half取余
                final int i = this.whichItemWorst.incrementAndGet() % half;
                return tmpList.get(i).getName();
            }
        }

        return null;
    }

    @Override
    public String toString() {
        return &quot;LatencyFaultToleranceImpl{&quot; +
            &quot;faultItemTable=&quot; + faultItemTable +
            &quot;, whichItemWorst=&quot; + whichItemWorst +
            '}';
    }

    class FaultItem implements Comparable&lt;FaultItem&gt; {
        private final String name;
        private volatile long currentLatency;
        private volatile long startTimestamp;

        public FaultItem(final String name) {
            this.name = name;
        }

        @Override
        public int compareTo(final FaultItem other) {
            if (this.isAvailable() != other.isAvailable()) {
                if (this.isAvailable())
                    return -1;

                if (other.isAvailable())
                    return 1;
            }

            if (this.currentLatency &lt; other.currentLatency)
                return -1;
            else if (this.currentLatency &gt; other.currentLatency) {
                return 1;
            }

            if (this.startTimestamp &lt; other.startTimestamp)
                return -1;
            else if (this.startTimestamp &gt; other.startTimestamp) {
                return 1;
            }

            return 0;
        }

        public boolean isAvailable() {
            return (System.currentTimeMillis() - startTimestamp) &gt;= 0;
        }

        @Override
        public int hashCode() {
            int result = getName() != null ? getName().hashCode() : 0;
            result = 31 * result + (int) (getCurrentLatency() ^ (getCurrentLatency() &gt;&gt;&gt; 32));
            result = 31 * result + (int) (getStartTimestamp() ^ (getStartTimestamp() &gt;&gt;&gt; 32));
            return result;
        }

        @Override
        public boolean equals(final Object o) {
            if (this == o)
                return true;
            if (!(o instanceof FaultItem))
                return false;

            final FaultItem faultItem = (FaultItem) o;

            if (getCurrentLatency() != faultItem.getCurrentLatency())
                return false;
            if (getStartTimestamp() != faultItem.getStartTimestamp())
                return false;
            return getName() != null ? getName().equals(faultItem.getName()) : faultItem.getName() == null;

        }

        @Override
        public String toString() {
            return &quot;FaultItem{&quot; +
                &quot;name='&quot; + name + '\'' +
                &quot;, currentLatency=&quot; + currentLatency +
                &quot;, startTimestamp=&quot; + startTimestamp +
                '}';
        }

        public String getName() {
            return name;
        }

        public long getCurrentLatency() {
            return currentLatency;
        }

        public void setCurrentLatency(final long currentLatency) {
            this.currentLatency = currentLatency;
        }

        public long getStartTimestamp() {
            return startTimestamp;
        }

        public void setStartTimestamp(final long startTimestamp) {
            this.startTimestamp = startTimestamp;
        }

    }
}

</code></pre>
<h4 id="consumer负载均衡">Consumer负载均衡</h4>
<p>消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个不同的消息队列。</p>
<p>在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到Consumer的心跳消息后，会将它维护在ConsumerManager的本地缓存变量—consumerTable，同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负载均衡提供可以依据的元数据信息。</p>
<p>在Consumer实例的启动流程中的启动MQClientInstance实例部分，会完成负载均衡服务线程—RebalanceService的启动（每隔20s执行一次）。通过查看源码可以发现，RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法，该方法是实现Consumer端负载均衡的核心。这里，rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程：</p>
<ol>
<li>从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）；</li>
<li>根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送获取该消费组下消费者Id列表的RPC通信请求（Broker端基于前面Consumer端上报的心跳包数据而构建的consumerTable做出响应返回，业务请求码：GET_CONSUMER_LIST_BY_GROUP）；</li>
<li>先对Topic下的消息消费队列、消费者Id排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。这里的平均分配算法，类似于分页的算法，将所有MessageQueue排好序类似于记录，将所有消费端Consumer排好序类似页数，并求出每一页需要包含的平均size和每个页面记录的范围range，最后遍历整个range而计算出当前Consumer端应该分配到的记录（这里即为：MessageQueue）。</li>
<li>然后，调用updateProcessQueueTableInRebalance()方法，具体的做法是，先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对。</li>
<li>下图中processQueueTable标注的红色部分，表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true，然后查看这些队列是否可以移除出processQueueTable缓存变量，这里具体执行removeUnnecessaryMessageQueue()方法，即每隔1s 查看是否可以获取当前消费处理队列的锁，拿到的话返回true。如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。如果返回true，则从processQueueTable缓存变量中移除对应的Entry；</li>
<li>下图中processQueueTable的绿色部分，表示与分配到的消息队列集合mqSet的交集。判断该ProcessQueue是否已经过期了，在Pull模式的不用管，如果是Push模式的，设置Dropped属性为true，并且调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry；</li>
<li>最后，为过滤后的消息队列集合（mqSet）中的每个MessageQueue创建一个ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中（其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset，随后填充至接下来要创建的pullRequest对象属性中），并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中，最后执行dispatchPullRequest()方法，将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230320005.png" alt="" loading="lazy"></figure>
<pre><code>// 文件地址:rocketmq-client/org.apache.rocketmq.client.impl.factory.MQClientInstance
public MQClientInstance(ClientConfig clientConfig, int instanceIndex, String clientId, RPCHook rpcHook) {
    。。。。。。
    // 启动重平衡服务
    this.rebalanceService = new RebalanceService(this);
    。。。。。。
}

// 文件地址:rocketmq-client org.apache.rocketmq.client.impl.consumer.RebalanceService
public void run() {
    log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        this.waitForRunning(waitInterval);
        // 执行重平衡--&gt;最终调用的是RebalanceImpl类的rebalanceByTopic()方法
        this.mqClientFactory.doRebalance();
    }

    log.info(this.getServiceName() + &quot; service end&quot;);
}

</code></pre>
<pre><code>// 文件地址:rocketmq-client/org.apache.rocketmq.client.impl.consumer.RebalanceImpl
// 重平衡的核心处理逻辑代码
// 该函数会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理
private void rebalanceByTopic(final String topic, final boolean isOrder) {
    switch (messageModel) {
        // 广播模式
        case BROADCASTING: {
            // 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）
            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);
            if (mqSet != null) {
                // 更新处理队列
                boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder);
                if (changed) {
                    this.messageQueueChanged(topic, mqSet, mqSet);
                    log.info(&quot;messageQueueChanged {} {} {} {}&quot;,
                        consumerGroup,
                        topic,
                        mqSet,
                        mqSet);
                }
            } else {
                log.warn(&quot;doRebalance, {}, but the topic[{}] not exist.&quot;, consumerGroup, topic);
            }
            break;
        }
        // 集群模式
        case CLUSTERING: {
            // 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）
            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);
            // 向Broker端发送获取该消费组下消费者Id列表的RPC通信请求
            List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);
            if (null == mqSet) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                    log.warn(&quot;doRebalance, {}, but the topic[{}] not exist.&quot;, consumerGroup, topic);
                }
            }

            if (null == cidAll) {
                log.warn(&quot;doRebalance, {} {}, get consumer id list failed&quot;, consumerGroup, topic);
            }

            if (mqSet != null &amp;&amp; cidAll != null) {
                List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();
                mqAll.addAll(mqSet);
                // 对Topic下的消息消费队列、消费者Id排序
                Collections.sort(mqAll);
                Collections.sort(cidAll);

                // 用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列
                AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;
                List&lt;MessageQueue&gt; allocateResult = null;
                try {
                    allocateResult = strategy.allocate(
                        this.consumerGroup,
                        this.mQClientFactory.getClientId(),
                        mqAll,
                        cidAll);
                } catch (Throwable e) {
                    log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName={}&quot;, strategy.getName(),
                        e);
                    return;
                }

                Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;();
                if (allocateResult != null) {
                    allocateResultSet.addAll(allocateResult);
                }

                // 更新处理队列
                boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);
                if (changed) {
                    log.info(
                        &quot;rebalanced result changed. allocateMessageQueueStrategyName={}, group={}, topic={}, clientId={}, mqAllSize={}, cidAllSize={}, rebalanceResultSize={}, rebalanceResultSet={}&quot;,
                        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),
                        allocateResultSet.size(), allocateResultSet);
                    this.messageQueueChanged(topic, mqSet, allocateResultSet);
                }
            }
            break;
        }
        default:
            break;
    }
}

private boolean updateProcessQueueTableInRebalance(final String topic, final Set&lt;MessageQueue&gt; mqSet,
    final boolean isOrder) {
    boolean changed = false;

    // 先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对。
    Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator();
    while (it.hasNext()) {
        Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next();
        MessageQueue mq = next.getKey();
        ProcessQueue pq = next.getValue();

        if (mq.getTopic().equals(topic)) {
            // 如果processQueueTable与分配到的消息队列集合mqSet互不包含
            if (!mqSet.contains(mq)) {
                // 将其Dropped属性设为true
                pq.setDropped(true);
                // 查看这些队列是否可以移除出processQueueTable缓存变量
                // removeUnnecessaryMessageQueue()函数每隔1s 会查看是否可以获取当前消费处理队列的锁，拿到的话返回true。
                // 如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。
                // 如果返回true，则从processQueueTable缓存变量中移除对应的Entry；
                if (this.removeUnnecessaryMessageQueue(mq, pq)) {
                    it.remove();
                    changed = true;
                    log.info(&quot;doRebalance, {}, remove unnecessary mq, {}&quot;, consumerGroup, mq);
                }
            } 
            // 如果processQueueTable与分配到的消息队列集合mqSet存在交集
            // 那么先判断ProcessQueue是否已经过期了
            else if (pq.isPullExpired()) { 
                switch (this.consumeType()) {
                    // pull模式不用做任何操作
                    case CONSUME_ACTIVELY:
                        break;
                    // push模式下  
                    case CONSUME_PASSIVELY:
                        // 将其Dropped属性设为true
                        pq.setDropped(true);
                        // 调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry；
                        if (this.removeUnnecessaryMessageQueue(mq, pq)) {
                            it.remove();
                            changed = true;
                            log.error(&quot;[BUG]doRebalance, {}, remove unnecessary mq, {}, because pull is pause, so try to fixed it&quot;,
                                consumerGroup, mq);
                        }
                        break;
                    default:
                        break;
                }
            }
        }
    }

    List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;();
    // 遍历过滤后的mqSet
    for (MessageQueue mq : mqSet) {
        if (!this.processQueueTable.containsKey(mq)) {
            // 尝试加锁，如果失败，则跳过
            if (isOrder &amp;&amp; !this.lock(mq)) {
                log.warn(&quot;doRebalance, {}, add a new mq failed, {}, because lock failed&quot;, consumerGroup, mq);
                continue;
            }

            // 移除脏offset 
            this.removeDirtyOffset(mq);
            // 创建ProcessQueue
            ProcessQueue pq = new ProcessQueue();

            long nextOffset = -1L;
            try {
                // 获取该MessageQueue对象的下一个进度消费值offset
                nextOffset = this.computePullFromWhereWithException(mq);
            } catch (Exception e) {
                log.info(&quot;doRebalance, {}, compute offset failed, {}&quot;, consumerGroup, mq);
                continue;
            }

            if (nextOffset &gt;= 0) {
                // 为每个MessageQueue创建一个ProcessQueue对象并存入processQueueTable队列中
                ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq);
                if (pre != null) {
                    log.info(&quot;doRebalance, {}, mq already exists, {}&quot;, consumerGroup, mq);
                } else {
                    log.info(&quot;doRebalance, {}, add a new mq, {}&quot;, consumerGroup, mq);
                    PullRequest pullRequest = new PullRequest();
                    pullRequest.setConsumerGroup(consumerGroup);
                    // nextOffset填充至pullRequest对象属性中
                    pullRequest.setNextOffset(nextOffset);
                    pullRequest.setMessageQueue(mq);
                    pullRequest.setProcessQueue(pq);
                    pullRequestList.add(pullRequest);
                    changed = true;
                }
            } else {
                log.warn(&quot;doRebalance, {}, add new mq failed, {}&quot;, consumerGroup, mq);
            }
        }
    }

    // 将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求
    // 此函数的实现仅在RebalancePushImpl中有实现，RebalancePullImpl中未实现该函数逻辑
    this.dispatchPullRequest(pullRequestList);

    return changed;
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RocketMQ安装与简介]]></title>
        <id>https://philosopherzb.github.io/post/rocketmq-an-zhuang-yu-jian-jie/</id>
        <link href="https://philosopherzb.github.io/post/rocketmq-an-zhuang-yu-jian-jie/">
        </link>
        <updated>2022-09-09T08:11:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Rocketmq的安装以及基本概念和特性。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/river-1589616_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="安装与运行">安装与运行</h2>
<h3 id="安装与运行-2">安装与运行</h3>
<p>以win10为例，下载安装rocketmq并单机运行；详细操作如下：</p>
<ol>
<li>安装包下载地址：<a href="https://rocketmq.apache.org/release_notes/">点击此处跳转下载页面</a></li>
<li>选择合适的版本，点击进去选择Binary版下载，然后解压即可（最好使用英文目录，不包括特殊字符）</li>
<li>win10配置系统变量，右击此电脑--选择属性--选择高级系统设置--点击环境变量，在系统变量下方选择新建：变量名：ROCKETMQ_HOME；变量值：${解压目录}\rocketmq-all-对应版本号-bin-release</li>
<li>开启cmd命令窗口，cd进入解压目录，然后输入 .\bin\mqnamesrv.cmd 启动 nameService</li>
<li>再开启一个cmd命令窗口，cd进入解压目录，然后输入 .\bin\mqbroker.cmd -n localhost:9876 autoCreateTopicEnable=true 启动 broker</li>
</ol>
<pre><code># 启动成功如下所示
D:\knowledge\java\rocketmq\rocketmq-xxx&gt;.\bin\mqnamesrv.cmd
Java HotSpot(TM) 64-Bit Server VM warning: Using the DefNew young collector with the CMS collector is deprecated and will likely be removed in a future release
Java HotSpot(TM) 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release.
The Name Server boot success. serializeType=JSON

D:\knowledge\java\rocketmq\rocketmq-xxx&gt;.\bin\mqbroker.cmd -n localhost:9876 autoCreateTopicEnable=true
The broker[LAPTOP-1TAHGGN6, 1.2.3.4:11111] boot success. serializeType=JSON and name server is localhost:9876

</code></pre>
<ol start="6">
<li>测试款已经发送消费消息：在此之前需要进入rocketmq解压目录的bin目录下，打开tools.cmd，在其中的set &quot;JAVA=%JAVA_HOME%\bin\java.exe&quot;前一行输入set NAMESRV_ADDR=localhost:9876</li>
</ol>
<pre><code># 键入NAMESRV_ADDR，否则无法使用该工具
set NAMESRV_ADDR=localhost:9876
set &quot;JAVA=%JAVA_HOME%\bin\java.exe&quot;

</code></pre>
<pre><code># 发送消息
D:\knowledge\java\rocketmq\rocketmq-xxx&gt;.\bin\tools.cmd  org.apache.rocketmq.example.quickstart.Producer
SendResult [sendStatus=SEND_OK, msgId=7F00000115807ADF9F5F63FC1C7B0010, offsetMsgId=0A1450C100002A9F000000000000114C, messageQueue=MessageQueue [topic=TopicTest, brokerName=LAPTOP-1TAHGGN6, queueId=1], queueOffset=4]

# 消费消息
D:\knowledge\java\rocketmq\rocketmq-xxx&gt;.\bin\tools.cmd  org.apache.rocketmq.example.quickstart.Consumer
Consumer Started.
ConsumeMessageThread_please_rename_unique_group_name_4_1 Receive New Messages: [MessageExt [brokerName=LAPTOP-1TAHGGN6, queueId=0, storeSize=190, queueOffset=0, sysFlag=0, bornTimestamp=1650419866707, bornHost=/10.20.80.193:60236, storeTimestamp=1650419866709, storeHost=/10.20.80.193:10911, msgId=0A1450C100002A9F00000000000007A0, commitLogOffset=1952, bodyCRC=1032136437, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message{topic='TopicTest', flag=0, properties={MIN_OFFSET=0, MAX_OFFSET=250, CONSUME_START_TIME=1650419883935, UNIQ_KEY=7F00000115807ADF9F5F63FC1C530003, CLUSTER=DefaultCluster, TAGS=TagA}, body=[72, 101, 108, 108, 111, 32, 82, 111, 99, 107, 101, 116, 77, 81, 32, 51], transactionId='null'}]]

</code></pre>
<h3 id="运行console">运行console</h3>
<p>以win10为例，下载rocketmq-console并运行；详细操作如下：</p>
<ol>
<li>下载地址：<a href="https://github.com/apache/rocketmq-externals/tree/release-rocketmq-console-1.0.0">点击此处跳转下载页面</a></li>
<li>直接使用IDEA打开，修改其中的配置文件，即可启动</li>
</ol>
<pre><code># 修改配置文件
rocketmq.config.namesrvAddr=localhost:9876
</code></pre>
<pre><code># 打包运行
mvn clean package -Dmaven.test.skip=true
java -jar target/rocketmq-console-ng-1.0.0.jar
</code></pre>
<h2 id="rocketmq">RocketMQ</h2>
<h3 id="简介">简介</h3>
<p>rocketmq 是由 alibaba 公司开发，现已转接给apache管理的开源项目；它是一个分布式的，支持多消息队列、主从同步，基于 nameService 的发布订阅模式的消息引擎系统；底层通信与连接基于netty实现，以达到更高速的网络处理效率。</p>
<h3 id="基本术语">基本术语</h3>
<p>RocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。ConsumerGroup 由多个Consumer 实例构成。</p>
<ul>
<li>生产者(Producer)：负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要。</li>
<li>消费者(Consumer)：负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费模式：拉取式消费、推动式消费（本质上也是pull模式）。同时还支持两种消费方式：集群消费（集群消费模式下,相同Consumer Group的每个Consumer实例平均分摊消息）和广播消费（广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息）。</li>
<li>主题(Topic)：用于存储同一类消息事件，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。打个简单的比喻：主题类似于文件系统中的文件夹，而消息事件则类似于文件夹中的文件。</li>
<li>消息(Message)：消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。</li>
<li>偏移量(Offset)：是一种元数据，且是一个不断递增的整数值（java Long类型），用于标识消息队列中的消息位置；当消费者处理完消息后，将会提交offset+1到broker中。</li>
<li>broker： 一个独立的 rocketmq 服务就被称为 broker；它作为消息中转角色，负责存储消息、转发消息。代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等。每个broker都会与所有的nameServer保持长连接并发送心跳，以便定时将topic信息注册到nameServer（低层通信与连接使用的是netty）。Master角色的Broker支持读和写，Slave角色的Broker仅支持读。</li>
<li>nameServer：名称服务充当路由消息的提供者。生产者或消费者能够通过名字服务查找各主题相应的Broker IP列表。多个Namesrv实例组成集群，但相互独立，没有信息交换。所有的内容在nameServer上都是内存式存储，并不会进行持久化，因此也被称为无状态节点。</li>
<li>组（group）：分为ProducerGroup，ConsumerGroup（要注意的是，消费者组的消费者实例必须订阅完全相同的Topic），代表某一类的生产者和消费者，同一个组中的生产者或消费者处理消息的逻辑是一致的。</li>
<li>消息队列（Message Queue）：在一个主题中可以存在一个或多个消息队列，每个消息队列中消息有序；它是消息的逻辑存储介质（实际存储文件为commitLog）。同一Topic下的多个Message Queue可以部署在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer仍然可以发送消息（消息发送的高可用性）。</li>
<li>标签（tag）：为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。</li>
</ul>
<h3 id="基本特性">基本特性</h3>
<h4 id="顺序消息">顺序消息</h4>
<p>消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。</p>
<p>RocketMQ可以严格的保证消息有序（单个message queue是有序的：FIFO）。顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。</p>
<ul>
<li>全局顺序：对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景</li>
<li>分区顺序：对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。</li>
</ul>
<pre><code>// 顺序消息需自定义消息路由规则
try {
    DefaultMQProducer producer = new DefaultMQProducer(&quot;unique_group_name&quot;);
    producer.setNamesrvAddr(&quot;localhost:9876&quot;);
    producer.start();

    Message message = new Message(&quot;topicName&quot;, &quot;tagName&quot;, &quot;msgContent&quot;.getBytes(StandardCharsets.UTF_8));
    message.setKeys(&quot;key&quot;);
    SendResult sendResult = producer.send(message, (mqs, msg, arg) -&gt; {
        Integer id = (Integer) arg;
        int index = id % mqs.size(); 
        return mqs.get(index);
    }, 1);// 此处的1即使消息队列使用的arg参数值，对应上面的Integer id = (Integer) arg;
  
    System.out.printf(&quot;%s%n&quot;, sendResult);
    producer.shutdown();
} catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) {
    e.printStackTrace();
}

</code></pre>
<pre><code>// 自带的消息路由规则
// 取arg参数的hashcode的绝对值，然后对mqs.size()取余，得到目标队列在mqs的下标
public class SelectMessageQueueByHash implements MessageQueueSelector {

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        int value = arg.hashCode() % mqs.size();
        if (value &lt; 0) {
            value = Math.abs(value);
        }
        return mqs.get(value);
    }
}

// 直接根据mqs.size()随机一个值作为目标队列在mqs的下标
public class SelectMessageQueueByRandom implements MessageQueueSelector {
    private Random random = new Random(System.currentTimeMillis());

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        int value = random.nextInt(mqs.size());
        return mqs.get(value);
    }
}

// 指定机房，目前return null，暂无实现逻辑
public class SelectMessageQueueByMachineRoom implements MessageQueueSelector {
    private Set&lt;String&gt; consumeridcs;

    @Override
    public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) {
        return null;
    }

    public Set&lt;String&gt; getConsumeridcs() {
        return consumeridcs;
    }

    public void setConsumeridcs(Set&lt;String&gt; consumeridcs) {
        this.consumeridcs = consumeridcs;
    }
}

</code></pre>
<pre><code>// 未指定MessageQueueSelector 时，rocketmq 将使用默认的规则选择一个message queue
// 文件地址：org.apache.rocketmq.client.impl.producer.TopicPublishInfo
public MessageQueue selectOneMessageQueue() {
    // 每次请求都递增然后对messageQueueSize取模，如果小于0便直接取0
    int index = this.sendWhichQueue.incrementAndGet();
    int pos = Math.abs(index) % this.messageQueueList.size();
    if (pos &lt; 0)
        pos = 0;
    return this.messageQueueList.get(pos);
}

// 文件地址：org.apache.rocketmq.client.common.ThreadLocalIndex
public int incrementAndGet() {
    Integer index = this.threadLocalIndex.get();
    if (null == index) {
        // 为空时随机取一个index
        index = Math.abs(random.nextInt());
        this.threadLocalIndex.set(index);
    }
    // 不为空便直接递增index
    this.threadLocalIndex.set(++index);
    return Math.abs(index);
}

</code></pre>
<h4 id="事务消息">事务消息</h4>
<p>RocketMQ(4.3.0版本及之后)事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致。关于事务消息的处理流程，有必要了解如下两个概念：半消息及消息状态检查：</p>
<p>半消息（Half(Prepare) Message）：指暂时无法投递的消息。当一条消息成功发送到MQ服务器，但服务器没有收到生产者对消息的第二次确认，则将该消息标记为“暂时无法投递”。这种状态的消息称为半消息。</p>
<p>消息状态检查（Message Status Check）：网络断开或生产者应用程序重启可能会导致事务消息的第二次确认丢失。当 MQ 服务器发现一条消息长时间处于半消息状态时，会向消息生产者发送请求，检查消息的最终状态（Commit 或 Rollback）。</p>
<p>详细设计可参考：<a href="https://rocketmq.apache.org/rocketmq/the-design-of-transactional-message/">点击此处跳转详情页面</a></p>
<p>事务消息发送流程如下：</p>
<ol>
<li>生产者向 MQ 服务器发送半消息。</li>
<li>发送半消息成功后，执行本地事务。</li>
<li>根据本地事务结果向 MQ 服务器发送提交或回滚消息。</li>
<li>如果本地事务执行过程中提交/回滚消息丢失或生产者挂起，MQ 服务器将向同一组中的每个生产者发送检查消息以获取事务状态。</li>
<li>生产者根据本地事务状态回复提交/回滚消息。</li>
<li>提交的消息将被传递给消费者，但回滚的消息将被 MQ 服务器丢弃。</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230317011.png" alt="" loading="lazy"></figure>
<pre><code>// 实现事务监听器
import org.apache.rocketmq.client.producer.LocalTransactionState;
import org.apache.rocketmq.client.producer.TransactionListener;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.common.message.MessageExt;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;

public class TransactionListenerImpl implements TransactionListener {
    private AtomicInteger transactionIndex = new AtomicInteger(0);

    private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;();

    @Override
    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
        int value = transactionIndex.getAndIncrement();
        int status = value % 3;
        localTrans.put(msg.getTransactionId(), status);
        return LocalTransactionState.UNKNOW;
    }

    @Override
    public LocalTransactionState checkLocalTransaction(MessageExt msg) {
        Integer status = localTrans.get(msg.getTransactionId());
        if (null != status) {
            switch (status) {
                case 0:
                    return LocalTransactionState.UNKNOW;
                case 1:
                    return LocalTransactionState.COMMIT_MESSAGE;
                case 2:
                    return LocalTransactionState.ROLLBACK_MESSAGE;
                default:
                    return LocalTransactionState.COMMIT_MESSAGE;
            }
        }
        return LocalTransactionState.COMMIT_MESSAGE;
    }
}

</code></pre>
<pre><code>// 发送事务消息
public static void main(String[] args) throws MQClientException, InterruptedException {
    TransactionListener transactionListener = new TransactionListenerImpl();
    TransactionMQProducer producer = new TransactionMQProducer(&quot;unique_group_name&quot;);
    ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(2000), r -&gt; {
        Thread thread = new Thread(r);
        thread.setName(&quot;client-transaction-msg-check-thread&quot;);
        return thread;
    });

    producer.setExecutorService(executorService);
    producer.setTransactionListener(transactionListener);
    producer.start();

    String[] tags = new String[] {&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;};
    for (int i = 0; i &lt; 10; i++) {
        try {
            Message msg =
                new Message(&quot;topicName&quot;, tags[i % tags.length], &quot;KEY&quot; + i,
                    (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
            SendResult sendResult = producer.sendMessageInTransaction(msg, null);
            System.out.printf(&quot;%s%n&quot;, sendResult);

            Thread.sleep(10);
        } catch (MQClientException | UnsupportedEncodingException e) {
            e.printStackTrace();
        }
    }

    for (int i = 0; i &lt; 100000; i++) {
        Thread.sleep(1000);
    }
    producer.shutdown();
}

</code></pre>
<h4 id="定时消息">定时消息</h4>
<p>定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。对level设值时会出现以下是那种情形：</p>
<ul>
<li>level == 0，消息为非延迟消息</li>
<li>1&lt;=level&lt;=maxLevel，消息延迟特定时间，例如level==1，延迟1s</li>
<li>level &gt; maxLevel，则level== maxLevel，例如level==20，延迟2h</li>
</ul>
<p>定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。</p>
<p>需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。</p>
<pre><code>// 发送定时消息
public static void main(String[] args) throws Exception {
    // 初始化 producer 以发送定时消息
    DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);
    // 启动producer
    producer.start();
    int totalMessagesToSend = 100;
    for (int i = 0; i &lt; totalMessagesToSend; i++) {
        Message message = new Message(&quot;TestTopic&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());
        // 此处设置3表示消息将会延迟10秒后发送，具体可见下述源码
        message.setDelayTimeLevel(3);
        // Send the message
        producer.send(message);
    }
  
    // Shutdown producer after use.
    producer.shutdown();
}

</code></pre>
<pre><code>// 文件地址：org.apache.rocketmq.store.schedule.ScheduleMessageService
// 转换延迟等级，将“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”按从左到右的顺序匹配1~18
public boolean parseDelayLevel() {
    // 存储时间单位
    HashMap&lt;String, Long&gt; timeUnitTable = new HashMap&lt;String, Long&gt;();
    timeUnitTable.put(&quot;s&quot;, 1000L);
    timeUnitTable.put(&quot;m&quot;, 1000L * 60);
    timeUnitTable.put(&quot;h&quot;, 1000L * 60 * 60);
    timeUnitTable.put(&quot;d&quot;, 1000L * 60 * 60 * 24);

    // 获取“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”
    String levelString = this.defaultMessageStore.getMessageStoreConfig().getMessageDelayLevel();
    try {
        // 切割获取对应的数组
        String[] levelArray = levelString.split(&quot; &quot;);
        for (int i = 0; i &lt; levelArray.length; i++) {
            String value = levelArray[i];
            String ch = value.substring(value.length() - 1);
            Long tu = timeUnitTable.get(ch);

            int level = i + 1;
            if (level &gt; this.maxDelayLevel) {
                this.maxDelayLevel = level;
            }
            long num = Long.parseLong(value.substring(0, value.length() - 1));
            long delayTimeMillis = tu * num;
            // 匹配1~18放入ConcurrentMap中
            this.delayLevelTable.put(level, delayTimeMillis);
            if (this.enableAsyncDeliver) {
                this.deliverPendingTable.put(level, new LinkedBlockingQueue&lt;&gt;());
            }
        }
    } catch (Exception e) {
        log.error(&quot;parseDelayLevel exception&quot;, e);
        log.info(&quot;levelString String = {}&quot;, levelString);
        return false;
    }

    return true;
}

</code></pre>
<h4 id="消息重投与重试">消息重投与重试</h4>
<p>生产者在发送消息时，同步消息失败会重投，异步消息有重试，oneway没有任何保证。消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。如下方法可以设置消息重试策略：</p>
<ul>
<li>retryTimesWhenSendFailed：同步发送失败重投次数，默认为2，因此生产者会最多尝试发送retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度保证消息不丢。超过重投次数，抛出异常，由客户端保证消息不丢。当出现RemotingException、MQClientException和部分MQBrokerException时会重投。</li>
<li>retryTimesWhenSendAsyncFailed：异步发送失败重试次数，异步重试不会选择其他broker，仅在同一个broker上做重试，不保证消息不丢。</li>
<li>retryAnotherBrokerWhenNotStoreOK：消息刷盘（主或备）超时或slave不可用（返回状态非SEND_OK），是否尝试发送到其他broker，默认false。十分重要消息可以开启。</li>
</ul>
<p>Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况：</p>
<ul>
<li>由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10秒后再重试。</li>
<li>由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。</li>
</ul>
<p>RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中。</p>
<p>重试次数过多时，便有必要将消息投递至死信队列中以防止陷入无限重试。</p>
<p>死信队列通常用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p>
<p>RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。</p>
<h4 id="流量控制与可靠性">流量控制与可靠性</h4>
<p>生产者流控，因为broker处理能力达到瓶颈；消费者流控，因为消费能力达到瓶颈。</p>
<h5 id="生产者流控">生产者流控</h5>
<ul>
<li>commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，返回流控。</li>
<li>如果开启transientStorePoolEnable == true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，返回流控。</li>
<li>broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，返回流控。</li>
<li>broker通过拒绝send 请求方式实现流量控制。</li>
<li>注意，生产者流控，不会尝试消息重投。</li>
</ul>
<h5 id="消费者流控">消费者流控</h5>
<ul>
<li>消费者本地缓存消息数超过pullThresholdForQueue时，默认1000。</li>
<li>消费者本地缓存消息大小超过pullThresholdSizeForQueue时，默认100MB。</li>
<li>消费者本地缓存消息跨度超过consumeConcurrentlyMaxSpan时，默认2000。</li>
<li>消费者流控的结果是降低拉取频率。</li>
</ul>
<h5 id="rocketmq支持消息的高可靠影响消息可靠性的几种情况">RocketMQ支持消息的高可靠，影响消息可靠性的几种情况</h5>
<ol>
<li>Broker非正常关闭</li>
<li>Broker异常Crash</li>
<li>OS Crash</li>
<li>机器掉电，但是能立即恢复供电情况</li>
<li>机器无法开机（可能是cpu、主板、内存等关键设备损坏）</li>
<li>磁盘设备损坏</li>
</ol>
<p>1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。</p>
<p>5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[i18n-sdk 使用手册]]></title>
        <id>https://philosopherzb.github.io/post/i18n-sdk-shi-yong-shou-ce/</id>
        <link href="https://philosopherzb.github.io/post/i18n-sdk-shi-yong-shou-ce/">
        </link>
        <updated>2022-08-30T06:22:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述i18n-sdk 的使用方式。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/boats-1802340_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="源码地址">源码地址</h2>
<p><a href="https://github.com/philosopherZB/demo-all/tree/master/i18n">点击此处跳转github查看具体源码</a></p>
<h2 id="引入依赖">引入依赖</h2>
<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;com.philosopherzb&lt;/groupId&gt;
        &lt;artifactId&gt;i18n-sdk&lt;/artifactId&gt;
         &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;
    &lt;/dependency&gt;
</code></pre>
<h2 id="使用-可参考i18n-client工程">使用--&gt;(可参考i18n-client工程)</h2>
<h3 id="配置文件在本地">配置文件在本地</h3>
<ul>
<li>在resource目录下创建 messages_en_US.properties, messages_zb_CN.properties</li>
<li>在配置文件中输入中英文配置信息</li>
<li>项目的application.properties配置文件中需要加入:<br>
<code>spring.main.allow-bean-definition-overriding=true</code><br>
<em>其中i18n为resources下的文件目录，messages是第一步中的properties前缀</em><br>
<code>spring.messages.basename=classpath:i18n/messages</code></li>
<li>代码中使用: MessageUtil.get(&quot;key&quot;); MessageUtil.get(&quot;key&quot;, &quot;params&quot;);</li>
<li>测试使用，通过在请求头信息中添加如下信息:<br>
<code>[{&quot;key&quot;:&quot;Accept-Language&quot;,&quot;value&quot;:&quot;en_US&quot;,&quot;description&quot;:&quot;英文&quot;,&quot;type&quot;:&quot;text&quot;,&quot;enabled&quot;:true}]</code><br>
<code>[{&quot;key&quot;:&quot;Accept-Language&quot;,&quot;value&quot;:&quot;zh_CN&quot;,&quot;description&quot;:&quot;中文&quot;,&quot;type&quot;:&quot;text&quot;,&quot;enabled&quot;:true}]</code></li>
</ul>
<h3 id="配置文件在nacos">配置文件在nacos</h3>
<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt;
        &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;
    &lt;/dependency&gt;
</code></pre>
<ul>
<li>如上引入nacos依赖</li>
<li>项目的application.properties配置文件中需要加入:<br>
<code>spring.main.allow-bean-definition-overriding=true</code><br>
<em>mode 表示i18n模式，local为本地，nacos为nacos配置中心，默认为local</em><br>
<code>spring.messages.mode=nacos</code><br>
<em>存储i18n的文件目录，默认为 i18n/</em><br>
<code>spring.messages.baseFolder=i18n/</code><br>
<em>此值与nacos中的配置信息需保持一致，且为必填。若为空则会抛出spring.messages.basename value is empty的异常信息。</em><br>
<code>spring.messages.basename=user-message</code><br>
<em>nacos的地址，为必填。若为空则会抛出spring.messages.serverAddress value is empty的异常信息。</em><br>
<code>spring.messages.serverAddress=127.0.0.1:8848</code><br>
<em>nacos的namespace值，为必填。若为空则会抛出spring.messages.namespace value is empty的异常信息。</em><br>
<code>spring.messages.namespace=e52f0660-c859-4762-b0f4-4f6f17727d59</code></li>
<li>代码中使用: MessageUtil.get(&quot;key&quot;); MessageUtil.get(&quot;key&quot;, &quot;params&quot;);</li>
<li>测试使用，通过在请求头信息中添加如下信息:<br>
<code>[{&quot;key&quot;:&quot;Accept-Language&quot;,&quot;value&quot;:&quot;en_US&quot;,&quot;description&quot;:&quot;英文&quot;,&quot;type&quot;:&quot;text&quot;,&quot;enabled&quot;:true}]</code><br>
<code>[{&quot;key&quot;:&quot;Accept-Language&quot;,&quot;value&quot;:&quot;zh_CN&quot;,&quot;description&quot;:&quot;中文&quot;,&quot;type&quot;:&quot;text&quot;,&quot;enabled&quot;:true}]</code></li>
</ul>
<h3 id="自动捕获javaxvalidationconstraints中的message作为国际化输出-可参考i18n-client工程">自动捕获javax.validation.constraints中的message作为国际化输出--&gt;(可参考i18n-client工程)</h3>
<h4 id="全局异常捕获">全局异常捕获</h4>
<ul>
<li>可查看 i18n-client 工程中的 com.philosopherzb.i18n.client.advice.handler.GlobalExceptionHandler</li>
</ul>
<pre><code>/**
 * @author philosopherZB
 */
@Slf4j
@RestControllerAdvice
public class GlobalExceptionHandler {

    private Function&lt;Exception, String&gt; messageExtractor = this::extractReadableMessage;

    @ExceptionHandler(RuntimeException.class)
    public Result&lt;String&gt; handleSystemException(Exception e) {
        log.error(&quot;service occurs runtime error: &quot;, e);
        return ResultUtils.failResult(BizErrorCode.SYSTEM_BUSY);
    }

    @ExceptionHandler({MethodArgumentNotValidException.class, BindException.class})
    public Result&lt;String&gt; handleArgumentException(Exception e) {
        String msg = this.messageExtractor.apply(e);
        return ResultUtils.failResult(BizErrorCode.PARAM_VALID_EXCEPTION.getCode(), msg);
    }

    @ExceptionHandler({ConstraintViolationException.class})
    public Result&lt;String&gt; handleException(ConstraintViolationException e) {
        log.error(&quot;param exception: &quot;, e);
        Optional&lt;ConstraintViolation&lt;?&gt;&gt; optional = e.getConstraintViolations().stream().findFirst();
        String msg = optional.isPresent() ? optional.get().getMessage() : BizErrorCode.PARAM_VALID_EXCEPTION.getErrorMessage();
        return ResultUtils.failResult(BizErrorCode.PARAM_VALID_EXCEPTION.getCode(), msg);
    }

    private String extractReadableMessage(Exception e) {
        log.error(&quot;param exception: &quot;, e);
        BindingResult bindingResult;
        if (e instanceof BindException) {
            bindingResult = ((BindException) e).getBindingResult();
        } else {
            bindingResult = ((MethodArgumentNotValidException) e).getBindingResult();
        }

        return Objects.requireNonNull(bindingResult.getFieldError()).getDefaultMessage();
    }
}

</code></pre>
<h4 id="通用型validation配置">通用型validation配置</h4>
<ul>
<li>可查看 i18n-client 工程中的 com.philosopherzb.i18n.client.advice.config.CommonValidationConfig 类</li>
<li>此配置器对于 javax.validation.constraints 中的message的格式要求为el形式</li>
<li>eg:  @NotBlank(message = &quot;{PARAM_INVALID}&quot;)</li>
<li>eg:  @NotBlank(message = &quot;prefix-{PARAM_INVALID}-suffix&quot;)</li>
<li>其中 PARAM_INVALID 为国际化配置文件中的key; 在花括号的左右两边可以输入额外的参数</li>
</ul>
<pre><code>/**
 * 此配置器对于 javax.validation.constraints 中的message的格式要求为el形式
 * eg:  @NotBlank(message = &quot;{PARAM_INVALID}&quot;)
 * eg:  @NotBlank(message = &quot;prefix-{PARAM_INVALID}-suffix&quot;)
 * 其中 PARAM_INVALID 为配置文件中的key
 *
 * @author philosopherZB
 */
@Configuration
public class CommonValidationConfig {
    @Bean
    public LocalValidatorFactoryBean localValidatorFactoryBean(MessageSource messageSource) {
        LocalValidatorFactoryBean bean = new LocalValidatorFactoryBean();
        bean.setValidationMessageSource(messageSource);
        return bean;
    }
}
</code></pre>
<h4 id="定制化validation配置">定制化validation配置</h4>
<ul>
<li>
<p>可查看 i18n-client 工程中的 com.philosopherzb.i18n.client.advice.config.CustomValidationConfig 类</p>
</li>
<li>
<p>此配置器对于 javax.validation.constraints 中的message的格式要求为el形式，或者定制化分隔符</p>
</li>
<li>
<p>eg:  @NotBlank(message = &quot;{PARAM_INVALID}&quot;)</p>
</li>
<li>
<p>eg:  @NotBlank(message = &quot;prefix-{PARAM_INVALID}-suffix&quot;)</p>
</li>
<li>
<p>其中 PARAM_INVALID 为国际化配置文件中的key; 在花括号的左右两边可以输入额外的参数</p>
</li>
<li>
<p>eg:  @NotBlank(message = I18nConstant.PARAM_IS_NULL_BY_SEPARATE + &quot;orderSource&quot;)</p>
</li>
<li>
<p>其中 18nConstant.PARAM_IS_NULL_BY_SEPARATE 是一个组合字符串，由 PARAM_IS_NULL_BY + SEPARATE构成</p>
</li>
<li>
<p>PARAM_IS_NULL_BY为配置文件中的key，而orderSource则为对应的字段名</p>
</li>
</ul>
<pre><code>/**
 * 此配置器对于 javax.validation.constraints 中的message的格式要求为el形式，或者分隔符
 * eg:  @NotBlank(message = &quot;{PARAM_INVALID}&quot;)
 * eg:  @NotBlank(message = &quot;prefix-{PARAM_INVALID}-suffix&quot;)
 * 其中 PARAM_INVALID 为配置文件中的key
 * &lt;p&gt;
 * eg:  @NotBlank(message = I18nConstant.PARAM_IS_NULL_BY_SEPARATE + &quot;orderSource&quot;)
 * 其中 18nConstant.PARAM_IS_NULL_BY_SEPARATE 是一个组合字符串，由 PARAM_IS_NULL_BY + SEPARATE构成
 * PARAM_IS_NULL_BY为配置文件中的key，而orderSource则为对应的字段名
 *
 * @author philosopherZB
 */
@Configuration
public class CustomValidationConfig {

    private static final Pattern MESSAGE_PATTERN = Pattern.compile(&quot;(?&lt;=\\{)[^}]*(?=})&quot;);

    @Bean
    @Primary
    public Validator localValidator() {
        return Validation.byDefaultProvider()
                .configure()
                .messageInterpolator(new I18nMessageInterpolator())
                .buildValidatorFactory()
                .getValidator();
    }

    static class I18nMessageInterpolator implements MessageInterpolator {
        @Override
        public String interpolate(String s, Context context) {
            return interpolate(s, context, null);
        }

        @Override
        public String interpolate(String s, Context context, Locale locale) {
            if (MessageUtil.prepared()) {
                if (s.contains(I18nConstant.SEPARATE)) {
                    String[] split = s.split(I18nConstant.SEPARATE);
                    return MessageUtil.get(split[0], split[1]);
                }
                Matcher matcher = MESSAGE_PATTERN.matcher(s);
                if (matcher.find()) {
                    String temp = MessageUtil.get(matcher.group());
                    return s.replaceFirst(&quot;\\{&quot;.concat(matcher.group()).concat(&quot;\\}&quot;), temp);
                }
                return MessageUtil.get(s);
            }
            return s;
        }
    }
}

</code></pre>
<pre><code>/**
 * @author philosopherZB
 */
public class I18nConstant {
    /**
     * 分隔符
     */
    public static final String SEPARATE = &quot;~&quot;;

    /**
     * 空值参数，可以指定参数名
     */
    public static final String PARAM_IS_NULL_BY = &quot;PARAM_IS_NULL_BY&quot;;
    /**
     * 空值参数，有分隔符，可以指定参数名
     */
    public static final String PARAM_IS_NULL_BY_SEPARATE = PARAM_IS_NULL_BY + SEPARATE;
}

</code></pre>
]]></content>
    </entry>
</feed>