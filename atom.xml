<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://philosopherzb.github.io</id>
    <title>Philosopher</title>
    <updated>2023-03-01T06:32:36.943Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://philosopherzb.github.io"/>
    <link rel="self" href="https://philosopherzb.github.io/atom.xml"/>
    <subtitle>WORLD AS CODE</subtitle>
    <logo>https://philosopherzb.github.io/images/avatar.png</logo>
    <icon>https://philosopherzb.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Philosopher</rights>
    <entry>
        <title type="html"><![CDATA[Java中的锁]]></title>
        <id>https://philosopherzb.github.io/post/java-zhong-de-suo/</id>
        <link href="https://philosopherzb.github.io/post/java-zhong-de-suo/">
        </link>
        <updated>2021-01-16T03:27:32.000Z</updated>
        <content type="html"><![CDATA[<h2 id="锁的类型">锁的类型</h2>
<h3 id="乐观锁">乐观锁</h3>
<p>乐观锁认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁。但是，在更新的时候会判断一下在此期间别人有没有去修改这个数据，采取写时先读出当前版本号，然后加锁操作（比较上一次的版本号，一致则更新），如果失败则重复读-比较-写操作。</p>
<p>CAS便是典型的乐观锁机制，其中会使用到sun.misc.Unsafe这个类进行Compare And Swap操作。</p>
<p>CAS 即比较并交换。是解决多线程并行情况下使用锁造成性能损耗的一种机制，CAS 操作包含三个操作数——内存位置(V)、预期原值(A)和新值(B)。如果内存位置的值(V)与预期原值(A)相匹配，那么处理器会自动将该位置值更新为新值(B)。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置(V)应该包含值(A)。如果包含该值，则将新值(B)放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可”。</p>
<h3 id="悲观锁">悲观锁</h3>
<p>悲观锁认为写操作更多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以会在每次读写的时候上锁，这样别人想读写这个数据便会block直到获取锁。</p>
<p>Synchronized便是典型的悲观锁，AQS框架下的锁会先尝试CAS获取锁，获取不到便会转为悲观锁。</p>
<h2 id="线程切换及其代价">线程切换及其代价</h2>
<h3 id="线程切换">线程切换</h3>
<p>java线程与操作系统上的原生线程是一一映射的。如果需要阻塞或者唤醒一个线程，便需要操作系统的介入，并切换用户态与内核态（这样的切换需要消耗大量的系统资源）。</p>
<h4 id="用户态切换到内核态的步骤主要如下">用户态切换到内核态的步骤主要如下</h4>
<ol>
<li>从当前进程的描述符中提取其内核栈的ss0及esp0信息。</li>
<li>使用ss0和esp0指向的内核栈将当前进程的cs，eip，eflags，ss，esp信息保存起来，这个过程也完成了由用户态到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。</li>
<li>将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。</li>
</ol>
<h4 id="名词解释如下">名词解释如下</h4>
<p>CS：代码段寄存器；存放当前正在运行的程序代码所在段的段基值；联合ip作为cpu指向当前正在执行的指令，不能随便修改。</p>
<p>DS：数据段寄存器；存放数据段的段基值；定义了一个数据段。</p>
<p>SS：堆栈段寄存器；存放堆栈段的段基值，联合sp定义一个堆栈值，一旦确定了堆栈地址，将不能随便改变。</p>
<p>内核态切换到用户态主要使用PSW（Program Status Word，程序状态字，又称状态寄存器），其一般用于反映处理器的状态及某些计算结果以及控制指令的执行：</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301001.png" alt="" loading="lazy"></figure>
<h3 id="切换的代价">切换的代价</h3>
<ul>
<li>如果线程切换是一个高频操作，那将耗费很多CPU处理时间（用户态，内核态之间的切换）。</li>
<li>甚至，如果同步代码块中的内容过于简单，状态切换消耗的时间有可能比用户代码执行的时间还要长。</li>
</ul>
<h2 id="java对象结构之对象头">Java对象结构之对象头</h2>
<h3 id="对象头">对象头</h3>
<p>对象头（Header）主要包含两部分信息：第一部分用于存储对象自身的运行时数据（如哈希码（HashCode），GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据长度在32位或者64位的虚拟机中分别为32bit以及64bit，官方称之为“Mark Word”）；</p>
<p>第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机可以通过这个指针来确定该对象属于哪个类的实例（并不是所有的虚拟机实现都需要在对象数据上保留类型指针，即查找对象的元数据信息并不一定要经过对象本身）。</p>
<p>如果对象是一个Java数组，那么对象头还需要记录该数组长度，因为普通的Java对象可以通过元数据信息确认对象大小，而数组却不行。</p>
<h3 id="markword">MarkWord</h3>
<p>markword数据的长度在32位和64位（未开启压缩指针）的虚拟机中分别为32bit和64bit，它的最后两位便是锁状态标识位，用来标记当前对象的状态，常用值如下：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301002.png" alt="" loading="lazy"></figure>
<p>32位虚拟机在不同状态下markword的结构图如下：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301003.png" alt="img" loading="lazy"></figure>
<h2 id="java中的锁">Java中的锁</h2>
<h3 id="主流锁图">主流锁图</h3>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301004.png" alt="img" loading="lazy"></figure>
<h3 id="自旋锁基于cas">自旋锁（基于CAS）</h3>
<p>如果持有锁的线程可以在很短的时间内释放锁，那么那些等待锁的线程便不需要进入阻塞挂起状态，而是自旋等待一会儿便可获取到同步资源，从而避免了线程切换的开销，这就是自旋锁。</p>
<p>自旋锁本身是有缺点的，它不能代替阻塞。</p>
<p>自旋锁虽然避免了线程切换的开销，但其占据了CPU处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好；反之，则会白白浪费处理器资源。甚至，当线程过多时，还会影响系统的整体性能。</p>
<p>因此，自旋等待的时间需要有一个限度，如果超过限定次数（默认10次，可以使用-XX:PreBlockSpin来更改）没有获取到锁，则应当挂起线程。</p>
<p>自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。</p>
<p>自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。</p>
<p>如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301005.png" alt="img" loading="lazy"></figure>
<h4 id="jvm针对当前cpu的负荷情况还做了如下自旋锁优化操作">JVM针对当前CPU的负荷情况还做了如下自旋锁优化操作：</h4>
<ul>
<li>如果平均负载小于CPUs则一直自旋</li>
<li>如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞</li>
<li>如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞</li>
<li>如果CPU处于节电模式则停止自旋</li>
<li>自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）</li>
<li>自旋时会适当放弃线程优先级之间的差异</li>
</ul>
<h3 id="synchronized无锁偏向锁轻量级锁重量级锁">Synchronized（无锁，偏向锁，轻量级锁，重量级锁）</h3>
<h4 id="synchronized队列">Synchronized队列</h4>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301006.png" alt="img" loading="lazy"></figure>
<p>可以看出，synchronized有多个队列，当多个线程一起访问某个对象监视器（monitor，其是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步））的时候，对象监视器会将这些线程存储在不同的容器里。</p>
<h5 id="结构概述">结构概述</h5>
<ul>
<li>ContentionList：竞争队列，所有请求锁的线程首先会被放入此队列中。</li>
<li>EntryList：ContentionList中一些有资格获取同步资源的线程将被移动到此队列中。</li>
<li>WaitSet：调用wait方法被阻塞的线程，放于此处。</li>
<li>OnDeck：任何时刻，最多只有一个线程正在竞争锁，该线程便是OnDeck。</li>
<li>Owner：已经获取到锁的线程被称为Owner。</li>
<li>!Owner：已经释放锁的线程。</li>
</ul>
<h5 id="队列协作过程">队列协作过程</h5>
<ul>
<li>JVM每次都会从队列尾部取出一个线程用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。</li>
<li>Owner在unlock时，也会将ContentionList中的部分线程迁移到EntryList，并指定EntryList中的某个线程为Ondeck（一般是最先进去的线程）。</li>
<li>Owner不会直接将锁传递给OnDeck，而是将锁竞争的权利交给OnDeck，OnDeck需要重新去竞争锁。这样虽然牺牲了一些公平性，但能极大的提高系统吞吐量，在JVM中，这种选择行为被称为“竞争切换”。</li>
<li>OnDeck获取到锁后就会变为Owner，而没有得到锁的则仍然停留在EntryList；如果OnDeck线程被wait阻塞，则会被移动至WaitSet，直到某个时刻被notify或notifyAll唤醒，才能重新进入EntryLIst。</li>
<li>处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。</li>
</ul>
<h4 id="无锁cas">无锁（CAS）</h4>
<p>无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。</p>
<p>无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。</p>
<h4 id="偏向锁">偏向锁</h4>
<p>偏向锁是指一段同步代码一直被一个线程所访问，那么这个线程便会自动获取锁，降低了获取锁的代价。</p>
<p>在运行过程中，不存在多线程竞争，则线程不需要触发同步，此时为了提高线程执行同步代码的效率，便出现了偏向锁。</p>
<h5 id="偏向锁执行过程">偏向锁执行过程</h5>
<ol>
<li>访问MarkWord中偏向锁的标识位是否设置为1，锁标识位是否设置为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则判断线程id是否指向当前线程，如果是，则进入步骤5，否则进入步骤3。</li>
<li>如果线程id未指向当前线程，则通过CAS操作竞争锁，如果竞争成功，则将MarkWord中的线程id设置为当前线程id，然后执行步骤5，否则进入步骤4。</li>
<li>如果CAS获取锁失败，则表示存在锁竞争。当到达全局安全点（safepoint，会导致很短时间的stop-the-world）时，获取偏向锁的线程将被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。</li>
<li>执行同步代码。</li>
</ol>
<h5 id="偏向锁的释放">偏向锁的释放</h5>
<p>偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。</p>
<p>偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h5 id="偏向锁适用场景">偏向锁适用场景</h5>
<p>始终只有一个线程操作同步资源，也就是锁无竞争状况下使用。一旦有了竞争，偏向锁便会升级为轻量级锁（升级需要撤销偏向锁，这个过程会stop-the-world）。</p>
<p>如果存在高并发锁竞争，应当禁用偏向锁，这样可以适当提高程序性能。</p>
<h5 id="jvm开启关闭偏向锁">jvm开启/关闭偏向锁</h5>
<p>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0<br>
（-XX:BiasedLockingStartupDelay=0的作用是在虚拟机启动后，立即启用偏向锁，如果不设置该参数，默认虚拟会在4秒后，才启动偏向锁。）</p>
<p>关闭偏向锁：-XX:-UseBiasedLocking</p>
<h4 id="轻量级锁">轻量级锁</h4>
<p>轻量级锁是由偏向锁升级而来的，当一个线程持有偏向锁执行同步块时，存在另外的线程来竞争锁，这时偏向锁便会升级为轻量级锁。</p>
<p>轻量级锁执行过程：</p>
<p>a、在代码进入同步块的时候，如果同步对象状态为无锁状态（锁标识位：01，是否偏向锁标识位：0），虚拟机首先会在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储对象目前的MarkWord的拷贝（官方称之为Displaced Mark Word）。线程堆栈与对象头状态图如下：</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301007.png" alt="img" loading="lazy"></figure>
<p>b、拷贝对象头的MarkWord复制到锁记录中。</p>
<p>c、拷贝成功后，虚拟机将使用CAS操作尝试将对象的MarkWord更新为指向Lock Record的指针，并将Lock Record中的owner指针指向object mark word，如果更新成功，则执行步骤d，否则执行步骤e。</p>
<p>d、更新成功后，该线程便拥有了这个对象的锁，此时对象MarkWord中的锁标识位将被设置为‘00’，表示此对象处于轻量级锁定状态。线程堆栈与对象头状态图如下：</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301008.png" alt="img" loading="lazy"></figure>
<p>e、如果这个更新操作失败了，虚拟机首先会检查对象的MarkWord是否指向当前线程的栈帧，如果是，则表示当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明有多个线程在竞争锁。</p>
<p>若当前只有一个等待线程，则该线程进行自旋等待，当自旋超过阈值，或者一个线程持有锁，一个在自旋，又有第三个来访问锁时，轻量级锁便会膨胀为重量级锁。</p>
<p>锁的标识位将被设置为‘10’，MarkWord中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也会进入阻塞状态。</p>
<h4 id="整体执行过程">整体执行过程</h4>
<h5 id="锁升级流程图">锁升级流程图：</h5>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301009.png" alt="img" loading="lazy"></figure>
<h5 id="synchronized执行过程">synchronized执行过程：</h5>
<ol>
<li>检测Mark Word中的锁标识是否为可偏向状态（锁标识位：01，是否偏向锁：1），如果是，则为偏向锁。</li>
<li>如果不是，则检查Mark Word里面的线程id是不是当前线程的ID，如果是，表示当前线程处于偏向锁</li>
<li>如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1</li>
<li>如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。</li>
<li>当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁</li>
<li>如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</li>
<li>如果自旋成功则依然处于轻量级状态。</li>
<li>如果自旋失败，则升级为重量级锁。</li>
</ol>
<h3 id="锁优化">锁优化</h3>
<h4 id="减少锁的时间">减少锁的时间</h4>
<p>不需要同步执行的代码，尽量不要放在同步块中，这样可以让锁更快的释放。</p>
<h4 id="减少锁的粒度">减少锁的粒度</h4>
<p>锁粒度的减少核心思想是利用空间换时间，它将物理上的一个锁，拆分为逻辑上的多个锁，增加并发度，从而降低了锁竞争。</p>
<p>典型代表有：ConcurrentHashMap（jdk1.8之前，有用到Segment数组）；LongAdder（实现机制与ConcurrentHashMap类似，其中有一个根据当前并发状态动态改变的Cell数组，注意：其竞争维度为cell个数+1，因为还有一个base数组）；LinkedBlockQueue（出队，入队采用了不同的锁，增加了并行效率）。</p>
<p>锁的拆分不能无限拆，需要根据当前系统CPU核数进行限制（不能超过CPU核数）。</p>
<h4 id="锁粗化">锁粗化</h4>
<p>大部分情况下，是要求将锁粒度减小，但某些情况下，也需要粗化锁粒度，比如循环中加锁。</p>
<h4 id="使用读写锁">使用读写锁</h4>
<p>ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写。例如：CopyOnWriteArrayList 、CopyOnWriteArraySet</p>
<p>CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。</p>
<p>CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的。</p>
<h4 id="使用cas">使用CAS</h4>
<p>如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择。</p>
<h4 id="消除缓存行的伪共享">消除缓存行的伪共享</h4>
<p>除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。</p>
<p>在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。</p>
<p>例如，多个不需要同步的变量因为存储在连续的32字节或64字节里面，当需要其中的一个变量时，就将它们作为一个缓存行一起加载到某个cup-1私有的缓存中（虽然只需要一个变量，但是cpu读取会以缓存行为最小单位，将其相邻的变量一起读入），被读入cpu缓存的变量相当于是对主内存变量的一个拷贝，也相当于变相的将在同一个缓存行中的几个变量加了一把锁，这个缓存行中任何一个变量发生了变化，当cup-2需要读取这个缓存行时，就需要先将cup-1中被改变了的整个缓存行更新回主存（即使其它变量没有更改），然后cup-2才能够读取，而cup-2可能需要更改这个缓存行的变量与cpu-1已经更改的缓存行中的变量是不一样的，所以这相当于给几个毫不相关的变量加了一把同步锁；</p>
<p>为了防止伪共享，不同jdk版本实现方式是不一样的：</p>
<ol>
<li>在jdk1.7之前会 将需要独占缓存行的变量前后添加一组long类型的变量，依靠这些无意义的数组的填充做到一个变量自己独占一个缓存行；</li>
<li>在jdk1.7因为jvm会将这些没有用到的变量优化掉，所以采用继承一个声明了好多long变量的类的方式来实现；</li>
<li>在jdk1.8中通过添加sun.misc.Contended注解来解决这个问题，若要使该注解有效必须在jvm中添加以下参数：-XX:-RestrictContended。sun.misc.Contended注解会在变量前面添加128字节的padding将当前变量与其他变量进行隔离</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java线程池详解]]></title>
        <id>https://philosopherzb.github.io/post/java-xian-cheng-chi-xiang-jie/</id>
        <link href="https://philosopherzb.github.io/post/java-xian-cheng-chi-xiang-jie/">
        </link>
        <updated>2021-01-09T05:49:27.000Z</updated>
        <content type="html"><![CDATA[<h2 id="线程池">线程池</h2>
<h3 id="线程池的优势">线程池的优势</h3>
<ul>
<li>降低系统资源消耗：通过重用已存在的线程，降低线程创建和销毁所造成的资源消耗。</li>
<li>提供系统响应速度：当任务来临时，直接复用已存在的线程进行工作，而无需等待线程的创建。</li>
<li>方便线程数的管控：过多的线程创建，会导致性能的急剧下降（线程上下文切换十分耗费性能），甚至出现OOM。</li>
<li>提供更加强大的功能，如延时定时线程池。</li>
</ul>
<h3 id="线程池的主要参数">线程池的主要参数</h3>
<pre><code>public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
</code></pre>
<ul>
<li>corePoolSize：核心线程数，默认情况下，核心线程一直存活在线程池中，即使它们处于闲置状态（可通过allowCoreThreadTimeOut进行控制）。当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会创建一个新的线程来执行任务，直到创建的线程数大于或等于corePoolSize时才进行线程复用（可通过prestartCoreThread()或者prestartAllCoreThreads()来提前启动线程池中的基本线程）。</li>
<li>maximumPoolSize：最大线程数，当队列满了，且已创建线程数小于maximumPoolSize时，线程池会创建新的线程来执行任务。</li>
<li>keepAliveTime：线程闲置时长，超过此时长将会被销毁。默认只对非核心线程生效，只有当ThreadPoolExecutor中的allowCoreThreadTimeOut设置为true时，才会对核心线程生效。</li>
<li>unit：用于指定keepAliveTime参数的时间单位。</li>
<li>workQueue：工作队列，用于保存等待执行的任务的阻塞队列。通过线程池的execute方法提交的Runnable对象都会存储在该队列中。</li>
</ul>
<ol>
<li>ArrayBlockingQueue：基于数组实现的有界的阻塞队列,该队列按照FIFO（先进先出）原则对队列中的元素进行排序。</li>
<li>LinkedBlockingQueue：基于链表实现的阻塞队列，该队列按照FIFO（先进先出）原则对队列中的元素进行排序。</li>
<li>SynchronousQueue：内部没有任何容量的阻塞队列。在它内部没有任何的缓存空间。对于SynchronousQueue中的数据元素只有当我们试着取走的时候才可能存在。</li>
<li>PriorityBlockingQueue：具有优先级的无限阻塞队列。</li>
<li>通过实现BlockingQueue接口来自定义所需要的阻塞队列</li>
</ol>
<ul>
<li>threadFactory：线程工厂，用于创建新线程。</li>
<li>handler：拒绝策略，当线程池饱和时（任务队列以及活动线程数都已达到最大值），此时便会执行对应的拒绝策略。</li>
</ul>
<ol>
<li>CallerRunsPolicy：使用调用者所在线程来运行任务。</li>
<li>AbortPolicy：直接抛出RejectedExecutionException异常。</li>
<li>DiscardPolicy：丢弃掉该任务，不进行处理</li>
<li>DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。</li>
</ol>
<h3 id="线程池流程图">线程池流程图</h3>
<ol>
<li>如果在线程池中的线程数量没有达到核心线程数量，这时候就会启动一个核心线程来执行任务（等于核心线程数时，会复用线程池中已存在的线程）。</li>
<li>如果线程池中的线程数量已经超过核心线程数，这时候任务就会被插入到任务队列中排队等待执行。</li>
<li>由于任务队列已满，无法将任务插入到任务队列中。这个时候如果线程池中的线程数量没有达到线程池所设定的最大值（maximumPoolSize），那么这时候就会立即启动一个非核心线程来执行任务。</li>
<li>如果线程池中的数量达到了所规定的最大值（maximumPoolSize），那么就会拒绝执行此任务，这时候就会调用RejectedExecutionHandler中的rejectedExecution方法来通知调用者。</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230228001.png" alt="img" loading="lazy"></figure>
<h3 id="四种线程池一般不推荐使用">四种线程池（一般不推荐使用）</h3>
<p>1、newCachedThreadPool：用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换），无界线程池，容易发生OOM。</p>
<pre><code>public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue&lt;Runnable&gt;());
}

</code></pre>
<p>2、newFixedThreadPool：创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）</p>
<pre><code>public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
}

</code></pre>
<p>3、newSingleThreadExecutor：创建一个单线程的线程池，适用于需要保证顺序执行各个任务。</p>
<pre><code>public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue&lt;Runnable&gt;()));
}

</code></pre>
<p>4、newScheduledThreadPool：适用于执行延时或者周期性任务.</p>
<pre><code>public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}
public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
          new DelayedWorkQueue());
}
//实例：
ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
service.schedule(() -&gt; System.out.println(Thread.currentThread().getName()+&quot;延迟三秒执行&quot;), 3, TimeUnit.SECONDS);
service.scheduleAtFixedRate(() -&gt; System.out.println(Thread.currentThread().getName()+&quot;延迟三秒后每隔2秒执行&quot;), 3, 2, TimeUnit.SECONDS);

</code></pre>
<p>schedule(Runnable command, long delay, TimeUnit unit)：延迟一定时间后执行Runnable任务；</p>
<p>schedule(Callable callable, long delay, TimeUnit unit)：延迟一定时间后执行Callable任务；</p>
<p>scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)：延迟一定时间后，以间隔period时间的频率周期性地执行任务(固定频率的含义就是可能设定的固定时间不足以完成线程任务，但是它不管，达到设定的延迟时间了就要执行下一次了)；</p>
<p>scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,TimeUnit unit)：与scheduleAtFixedRate()方法很类似，但是不同的是scheduleWithFixedDelay()方法的周期时间间隔是以上一个任务执行结束到下一个任务开始执行的间隔，而scheduleAtFixedRate()方法的周期时间间隔是以上一个任务开始执行到下一个任务开始执行的间隔，也就是这一些任务系列的触发时间都是可预知的.</p>
<h3 id="线程池中的线程数配置">线程池中的线程数配置</h3>
<ul>
<li>CPU密集型任务：线程池中线程个数应尽量少，如配置N+1个线程的线程池；</li>
<li>IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数 时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率，如2*N；</li>
<li>混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java多线程基础]]></title>
        <id>https://philosopherzb.github.io/post/java-duo-xian-cheng-ji-chu/</id>
        <link href="https://philosopherzb.github.io/post/java-duo-xian-cheng-ji-chu/">
        </link>
        <updated>2020-12-18T08:13:34.000Z</updated>
        <content type="html"><![CDATA[<h2 id="多线程基础">多线程基础</h2>
<h3 id="java多线程并发库">java多线程并发库</h3>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230227001.png" alt="img" loading="lazy"></figure>
<h3 id="进程与线程">进程与线程</h3>
<p>进程：是程序运行以及资源分配的基本单位，一个程序至少有一个进程。</p>
<p>线程：是CPU调度和分配的基本单位，一个进程至少有一个线程。同一个进程中的线程共享其资源（减少切换，可提高效率），且可以并发执行（并发：同一时间间隔可以做多件事；并行：同一时刻可以做多件事（多核））。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230227002.png" alt="img" loading="lazy"></figure>
<h3 id="线程的上文切换">线程的上文切换</h3>
<ul>
<li>一个CPU核在任意时刻只能执行一个线程，如果有多个线程（超过CPU核数）存在，CPU将会采用时间片轮转的方式进行线程切换，即给每一个线程分配一个时间片，当一个线程的时间片用完的时候便会处于就绪状态，并让出CPU给其他线程使用，这就是一次上下文切换。</li>
<li>上下文切换时是通过运行时数据区中的程序计数器来存储各个线程的运行状态的，以便于下次运行线程时可以接着上次指令继续运行（比如线程A做了一次计算准备返回数据时，切换到了线程B，然后又切回线程A，是直接返回数据，而不是再去计算一遍）。</li>
<li>程序计数器指的是JVM中的一块内存区域，它可以看作是当前线程所执行字节码的行号指示器，通过它，Java可以知道每个线程执行到了哪一步指令（由此可以看出程序计数器是线程私有的）。</li>
<li>一般而言，上下文切换是比较耗费CPU时间的一种操作。</li>
</ul>
<h3 id="线程的几种状态">线程的几种状态</h3>
<ul>
<li>创建：指的是生成线程对象，此时并没有调用start方法。</li>
<li>就绪：调用线程的start方法后，线程便进入了就绪状态，此时等待系统调度。</li>
<li>运行：通过系统调度，开始运行线程中的run函数。</li>
<li>等待：调用了Object.wait()会进入等待队列。一般需要等待其他线程做出一些特定的通知或者中断。</li>
<li>超时等待：该状态与等待状态有一点区别就是它会自动返回，比如调用Threa.sleep(long)，在超时之后，会自动返回进入就绪状态。</li>
<li>阻塞：指的是去获取锁时(等待进入synchronized方法或块)，发现同步锁被占用了，这时线程会被放入锁池，等待获取锁。</li>
<li>死亡：运行完run方法，main方法（main方法指的是主线程）之后正常退出，也有可能出现异常导致死亡；死亡的线程不能重新启用，否则报错。</li>
</ul>
<h2 id="创建线程的几种方式">创建线程的几种方式</h2>
<h3 id="继承thread">继承Thread</h3>
<pre><code>public class ThreadTest {
    public static void main(String[] args){
        new TestThread().start();
    }
}

class TestThread extends Thread{
    @Override
    public void run(){
        System.out.println(&quot;Test Thread&quot;);
    }
}
</code></pre>
<h3 id="实现runnable">实现Runnable</h3>
<pre><code>public class ThreadTest {
    public static void main(String[] args){
        new Thread(new TestRunnable()).start();
    }
}

class TestRunnable implements Runnable{
    @Override
    public void run() {
        System.out.println(&quot;Test Runnable&quot;);
    }
}
</code></pre>
<h3 id="实现callable">实现Callable</h3>
<pre><code>public class ThreadTest {
    public static void main(String[] args){
        FutureTask&lt;Integer&gt; task = new FutureTask(new TestCallable());
        new Thread(task).start();
        try {
            System.out.println(task.get());//get方法会得到call执行完之后的值
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
    }
}

class TestCallable implements Callable&lt;Integer&gt; {
    @Override
    public Integer call() throws Exception {
        int num = 0;
        while(num &lt; 5){
            num++;
        }
        return num;
    }
}
</code></pre>
<h2 id="线程安全性">线程安全性</h2>
<ul>
<li>原子性：同一时刻只允许一个线程对数据进行操作（atomic开头的原子类,synchronized，Lock）。</li>
<li>可见性：一个线程对共享变量的修改，可以及时地被其他线程观察到，（synchronized,volatile，Lock）。</li>
<li>有序性：指的是可以观察到其他线程的指令执行顺序，由于指令重排，一般情况下是无序的（happens-before原则）。</li>
</ul>
<h3 id="线程死锁">线程死锁</h3>
<h4 id="死锁">死锁</h4>
<ul>
<li>指的是多个线程在执行过程中，因争夺资源而陷入环路阻塞的一种现象。</li>
<li>示例代码如下（运行之后，两个线程陷入死锁中，如果没有外力中断，将会一直锁定）：</li>
</ul>
<pre><code>public class ThreadTest {
    //共享资源A
    private static final Object A = new Object();
    //共享资源B
    private static final Object B = new Object();

    public static void main(String[] args){
        new Thread(() -&gt; {
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &quot;：得到资源---A&quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &quot;：去获取资源---B&quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &quot;：得到资源---B&quot;);
                }
            }
        },&quot;Thread-01&quot;).start();

        new Thread(() -&gt; {
            synchronized (B){
                System.out.println(Thread.currentThread().getName() + &quot;：得到资源---B&quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &quot;：去获取资源---A&quot;);
                synchronized (A){
                    System.out.println(Thread.currentThread().getName() + &quot;：得到资源---A&quot;);
                }
            }
        },&quot;Thread-02&quot;).start();
    }
}
</code></pre>
<h4 id="死锁四个必要条件以及如何避免死锁">死锁四个必要条件以及如何避免死锁</h4>
<ul>
<li>互斥条件：一个资源在任意时刻只能被一个线程占用，如果有其他线程请求该资源，需要等待原线程释放资源（此条件不能被破坏，因为锁本身就是为了互斥访问）。</li>
<li>请求和保持条件：一个线程已经获取了一部分资源，又去请求其他资源，如果其他资源正被占用，原线程陷入阻塞，且不会释放自己占用的资源（一次性申请所有资源；或者阻塞时，释放自己占用的资源）。</li>
<li>不可剥夺条件：一个线程已经获得的资源，在自己未使用完之前不能被其他线程剥夺，只能自己使用结束后释放（如果去获取正在被其他线程使用的资源而阻塞时，可以释放自己占用的资源）。</li>
<li>环路等待条件：多个进程之间形成一种头尾相接的循环等待资源关系（按一定的顺序来获取资源）。</li>
<li>针对上述例子而言，可以让现线程1先获取资源AB，执行完之后，再让线程2获取资源AB，改动如下（执行顺序为：线程1先获取资源A，接着释放CPU，线程2执行准备去获取资源A，发现资源A已被占用，此时线程2阻塞，然后一秒之后释放CPU，线程1接着执行，去获取资源B，正常获取，执行完毕，释放CPU；线程2开始获取资源A，由于线程1已经执行完毕释放了锁，所以线程2正常获取资源A，接着休眠一秒释放CPU，然后又去获取资源B，同样正常获取，执行完毕）：</li>
</ul>
<pre><code>public class ThreadTest {
    //共享资源A
    private static final Object A = new Object();
    //共享资源B
    private static final Object B = new Object();

    public static void main(String[] args){
        new Thread(() -&gt; {
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &quot;：得到资源---A&quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &quot;：去获取资源---B&quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &quot;：得到资源---B&quot;);
                }
            }
        },&quot;Thread-01&quot;).start();

        new Thread(() -&gt; {
            //线程2去获取A时被阻塞
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &quot;：得到资源---A&quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &quot;：去获取资源---B&quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &quot;：得到资源---B&quot;);
                }
            }
        },&quot;Thread-02&quot;).start();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java基础知识]]></title>
        <id>https://philosopherzb.github.io/post/java-ji-chu-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/java-ji-chu-zhi-shi/">
        </link>
        <updated>2020-10-14T07:12:00.000Z</updated>
        <content type="html"><![CDATA[<h2 id="面向对象的三大特性">面向对象的三大特性</h2>
<h3 id="封装">封装</h3>
<ul>
<li>将现实中的客观事物封装成抽象的类。</li>
<li>对一个类中的变量，方法进行访问符修饰，以达到有些变量，方法对外开放，有些变量，方法隐藏。</li>
<li>针对第2点对应的访问修饰符有(范围从大到小)：public &gt; protected &gt; default &gt; private。</li>
<li>由于封装隐藏了具体实现，仅提供接口供外部调用，所以在一定程度上可以提高安全性。</li>
</ul>
<h3 id="继承">继承</h3>
<ul>
<li>可以实现已存在的类的变量，方法（非private），并可以扩展单属于自我的变量及方法。</li>
<li>继承在Java中为单继承，即一个子类只能继承一个父类（可以实现多个接口）。</li>
<li>通过继承创建的类称为“子类”，“派生类”。</li>
<li>被继承的类称为“父类”，“基类”，“超类”。</li>
<li>继承的关系是is-a，比如说老师是人，狮子是动物等。</li>
<li>继承可以降低代码的重复性，方便后续对公共行为的维护，不过同时也增加了代码的耦合度。</li>
<li>子类不继承父类的构造器，而是显示或隐式的调用（如果父类中存在不带参构造器，则子类隐式调用该构造器；否则如果父类中仅存在带参构造器，则子类需要通过super来显示调用父类带参构造器）。</li>
</ul>
<h3 id="多态">多态</h3>
<ul>
<li>对同一个行为体现出不同的表现形式，比如吃，可以吃饭，吃零食等。</li>
<li>在Java中体现为对方法的重写以及重载，即传入参数来决定做哪一种具体的动作（重载）不同类之间同一方法不同表现（重写）。</li>
<li>重写一般为父子类之间对方法的不同操作，重载一般为同一个类中对方法的不同操作。</li>
</ul>
<h2 id="基本数据类型四个整数两个浮点一个字符一个布尔">基本数据类型（四个整数，两个浮点，一个字符，一个布尔）</h2>
<ul>
<li>byte，占8位，1字节，默认值：0，包装类：java.lang.Byte</li>
<li>short，占16位，2字节，默认值：0，包装类：java.lang.Short</li>
<li>int，占32位，4字节，默认值：0，包装类：java.lang.Integer</li>
<li>long，占64位，8字节，默认值：0L，包装类：java.lang.Long</li>
<li>float，占32位，4字节，默认值：0.0f，包装类：java.lang.Float</li>
<li>double，占64位，8字节，默认值：0.fd，包装类：java.lang.Double</li>
<li>char，可以存储任何字符，包装类：java.lang.Character</li>
<li>boolean，默认值：false，包装类：java.lang.Boolean</li>
</ul>
<h2 id="面向对象的六大基本原册">面向对象的六大基本原册</h2>
<h3 id="单一职责原则single-responsibility-priciple">单一职责原则（Single Responsibility Priciple）</h3>
<ul>
<li>对于一个类而言，应该只有一个引起他变化的原因。</li>
<li>比如，不要将teacher,doctor都放在一个person类中，而是将其拆成teacher类，doctor类。</li>
<li>能够一定程度上降低耦合度。</li>
</ul>
<h3 id="开闭原则open-close-priciple">开闭原则（Open Close Priciple）</h3>
<ul>
<li>对于扩展是开放的，对于修改是关闭的。</li>
<li>一般来说就是不要修改之前的代码，可以选择继承或者实现接口来扩展对应的功能。</li>
</ul>
<h3 id="里式替换原则liskov-substitution-priciple">里式替换原则（Liskov Substitution Priciple）</h3>
<ul>
<li>所有引用父类的地方都可以透明的使用其子类对象。</li>
<li>即父类出现的地方，把父类换成子类不会出现异常或错误；反之，子类出现的地方，把子类换成父类可能会出现异常或错误。</li>
<li>比如,person类具有eat功能，那么将person.eat换成teacher.eat是没有问题的；而如果teacher类具有独特的teach功能，那么如果将teacher.teach换成person.teach就会出现错误。</li>
</ul>
<h3 id="依赖倒置原则dependence-inversion-priciple">依赖倒置原则（Dependence Inversion Priciple）</h3>
<ul>
<li>高层模块不依赖低层模块，而是应该依赖其抽象</li>
<li>抽象不依赖于细节，细节依赖于抽象</li>
<li>比如teacher类中应该尽量做一些老师共有的抽象行为，比如教书，这样后面的语文老师，数学老师等可以继承该抽象老师类进行扩展。</li>
</ul>
<h3 id="接口隔离原则interface-segregation-priciple">接口隔离原则（Interface Segregation Priciple）</h3>
<ul>
<li>客户端不应该依赖它不需要的接口;一个类对另一个类的依赖应该建立在最小的接口上</li>
<li>尽量一个接口只实现一个功能，如果接口功能太多可进行拆分。</li>
</ul>
<h3 id="迪米特原则law-of-demeter-or-least-knowlegde-priciple">迪米特原则（Law of Demeter or Least Knowlegde Priciple）</h3>
<ul>
<li>一个对象应该对其他对象有最少的了解。</li>
<li>此原则与接口隔离原则可以结合使用，尽量保持一个方法一个具体行为，而不要涵盖多个行为。</li>
</ul>
]]></content>
    </entry>
</feed>