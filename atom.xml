<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://philosopherzb.github.io</id>
    <title>Philosopher</title>
    <updated>2023-03-06T08:59:43.088Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://philosopherzb.github.io"/>
    <link rel="self" href="https://philosopherzb.github.io/atom.xml"/>
    <subtitle>WORLD AS CODE</subtitle>
    <logo>https://philosopherzb.github.io/images/avatar.png</logo>
    <icon>https://philosopherzb.github.io/favicon.ico</icon>
    <rights>All rights reserved 2023, Philosopher</rights>
    <entry>
        <title type="html"><![CDATA[MySQL日志系统]]></title>
        <id>https://philosopherzb.github.io/post/mysql-ri-zhi-xi-tong/</id>
        <link href="https://philosopherzb.github.io/post/mysql-ri-zhi-xi-tong/">
        </link>
        <updated>2022-03-19T08:07:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述MySQL日志系统，包括InnoDB引擎日志。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hd-wallpaper-2836301_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="日志系统">日志系统</h2>
<h3 id="概要">概要</h3>
<p>日志是mysql数据库的重要组成部分，记录着数据库运行期间的各种信息；其中包括错误日志，查询日志，慢查询日志，二进制日志等。</p>
<table>
<thead>
<tr>
<th>日志类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Error log</td>
<td>mysql启动、运行、停止期间发生的问题记录</td>
</tr>
<tr>
<td>General query log</td>
<td>客户端建立连接以及期间发生的所有sql操作</td>
</tr>
<tr>
<td>Slow query log</td>
<td>记录执行时间过长或没有使用索引的查询语句</td>
</tr>
<tr>
<td>Binary log</td>
<td>记录数据库的变动操作，如insert，create，alert等语句，所以该日志也可用于主从复制。</td>
</tr>
<tr>
<td>Relay log</td>
<td>中继日志一般用于接受复制源的数据变动（主从复制时会用到）</td>
</tr>
<tr>
<td>DDL log (metadata log)</td>
<td>记录了执行DDL语句的元数据操作</td>
</tr>
<tr>
<td>Engine log</td>
<td>引擎会有自己的额外日志</td>
</tr>
</tbody>
</table>
<h3 id="错误日志">错误日志</h3>
<p>错误日志包含了数据库启动和宕机时的记录；除此之外，它还包含服务启动、运行、宕机时的一些诊断性日志如errors,warnings和notes等。</p>
<p>一般情况下，错误日志有助于检查数据库运行状态，查看日志文件语句如下：</p>
<pre><code>show variables like '%log_error%';

</code></pre>
<h3 id="查询日志">查询日志</h3>
<p>查询日志记录了mysql服务实例的所有操作，如select,delete,insert等；一般情况，该日志不会被打开，避免造成mysql性能下降。查看该日志文件的语句如下：</p>
<pre><code>show variables like '%general_log%';
</code></pre>
<h3 id="慢查询日志">慢查询日志</h3>
<p>慢查询日志由执行时间超过long_query_time的sql语句组成，且必须有至少min_examined_row_limit行数据被检查过。</p>
<p>慢查询日志可以有效的跟踪执行时间过长或者没有使用索引的查询语句。查看语句如下：</p>
<pre><code>-- 查看日志文件
show variables like '%slow_query_log%';
-- 查看参数值
show variables like '%long_query_time%';
show variables like '%min_examined_row_limit%';

-- log_quries_not_using_indexes 是否将不使用索引的查询语句记录到慢查询日志中，无论查询速度有多快。
SET GLOBAL log_queries_not_using_indexes=ON;
show variables like 'log_queries_not_using_indexes';

-- 如果log_quries_not_using_indexes处于开启状态，那么mysql还提供了log_throttle_queries_not_using_indexes 用来控制每分钟写入多少条数据
show variables like 'log_throttle_queries_not_using_indexes';

-- 日志的输出格式，FILE或者table
show variables like 'log_output';

</code></pre>
<h3 id="中继日志">中继日志</h3>
<p>中继日志一般用于主从复制，基本结构与binlog一致。</p>
<h3 id="元数据日志">元数据日志</h3>
<p>元数据日志记录了通过数据库定义的能够影响表分区的语句操作，例如： ALTER TABLE t3 DROP PARTITION p2；mysql必须确保分区被完全移除，且该分区位于table t3的分区列表中的定义也被移除。为了防止在移除分区操作时机器宕机导致的移除失败，元数据日志便诞生了，因为其记录了具体的语句操作，mysql完全可以根据这些语句重新进行移除操作。</p>
<h3 id="二进制日志">二进制日志</h3>
<p>二进制日志记录了对mysql数据库执行更新的所有操作，需要注意的是不包括查询类操作，如select，show等；同时，某些操作本身可能并未对数据库进行修改，但这些操作仍然会被写入二进制日志，如update一条不存在的数据（update t set a=1 where a=2）。</p>
<pre><code>-- 查看二进制日志是否开启，默认情况下是关闭的
show variables like '%log_bin%';

</code></pre>
<h4 id="作用">作用</h4>
<p>二进制日志的具体用途如下：</p>
<ul>
<li>恢复(recovery)：二进制日志包含数据所有的更新操作，一旦数据库宕机，完全可以根据二进制日志进行备份恢复。如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。</li>
<li>复制(replication)：一般与relay log配合使用，进行主从复制操作。</li>
<li>审计(audit)：可以检查该日志来判断是否有注入攻击。</li>
</ul>
<h4 id="配置">配置</h4>
<p>二进制日志默认是关闭状态，需要手动配置才能开启。mysql配置文件为/etc/my.cnf，使用vim编辑该文件，键入如下内容：</p>
<pre><code># binlog
# 指明存储文件位置
log-bin=/temp/mysql-bin.log
# 设置binlog清理时间
expire-logs-days=14
# 每个文件的大小
max-binlog-size=512M
# mysql集群的服务id
server-id=1

</code></pre>
<pre><code># 参数说明
log_bin：设置此参数表示启用binlog功能，并指定路径名称

log_bin_index：设置此参数是指定二进制索引文件的路径与名称

expire-logs-days：设置binlog清理时间（手动清理：purge master logs before '2010-02-16 00:00:00';）

binlog_do_db：此参数表示只记录指定数据库的二进制日志

binlog_ignore_db：此参数表示不记录指定的数据库的二进制日志

max_binlog_cache_size：此参数表示binlog使用的内存最大的尺寸

binlog_cache_size：此参数表示binlog使用的内存大小，可以通过状态变量binlog_cache_use和binlog_cache_disk_use来帮助测试。
binlog_cache_use：使用二进制日志缓存的事务数量
binlog_cache_disk_use:使用二进制日志缓存但超过binlog_cache_size值并使用临时文件来保存事务中的语句的事务数量

max_binlog_size：Binlog最大值，最大和默认值是1GB，该设置并不能严格控制Binlog的大小，尤其是Binlog比较靠近最大值而又遇到一个比较大事务时，
为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的所有SQL都记录进当前日志，直到事务结束

</code></pre>
<pre><code># binlog刷盘策略参数配置
sync_binlog：这个参数直接影响mysql的性能和完整性
sync_binlog=0：当事务提交后，Mysql仅仅是将binlog_cache中的数据写入Binlog文件，但不执行fsync操作，而是让Filesystem自行决定什么时候来做同步。此模式相对来说性能最高，但不安全，宕机时容易丢失数据。
sync_binlog=1：每次事务提交时，都将binlog刷入磁盘。此模式最安全，但性能相对偏低。
sync_binlog=n：在进行n次事务提交以后，Mysql将执行一次fsync之类的磁盘同步指令，通知文件系统将Binlog文件缓存刷新到磁盘。如果容许出现数据丢失，可以适当的提高此设置值来获取更好的性能。

</code></pre>
<h4 id="格式">格式</h4>
<p>mysql5.1版本开始引入了额外的binlog格式参数，分别为：STATEMENT，ROW，MIXED。</p>
<pre><code>-- 查看binlog格式
show variables like '%binlog_format%';
</code></pre>
<ul>
<li>STATEMENT：记录的是逻辑SQL语句，即所有的数据库更新操作。该模式下日志量相对ROW会更少，节省了IO及存储资源，性能相对有所提高。注意：在RC(Read committed，读已提交)隔离级别下，此模式会导致主从复制数据不一致问题（例如：一条删除语句与一条新增语句在两个session中提交，最终master可能是先删除后新增，但slave库复制时可是先新增后删除，导致数据不一致）。解决方案便是RC选择ROW模式，RR（可重复读有间隙锁防止session执行顺序错乱）选择STATEMENT模式。</li>
<li>ROW：记录表行数据的变更情况，而非单纯的逻辑sql语句。如果binlog格式设置为ROW，那么隔离级别可以设置为RC，以提高并发度；当然随之而来的便是IO及存储资源的增加。</li>
<li>MIXED：默认依旧使用STATEMENT格式，只在某些情况下使用ROW格式；如：NDB引擎，insert delay语句，临时表，自定义函数等。</li>
</ul>
<h3 id="引擎日志">引擎日志</h3>
<p>事务一般都有ACID四个特性，其中隔离性可以通过锁来实现；原子性，一致性，持久性则需要通过日志系统进行保障。以InnoDB为例，redo log保证了持久性，undo log则保证了原子性。</p>
<p>InnoDB架构官网链接：<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html">点击此处跳转官网页面</a></p>
<h4 id="redo-log">redo log</h4>
<p>在mysql中，持久性作为事务四大特性之一，需要确保对数据的修改能够永久地保存下来；如果在每次更新数据时都简单地采用直接刷入磁盘的操作，将会导致整个服务性能变得低下。以InnoDB引擎为例，原因如下：</p>
<ul>
<li>InnoDB引擎与磁盘进行交互的基本单位是数据页，一次事务操作可能只修改了几个字节，这个时候将整个数据页刷入磁盘，将会浪费大量的资源。</li>
<li>一个事务操作可能涉及多个不同的数据页，且当这些数据页在磁盘上不连续时，写入性能也将变得很差（随机IO多了寻址(seek)步骤）</li>
</ul>
<p>于是，InnoDB引擎设计了redo log专门记录着事务操作引起的数据变化，确切地说是记录了事务操作对数据页做了哪些修改。</p>
<p>这个日志与磁盘配合的整个过程，在MySQL中被称之为WAL(Write-Ahead Logging，预写式技术)；WAL会先将记录写入日志，然后在系统空闲的时候或者按照设定的更新策略进行刷磁盘操作(刷脏页，fsync)。</p>
<h5 id="redo-log记录形式">redo log记录形式</h5>
<p>redo log本身只记录数据页的变更，且采用了大小固定，循环写入的实现方案进行log记录。为了实现循环写入，redo log中设置了两个标志位：checkpoint 和 write pos。</p>
<ul>
<li>write pos 表示redo log当前记录的LSN(log sequence number,日志序列号：日志空间中每条日志的结束点，用字节偏移量表示)，即记录写入位置。</li>
<li>checkpoint 表示脏页（缓存中的数据页被称为脏页）刷盘后对应的redo log所处的LSN，即记录擦除位置。</li>
</ul>
<p>在进行log记录时，如果write pos追上了checkpoint，那么就表示redo log已经写满了；此时需要停止写入，并运行checkpoint规则进行刷磁盘操作（先更新内存，再将buffer中的脏数据（缓存中的数据被称为脏数据）fsync到磁盘）。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306004.png" alt="img" loading="lazy"></figure>
<h5 id="redo-log刷磁盘">redo log刷磁盘</h5>
<p>redo log包含两个核心部分，分别是内存中的日志缓冲(redo log buffer)以及磁盘上的日志文件(redo log file)。当执行一条更新sql时，数据会先写入redo log buffer，之后再写入redo log file。</p>
<p>在计算机操作系统中，用户空间(user space)下的缓存区数据是无法直接写入磁盘的，一般都需要经过内核空间(kernel space)的缓存区(OS Buffer)，之后才能真正写入磁盘。具体流程图如下所示：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306005.png" alt="" loading="lazy"></figure>
<p>在InnoDB中有一个配置参数可以用来控制日志的刷新频率：innodb_flush_log_at_trx_commit。</p>
<table>
<thead>
<tr>
<th>参数值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>0（延时写）</td>
<td>事务提交之后，日志只记录到 log buffer 中，之后每秒写一次日志到缓存（OS Buffer）并刷新（fsync）到磁盘，尚未刷新的日志可能会丢失。</td>
</tr>
<tr>
<td>1（实时写，实时刷）</td>
<td>事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。</td>
</tr>
<tr>
<td>2（实时写，延时刷）</td>
<td>每次事务提交之后，日志写到 OS Buffer，每秒刷一次到磁盘，尚未刷新的日志可能会丢失。</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306007.png" alt="img" loading="lazy"></figure>
<h5 id="redo-log与binlog">redo log与binlog</h5>
<p>binlog是mysql服务共有的日志文件，而redo log则是InnoDB独有的日志文件。同时，redo log是基于crash recovery，保证MySQL宕机后的数据恢复（crash-safe）；而binlog是基于point-in-time recovery，保证服务器可以基于时间点对数据进行恢复，或者对数据进行备份。</p>
<p>注意：单纯的binlog日志系统是不具备crash-safe功能的，因为binlog一般只能提供归档功能（记录了对mysql数据库执行更新的所有操作）。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306008.png" alt="img" loading="lazy"></figure>
<p>以InnoDB引擎对update table set b = 2 where a = 1语句操作为例，其中都会涉及redo log日志和binlog日志，具体流程如下：</p>
<ol>
<li>查询 a=1 这一行。如果 a=1 这一行所在的数据页本来就在内存中，便直接返回；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>修改 a=1 这行的b为2，并写入新行。</li>
<li>引擎将这行新数据更新到内存（InnoDB Buffer Pool）中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。</li>
<li>sql语句写入 binlog，并把 binlog 刷入磁盘（依据配置的刷盘机制）。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306009.png" alt="img" loading="lazy"></figure>
<h4 id="undo-log">undo log</h4>
<p>回滚日志主要是为了保证数据库事务的原子性，当一个事务对数据库进行修改时，InnoDB引擎不仅会记录redo log，还会生成对应的undo log日志；当事务执行失败或者调用rollback时，便可以利用undo log将数据回滚到修改之前的样子。</p>
<p>关于 undo Log 的存储：InnoDB 中有回滚段(rollback segment)，每个回滚段记录 1024 个 undo log segment，在每个 undo log segment 段中进行申请 undo 页。系统表空间偏移量为 5 的页记录了所有的 rollback segment header 所在的页。</p>
<p>undo log有两个作用：一是提供回滚，二是实现MVCC；两种格式：insert undo log（记录插入对应的回滚日志） 和 update undo log（记录更新和删除对应的回滚日志）。</p>
<p>undo log详解可参考：<a href="http://mysql.taobao.org/monthly/2021/10/01/">点击此处跳转页面</a></p>
<h4 id="innodb故障恢复">InnoDB故障恢复</h4>
<p>由上小节可知，InnoDB事务处理采用的是二阶段提交，因此故障恢复也将依据二阶段进行。</p>
<p>注意1：binlog的完整性依据不同的日志格式而不同，STATEMENT格式为COMMIT，而ROW格式最后一行会有一个XID event，且5.6.2版本后，mysql还新增了binlog-checknum用于验证binlog的完整性。</p>
<p>注意2：redo log与binlog有一个共同的数据字段：XID。</p>
<ol>
<li>数据库启动后，InnoDB引擎会根据redo log寻找最近的一次checkpoint位置，随后根据checkpoint对应的LSN(log sequence number,日志序列号)获取需要重做的日志。</li>
<li>根据redo log回滚未prepared和commit的事务，但对于已经prepared，但未commit的事务，暂时挂起，将其保存到一个链表中。</li>
<li>mysql读取最后一个binlog文件。binlog文件通常是以固定的文件名加一组连续的编号来命名的，并且将其记录到一个binlog索引文件中，因此索引文件中的最后一个binlog文件即是MySQL将要读取的最后一个binlog文件。</li>
<li>如果binlog中记录了上次mysql为异常关闭（文件头是否存在标记LOG_EVENT_BINLOG_IN_USE_F），则依次读取binlog中所有的log event，并将所有已提交事务的xid取出归总到一个列表；同时，定位出最后一个完整事务的位置。</li>
<li>遍历第二步中的列表，判断其是否在第四步中的提交事务列表中，如果是，则提交此事务；否则回滚。</li>
<li>将最后一个完整事务位置之后的binlog清除，到此故障恢复便已全部完成。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL架构与EXPLAIN与锁]]></title>
        <id>https://philosopherzb.github.io/post/mysql-jia-gou-yu-explain-yu-suo/</id>
        <link href="https://philosopherzb.github.io/post/mysql-jia-gou-yu-explain-yu-suo/">
        </link>
        <updated>2022-03-05T02:51:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述MySQL架构组件，EXPLAIN语法分析以及各类锁细节。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sea-164989_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="mysql架构">MySQL架构</h2>
<h3 id="架构图">架构图</h3>
<h4 id="国外架构图">国外架构图</h4>
<p>图片文章链接：<a href="https://www.rathishkumar.com/2016/04/understanding-mysql-architecture.html">点击此处跳转页面</a></p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306001.png" alt="" loading="lazy"></figure>
<h4 id="国内架构图">国内架构图</h4>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306002.png" alt="img" loading="lazy"></figure>
<h3 id="架构层说明">架构层说明</h3>
<h4 id="客户端层">客户端层</h4>
<p>mysql是一个标准的cs(client-server)服务器，请求一般由客户主动发起，包括但不限于java，python，php等。</p>
<h4 id="服务端层">服务端层</h4>
<p>服务层包含了mysql所有的核心功能，具体可分为如下几种：</p>
<ul>
<li>连接器(Connection Pool)：维护客户端与服务端的连接，认证连接账号密码，确认连接账号的权限。</li>
<li>查询缓存(Query Cache)：缓存了select语法的结果集，如果命中了缓存则直接返回数据给客户端。注意：mysql8此功能已弃用。</li>
<li>分析器(Parser)：对即将执行的sql进行分析，包括词法分析(Lexical analysis，判断从字节流生成的单词或标识是否符合规范)和语法分析(Syntactic analys，确保语句符合sql规范)；同时，会创建一个内部的parse-tree结构。</li>
<li>优化器(Optimizer)：针对内部的parse-tree，mysql可以应用多种优化技术，如重写查询，扫描表的顺序以及选择合适的索引使用等。可以用explain查看分析优化结果。</li>
</ul>
<h4 id="引擎层">引擎层</h4>
<p>mysql提供给可插拔式的引擎技术，可根据不同的业务选择不同的引擎。</p>
<h4 id="存储层">存储层</h4>
<p>实际的物理存储介质。</p>
<h3 id="explain语句">EXPLAIN语句</h3>
<p>explain可以与select，delete，insert，replace以及update语句一同使用，结果会显示来自优化器（Optimizer）的有关语句执行计划的信息。</p>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html">点击此处跳转官网页面</a></p>
<p>explain输出格式参数如下所示：</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>JSON Name</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>select_id</td>
<td>select 标识符</td>
</tr>
<tr>
<td>select_type</td>
<td>None</td>
<td>select 类型</td>
</tr>
<tr>
<td>table</td>
<td>table_name</td>
<td>输出行对应的表名</td>
</tr>
<tr>
<td>partitions</td>
<td>partitions</td>
<td>匹配的分区</td>
</tr>
<tr>
<td>type</td>
<td>access_type</td>
<td>连接/访问类型</td>
</tr>
<tr>
<td>possible_keys</td>
<td>possible_keys</td>
<td>可供选择的匹配索引</td>
</tr>
<tr>
<td>key</td>
<td>key</td>
<td>实际匹配的索引</td>
</tr>
<tr>
<td>key_len</td>
<td>key_length</td>
<td>所选key的长度</td>
</tr>
<tr>
<td>ref</td>
<td>ref</td>
<td>与索引比较的列</td>
</tr>
<tr>
<td>rows</td>
<td>rows</td>
<td>预计要检查多少行</td>
</tr>
<tr>
<td>filtered</td>
<td>filtered</td>
<td>通过表条件过滤的行百分比</td>
</tr>
<tr>
<td>Extra</td>
<td>None</td>
<td>额外信息</td>
</tr>
</tbody>
</table>
<h4 id="idjson-name-select_id">id(JSON name: select_id)</h4>
<p>select 标识符，是一次查询中select的序列号。当行引用了另一行的联合结果时，此值可以为NULL。当然，它也可以显示联合行的结果，格式类似于：union M,N。其中M，N表示不同的行。</p>
<h4 id="select_typejson-name-none">select_type(JSON name: None)</h4>
<p>select类型，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>select_type Value</th>
<th>JSON Name</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIMPLE</td>
<td>None</td>
<td>简单查询（未使用联合查询及子查询）</td>
</tr>
<tr>
<td>PRIMARY</td>
<td>None</td>
<td>多层查询时，外层查询将被标记为primary（如两表做UNION或者存在子查询的外层的表操作为PRIMARY，内层的操作为UNION）</td>
</tr>
<tr>
<td>UNION</td>
<td>None</td>
<td>UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句没有依赖关系）</td>
</tr>
<tr>
<td>DEPENDENT UNION</td>
<td>dependent (true)</td>
<td>UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句有依赖关系）</td>
</tr>
<tr>
<td>UNION RESULT</td>
<td>union_result</td>
<td>union查询结果</td>
</tr>
<tr>
<td>SUBQUERY</td>
<td>None</td>
<td>子查询</td>
</tr>
<tr>
<td>DEPENDENT SUBQUERY</td>
<td>dependent (true)</td>
<td>依赖于外部查询的子查询</td>
</tr>
<tr>
<td>DERIVED</td>
<td>None</td>
<td>衍生表</td>
</tr>
<tr>
<td>DEPENDENT DERIVED</td>
<td>dependent (true)</td>
<td>依赖于另一张表的衍生表</td>
</tr>
<tr>
<td>MATERIALIZED</td>
<td>materialized_from_subquery</td>
<td>物化子查询</td>
</tr>
<tr>
<td>UNCACHEABLE SUBQUERY</td>
<td>cacheable (false)</td>
<td>对于外层的主表，子查询不可被物化，每次都需要计算（耗时操作）</td>
</tr>
<tr>
<td>UNCACHEABLE UNION</td>
<td>cacheable (false)</td>
<td>UNION操作中，内层的不可被物化的子查询（类似于UNCACHEABLE SUBQUERY）</td>
</tr>
</tbody>
</table>
<h4 id="tablejson-name-table_name">table(JSON name: table_name)</h4>
<p>输出行所引用的表。除此之外，它还包括联合查询：union M,N（表示连表查询）；衍生表：derived M（M表的衍生结果，例如子查询的from结果）；子查询：subquery M（M表的子查询结果）。</p>
<h4 id="typejson-name-access_type">type(JSON name: access_type)</h4>
<p>表的连接查询方式，性能从高到低如下表所示：</p>
<table>
<thead>
<tr>
<th>type value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>system</td>
<td>表中只有一行，算是一种特殊的const连接类型</td>
</tr>
<tr>
<td>const</td>
<td>单表中最多有一个匹配行，一般是primary key 或者 unique index的检索</td>
</tr>
<tr>
<td>eq_ref</td>
<td>多表连接中被驱动表的连接列上有primary key或者unique index的检索</td>
</tr>
<tr>
<td>ref</td>
<td>与eq_ref类似，但不是使用primary key或者unique index，而是普通索引。也可以是单表上non-unique索引检索</td>
</tr>
<tr>
<td>fulltext</td>
<td>使用FULLTEXT索引执行连接</td>
</tr>
<tr>
<td>ref_or_null</td>
<td>与ref类似，区别在于条件中包含对NULL的查询</td>
</tr>
<tr>
<td>index_merge</td>
<td>索引合并优化，利用一个表里的N个索引查询,key包含索引列表，key_len则表示这些索引键的最长长度。</td>
</tr>
<tr>
<td>unique_subquery</td>
<td>in的后面是一个查询primary key\unique字段的子查询，即子查询中使用eq_ref类型查询。</td>
</tr>
<tr>
<td>index_subquery</td>
<td>in的后面是一个查询普通index字段的子查询，即子查询中使用了ref类型查询。</td>
</tr>
<tr>
<td>range</td>
<td>单表索引中的范围查询,使用索引查询出单个表中的一些行数据。ref列会变为null</td>
</tr>
<tr>
<td>index</td>
<td>等于ALL。它有两种情况：(1)覆盖索引（Extra列会显示 Using index） (2)用索引的顺序做一个全表扫描。</td>
</tr>
<tr>
<td>all</td>
<td>全表扫描</td>
</tr>
</tbody>
</table>
<pre><code>-- 样例
-- const
SELECT * FROM tbl_name WHERE primary_key=1;
SELECT * FROM tbl_name
  WHERE primary_key_part1=1 AND primary_key_part2=2;

-- eq_ref
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref
SELECT * FROM ref_table WHERE key_column=expr;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref_or_null
SELECT * FROM ref_table
  WHERE key_column=expr OR key_column IS NULL;
  
-- unique_subquery
value IN (SELECT primary_key FROM single_table WHERE some_expr)  

-- index_subquery
value IN (SELECT key_column FROM single_table WHERE some_expr)

-- range
SELECT * FROM tbl_name
  WHERE key_column = 10;
SELECT * FROM tbl_name
  WHERE key_column BETWEEN 10 and 20;
SELECT * FROM tbl_name
  WHERE key_column IN (10,20,30);
SELECT * FROM tbl_name
  WHERE key_part1 = 10 AND key_part2 IN (10,20,30);

</code></pre>
<h4 id="extrajson-name-none">Extra(JSON name: None)</h4>
<p>包含了mysql解析查询的一些额外信息。</p>
<table>
<thead>
<tr>
<th>type value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backword index scan</td>
<td>优化器可以在InnoDB引擎中使用降序索引，一般与Using index一同出现</td>
</tr>
<tr>
<td>const row not found</td>
<td>所要查询的表为空</td>
</tr>
<tr>
<td>Distinct</td>
<td>mysql正在查询distinct值，因此当它查到匹配行后便会停止继续搜索更多行。</td>
</tr>
<tr>
<td>impossible HAVING</td>
<td>having条件总为false，且无法搜索到任何行</td>
</tr>
<tr>
<td>Impossible WHERE</td>
<td>where条件总为false，且无法搜索到任何行</td>
</tr>
<tr>
<td>Impossible WHERE noticed after reading const tables</td>
<td>mysql读取所有的const（及system）表之后，发现where条件均不满足（即where条件为false）</td>
</tr>
<tr>
<td>no matching row in const table</td>
<td>对于一个连接查询，结果是一个空表或者没有一条满足唯一索引条件的行。</td>
</tr>
<tr>
<td>Not exists</td>
<td>优化器发现内表记录不可能满足where条件（left join，如：SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL;）</td>
</tr>
<tr>
<td>Using filesort</td>
<td>MySQL 必须执行额外的检查以找出如何按排序顺序检索行。排序是通过根据连接类型遍历所有行并存储排序键和指向与WHERE子句匹配的所有行的指针来完成的。然后对键进行排序，并按排序顺序检索行</td>
</tr>
<tr>
<td>Using index</td>
<td>使用索引树中的信息从表中检索列信息，无须额外操作。（覆盖索引）</td>
</tr>
<tr>
<td>Using index for group-by</td>
<td>与Using index类似，对于group by列或者distinct列，可以利用索引检索出数据，而不需要去表里查数据、分组、排序、去重等等</td>
</tr>
<tr>
<td>Using join buffer</td>
<td>之前的表连接在nested loop之后放进join buffer，再来和本表进行join。</td>
</tr>
<tr>
<td>Using sort_union,using union,using intersect</td>
<td>index_merge的三种情况</td>
</tr>
<tr>
<td>Using temporary</td>
<td>使用了临时表来存储中间结果集，适用于group by，distinct，或order by列为不同表的列。</td>
</tr>
<tr>
<td>Using where</td>
<td>在存储引擎层检索出记录后，在server利用where条件进行过滤，并返回给客户端</td>
</tr>
</tbody>
</table>
<h2 id="mysql锁">MySQL锁</h2>
<h3 id="隔离级别">隔离级别</h3>
<table>
<thead>
<tr>
<th>Isolation Level（隔离级别）</th>
<th>Dirty Reads（脏读）</th>
<th>Non-Repeatable Reads（不可重复读）</th>
<th>Phantom Reads（幻读）</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read uncommitted（读未提交）</td>
<td>允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>Read committed(Sql server, Oracle)（读已提交）</td>
<td>不允许</td>
<td>允许</td>
<td>允许</td>
</tr>
<tr>
<td>Repeatable reads(Mysql)（可重复读）</td>
<td>不允许</td>
<td>不允许</td>
<td>允许</td>
</tr>
<tr>
<td>Serializable（串行化）</td>
<td>不允许</td>
<td>不允许</td>
<td>不允许</td>
</tr>
</tbody>
</table>
<ul>
<li>Dirty reads：脏读，A事务可以读到B事务还未提交的数据。</li>
<li>Non-repeatable read：不可重复读，A事务读取一行数据，B事务后续修改了这行数据，A事务再次读取这行数据，结果得到的数据不同。</li>
<li>Phantom reads：幻读，A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者删除已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次多/少了一些行。</li>
</ul>
<p>注意1：mysql默认使用RR隔离级别，这是由于binlog的格式问题（statement-记录修改的SQL语句,row-记录每行实际数据的变更,mixed-前面两种混合）所导致的，在5.0之前binlog只有statement一种格式，而主从复制时，这会导致数据的不一致。</p>
<p>注意2：其他数据库选用RC隔离级别，是由于RR隔离级别增加了间隙锁，会增加发生死锁的概率；同时，条件列未命中索引时，会锁全表，RC只会锁行。</p>
<p>注意3：RC隔离级别下，主从复制需要采用binlog的row格式，基于行的复制，这样不会出现主从不一致问题。</p>
<h3 id="锁分类">锁分类</h3>
<h4 id="按操作数据的类型">按操作数据的类型</h4>
<ul>
<li>共享锁(读锁，Shared Locks，S锁)：在事务要读取一条记录时，需要先获取该记录的S锁。S锁可以在同一时刻被多个事务同时持有；即多个读事务可以并发的进行，但不允许出现写事务。可以用select ...... lock in share mode;的方式手工加上一把S锁。</li>
<li>独占锁(写锁，排他锁，Exclusive Locks，X锁)：在事务要改动一条记录时，需要先获取该记录的X锁。X锁在同一时刻最多只能被一个事务持有；即当前写事务进行时，不允许其他读事务与写事务出现。X锁的加锁方式有两种，第一种是自动加锁，在对数据进行增删改的时候，都会默认加上一个X锁；还有一种是手工加锁，可以用一个FOR UPDATE给一行数据加上一个X锁。</li>
</ul>
<h4 id="按操作数据的粒度">按操作数据的粒度</h4>
<p>粒度：指数据仓库的数据单位中保存数据的细化或综合程度的级别。细化程度越高，粒度级就越小；相反，细化程度越低，粒度级就越大。</p>
<p>在数据库中为了获取更高的并发度，每次锁定的数据范围越小越好，即锁粒度越低越好。理论上来说，如果只锁定当前操作数据将会获得最大的并发度。</p>
<p>值得注意的是锁的管理也是需要耗费额外资源。</p>
<ul>
<li>表级锁(table-level locking)：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）。一般适合查询为主并带有少量更新（读多写少）的应用场景。</li>
<li>行级锁(row-level locking)：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）。一般适合大量并发更新并带有少量查询（写多读少）的应用场景。</li>
<li>页级锁(page-level locking)：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般（BDB存储引擎支持页级锁，也支持表级锁）。</li>
</ul>
<h4 id="按思想维度">按思想维度</h4>
<ul>
<li>乐观锁(Optimistic Lock)：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会根据版本号（一般情况是版本号，也可以使用时间戳等其他控制条件）判断一下在此期间别人有没有去更新这个数据。乐观锁适用于多读的应用类型，这样可以提高吞吐量。</li>
<li>悲观锁(Pessimistic Lock)：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，排他锁等，都是在做操作之前先上锁。</li>
</ul>
<h3 id="innodb引擎锁">InnoDB引擎锁</h3>
<p>作为mysql服务的默认引擎，其中的锁机制自然也是值得深究的。</p>
<p>查看表锁争用情况语句：show status like 'Table%';</p>
<p>查看引擎状态语句：SHOW ENGINE engine_name {STATUS | MUTEX}；例如：SHOW ENGINE INNODB STATUS</p>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html">点击此处跳转官网页面</a></p>
<h4 id="innodb表级锁">InnoDB表级锁</h4>
<ul>
<li>自增锁(AUTO-INC Locks)：是一种特殊的表级锁，它仅针对拥有AUTO_INCREMENT行的表。为了保证自增键数据的连续性，每次插入数据的时候，都会给该表加上一个自增锁，直到前一个事务执行成功，后一个事务才能执行。可以通过innodb_autoinc_lock_mode变量指定自增锁模式。</li>
<li>意向共享锁(intention shared lock，IS锁)：表明一个事务试图给表中的各个行设置共享锁；如果另一个事务要给数据行设置共享锁，则需先获取该行所在的表的IS锁；select ... for share可以设置IS锁。</li>
<li>意向独占锁(intention exclusive lock，IX锁)：表明一个事务试图给表中的各个行设置独占锁；如果另一个事务要给数据行设置独占锁，则需先获取该行所在的表的IX锁；select ... for update可以设置IX锁。</li>
</ul>
<p>关于各级别锁的兼容情形如下表所示（如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放）：</p>
<table>
<thead>
<tr>
<th></th>
<th>X</th>
<th>IX</th>
<th>S</th>
<th>IS</th>
</tr>
</thead>
<tbody>
<tr>
<td>X</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
<td>冲突</td>
</tr>
<tr>
<td>IX</td>
<td>冲突</td>
<td>兼容</td>
<td>冲突</td>
<td>兼容</td>
</tr>
<tr>
<td>S</td>
<td>冲突</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
</tr>
<tr>
<td>IS</td>
<td>冲突</td>
<td>兼容</td>
<td>兼容</td>
<td>兼容</td>
</tr>
</tbody>
</table>
<h4 id="innodb行级锁">InnoDB行级锁</h4>
<p>InnoDB中的行级锁是通过锁定索引来实现的，这意味着只有通过索引条件进行检索的语句才会被施加行级锁，否则将使用表级锁。</p>
<p>注意：只有当执行计划真正使用了索引（用explain分析），才会施加行级锁；多个不同的session如果使用了同一个索引键，将会出现锁冲突场景。</p>
<p>聚集索引：一般是主键；如果主键不存在则使用不为空的唯一索引；如果主键和非空唯一索引都不存在，将会使用InnoDB引擎内置的6字节rowId（名称：GEN_CLUST_INDEX）。</p>
<h5 id="记录锁">记录锁</h5>
<p>记录锁(Record Locks)：使用精确匹配(=)锁定一个索引记录，例如：select c1 from t where c1 = 10 for update;锁定成功后，将不允许其他事务对该条记录进行修改删除操作。</p>
<p>值得注意的是，记录锁实际锁定的是索引（主键索引，唯一索引，普通索引，联合索引等），即使表并没有定义索引（对于这种情况，InnoDB会创建一个隐式的聚集索引并使用该索引来进行记录锁定）。</p>
<p>通过主键索引或唯一索引对数据进行update操作时，会自动对该行数据添加记录锁。例如：update t_test set test_name = 'demo_name' where id = 1;</p>
<h5 id="间隙锁">间隙锁</h5>
<p>间隙锁(Gap Locks)：使用范围匹配(&gt;,&lt;,between等)并请求共享或独占锁时将会锁定一个索引间隙，例如：select c1 from t where c1 between 10 and 30 for update;锁定成功后，在(10,30)之间的c1值将不允许插入。</p>
<p>间隙锁锁定的是一个不包括边界的区间，即左开右开区间。</p>
<p>语句：SELECT * FROM table_name WHERE id = 100 FOR UPDATE;如果id不是索引，则会触发间隙锁，将100之前的区间锁定(验证时更新id=100的数据同样会被阻塞)。</p>
<p>很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，应该尽量优化业务逻辑，使用相等条件来访问更新数据，避免使用范围条件。</p>
<p>注意：间隙锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，间隙锁可以预防幻读。</p>
<h5 id="临键锁">临键锁</h5>
<p>临键锁(Next-Key Locks)：临键锁是记录锁和间隙锁的组合。也可以称之为特殊的间隙锁，它的锁定范围是索引记录及之前的间隙，是一个左开右闭区间。</p>
<p>使用范围查询并命中了非唯一索引或非主键索引的record记录，此时锁住的就是临键区间。值得注意的是临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。</p>
<p>假设一个索引值包含10,11,13和20，那么该索引可能的临键锁区间有：(negative infinity, 10]，(10, 11]，(11, 13]，(13, 20]，(20, positive infinity)。</p>
<p>对于最后一个间隙区间，临键锁会锁定索引中最大值以上的间隙。</p>
<p>mysql默认行锁类型就是临键锁(Next-Key Locks)。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-Key Locks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。</p>
<p>注意：临键锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，临键锁可以预防幻读。</p>
<h3 id="innodb-mvcc">InnoDB MVCC</h3>
<p>官网链接：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html">点击此处跳转官网页面</a></p>
<p>InnoDB multiversion concurrency control(MVCC，多版本并发控制)，主要是为了在RC(Read committed)，RR(Repeatable reads)隔离级别下提高数据库并发性能。</p>
<p>InnoDB是一个多版本存储引擎，它会将行变动的老版本信息存储下来用于回滚及并发控制。这种特性是基于undo log日志系统实现的；多版本的信息被存储在undo 表空间一个被称作回滚段(rollback segment)的数据结构中。</p>
<p>当进行并发读写时，InnoDB基于MVCC机制可以达到不加锁的一致性读效果，从而提高并发度；需要注意的是：基于MVCC的读可能会读到老数据，因为快照读会看到在该时间点之前提交的事务所做的更改，而不会看到稍后或未提交的事务所做的更改。</p>
<p>MVCC简单步骤：当一个读事务产生时，它会进行快照读并生成一个读视图(Read View)，随后根据read view中的记录(trx_ids)访问某个表索引上的记录，通过比较trx_id来确定事务可见性，如果不可见就沿着DB_ROLL_PTR往更老的版本寻找匹配数据。</p>
<p>如下图所示，事务R开始需要查询表t上的id为1的记录，R开始时事务I已经提交，事务J还在运行，事务K还没开始，这些信息都被记录在了事务R的ReadView中。事务R从索引中找到对应的这条Record[1, C]，对应的trx_id是K，不可见。沿着Rollptr找到Undo中的前一版本[1, B]，对应的trx_id是J，不可见。继续沿着Rollptr找到[1, A]，trx_id是I可见，返回结果。（此段及图片摘自：<a href="http://mysql.taobao.org/monthly/2021/10/01/">点击此处跳转文章</a>）</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306003.png" alt="img" loading="lazy"></figure>
<h4 id="当前读与快照读">当前读与快照读</h4>
<ul>
<li>当前读：返回的永远是最新的数据，一般通过加锁来实现，例如select ... for update；</li>
<li>快照读：基于MVCC，并由InnoDB多版本存储引擎实现，可以让一个读事务读取多版本中可见的版本数据。</li>
<li>RR级别下快照读：RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的（除了当前事务本身的更新操作），而早于Read View提交的事务所做的修改均是可见。</li>
<li>RC级别下快照读：每次快照读时都会生成一个快照和Read View，这也就是为何可以看到其他事务提交的更新的原因。</li>
</ul>
<h4 id="innodb行内部存储字段">InnoDB行内部存储字段</h4>
<ul>
<li>DB_TRX_ID：6字节，记录了最后一次行插入或更新事务的事务标识。此外，删除在内部也会被视作更新，即在行中的一个特定位上打上已删除标记。</li>
<li>DB_ROLL_PTR：7字节，一般被称作回滚指针，它指向回滚段(rollback segment中的回滚日志记录。</li>
<li>DB_ROW_ID：6字节，行id，随着行新增而自增；如果是由InnoDB自动生成的聚集索引，则索引即为该值；否则，该值不会出现在任何索引中。</li>
</ul>
<h4 id="read-view相关属性">Read View相关属性</h4>
<ul>
<li>m_ids：表示在生成READVIEW时当前系统中活跃的读写事务的事务id列表，活跃的是指当前系统中那些尚未提交的事务。</li>
<li>m_up_limit_id：表示在生成READVIEW时当前系统中活跃的读写事务中最小的事务id，也就是trx_ids中的最小值。</li>
<li>m_low_limit_id：表示生成READVIEW时系统中应该分配给下一个事务的事务id值，由于事务id一般是递增分配的，所以max_trx_id就是trx_ids中最大的那个id再加上1。</li>
<li>m_creator_trx_id：表示生成该READVIEW的事务id，由于只有在对表中记录做改动（增删改）时才会为事务分配事务id，所以在一个读取数据的事务中的事务id默认为0。</li>
</ul>
<h4 id="read-view-可见性判断具体可参见mysql源码">Read View 可见性判断（具体可参见mysql源码）</h4>
<ul>
<li>如果trx_id = m_creator_trx_id，表示当前读事务正在读取被自己修改过的记录，该版本可以被当前事务访问。</li>
<li>如果trx_id &lt; m_up_limit_id，表明生成该版本的事务在当前事务生成READVIEW前已经提交了，所以该版本可以被当前事务访问。</li>
<li>如果trx_id &gt;= m_low_limit_id，表明生成该版本的事务在当前事务生成READVIEW后提交，所以该版本不可被当前事务访问。</li>
<li>如果 trx_id在m_low_limit_id, m_up_limit_id之间，则需要判断trx_id是否在m_ids列表中；如果存在，则表明事务处于活跃状态，此时是不可见的；否则可见。</li>
</ul>
<pre><code>源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/read/read0read.cc
/**
ReadView constructor */
ReadView::ReadView()
    : m_low_limit_id(),
      m_up_limit_id(),
      m_creator_trx_id(),
      m_ids(),
      m_low_limit_no() {
  ut_d(::memset(&amp;m_view_list, 0x0, sizeof(m_view_list)));
  ut_d(m_view_low_limit_no = 0);
}

/**
Opens a read view where exactly the transactions serialized before this
point in time are seen in the view.
@param id		Creator transaction id */

void ReadView::prepare(trx_id_t id) {
  ut_ad(trx_sys_mutex_own());

  m_creator_trx_id = id;

  m_low_limit_no = trx_get_serialisation_min_trx_no();

  m_low_limit_id = trx_sys_get_next_trx_id_or_no();

  ut_a(m_low_limit_no &lt;= m_low_limit_id);

  if (!trx_sys-&gt;rw_trx_ids.empty()) {
    copy_trx_ids(trx_sys-&gt;rw_trx_ids);
  } else {
    m_ids.clear();
  }

  /* The first active transaction has the smallest id. */
  m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id;

  ut_a(m_up_limit_id &lt;= m_low_limit_id);

  ut_d(m_view_low_limit_no = m_low_limit_no);
  m_closed = false;
}

源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/include/read0types.h
/** Check whether the changes by id are visible.
@param[in]	id	transaction id to check against the view
@param[in]	name	table name
@return whether the view sees the modifications of id. */
[[nodiscard]] bool changes_visible(trx_id_t id,
                                 const table_name_t &amp;name) const {
ut_ad(id &gt; 0);

if (id &lt; m_up_limit_id || id == m_creator_trx_id) {
  return (true);
}

check_trx_id_sanity(id, name);

if (id &gt;= m_low_limit_id) {
  return (false);

} else if (m_ids.empty()) {
  return (true);
}

const ids_t::value_type *p = m_ids.data();

return (!std::binary_search(p, p + m_ids.size(), id));
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES7架构原理及选举源码]]></title>
        <id>https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/</id>
        <link href="https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/">
        </link>
        <updated>2022-02-28T07:00:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch架构组件，读写原理，性能优化以及节点选举和选举流程源码。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-1462655_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="原理概述">原理概述</h2>
<h3 id="基础架构图">基础架构图</h3>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303025.png" alt="img" loading="lazy"></figure>
<p>1: Gateway是ES用来存储索引的文件系统。支持多种类型：包括本地文件系统(默认)，分片文件系统，HDFS，S3等。</p>
<p>2: Distributed Lucene Directory指的是Apach Lucene框架。</p>
<p>3: Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块以及River模块（river代表数据从其他存储框架（如：mysql）流入ES）。</p>
<p>4: ES模块之上是 Discovery、Scripting和第三方插件。</p>
<p>5: 再上层是ES的传输模块和JMX.传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX是java的管理框架，用来管理ES应用。</p>
<p>6: 最上层是ES提供给用户的接口，可以通过RESTful接口或定制的SDK和ES集群进行交互。</p>
<h2 id="读写原理">读写原理</h2>
<h3 id="术语介绍">术语介绍</h3>
<p>segment file: 类似于倒排索引，但其中包含的数据结构更丰富（Inverted Index, Stored Fields, Document Values, Cache等）；一组segment集合加上commit point便构成了Lucene中的index（动态索引，可类比Java中的动态数组概念，每个segment便是一个数组，commit point便是ArrayList；也类似于Java1.8的ConcurrentHashMap分段概念）。</p>
<p>commit point: 记录了当前所有可用的segment file文件。数据可被搜索到。</p>
<p>translog: 持久化地记录了所有还没被刷到磁盘的操作，避免宕机时，数据丢失。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。translog 会每隔 5 秒异步执行或者在每一个请求完成之后执行一次 fsync 操作，将 translog 从缓存刷入磁盘，这个操作比较耗时，如果对数据一致性要求不是很高时建议将索引改为 async ，如果节点宕机时会有 5 秒数据丢失;</p>
<p>In-memory buffer: ES中的内存缓存，每当索引数据时，都会将数据先存储到该buffer及translog中。</p>
<p>refresh: 打开或创建一个新的segment的过程，即将数据从内存刷入filesystem cache并清空当前buffer的过程(默认每隔一秒或者buffer满了便会执行该操作)。</p>
<p>merge: refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>flush&amp;commit: 默认每隔30分钟或者translog数据量达到512mb则会触发一次flush操作。此过程会将所有数据刷入硬盘中进行持久化存储。</p>
<h3 id="写操作原理">写操作原理</h3>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303026.png" alt="img" loading="lazy"></figure>
<p>具体步骤如下：</p>
<p>1、数据写入buffer及translog中，此时是搜索不到的。</p>
<p>2、默认每隔一秒或buffer已满，则执行一次refresh操作，将数据刷入filesystem cache生成segment file，此时数据可被搜索，并清空当前的buffer。</p>
<p>3、translog中的数据存储在os cache中，之后默认每隔5秒会持久化到磁盘中（时间可设置，长短将影响性能）。</p>
<p>4、重复上述步骤，直到抵达默认的30分钟或者translog达到512mb时（相关参数可配置），便会触发一次flush操作（commit操作）：该操作首先将buffer中现有的数据refresh到os cache中去，并清空buffer；然后将一个commit point写入磁盘文件，里面标识着这个commit point 对应的所有segment file，同时强行将os cache中目前所有的数据都fsync到磁盘文件中去；最后清空现有 translog日志文件，重启一个新的translog，此时flush操作完成。</p>
<p>额外补充：</p>
<p>5、删除操作，commit的时候会产生一个.del文件，里面将某个doc标记为delete状态（并非实时删除），搜索时会自动过滤掉标记为删除状态的数据。</p>
<p>6、更新操作，将原来的doc标识为delete状态，然后重新写入一条新数据即可。</p>
<p>7、refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似大小的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。</p>
<p>8、数据一致性由translog保证（丢失数据取决于fsync的时间）；副本一致性则是采用的半同步机制，即主分片写成功后，只需一部分数量（quorum）的副本写入成功即可返回。相关配置wait_for_active_shards的默认值为int( (primary + number_of_replicas) / 2 ) + 1</p>
<h3 id="读操作原理">读操作原理</h3>
<p>读过程大体上分为查询与取回两个阶段。</p>
<ol>
<li>查询阶段</li>
<li>当一个搜索请求被发送到某个节点时，该节点就变成协调节点。这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。</li>
<li>首先将广播请求到索引中每一个节点的分片拷贝，查询请求可以被某个主分片或某个副分片处理（这就是为什么更多的副本（当结合更多的硬件）能够增加搜索吞吐率），协调节点将在之后的请求中轮训所有的分片拷贝来分摊负载。</li>
<li>每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列—也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。</li>
<li>协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。</li>
<li>取回阶段</li>
<li>查询过程得到的排序结果，标记出哪些文档是符合要求的，此时仍然需要获取这些文档返回给客户端。</li>
<li>协调节点会辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求；每个分片加载并修饰文档，如果有需要的话，接着返回文档给协调节点</li>
<li>一旦所有的文档都被取回了，协调节点返回结果给客户端。</li>
</ol>
<p>注意1：先查后取的过程支持用 from 和 size 参数分页，但是这是有限制的。要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 number_of_shards * (from + size) 排序文档，来找到被包含在 size 里的文档。</p>
<p>注意2：一般不建议使用深度搜索，这将会耗费大量额外的cpu，内存与带宽（ES默认深度分页限制为10000条，即from + size &lt;=10000）;如果有需要，可以使用scroll进行查询。</p>
<h2 id="性能优化">性能优化</h2>
<h3 id="filesystem-cache">filesystem cache</h3>
<p>由上述写过程原理可知，ES的数据在filesystem cache中便可被搜索到，那么对应的，如果给予filesystem cache更多的机器内存，让它足以容纳下所有的index segment file，相应的查询效率将会获得长足的提高（内存与磁盘查询效率相差巨大）。同时，如果数据量非常之大，那么ES中应该尽量存储doc_id之类的字段，减少大文本存储（大文本存入分布式文件系统中）。</p>
<h3 id="数据预热与冷热分离">数据预热与冷热分离</h3>
<p>某些热点数据，可通过缓存预热系统进行提前查询，让其流入filesystem cache中；同时，对冷热数据进行隔离存储，确保热数据一直在filesystem cache。</p>
<h3 id="合理的文档设计">合理的文档设计</h3>
<p>不要出现复杂性的查询操作，尽量在设计阶段就做一定的冗余，让相关数据在同一个文档中。</p>
<h3 id="避免深度分页">避免深度分页</h3>
<p>就像读过程原理中所描述，过度的深分页查询，会占用大量的cpu，内存与带宽；如果有对应的需求，可通过scroll api进行查询。</p>
<h2 id="节点发现与选举流程源码">节点发现与选举流程源码</h2>
<p>节点启动时，便会开始加入集群；启动函数：org.elasticsearch.node.Node.start()</p>
<pre><code>public Node start() throws NodeValidationException {
    // start after transport service so the local disco is known
    // start before cluster service so that it can set initial state on ClusterApplierService
    discovery.start(); 
    clusterService.start();
    // 服务发现函数
    discovery.startInitialJoin();
}

</code></pre>
<p>查询mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.findMaster()；此处选举id最小的节点是因为es沿用了bully算法。</p>
<pre><code>private DiscoveryNode findMaster() {
    logger.trace(&quot;starting to ping&quot;);
    // 开始ping操作，获取当前集群处于活跃状态的节点信息
    // pingAndWait函数实际上调用了org.elasticsearch.discovery.zen.UnicastZenPing.ping()
    // 它会主动从discovery.seed_hosts配置中读取信息（7.*之前的老版本配置为：discovery.zen.ping.unicast.hosts）
    // 最终返回的节点信息中，包含有master信息
    List&lt;ZenPing.PingResponse&gt; fullPingResponses = pingAndWait(pingTimeout).toList();

    // 将本节点也加入 fullPingResponses 中
    final DiscoveryNode localNode = transportService.getLocalNode();
    assert fullPingResponses.stream().map(ZenPing.PingResponse::node).filter(n -&gt; n.equals(localNode)).findAny().isPresent() == false;
    fullPingResponses.add(new ZenPing.PingResponse(localNode, null, this.clusterState()));

    // filter responses
    // 如果配置了discovery.zen.master_election.ignore_non_master_ping（即：masterElectionIgnoreNonMasters）为true将会过滤出所有的主节点信息
    // 默认为false
    final List&lt;ZenPing.PingResponse&gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);

    // 遍历列表，将节点认为的主节点信息存入activeMasters
    List&lt;DiscoveryNode&gt; activeMasters = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        // We can't include the local node in pingMasters list, otherwise we may up electing ourselves without
        // any check / verifications from other nodes in ZenDiscover#innerJoinCluster()
        if (pingResponse.master() != null &amp;&amp; localNode.equals(pingResponse.master()) == false) {
            activeMasters.add(pingResponse.master());
        }
    }

    // 如果ping过程中发现了具备资格成为master的节点，将其存入masterCandidates 
    List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = new ArrayList&lt;&gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        if (pingResponse.node().isMasterNode()) {
            masterCandidates.add(new ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));
        }
    }

    if (activeMasters.isEmpty()) {
        // 判断是否有足够的候选者，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.hasEnoughMasterNodes()
        if (electMaster.hasEnoughCandidates(masterCandidates)) {
            // 从候选者中选举新的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.electMaster()
            // 选举逻辑比较简单，直接按id排序，随后取出最小id的节点，即为主节点
            final ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);
            logger.trace(&quot;candidate {} won election&quot;, winner);
            return winner.getNode();
        } else {
            // if we don't have enough master nodes, we bail, because there are not enough master to elect from
            logger.warn(
                    &quot;not enough master nodes discovered during pinging (found [{}], but needed [{}]), pinging again&quot;,
                    masterCandidates,
                    electMaster.minimumMasterNodes()
            );
            return null;
        }
    } else {
        assert activeMasters.contains(localNode) == false
                : &quot;local node should never be elected as master when other nodes indicate an active master&quot;;
        // lets tie break between discovered nodes
        // 按id进行二级排序，并返回最小id的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.tieBreakActiveMasters()
        return electMaster.tieBreakActiveMasters(activeMasters);
    }
}

</code></pre>
<p>确认mater节点；对应函数在discovery.startInitialJoin()中；<br>
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster()</p>
<pre><code>// 1.本节点是master
if (transportService.getLocalNode().equals(masterNode)) {
    // 等待足够多的节点加入本节点
    final int requiredJoins = Math.max(0, electMaster.minimumMasterNodes() - 1); // we count as one
    logger.debug(&quot;elected as master, waiting for incoming joins ([{}] needed)&quot;, requiredJoins);
    // masterElectionWaitForJoinsTimeout默认超时时间为30秒，如果超时则直接return
    // 对应函数：org.elasticsearch.discovery.zen.NodeJoinController.waitToBeElectedAsMaster()
    nodeJoinController.waitToBeElectedAsMaster(
        requiredJoins,
        masterElectionWaitForJoinsTimeout,
        new NodeJoinController.ElectionCallback() {
            // 进行master选举
            @Override
            public void onElectedAsMaster(ClusterState state) {
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDone(currentThread);
                }
            }

            // 失败则重新发起加入集群流程
            @Override
            public void onFailure(Throwable t) {
                logger.trace(&quot;failed while waiting for nodes to join, rejoining&quot;, t);
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
                }
            }
        }

    );
}

// NodeJoinController.waitToBeElectedAsMaster()
public void waitToBeElectedAsMaster(int requiredMasterJoins, TimeValue timeValue, final ElectionCallback callback) {
    try {
        // check what we have so far..
        // capture the context we add the callback to make sure we fail our own
        // 检查是否已有requiredMasterJoins的节点数
        synchronized (this) {
            assert electionContext != null : &quot;waitToBeElectedAsMaster is called we are not accumulating joins&quot;;
            myElectionContext = electionContext;
            electionContext.onAttemptToBeElected(requiredMasterJoins, wrapperCallback);
            // 如果节点数已达标，将该节点设置为master
            checkPendingJoinsAndElectIfNeeded();
        }

        try {
            // 超时直接return
            if (done.await(timeValue.millis(), TimeUnit.MILLISECONDS)) {
                // callback handles everything
                return;
            }
        } catch (InterruptedException e) {

        }
    } catch (Exception e) {
        logger.error(&quot;unexpected failure while waiting for incoming joins&quot;, e);
        if (myElectionContext != null) {
            failContextIfNeeded(myElectionContext, &quot;unexpected failure while waiting for pending joins [&quot; + e.getMessage() + &quot;]&quot;);
        }
    }
}

// NodeJoinController.checkPendingJoinsAndElectIfNeeded()
private synchronized void checkPendingJoinsAndElectIfNeeded() {
    // 发布clusterState
    electionContext.closeAndBecomeMaster();
}

// NodeJoinController.closeAndBecomeMaster
public synchronized void closeAndBecomeMaster() {
    innerClose();

    Map&lt;JoinTaskExecutor.Task, ClusterStateTaskListener&gt; tasks = getPendingAsTasks(&quot;become master&quot;);
    final String source = &quot;zen-disco-elected-as-master ([&quot; + tasks.size() + &quot;] nodes joined)&quot;;

    // noop listener, the election finished listener determines result
    tasks.put(JoinTaskExecutor.newBecomeMasterTask(), (source1, e) -&gt; {});
    tasks.put(JoinTaskExecutor.newFinishElectionTask(), electionFinishedListener);
    // 提交更新状态的任务
    masterService.submitStateUpdateTasks(source, tasks, ClusterStateTaskConfig.build(Priority.URGENT), joinTaskExecutor);
}

</code></pre>
<pre><code>// 本节点不是master
// process any incoming joins (they will fail because we are not the master)
// 拒绝其他节点加入，因为本节点不是master
nodeJoinController.stopElectionContext(masterNode + &quot; elected&quot;);

// send join request
// 发送加入master的请求
final boolean success = joinElectedMaster(masterNode);

synchronized (stateMutex) {
    if (success) {
        // currentMasterNode 为空，或者当选的master不是之前选择的节点，进行重试加入
        DiscoveryNode currentMasterNode = this.clusterState().getNodes().getMasterNode();
        if (currentMasterNode == null) {
            // Post 1.3.0, the master should publish a new cluster state before acking our join request. we now should have
            // a valid master.
            logger.debug(&quot;no master node is set, despite of join request completing. retrying pings.&quot;);
            joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
        } else if (currentMasterNode.equals(masterNode) == false) {
            // update cluster state
            joinThreadControl.stopRunningThreadAndRejoin(&quot;master_switched_while_finalizing_join&quot;);
        }

        joinThreadControl.markThreadAsDone(currentThread);
    } else {
        // failed to join. Try again...
        // 失败则重新发起加入集群流程
        joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
    }
}

private boolean joinElectedMaster(DiscoveryNode masterNode) {
    try {
        // first, make sure we can connect to the master
        transportService.connectToNode(masterNode);
    } catch (Exception e) {
        logger.warn(() -&gt; new ParameterizedMessage(&quot;failed to connect to master [{}], retrying...&quot;, masterNode), e);
        return false;
    }
    int joinAttempt = 0; // we retry on illegal state if the master is not yet ready
    while (true) {
        try {
            logger.trace(&quot;joining master {}&quot;, masterNode);
            // joinTimeout 默认超时时间60s，org.elasticsearch.discovery.zen.MembershipAction.MembershipAction()
            membership.sendJoinRequestBlocking(masterNode, transportService.getLocalNode(), joinTimeout);
            return true;
        } catch (Exception e) {
            final Throwable unwrap = ExceptionsHelper.unwrapCause(e);
            if (unwrap instanceof NotMasterException) {
                // joinRetryAttempts 重试次数，默认3次
                if (++joinAttempt == this.joinRetryAttempts) {
                    logger.info(
                        &quot;failed to send join request to master [{}], reason [{}], tried [{}] times&quot;,
                        masterNode,
                        ExceptionsHelper.detailedMessage(e),
                        joinAttempt
                    );
                    return false;
                }
            } else {
                return false;
            }
        }

        try {
            Thread.sleep(this.joinRetryDelay.millis());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}

</code></pre>
<p>由上述步骤总结如下：</p>
<p>1、服务启动后，开始进行加入集群操作；</p>
<p>2、调用ping命令，最终获取一个包含节点基本信息及其所认为的master信息的列表（包括本节点）；</p>
<p>3、过滤结果列表，将master节点汇总到activeMasters，将master候选者节点汇总到masterCandidates；</p>
<p>4、判断如果activeMasters不为空，则从activeMasters中选择最小ID的一个节点；否则从candidateMasters中选择，先判断是否有足够的候选者，之后再排序选择ID最小的一个节点作为新的master；</p>
<p>5、投票阶段，每个节点都向自己认为的master进行joinRequest请求,对应的会产生如下两种情形：</p>
<ul>
<li>本节点是master：该节点统计发送过来的joinRequest个数，如果在指定的时间（默认30s，可配置）内达到requiredJoins个数，则发布集群信息，并回复joinRequest请求，最后完成选举，否则选举失败；</li>
<li>本节点不是master：首先，拒绝其他节点的joinRequest，其次向该节点认为的master发送joinRequest请求，并等待，如果在指定的时间（60s，可配置）未收到回复或异常重试3次都失败了则选举失败，之后将重新发起加入集群流程；否则如果收到的回复中没有master信息或者master信息不是之前选择的临时master节点则选举失败，同样会进行重新加入操作。</li>
</ul>
<p>注意：es使用延迟选举解决了选举过程中不断出现master假死现象（即master由于负载过重而假死，随后第二小id的节点成为master，之后故障节点又恢复再次被选为master，接着又假死...如此循环）；同时，es增加了法定得票人数机制，解决了脑裂（split-brain）问题。</p>
<p>脑裂指的是集群中出现多个主节点，导致集群割裂的一种异常情况。</p>
<p>法定个数：有master资格的节点数（官方建议）：n/2 + 1；其中n为有资格成为主节点的节点数。</p>
<pre><code>// 7.*版本后，discovery.zen.minimum_master_node已不再提供配置，而是由内置的代码处理
private void commonNodeConfig(ElasticsearchNode node, String nodeNames, ElasticsearchNode firstNode) {
    if (node.getVersion().onOrAfter(&quot;7.0.0&quot;)) {
        node.defaultConfig.keySet()
            .stream()
            .filter(name -&gt; name.startsWith(&quot;discovery.zen.&quot;))
            .collect(Collectors.toList())
            .forEach(node.defaultConfig::remove);
        if (nodeNames != null &amp;&amp; node.settings.getOrDefault(&quot;discovery.type&quot;, &quot;anything&quot;).equals(&quot;single-node&quot;) == false) {
            node.defaultConfig.put(&quot;cluster.initial_master_nodes&quot;, &quot;[&quot; + nodeNames + &quot;]&quot;);
        }
        node.defaultConfig.put(&quot;discovery.seed_providers&quot;, &quot;file&quot;);
        node.defaultConfig.put(&quot;discovery.seed_hosts&quot;, &quot;[]&quot;);
    } else {
        node.defaultConfig.put(&quot;discovery.zen.master_election.wait_for_joins_timeout&quot;, &quot;5s&quot;);
        if (nodes.size() &gt; 1) {
            node.defaultConfig.put(&quot;discovery.zen.minimum_master_nodes&quot;, Integer.toString(nodes.size() / 2 + 1));
        }
        if (node.getVersion().onOrAfter(&quot;6.5.0&quot;)) {
            node.defaultConfig.put(&quot;discovery.zen.hosts_provider&quot;, &quot;file&quot;);
            node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
        } else {
            if (firstNode == null) {
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[]&quot;);
            } else {
                firstNode.waitForAllConditions();
                node.defaultConfig.put(&quot;discovery.zen.ping.unicast.hosts&quot;, &quot;[\&quot;&quot; + firstNode.getTransportPortURI() + &quot;\&quot;]&quot;);
            }
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ES基本概念与集群]]></title>
        <id>https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/</id>
        <link href="https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/">
        </link>
        <updated>2022-02-19T06:27:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述elasticsearch基本结构，术语介绍以及路由算法，分片原理等。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/conifers-1850227_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="基本概念">基本概念</h2>
<h3 id="简介">简介</h3>
<p>ElasticSearch是一个基于Apach Lucene构建的搜索引擎，其天生便是分布式的，具备极强的可扩展性，除此之外，强大的实时分析特性以及分布式存储都是其不可忽视的优点。</p>
<p>ES的主旨在于随时可用以及按需扩容。垂直扩容（纵向扩容）：性能更强大的硬件机器；水平扩容（横向扩容）：数量更多的服务器。</p>
<p>由于硬件限制，现阶段的垂直扩容必然存在一个极限，所以对于ES而言，真正的扩容能力还是来自于水平扩容-为集群增加更多的机器（多节点负载与分布式容灾，同时可以进行PB级别的数据分析）。</p>
<h3 id="名词解释">名词解释</h3>
<h4 id="索引存储索引">索引（存储索引）</h4>
<p>索引（Index）是ElasticSearch存放数据的地方（为了区分搜索索引，暂且称其为存储索引）。以关系数据库类比的话，ES中的索引相当于数据库（es6之后等同于数据表，参见；1.2.2文档类型-重点注意）的概念。但是与关系数据库相比，ES可以更快速且高效的对索引中的数据进行全文检索。</p>
<p>究其根本是由于ES/Lucene使用的倒排索引相较于关系数据库中的b-tree，b+tree而言，多了一层内存索引概念（此处的索引指搜索索引，而非存储索引）。</p>
<p>内存索引是对磁盘索引的一层简化封装，例如：磁盘索引为Alex，Bob，Curl，Abnormal；那么内存索引则为：A，B，C，b，这些简化字段会组成一颗trie tree（前缀树，根据字典顺序升序排列），通过特定的压缩技术（Lucene Finite State Transducers <a href="https://cs.nyu.edu/~mohri/pub/fla.pdf">点击此处跳转文档页面</a>）可以将其尺寸缩小数十倍，使得用内存缓存trie tree变成可能。</p>
<p>正是基于内存索引的优化，ES/Lucene才能比关系数据库更快的检索出结果；因为其在内存中已经找到了对应的磁盘索引，可以直接根据磁盘索引查询对应的磁盘数据，而关系数据库则需要遍历查找出对应的磁盘索引，之后再根据磁盘索引查询磁盘数据，这中间便多了磁盘的random access次数（一次磁盘random access大概耗时10ms，耗时会随着磁盘硬件的优劣而产生一定的浮动）。</p>
<p>关于多字段查询，ES/Lucene有两种合并方式：1.skip list实现联合索引的；对跳表中的数据进行快速与运算。2.bitset实现快速合并，进行按位与运算。两种方式的比较可参考：<a href="https://www.elastic.co/cn/blog/frame-of-reference-and-roaring-bitmaps">点击此处跳转页面</a></p>
<p>综上所述，整体效果图如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303015.png" alt="img" loading="lazy"></figure>
<h4 id="文档类型">文档类型</h4>
<p>ES中的索引可以存储许多不同用途的对象，如：学生对象，课程对象等，为了更轻松地区分这些对象，文档类型这个概念便应运而生（可类比于关系数据库中的表）；在实际操作中，为文档划分不同的类型，可以更方便的操作数据。</p>
<p>注意：划分文档类型时存在一定的限制条件，其中之一便是不同的文档类型对同一字段不能设置为不同的字段类型。例如：学生对象中的课程id是Integer类型，而课程对象中的id是String，这是不行的。详情可参考：<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping.html">点击此处跳转页面</a></p>
<p>重点注意：es6.0.0之前单个索引可以有多个文档类型，es6.0.0之后单个索引只能有一个文档类型，7.0.0之后文档类型字段已被设置为过期，8.0.0将会完全不支持文档类型字段。原因参见上述注意点。</p>
<h4 id="文档及字段">文档及字段</h4>
<p>文档（document）是ES中存储的主要实体（类比于关系数据库中的一行数据），而字段则是具体的一对KV组合（类比于关系数据库中的一列数据）。</p>
<p>需要额外注意的是：字段类型（字符串型，数值型，日期型）决定了ES该执行何种操作，如比较、排序等。</p>
<p>幸运的是ES可以自动确定字段类型，当然也可以通过模式映射（schema mapping）自定义文档结构。</p>
<h2 id="集群概念">集群概念</h2>
<h3 id="节点与集群">节点与集群</h3>
<p>ElasticSearch可以作为一个独立的搜索服务器工作。然而，为了能够处理大型数据集并实现高可用容灾功能，我们有必要在多台服务器上部署运行ES。</p>
<p>一个运行中的ES实例称为一个节点，而集群则是由一个或多个拥有相同cluster.name配置的节点组成，集群中的所有节点共享数据且分担负载。</p>
<p>一个集群存在一个主节点（选举生成），它负责管理集群范围内的所有变更，如节点的增删，索引的增删等（不涉及文档级别）。</p>
<p>查看集群健康状态：curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot;</p>
<p>其中status字段展示了集群的健康状况：green：所有主/副本分片都是正常的；yellow：所有主分片都正常，但并不是所有副本分片都正常；red：所有主/副本分片都不正常。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303016.png" alt="img" loading="lazy"></figure>
<h3 id="分片概述">分片概述</h3>
<p>一个分片是一个底层的工作单元，它只存储了全部数据的一部分。前文所说的索引（存储数据的地方），实际上也是指向一个或多个物理分片的逻辑命名空间。</p>
<p>每个分片都是一个完整的搜索引擎，也即是一个Lucene实例。应用程序并不需要关注分片的存在，只需跟索引进行交互即可（ES透明处理了分片数据合并的过程）。</p>
<p>所有的分片都可以存储在集群中的任一节点中，而文档数据则存储在各个分片内，这便是ES集群管理数据的方式。</p>
<p>一个分片既可以是主分片，也可以是副本分片。索引中的任意文档都归属于一个主分片，所以主分片的数量决定了索引能够保存的最大数据量（Integer.MAX_VALUE-128，这是理论最大值，实际中还与硬件设备、文档大小、文档复杂度，索引和查询文档的方式以及期待的响应时长有关）。</p>
<p>副本分片主要用于高可用容灾与备份，是对主分片数据的一个拷贝，同时提供搜索和返回文档等读操作。</p>
<p>注意：扩容时，我们可以通过增加副本分片来提高搜索性能，但如果节点不变的情况下，我们增大副本分片仅仅只能带来容灾备份；这是因为每个分片从节点上获取的资源会变少，所以想增加吞吐量唯有扩展机器资源了。</p>
<p>设置三个主分片以及一个副本分片（每个主分片都拥有一个副本分片）：</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303017.png" alt="" loading="lazy"></figure>
<p>修改一个副本分片为两个副本分片：</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303018.png" alt="img" loading="lazy"></figure>
<h3 id="路由算法">路由算法</h3>
<p>分布式存储少不了路由算法，在ES中是通过hash算法来确定数据该存储到哪一个节点/分片中的。</p>
<p>公式：shard = hash(routeKey) % number_of_primary_shards</p>
<p>其中routeKey是一个随机数，一般情况下默认是文档id，不过也可以直接指定对应的值。</p>
<p>该公式也表明了主分片数为何只能在创建索引的时候设置，并且不允许被修改（如果被更改，那么之前的数据将无法被查询到，因为路由值已经不同）。</p>
<h3 id="集群交互">集群交互</h3>
<p>以三节点集群为例，其中包含一个blogs的索引，它对应的设置为：主分片数：2，副本数：2。一般相同分片的副本不会存放在同一节点，如下图：</p>
<p>注意：</p>
<ol>
<li>ES中的每个节点都有能力处理任意操作请求。</li>
<li>如果某个节点被指定为接受请求的节点，那么该节点被称为协调节点（coordinating  node）</li>
<li>为了后续更好的扩展负载，一般使用轮询机制遍历集群中的所有节点。</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303019.png" alt="img" loading="lazy"></figure>
<h4 id="新建删除文档">新建/删除文档</h4>
<p>新建与删除操作需要在主节点操作结束后，才能同步至副本分片中，如下所示：</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303020.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送新建，删除请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3上的请求执行成功后，它会将请求并行地转发至NODE1与NODE2上的副本分片。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>额外参数补充：</p>
<ul>
<li>consistency：一致性。此参数默认配置下进行写操作时，主分片会要求集群中的大部分（规定数量（quorum））分片副本处于活跃可用状态，否则将不会进行写操作。如此设置的目的是为了防止出现网络分区故障时，写操作出现数据不一致的现象。</li>
<li>规定数量公式：int((primary + number_of_replicas)/2) + 1；其中number_of_replicas指的是设置索引时对应的副本分片数，且只有该值大于1时，规定数量设置才会生效（因为单节点默认配置会影响写操作）。</li>
<li>consistency参数值：one 表示主分片状态ok即可执行写操作；all 表示主分片及所有副本分片都ok才能进行写操作；quorum 默认设置，表示副本分片达到规定数量即可执行写操作。</li>
</ul>
<h4 id="更新文档">更新文档</h4>
<p>更新操作相较于新建/删除多了一个额外的冲突重试步骤，如下图所示；</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303021.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。</li>
<li>NODE3从主分片搜索对应的文档数据，修改_source中的内容，并重新存储至主分片上。如果此过程中，文档被另一个进程修改，那么步骤3将会重复执行，直到retry_on_conflict次后放弃。</li>
<li>NODE3上的请求执行成功后，它会将新版本的文档并行地转发至NODE1与NODE2上的副本分片，重新建立索引。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。</li>
</ol>
<p>注意：主分片并不会将更改请求转发至副本分片，而是将新版本的文档完整的转发过去，且不保证顺序。如果ES转发更改请求，那么由于顺序的不一致，可能导致文档更新有误，从而使错误的数据存储下来。</p>
<h4 id="检索文档">检索文档</h4>
<p>ES可以从主分片或者副本分片中得到需要搜素的文档，如下图所示：</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303022.png" alt="img" loading="lazy"></figure>
<p>操作步骤如下：</p>
<ol>
<li>客户端向NODE1发送更新请求。</li>
<li>NODE1通过路由算法得到文档所属的分片P0，分片P0的副本分片存在所有节点上，在这种情况下（轮询机制），它将请求转发至NODE2。</li>
<li>NODE2将文档返回给NODE1，NODE1再将文档返回给客户端。</li>
</ol>
<p>注意：在处理读请求时，协调节点在每次请求时都会通过轮询机制遍历所有节点来达到负载均衡。这也是步骤2会从NODE2获取数据的原因。</p>
<p>在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p>
<h4 id="批量操作文档">批量操作文档</h4>
<p>ES批量操作与单文档操作基本一致。区别在于协调节点会将整个文档分解为每个分片的多文档请求，并将这些请求转发至每个参与节点。</p>
<p>使用单个 mget 请求取回多个文档所需的步骤顺序：</p>
<ol>
<li>客户端向 Node 1 发送 mget 请求。</li>
<li>Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303023.png" alt="img" loading="lazy"></figure>
<p>bulk API 操作步骤：</p>
<ol>
<li>客户端向 Node 1 发送 bulk 请求。</li>
<li>Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</li>
<li>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</li>
</ol>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303024.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CPU飙升问题排查]]></title>
        <id>https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/</id>
        <link href="https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/">
        </link>
        <updated>2022-02-05T03:13:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述运行中的Java程序导致的CPU飙升问题排查过程和方法。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hot-air-balloon-1756150_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="cpu飙升问题排查">CPU飙升问题排查</h2>
<h3 id="问题描述">问题描述</h3>
<p>线上系统突然运行缓慢，CPU飙升，甚至到100%，以及Full GC次数过多，接着就是各种报警：例如接口超时报警等。此时急需快速线上排查问题。</p>
<h3 id="问题排查">问题排查</h3>
<p>不管什么问题，既然是CPU飙升，肯定是查一下耗CPU的线程，然后看看GC。</p>
<h4 id="排查步骤">排查步骤</h4>
<ol>
<li>执行“top”命令：查看所有进程占系统CPU的排序。极大可能排第一个的就是咱们的java进程（COMMAND列，也可以直接使用top -p <code>pgrep -d,java</code>查看系统中JAVA进程的CPU占用情况）。PID那一列就是进程号。</li>
<li>执行“top -Hp 进程号”命令：查看java进程下的所有线程占CPU的情况。</li>
<li>执行“printf &quot;%x\n 10&quot;命令 ：后续查看线程堆栈信息展示的都是十六进制，为了找到咱们的线程堆栈信息，咱们需要把线程号转成16进制。例如,printf &quot;%x\n 10-》打印：a，那么在jstack中线程号就是0xa.</li>
<li>执行 “jstack 进程号 | grep 线程ID” 查找某进程下-》线程ID（jstack堆栈信息中的nid）=0xa的线程堆栈信息。如果“&quot;VM Thread&quot; os_prio=0 tid=0x00007f871806e000 nid=0xa runnable”，第一个双引号圈起来的就是线程名，如果是“VM Thread”这就是虚拟机GC回收线程了</li>
<li>执行“jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一次统计）”，查看某进程GC持续变化情况，如果发现返回中FGC很大且一直增大-》确认Full GC! 也可以使用“jmap -heap 进程ID”查看一下进程的堆内存是不是要溢出了，特别是老年代内存使用情况，一般是达到阈值(具体看垃圾回收器和启动时配置的阈值)进程就会Full GC。</li>
<li>执行“jmap -dump:format=b,file=filename 进程ID”，导出某进程下内存heap输出到文件中。可以通过jvisualvm查看（直接双击打开jvisualvm.exe，点击文件-&gt;装入，在文件类型那一栏选择堆，选择要分析的dump文件，打开）。</li>
</ol>
<p>注意：jmap会导致JVM的停止（您的应用程序已停止。获得准确的堆转储的唯一实用方法是在创建转储时停止所有应用程序活动。这是“简短”暂停还是“长时间”暂停取决于要转储多少。如果使用“ -dump”，则将转储整个堆，包括不可达的对象。如果使用“-dump：live”，则只会转储可访问的对象……但这（至少）需要标记堆以找出可访问的对象。但是，如果要转储千兆字节大小的堆，则期望暂停时间以分钟而不是秒为单位。）。</p>
<h4 id="原因分析">原因分析</h4>
<h5 id="内存消耗过大导致full-gc次数过多">内存消耗过大，导致Full GC次数过多</h5>
<p>执行步骤1-5：</p>
<ul>
<li>多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程-》上一节步骤2</li>
<li>通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。--》上一节步骤5</li>
</ul>
<p>确定是Full GC,接下来找到具体原因：</p>
<ul>
<li>生成大量的对象，导致内存溢出-》执行步骤6，查看具体内存对象占用情况。</li>
<li>内存占用不高，但是Full GC次数还是比较多，此时可能是代码中手动调用 System.gc()导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。</li>
</ul>
<h5 id="代码中有大量消耗cpu的操作导致cpu过高系统运行缓慢">代码中有大量消耗CPU的操作，导致CPU过高，系统运行缓慢；</h5>
<p>执行步骤1-4：在步骤4jstack，可直接定位到代码行。例如某些复杂算法，甚至算法BUG，无限循环递归等等。</p>
<h5 id="由于锁使用不当导致死锁">由于锁使用不当，导致死锁。</h5>
<p>执行步骤1-4： 如果有死锁，会直接提示。关键字：deadlock.步骤四，会打印出业务死锁的位置。</p>
<p>造成死锁的原因：最典型的就是2个线程互相等待对方持有的锁。</p>
<h5 id="随机出现大量线程访问接口缓慢">随机出现大量线程访问接口缓慢。</h5>
<p>代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；平时消耗的CPU不多，而且占用的内存也不高。</p>
<p>思路：首先找到该接口，通过压测工具不断加大访问力度，大量线程将阻塞于该阻塞点。</p>
<p>执行步骤1-4，如下，找到业务代码阻塞点，这里业务代码使用了TimeUnit.sleep()方法，使线程进入了TIMED_WAITING(期限等待)状态。</p>
<pre><code>&quot;http-nio-8080-exec-4&quot; #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)-》期限等待
 at java.lang.Thread.sleep(Native Method)
 at java.lang.Thread.sleep(Thread.java:340)
 at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
 at com.*.user.controller.UserController.detail(UserController.java:18)-》业务代码阻塞点
</code></pre>
<h5 id="某个线程由于某种原因而进入waiting状态此时该功能整体不可用但是无法复现">某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；</h5>
<p>执行步骤1-4：jstack多查询几次，每次间隔30秒，对比一直停留在parking 导致的WAITING状态的线程。例如CountDownLatch倒计时器，使得相关线程等待-&gt;AQS-&gt;LockSupport.park()。</p>
<pre><code>&quot;Thread-0&quot; #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000]
java.lang.Thread.State: WAITING (parking) -&gt;无期限等待
at sun.misc.Unsafe.park(Native Method)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
at com.*.SyncTask.lambda$main$0(SyncTask.java:8)-》业务代码阻塞点
at com.*.SyncTask$$Lambda$1/1791741888.run(Unknown Source)
at java.lang.Thread.run(Thread.java:748)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[zabbix5.4采集日志进行钉钉告警]]></title>
        <id>https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/</id>
        <link href="https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/">
        </link>
        <updated>2022-01-22T02:28:06.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述zabbix5.4采集日志进行钉钉告警</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/landscape-1192669_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="配置钉钉机器人">配置钉钉机器人</h2>
<p>电脑版钉钉，选中对应的钉钉群，点击群设置---&gt;智能群助手---&gt;添加机器人---&gt;自定义---&gt;添加。</p>
<p>安全设置根据需要自行选择（演示选择的是自定义关键词），需要记住对应的Webhook（用作python脚本调接口使用）</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302016.png" alt="img" loading="lazy"></figure>
<h2 id="配置zabbix">配置zabbix</h2>
<h3 id="zabbix-server配置">zabbix-server配置</h3>
<p>使用命令查找对应的告警配置文件目录。</p>
<pre><code>cat /etc/zabbix/zabbix_server.conf | grep AlertScripts
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303001.png" alt="" loading="lazy"></figure>
<pre><code>find / -name alertscripts
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303002.png" alt="" loading="lazy"></figure>
<p>找到告警目录后，使用cd命令，切入该目录，并执行vi dingding.py。</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303003.png" alt="" loading="lazy"></figure>
<p>dingding.py内容如下（钉钉文档：<a href="https://developers.dingtalk.com/document/app/custom-robot-access">点击此处跳转页面</a>）</p>
<pre><code>#!/usr/bin/env python3.8
#coding:utf-8
#zabbix dingding alert
import requests,json,sys,os,datetime
webhook=&quot;https://oapi.dingtalk.com/robot/send?access_token=******&quot;
user=sys.argv[1]
text=sys.argv[3]
data={
    &quot;msgtype&quot;: &quot;text&quot;,
    &quot;text&quot;: {
        &quot;content&quot;: text
    },
    &quot;at&quot;: {
        &quot;atMobiles&quot;: [
            user
        ],
        &quot;isAtAll&quot;: False
    }
}
headers = {'Content-Type': 'application/json'}
x=requests.post(url=webhook,data=json.dumps(data),headers=headers)
print(x.status_code)
print(x.text)

</code></pre>
<p>注意：代码的第一句（#!/usr/bin/env python3.8）中的 python3.8取决于系统安装的python版本，使用whereis  python进行查看。</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303004.png" alt="" loading="lazy"></figure>
<p>随后使用如下命令进行权限设置（如若未设置，将无法执行脚本文件）</p>
<pre><code>[root@localhost alertscripts]# chmod 755 dingding.py 
[root@localhost alertscripts]# chown zabbix.zabbix dingding.py

</code></pre>
<p>测试时，前两个参数，随便填，最后的文本内容需要加上在钉钉机器人配置时设置的关键词。</p>
<pre><code>[root@localhost alertscripts]# ./dingding.py 123 wrq &quot;{monitor,test}&quot;
200
{&quot;errcode&quot;:0,&quot;errmsg&quot;:&quot;ok&quot;}
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303005.png" alt="" loading="lazy"></figure>
<p>问题：可能出现一些安装包不存在，比如requests，使用pip3 list 查看安装了哪些包。如果没有安装requests，可以执行pip3 install requests进行安装。</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303006.png" alt="img" loading="lazy"></figure>
<h3 id="zabbix-web配置">zabbix-web配置</h3>
<h4 id="在已添加的主机上在创建一个监控项">在已添加的主机上在创建一个监控项</h4>
<p>logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,]<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件进行日志信息采集。</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303007.png" alt="img" loading="lazy"></figure>
<h4 id="在已添加的主机上在创建一个触发器">在已添加的主机上在创建一个触发器</h4>
<p>find(/zabbix-agent/logrt[&quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&quot;,,,,skip,],#10,,&quot;HIGH&quot;)=1<br>
表示匹配/var/log/testlog/zabbix20210715.0.log文件中的HIGH字段进行告警触发。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303008.png" alt="img" loading="lazy"></figure>
<h4 id="在管理界面添加一个媒体类型">在管理界面添加一个媒体类型</h4>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303009.png" alt="img" loading="lazy"></figure>
<h4 id="在配置界面的动作操作中添加一个触发器动作">在配置界面的动作操作中添加一个触发器动作</h4>
<p>条件选择触发器名称匹配。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303010.png" alt="" loading="lazy"></figure>
<p>随后点击操作</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303011.png" alt="" loading="lazy"></figure>
<pre><code>配置信息如下：
业务告警（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303012.png" alt="" loading="lazy"></figure>
<pre><code>故障恢复（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
</code></pre>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303013.png" alt="" loading="lazy"></figure>
<p>上述操作中，需要注意的是Send to users选项，该选项对应的值需与媒体类型关联。比如上面选择的用户是Admin，那么需要在管理界面选择用户Admin进行媒体类型的添加。</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303014.png" alt="" loading="lazy"></figure>
<h4 id="拼接地址调转zabbix指定界面">拼接地址调转zabbix指定界面</h4>
<pre><code>// 拼接地址调转zabbix指定界面
String t = &quot;http://localhost:8096/index.php?request=zabbix.php%3Faction%3Dhost.dashboard.view%26hostid%3D10435&amp;name=Admin&amp;password=zabbix&amp;autologin=1&amp;enter=Sign+in&quot;;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WSL2 & Docker & Zabbix]]></title>
        <id>https://philosopherzb.github.io/post/wsl2-and-docker-and-zabbix/</id>
        <link href="https://philosopherzb.github.io/post/wsl2-and-docker-and-zabbix/">
        </link>
        <updated>2022-01-08T07:31:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述如何安装wsl2，docker以及zabbix。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/forest-1072828_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="install-wsl-update-to-wsl2">Install WSL &amp; update to WSL2</h2>
<p>WSL，全名：Windows Subsystem for Linux，是一个运行在windows系统上的Linux子系统，它支持绝大部分的Linux功能，避免了安装虚拟机。</p>
<h3 id="安装前的一些必要项">安装前的一些必要项</h3>
<p>确保计算机开启了虚拟化技术这项配置，开机进入BIOS界面，选择configuration-》Intel Virtual Technology进行开启即可。</p>
<p>使用WSL2的系统版本必须为windows10，且对应的最低版本要求如下（win+R，输入winver回车即可查看本机系统版本）：</p>
<ul>
<li>For x64 systems: Version 1903 or higher, with Build 18362 or higher.</li>
<li>For ARM64 systems: Version 2004 or higher, with Build 19041 or higher</li>
<li>Builds版本低于 18362 是不支持 WSL 2的。 <a href="https://www.microsoft.com/zh-cn/software-download/windows10">点击此处可跳转下载地址</a> 下载最新的windows进行更新。</li>
</ul>
<h3 id="安装wsl">安装WSL</h3>
<p>以管理员的权限打开powershell（右击左下角的win logo选择即可），键入如下命令：</p>
<pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
</code></pre>
<p>命令执行之后，重启电脑即可完成WSL的安装。</p>
<p>下载WSL2最新的安装包进行更新。<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">点击此处可跳转下载地址</a></p>
<p>下载完成后，双击运行即可。</p>
<p>将wsl2设置为默认版本，输入命令：wsl --set-default-version 2</p>
<h3 id="安装liunx操作系统">安装Liunx操作系统</h3>
<p><a href="https://aka.ms/wslstore">点击此处可跳转下载地址</a>选择一款系统点击get进行安装。</p>
<p><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302008.png" alt="img" loading="lazy"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302009.png" alt="" loading="lazy"></p>
<p>等待计算机自动安装完成后，左击桌面左下角的win logo，选择刚刚安装的操作系统。第一次进入需要等待几分钟，随后创建一个用户即可登录使用了。</p>
<p>点击左下方任务栏上的搜索按钮，在搜索框中输入“终端”，选择虚拟机打开。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302010.png" alt="" loading="lazy"></figure>
<p>可以在powershell中的键入wsl --list --verbose查看版本信息</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302011.png" alt="img" loading="lazy"></figure>
<p>额外：可以安装Windows Terminal，便于多界面管理终端。<a href="https://docs.microsoft.com/en-us/windows/terminal/get-started">点击此处可跳转下载地址</a></p>
<p>wls官方地址：<a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">点击此处可跳转</a></p>
<p>启动报错时可参考：<a href="https://appuals.com/wsl-fails-to-start-error-4294967295/">点击此处可跳转</a></p>
<h2 id="docker-desktop-for-windows">Docker desktop for windows</h2>
<h3 id="安装docker">安装Docker</h3>
<p>安装完WSL2后，<a href="https://docs.docker.com/docker-for-windows/wsl/#download">点击此处可跳转下载地址</a>下载docker安装包，随后直接双击安装即可。</p>
<p>注意1：docker默认安装在C盘目录下，如果需要迁移，需要进行如下操作：</p>
<p>以管理员身份打开cmd窗口，然后运行命令：mklink /j &quot;C:\Program Files\Docker&quot; &quot;D:\Program Files\Docker&quot;，在此之前要先创建&quot;D:\Program Files\Docker&quot;目录。最后安装docker即可。（ mklink /j 表示创建一个链接）</p>
<p>注意2：docker镜像文件默认存储在wsl中，也就是系统盘，可以通过如下命令进行迁移（需要先创建对应的文件目录D:\Program Files\wsl\data）。</p>
<pre><code>-- 导出文件
wsl --export docker-desktop-data &quot;D:\Program Files\wsl\data\docker-desktop-data.tar&quot;
wsl --export docker-desktop &quot;D:\Program Files\wsl\data\docker-desktop.tar&quot;
-- 注销原来的文件
wsl --unregister docker-desktop
wsl --unregister docker-desktop-data
-- 数据导入新文件中
wsl --import docker-desktop-data &quot;D:\Program Files\wsl\data&quot; &quot;D:\Program Files\wsl\data\docker-desktop-data.tar&quot; --version 2
wsl --import docker-desktop &quot;D:\Program Files\wsl\data&quot; &quot;D:\Program Files\wsl\data\docker-desktop.tar&quot; --version 2
</code></pre>
<p>注意3：在docker的设置界面，需要开启与虚拟机的集成。</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302012.png" alt="img" loading="lazy"></figure>
<h2 id="zabbix54">Zabbix5.4</h2>
<h3 id="安装zabbix">安装zabbix</h3>
<p>在docker中安装监控工具zabbix，操作步骤如下（官网地址：<a href="https://www.zabbix.com/documentation/current/manual/installation/containers">点击此处可跳转</a>）：</p>
<h4 id="创建docker容器专用网关">创建docker容器专用网关</h4>
<pre><code>docker network create --subnet 172.20.0.0/16 --ip-range 172.20.240.0/20 zabbix-net
docker network create -d bridge zabbix-net
</code></pre>
<h4 id="运行一个空的mysql80服务实例">运行一个空的mysql8.0服务实例</h4>
<p>注意：` 符号为windows中powershell下的换行符，位于ESC键下方</p>
<pre><code>docker run --name mysql-server -t `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      --network=zabbix-net `
      -d mysql:8.0 `
      --character-set-server=utf8 --collation-server=utf8_bin
</code></pre>
<h4 id="运行zabbix-java-gateway实例版本为ubuntu-latest">运行zabbix-java-gateway实例，版本为ubuntu-latest</h4>
<p>版本标签含义如下：</p>
<p>latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本（如果docker pull的时候不输入TAG，将会默认使用该标签）</p>
<p>alpine-latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本</p>
<p>ubuntu-latest: 基于Ubuntu镜像的zabbix组件最终稳定版本</p>
<p>alpine-5.4-latest: 基于Alpine Linux镜像的zabbix5.4组件最终次要版本</p>
<p>ubuntu-5.4-latest: 基于Ubuntu镜像的zabbix5.4组件最终次要版本</p>
<p>alpine-5.4.*: 基于Alpine Linux镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2</p>
<p>ubuntu-5.4.*: 基于Ubuntu镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2</p>
<pre><code>docker run --name zabbix-java-gateway -t `
      --network=zabbix-net `
      --restart unless-stopped `
      -d zabbix/zabbix-java-gateway:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-server-mysql服务并将其与mysql服务关联">运行zabbix-server-mysql服务，并将其与mysql服务关联</h4>
<p>注意：zabbix服务实例向主机公开10051/TCP端口（Zabbix Trapper）</p>
<pre><code>docker run --name zabbix-server-mysql -t `
      -e DB_SERVER_HOST=&quot;mysql-server&quot; `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      -e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      -p 10051:10051 `
      --restart unless-stopped `
      -d zabbix/zabbix-server-mysql:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-web-nginx-mysql服务并将其与mysql及zabbix-server-mysql关联">运行zabbix-web-nginx-mysql服务，并将其与mysql及zabbix-server-mysql关联</h4>
<p>注意：至此zabbix服务已在本机的8096端口暴露。</p>
<p>在docker镜像中nginx的默认端口是8080而非80，可进入镜像的/etc/zabbix/nginx.conf查看，命令如下：</p>
<pre><code>docker ps
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat nginx.conf
</code></pre>
<pre><code>docker run --name zabbix-web-nginx-mysql -t `
      -e ZBX_SERVER_HOST=&quot;zabbix-server-mysql&quot; `
      -e DB_SERVER_HOST=&quot;mysql-server&quot; `
      -e MYSQL_DATABASE=&quot;zabbix&quot; `
      -e MYSQL_USER=&quot;zabbix&quot; `
      -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; `
      -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      --link zabbix-server-mysql:zabbix-server `
      -p 8096:8080 `
      --restart unless-stopped `
      -d zabbix/zabbix-web-nginx-mysql:ubuntu-latest
</code></pre>
<h4 id="运行zabbix-agent服务并关联zabbix-server配置在同一个网桥下">运行zabbix-agent服务，并关联zabbix-server（配置在同一个网桥下）</h4>
<p>注意：web界面Configuration中的Hosts配置中的Name必须与/etc/zabbix/zabbix_agentd.conf中的hostName保持一致，命令如下：</p>
<pre><code>docker ps
# root权限进入
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat zabbix_agentd.conf

web界面Configuration中的Hosts配置中的IP address为zabbix-agent容器所在的地址，命令如下：
docker network ls
docker network inspect NETWORK ID（指第一步中创建zabbix-net对应的id值）
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302013.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302014.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302015.png" alt="" loading="lazy"></figure>
<pre><code>docker run --name zabbix-agent `
      -e ZBX_HOSTNAME=&quot;zabbix-agent&quot; `
      -e ZBX_SERVER_HOST=&quot;zabbix-server-mysql&quot; `
      -e ZBX_SERVER_PORT=10051 `
      --network=zabbix-net `
      --link zabbix-server-mysql:zabbix-server-mysql `
      -p 10050:10050 `
      -d zabbix/zabbix-agent:ubuntu-latest

显示所有ip地址
docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' $(docker ps -aq)
显示zabbix-agen ip地址
docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' zabbix-agent
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux常用命令]]></title>
        <id>https://philosopherzb.github.io/post/linux-chang-yong-ming-ling/</id>
        <link href="https://philosopherzb.github.io/post/linux-chang-yong-ming-ling/">
        </link>
        <updated>2021-12-18T03:25:34.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Linux中常用的一些操作命令。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-440520_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="scp传输文件">SCP（传输文件）</h2>
<p>将win10 D盘temp目录下的文件传输到199.199.199.199的root目录下。</p>
<pre><code>scp D:\temp\***.tar root@199.199.199.199:/root

</code></pre>
<p>将199.199.199.199的root目录下文件传输到win10 D盘temp目录</p>
<pre><code>scp root@199.199.199.199:/root/***.txt D:\temp\

</code></pre>
<h2 id="tar解压缩">TAR（解压缩）</h2>
<p>压缩指定目录下的文件（注意：win为 \，linux为 /）</p>
<pre><code>tar -cvzf  D:\temp\***.tar &quot;D:\temp\***&quot;
# -l   压 缩文件时，把LF字符 置换成LF+CR字 符。
# -ll   压 缩文件时，把LF+CR字 符置换成LF字符。
tar -cvzf -ll  D:\temp\***.tar &quot;D:\temp\***&quot;

</code></pre>
<p>解压指定目录下的文件到指定目录（注意：win为 \，linux为 /）</p>
<pre><code> tar -zxvf /root/***.tar -C /opt/temp/

</code></pre>
<h2 id="mv移动文件">MV（移动文件）</h2>
<p>移动目录下的所有文件至指定目录下</p>
<pre><code>mv  /root/temp/*       /opt/temp/

</code></pre>
<h2 id="find-whereis查询文件">FIND $ WHEREIS（查询文件）</h2>
<p>查询文件</p>
<pre><code>find / -name agent
whereis agent
</code></pre>
<h2 id="dos2unix转换格式">DOS2UNIX（转换格式）</h2>
<p>在win系统中写的shell脚本移动至linux执行时，会提示错误：line 2: $'\r': command not found，这是因为win系统下的换行符为\r\n，而linux系统的为\n，所以需要进行格式转换。</p>
<p>单个，或多个文件格式转换</p>
<pre><code>dos2unix filename1, filename2
</code></pre>
<p>将指定目录下的所有sh结尾的文件进行格式转换</p>
<p>注意：一定要有{}，标示参数；以“;”结尾； {} 和\之间一定要有一个空格</p>
<pre><code>find /apps/cws -name &quot;*.sh&quot; -exec dos2unix {} \;   

</code></pre>
<p>也可以使用xargs命令，不过xargs命令需要和管道符结合使用，并且xargs命令将所有的传入的数据当作一个参数处理。</p>
<pre><code>find /opt/temp/ -name &quot;*.sh&quot; | xargs dos2unix
</code></pre>
<h2 id="ps进程状态process-status">PS（进程状态process status）</h2>
<p>显示所有进程信息，连同命令行</p>
<pre><code>ps -ef
</code></pre>
<p>列出目前正在内存中的程序</p>
<pre><code>ps aux
</code></pre>
<p>通过指定名称列出当前正在内存中的程序的状态(grep命令用于查找符合条件的字符串)</p>
<pre><code>ps aux | grep name
</code></pre>
<h2 id="top任务管理器">TOP（任务管理器）</h2>
<p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。</p>
<pre><code>top
</code></pre>
<h2 id="sudo操作命令">SUDO（操作命令）</h2>
<p>用于切换用户</p>
<pre><code># 切换至root用户登录
sudo -i
</code></pre>
<h2 id="rz传输文件">RZ（传输文件）</h2>
<p>使用finalshell软件时，在命令窗口输入rz可以直接选择外部文件传入服务器。</p>
<pre><code>rz
</code></pre>
<h2 id="firewall防火墙">Firewall（防火墙）</h2>
<pre><code># 安装防火墙
yum install firewalld firewalld-config
</code></pre>
<pre><code>Firewall开启常见端口命令：

firewall-cmd --zone=public--add-port=80/tcp --permanent

firewall-cmd --zone=public--add-port=443/tcp --permanent

firewall-cmd --zone=public --add-port=22/tcp--permanent

firewall-cmd --zone=public --add-port=9000/tcp --permanent

firewall-cmd --zone=public--add-port=53/udp --permanent

Firewall关闭常见端口命令：

firewall-cmd --zone=public--remove-port=80/tcp --permanent

firewall-cmd --zone=public--remove-port=443/tcp --permanent

firewall-cmd --zone=public--remove-port=22/tcp --permanent

firewall-cmd --zone=public--remove-port=21/tcp --permanent

firewall-cmd --zone=public--remove-port=53/udp --permanent

批量添加区间端口：

firewall-cmd --zone=public--add-port=4400-4600/udp --permanent

firewall-cmd --zone=public--add-port=4400-4600/tcp --permanent

开启防火墙命令：

systemctl start firewalld.service

重启防火墙命令：

firewall-cmd --reload  或者   service firewalld restart

查看端口列表：

firewall-cmd --permanent --list-port
firewall-cmd --list-all

禁用防火墙：

systemctl stop firewalld

设置开机启动：

systemctl enable firewalld

停止并禁用开机启动：

sytemctl disable firewalld

查看状态：

systemctl status firewalld或者firewall-cmd --state

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Centos7基本知识]]></title>
        <id>https://philosopherzb.github.io/post/centos7-ji-ben-zhi-shi/</id>
        <link href="https://philosopherzb.github.io/post/centos7-ji-ben-zhi-shi/">
        </link>
        <updated>2021-12-04T03:18:08.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述Centos7系统相关的操作及命令介绍。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-1802337_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="图形命令切换">图形/命令切换</h2>
<h3 id="图形界面进入命令行">图形界面进入命令行</h3>
<p>右击或者在application中打开终端，输入：init 3，即可进入命令行；也可以直接ctrl+alt+f2，进入命令行。</p>
<h3 id="命令行进入图形界面">命令行进入图形界面</h3>
<p>输入：init 5或者：startx，即可进入图形界面。</p>
<p>不过由 startx 再进入命令行会无法进入，可以重新输入：init 5，</p>
<p>重启一下x window，然后再输入：init 3，便可进入命令行。</p>
<h3 id="设置开机进入x-window还是命令行">设置开机进入x window还是命令行</h3>
<p>命令行状态下，root管理员，键入：cat /etc/inittab，</p>
<p>根据提示输入：systemctl get-default，可查看当前进入为那种状态。</p>
<p>如若需要更改可以输入：systemctl set-default multi-user.target------命令行</p>
<p>systemctl set-default graphical.target------图形界面</p>
<h2 id="日期相关">日期相关</h2>
<p>1、指令太长的时候，可以使用反斜杠 () 来跳脱[Enter]符号，使指令连续到下一 行。注意！反斜杠后就立刻接回车，才能跳脱。</p>
<p>2、linux区分大小写！！！</p>
<p>3、ls -al 列出『自己家目录(~)』下的『所有隐藏档不相关的文件属性』</p>
<p>4、显示当前语系：echo $LANG</p>
<p>5、日期：date(正常显示)，date +%y/%m/%d(年月日显示)，date +%H:%M(时钟显示)</p>
<p>6、万年历：cal [month][year]</p>
<p>7、计算器：bc，如需显示小数，在键入bc之后，输入：scale=4,（数字4表示小数有4位）退出键入：quit</p>
<p>8、在指令列模式里面下达指令时，会有两种主要的情况：</p>
<ul>
<li>一种是该指令会直接显示结果然后回到命令提示字符等待下一个指令的输入；</li>
<li>一种是进入到该指令的环境，直到结束该指令才回到命令提示字符的环境。</li>
</ul>
<h2 id="常用快捷键">常用快捷键</h2>
<p>1、Tab键，可进行 [[命令补全]] 和 [[档案补齐]]</p>
<ul>
<li>比如在ca后面连续按两下  Tab，即可查看补全的命令。</li>
<li>而档案补齐可以在 ls -al /.bash后面连续按两下Tab，可进行查看。</li>
</ul>
<p>2、Ctrl+C组合键，即先按下Ctrl不放，再按下C键，便可终止运行的命令。</p>
<p>比如：键入：find / 之后会不停的搜寻，此时，可以使用Ctrl+C来终止运行；不过如果是在进行很重要的指令，则不要急着使用组合键终止命令。</p>
<p>3、Ctrl+D组合键，相当于exit，如果使用，可直接退出文字接口。</p>
<p>4、使用man（manual 操作说明的简写），当需要知道某一个命令的详细指令的时候可以使用。比如：man date，如需退出，按下q即可，翻页按空格键。</p>
<p>5、当使用man date之后，界面左上角会出现DATE(1)，其中的括号中的1的概念如下：</p>
<ul>
<li>1 用户在shell环境中可以操作的指令或可执行文件（重要）</li>
<li>2 系统核心可呼叫的函数与工具等</li>
<li>3 一些常用的函数(function)与函式库(library)，大部分为C的函式库(libc)</li>
<li>4 装置档案的说明，通常在/dev下的档案</li>
<li>5 配置文件或者是某些档案的格式 （重要）</li>
<li>6 游戏(games)</li>
<li>7 惯例与协议等，例如Linux文件系统、网络协议、ASCII code等等的说明</li>
<li>8 系统管理员可用的管理指令 （重要）</li>
<li>9 跟kernel有关的文件</li>
</ul>
<p>6、在man page页面可有如下快捷键操作：</p>
<pre><code>空格键              向下翻一页

[Page Down]    向下翻一页

[Page Up]         向上翻一页

[Home]            去到第一页

[End]                去到最后一页

/string              向『下』搜寻 string 这个字符串，如果要搜寻 date 的话，就输入 /date

?string              向『上』搜寻 string 这个字符串

n, N                  利用 / 或 ? 来搜寻字符串时，可以用 n 来继续下一个搜寻 (不论是 / 或?) ，

可以利用 N 来进行『反向』搜寻。举例来说，我以 /date 搜寻 date 字符串，

那么可以 n 继续往下查询，用 N 往上查询。 若以 ?date 向上查询 date 字符串，

那我可以用 n 继续『向上』 查询，用 N 反向查询。

q                      结束这次的 man page
</code></pre>
<p>7、查看与【man】这个指令相关的的说明文件：</p>
<p>命令行键入：man -f man   等同于whatis man</p>
<p>8、利用关键词将说明文件里面只要含有man那个字眼的(不见得是完整字符串) 就将他取出：命令行键入：man -k man  等同于apropos man</p>
<h2 id="infopage及nano">InfoPage及nano</h2>
<p>1、info page</p>
<pre><code>info与man的用途其实差不多，都是用来查询指令的用法或者是档案的格式。

但是与man page一口气输出一堆信息不同的是，info page则是将文件数据拆成

一个一个的段落，每个段落用自己的页面来撰写， 并且在各个页面中还有类似网

页的『超链接』来跳到各不同的页面中，每个独立的 页面也被称为一个节点(node)

命令行键入：info info
</code></pre>
<p>2、出现的第一行里面的数据意义为：</p>
<pre><code>File：代表这个info page的资料是来自info.info档案所提供的；

Node：代表目前的这个页面是属亍Top节点。 意思是info.info内

含有很多信息，而Top仅是 info.info档案内的一个节点内容而已；

Next：下一个节点的名称为Getting Started，你也可以按『N』到下个节点去；

Up：回到上一层的节点总揽画面，你也可以按下『U』回到上一层；

Prev：前一个节点。但由于Top是info.info的第一个节点，所以上面没有前一个节点的信息
</code></pre>
<p>3、info page页面快捷键操作：</p>
<pre><code>空格键                 向下翻一页

[Page Down]       向下翻一页

[Page Up]            向上翻一页

[tab]                    在 node 之间移劢，有 node 的地方，通常会以 * 显示。

[Enter]                 当光标在 node 上面时，按下 Enter 可以进入该 node 。

b                         移动光标到该 info 画面当中的第一个 node 处

e                         移动光标到该 info 画面当中的最后一个 node 处

n                         前往下一个 node 处

p                         前往上一个 node 处

u                         向上移动一层

s(/)                      在 info page 当中进行搜寻

h                         显示求助选单

?                         指令一览表

q                         结束这次的 info page
</code></pre>
<p>4、说明文档所在地。架设一些其他的服务，或想要利用一整组软件来达成某项功能时</p>
<pre><code>键入：cd /usr/share/doc

即可进入doc文件夹下方，有很多文档的说明。（实践中未找到？？？）
</code></pre>
<p>5、超简单文书编辑器： nano</p>
<pre><code>[ctrl]-G：   取得联机帮助(help)，很有用的！

[ctrl]-X：   离开naon软件，若有修改过档案会提示是否需要储存喔！

[ctrl]-O：   储存档案，若你有权限的话就能够储存档案了；

[ctrl]-R：   从其他档案读入资料，可以将某个档案的内容贴在本档案中；

[ctrl]-W：  搜寻字符串，这个也是径有帮助的指令喔！

[ctrl]-C：   说明目前光标所在处的行数与列数等信息；

[ctrl]-_：    可以直接输入行号，让光标快速移动到该行；

[alt]-Y：    校正语法功能开启或关闭(单击开、再单击关)

[alt]-M：   可以支持鼠标来移动光标的功能
</code></pre>
<p>6、关机</p>
<pre><code>重新启动，关机： reboot, halt, poweroff

键入：man shutdown  查看具体细节。

常用的是：shutdown -h now 立即关机

shutdown -r now  立即重启

init 0           立即关机

init 6           立即重启

reboot         立即重启
</code></pre>
<h2 id="linux文件属性">Linux文件属性</h2>
<p>root登陆后，键入ls -al</p>
<p>-rw-r--r--  1 root  root  2272  Jul  5 09:50  initial-setup-ks.cfg</p>
<p>[权限]  [连结数]  [拥有者]  [群组]  [档案容量]  [ 修改日期 ] [檔名]</p>
<p>1、 第一栏代表这个档案的类型与权限(permission)：</p>
<pre><code>-rw-r--r--    其中一共有十个字符。

第一个字符表示档案类型，第二，三，四表示档案拥有者权限

第五，六，七表示档案所属群组的权限，第八，九，十表示其他人的权限
</code></pre>
<p>2、第一个字符代表这个档案是『目录、档案或链接文件等等』：</p>
<pre><code>当为[ d ]则是目录；

当为[ - ]则是档案；

若是[ l ]则表示为连结档(link file)；

若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；

若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)
</code></pre>
<p>3、接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。其中，</p>
<pre><code>[ r ]代表可读 (read)、

[ w ]代表可写(write)、

[ x ]代表可执行(execute)。

要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已
</code></pre>
<p>4、第二栏表示有多少档名连结到此节点(i-node)</p>
<pre><code>每个档案都会将他的权限与属性记录到文件系统的i-node中，

不过，我们使用的目录树却是使用文件名来记录的， 因此每个档名

就会连结到一个i-node！这个属性记录的，就是有多少不同的档

名连结到相同的一个i-node了。
</code></pre>
<p>5、第三栏表示这个档案(或目录)的『拥有者账号』</p>
<p>6、第四栏表示这个档案的所属群组</p>
<p>7、第五栏为这个档案的容量大小，默认单位为bytes</p>
<p>8、第六栏为这个档案的建档日期或者是最近的修改日期</p>
<pre><code>这一栏的内容分别为日期(月/日)及时间。如果这个档案

被修改的时间距离现在太久了，那么时间部分会仅显示年份而已。

显示完整的时间格式，可以利用ls的选顷，

亦即：『ls -al --full-time』就能够显示出完整的时间格式
</code></pre>
<p>9、第七栏为这个档案的档名</p>
<pre><code>如果档名之前多一个『 . 』，则代表这个档案为『隐藏档』
</code></pre>
<h2 id="设置变更">设置变更</h2>
<p>1、改变所属群组, chgrp</p>
<pre><code>这个指令就是change group的缩写

chgrp [-R] dirname/filename ...

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案、目录

都更新成为这个群组之意。常常用在变更某一目录内所有的档案之情况

chgrp users initial-setup-ks.cfg

chgrp testing initial-setup-ks.cfg（错误信息：invalid group name `testing'）

只有当你要改变的那个文件或者目录中有要改变成的对应群组，才能改变，否则报错，找不到

比如此次实例中的群组就在/etc/group中存在root和users群组，但不存在testing群组
</code></pre>
<p>2、改变档案拥有者, chown</p>
<pre><code>这个指令就是change owner的缩写

跟概念群组一样，这里要注意的是， 用户必项是已经存在系统中的账号，

也就是在/etc/passwd 这个档案中有纪录的用户名称才能改变。

chown [-R] 账号名称 档案或目录

chown [-R] 账号名称:组名 档案或目录

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案都变更

chown bin initial-setup-ks.cfg

chown还可以顺便直接修改群组的名称，中间使用冒号(也可以使用点)，前面为拥有者，后面为群组

chown bin:users initial-setup-ks.cfg

chown bin.users initial-setup-ks.cfg

有时候需要变更档案的拥有者，最常见的例子就是在复制档案给你之外的其他人时

cp 来源档案 目标文件
</code></pre>
<p>（cp .bashrc .bashrc_test ）</p>
<pre><code>先复制一下，然后在更改复制了的使用者，群组。
</code></pre>
<p>3、改变权限, chmod</p>
<pre><code>权限的设定方法有两种， 分别可以使用数字或者是符号来进行权限的变更

数字类型改变档案权限。

Linux档案的基本权限就有九个，分别是owner/group/others三种身份各有自己的 read/write/execute权限

可以使用数字来代表各个权限，如下

r:4 ，w:2， x:1

每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，

例如当权限为： [rwxrwx---] 分数则是：

owner = rwx = 4+2+1 = 7

group = rwx = 4+2+1 = 7

others= --- = 0+0+0 = 0

符号类型改变档案权限

九个权限分别是(1)user (2)group (3)others三种身份啦！那么我们就可以藉由u, g, o来代表三种身份的权限！

此外， a 则代表 all 亦即全部的身份！那么读写的权限就可以写成r, w, x

其中+表示加入，-表示减去，=表示设定

chmod a+w initial-setup-ks.cfg   设定该档案u，g，o都具有w（写）权限

chmod a-w initial-setup-ks.cfg   设定该档案u，g，o都去掉w（写）权限

chmod u=rwx,go=rw initial-setup-ks.cfg   设定该档案u具有rwx权限，go都具有rw权限
</code></pre>
<p>4、『 su - yy 』这个指令来变换身份，只能进入普通账户，进入root需要重新输入密码</p>
<p>5、『 cat ~/.bashrc 』就可以看到该档案的内容。 (cat 是将一个档案内容读出来的指令)</p>
<p>6、Linux目录配置的依据--FHS（Filesystem Hierarchy Standard 文件系统阶层标准）</p>
<pre><code>主要有以下四个类型：

可分享的：可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据，是能够分享给网络上其他主机挂载用的目录。

不可分享的：自己机器上面运作的装置档案或者是与程序有关的socket档案等，由与仅与自身机器有关，所以当然就不适合分享给其他主机了。

不变的：有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等。

可变动的：经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等 。
</code></pre>
<p>7、FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义</p>
<pre><code>/ (root, 根目录)：与开机系统有关；

/usr (unix software resource)：与软件安装/执行有关；

/var (variable)：与系统运作过程有关
</code></pre>
<h2 id="目录及文件">目录及文件</h2>
<p>1、相对路径与绝对路径：</p>
<pre><code>绝对路径：路径的写法『一定由根目录 / 写起』，例如： /usr/share/doc 这个目录。

相对路径：路径的写法『不是由 / 写起』，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写：『cd ../man』这就是相对路径的写法啦！相对路径意指『相对于目前工作目录的路径！』
</code></pre>
<p>2、目录的相关操作：</p>
<pre><code>『.』                代表此层目录

『..』               代表上一层目录

『-』               代表前一个工作目录

『~』              代表『目前用户身份』所在的家目录

『~yy』           代表yy这个用户的家目录(yy是个账号名称)
</code></pre>
<p>常见处理目录的指令(可用man查看)：</p>
<pre><code>cd：变换目录              （Change Directory）

pwd：显示当前目录        （Print Working Directory）

-P(大写)  ：显示出确实的路径，而非使用链接 (link) 路径。

mkdir：建立一个新的目录

mkdir [-mp] 目录名

-m ：配置文件案的权限！直接设定，不需要看预设权限 (umask) 的脸色

-p ：帮助你直接将所需要的目录(包含上层目录)递归建立起来

rmdir： 删除一个空的目录

-p ：连同上层『空的』目录也一起删除
</code></pre>
<p>3、执行文件路径的变量： $PATH</p>
<pre><code>a、不同身份使用者预设的PATH不同，默认能够随意执行的指令也不同(如root与yy)

b、PATH是可以修改的，所以一般使用者还是可以通过修改PATH来执行某些位于/sbin或/usr/sbin下的指令来查询

c、使用绝对路径或相对路径直接指定某个指令的文件名来执行，会比搜寻PATH来的正确

d、指令应该要放置到正确的目录下，执行才会比较方便

e、本目录(.)最好不要放到PATH当中
</code></pre>
<p>4、复制、删除与移动： cp, rm, mv</p>
<pre><code>cp (复制档案或目录)

[root@localhost]# cp /.bashrc /tmp/bashrc  &lt;==将.bashrc复制到/tmp下，并更名为bashrc

[root@localhost tmp]# cp /var/log/wtmp .  &lt;==将wtmp复制到当前目录，最后的『.』不要忘了！

在不加任何选项的情况下，档案的某些属性/权限会改变

这是个很重要的特性！而且连档案建立的时间也不一样了！

如果想要将档案的所有特性都一起复制过来，加上 -a 便可以了

[root@localhost tmp]# cp -r /etc/ /tmp     &lt;==如果为目录，则不能直接复制，需加上-r，与此同时，档案与目录的权限也可能会被改变，这个时候可以用『 cp -a /etc /tmp 』来下达指令！尤其是在备份的情况下！
</code></pre>
<p>cp 有种种的文件属性与权限的特性，所以，在复制时，须了解到：</p>
<pre><code>a、是否需要完整的保留来源档案的信息？

b、来源档案是否为连结档 (symbolic link file)？

c、来源档是否为特殊的档案，例如 FIFO, socket 等？

d、来源文件是否为目录？

rm (移除档案或目录)

[root@localhost tmp]# rm -i bashrc  &lt;==加上 -i 选项便会主动询问，避免删除到错误的档名！

[root@localhost tmp]# rm -i bashrc* &lt;==通过通配符『*』的帮忙，将/tmp底下开头为bashrc的档名通通删除。通配符『*』代表的是 0 到无穷多个任意字符。</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[IDEA属性及插件配置]]></title>
        <id>https://philosopherzb.github.io/post/idea-shu-xing-ji-cha-jian-pei-zhi/</id>
        <link href="https://philosopherzb.github.io/post/idea-shu-xing-ji-cha-jian-pei-zhi/">
        </link>
        <updated>2021-04-10T11:34:42.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本章主要简述IDEA常用的一些配置以及相关插件，搭配使用或可提升编码效率。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/valley-90388_1280.jpg" alt="" loading="lazy"></figure>
<h2 id="idea统一设置">IDEA统一设置</h2>
<p>为保证大家有统一的代码规范和IDE行为，现对IDEA的设置进行统一说明。需要指出的是，下列的IDEA设置，均在默认设置的基础上进行个性化变更的。</p>
<p>使用IDEA的自动格式化，对所有源文件以及配置文件进行格式化后提交。（IDEA默认的快捷键为：Ctrl + Alt + L，mac系统为:command + option + L）。</p>
<p>使用IDEA的优化导入类和包进行import语句的合理排列。（IDEA的默认快捷键为：Ctrl + Alt + O，mac系统为:command + option + O）。</p>
<h3 id="配置类">配置类</h3>
<p>配置类的设置入口为File-&gt;Settings,下面所说的所有配置，都是在这个菜单下进行的。</p>
<h4 id="导包优化配置">导包优化配置</h4>
<p>进行优化导入包时，可能会出现几个通包路径下的类出现折叠成*的情况，这是违反通用编码规约的（存在导错包的情形）。因此，在进行导包优化之前，请设置IDEA的自动折叠功能为999，如下图所示：</p>
<p>依次进入Editor-&gt;Code Style-&gt;Java 将Class count to use import ‘*’这一项后面的数值改为999</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301031.png" alt="img" loading="lazy"></figure>
<h4 id="文件编码配置">文件编码配置</h4>
<p>依次进入Editor-&gt;File Encodings，将所有字符集设置，调整为UTF-8，并且将UTF-8的pom设置为no pom，如下图：</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301032.png" alt="img" loading="lazy"></figure>
<h4 id="换行符统一配置">换行符统一配置</h4>
<p>统一使用Unix风格的换行符，找到Editor-&gt;Code Style-&gt;Line separator，设置成Unix and OS X(\n)</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301033.png" alt="img" loading="lazy"></figure>
<h4 id="个性化配置">个性化配置</h4>
<p>一些个性化的简单配置。</p>
<h5 id="字体配置如下editor-font">字体配置如下Editor-&gt;Font：</h5>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301034.png" alt="" loading="lazy"></figure>
<h5 id="git配置如下version-control-git需要事先安装git找到对应的bin目录即可">git配置如下Version Control-&gt;Git(需要事先安装git，找到对应的bin目录即可)：</h5>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301035.png" alt="" loading="lazy"></figure>
<h5 id="序列化时未引入序列化id报警配置如下editor-inspections">序列化时未引入序列化id报警配置如下Editor-&gt;Inspections：</h5>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301036.png" alt="" loading="lazy"></figure>
<p>类头自动加载注释配置如下Editor-&gt;File and Code Templates：</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301037.png" alt="img" loading="lazy"></figure>
<h3 id="插件类">插件类</h3>
<p>为简化开发步骤，并且让大家在沟通一些插件功能时，可以用统一的语言，现对开发时使用的基本插件进行下列约定，请开发前，在IDEA中安装下列插件。</p>
<h4 id="lombok插件">Lombok插件</h4>
<p>开发过程中，编写JavaBean，需要些大量的get set方法，虽然IDEA有快捷键可以生成这些方法，但是对于整体代码的整洁度，多多少少还是有一些影响。</p>
<p>所以，在开发过程中，我们会大量用到Lombok，在编译期自动生成get set方法，equals方法以及hashcode方法。</p>
<p>该插件，可以自动识别@Data等注解，让代码IDEA能够对自动生成的方法进行导航。并且在编写代码时，能够自动对get,set方法进行提示补全。</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301038.png" alt="img" loading="lazy"></figure>
<h4 id="maven-helper插件">Maven Helper插件</h4>
<p>编写pom过程中，总会遇到各种各样的依赖问题，Maven Helper插件，提供了一种mvn dependency:tree之外的解决方案。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301039.png" alt="" loading="lazy"></figure>
<p>安装插件后，在打开pom文件，可以看到多了Dependency Analyzer标签。</p>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301040.png" alt="" loading="lazy"></figure>
<p>可以方便地找到冲突的依赖,并且支持以图形化的形式查看依赖树。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301041.png" alt="img" loading="lazy"></figure>
<h4 id="free-mybatis-plugin插件">Free Mybatis plugin插件</h4>
<p>用于Mybatis接口与xml文件的快速跳转。安装插件后，可以在接口中直接跳转到对应mybatis xml配置文件的对应方法上。</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301042.png" alt="img" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301043.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301044.png" alt="" loading="lazy"></figure>
<h4 id="alibaba-java-coding-guidelines插件">Alibaba Java Coding Guidelines插件</h4>
<p>使用“Alibaba Java Coding Guidelines”，插件，对工程下所有代码进行扫描。一期暂定消除所有Blocker与Critial的错误，同时Major的错误不得超过50个。</p>
<p>在有些情况下，必然会产生警告（比如无法避免的泛型转原始类型），在确认不会产生意外错误时，使用@SuppressWarning 来抑制警告。若如此做，代码评审时，会对此注解进行重点关注。所以务必确保该注解不被滥用。</p>
<figure data-type="image" tabindex="16"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301045.png" alt="" loading="lazy"></figure>
<p>直接右击项目，选择编码规约扫描</p>
<figure data-type="image" tabindex="17"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301046.png" alt="img" loading="lazy"></figure>
<h4 id="findbugs插件">FindBugs插件</h4>
<p>对工程下所有代码进行扫描，检查存在的bug。<a href="https://plugins.jetbrains.com/plugin/3847-findbugs-idea/versions">点击此处跳转下载页面</a></p>
<figure data-type="image" tabindex="18"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301047.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="19"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301048.png" alt="" loading="lazy"></figure>
<p>find-sec-bugs为FindBugs-IDEA的扩展库，可以增加额外的扫描结果。<a href="https://find-sec-bugs.github.io/download.htm">点击此处跳转下载页面</a></p>
<figure data-type="image" tabindex="20"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301049.png" alt="img" loading="lazy"></figure>
<h4 id="visualvm-launcher插件">VisualVM Launcher插件</h4>
<p>运行java程序的时候启动visualvm，方便查看jvm的情况 比如堆内存大小的分配</p>
<p>某个对象占用了多大的内存，jvm调优必备工具。</p>
<figure data-type="image" tabindex="21"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301050.png" alt="" loading="lazy"></figure>
<p>配置如下：</p>
<figure data-type="image" tabindex="22"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301051.png" alt="" loading="lazy"></figure>
<p>使用如下：</p>
<figure data-type="image" tabindex="23"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301052.png" alt="img" loading="lazy"></figure>
<h4 id="jclasslib插件">jclasslib插件</h4>
<p>查看java字节码插件，相比于命令行的javap -v className更加方便。直接在idea的插件中搜索并下载即可。</p>
<figure data-type="image" tabindex="24"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301053.png" alt="" loading="lazy"></figure>
<p>使用时，先选择需要查看字节码的java类，之后选择View -&gt; Show Bytecode With jclasslib即可打开字节码视图。</p>
<figure data-type="image" tabindex="25"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301054.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="26"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301055.png" alt="img" loading="lazy"></figure>
<h4 id="bashsupport插件">bashsupport插件</h4>
<p>支持bash编码，智能提示。</p>
<figure data-type="image" tabindex="27"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301056.png" alt="" loading="lazy"></figure>
<p>配置启动项，选择git安装目录中的bash.exe即可。</p>
<figure data-type="image" tabindex="28"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301057.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="29"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301058.png" alt="" loading="lazy"></figure>
<p>编写完成后，直接右击run便可看到执行结果。</p>
<figure data-type="image" tabindex="30"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301059.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
</feed>