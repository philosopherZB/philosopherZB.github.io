<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="Philosopher blog">
<meta name="description" content="WORLD AS CODE">
<meta name="theme-color" content="#000">
<title>Philosopher</title>
<link rel="shortcut icon" href="/favicon.ico?v=1678949797844">
<link rel="stylesheet" href="/media/css/pisces.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/default.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/media/js/jquery.js"></script>
<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>






</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="pisces">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>Philosopher</span>
            </a>  
          
        </div>
        
          <p class="subtitle">WORLD AS CODE</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item nav-item-active">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友链
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout pisces ">
      <div class="section-layout-wrapper">
        <div id="sidebarMeta" class="sidebar">
    
<div class="sidebar-wrapper box-shadow-wrapper bg-color">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">Philosopher</p>
    
    <div class="site-description right-motion">
      
      
      
        <p>world-as-code</p>
      
      
    </div>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">31</span>
        <span class="site-item-stat-name language" data-lan="article">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name language" data-lan="category">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name language" data-lan="tag">标签</span>
      </a>
    </div>
  </div>
  
    
      <div class="sidebar-item">
        <span class="site-item-rss">
            <i class="fa fa-rss"></i>
            <a href="https://philosopherzb.github.io/atom.xml" target="_blank">RSS</a>
        </span>
      </div>
    
  
  



</div>
</div>
<script>
  let sidebarMeta = document.querySelector('#sidebarMeta');
  let scheme = 'pisces';
  let sidebarWrapper = document.querySelector('.sidebar-wrapper');
  if (sidebarMeta && (scheme === 'pisces' || scheme === 'gemini')) {
    document.addEventListener('scroll', function(e) {
      if (document.scrollingElement.scrollTop > parseInt(sidebarMeta.style.marginTop) + 10) {
        sidebarWrapper.classList.add('home-sidebar-fixed')
      } else {
        sidebarWrapper.classList.remove('home-sidebar-fixed')
      }
    });
  }
  </script>
        <div class="section-box pisces">
          <section class="section bg-color posts-expand slide-down-in">
            
  <article class="post-list-box  post box-shadow-wrapper">
    <div class="article-wrapper bg-color">
      <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://philosopherzb.github.io/post/java-ji-chu-zhi-shi/">
      Java基础知识
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2020-10-14 15:12:00">2020-10-14</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://philosopherzb.github.io/tag/DzLW6IbZ3/">
        <span>java</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>5<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>1191<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
      <div class="post-body">
        
        
          
            <!-- 没有手动摘要切开启了自动摘要,则根据配置筛除摘要内容 -->
            
            
              
              
              
            
              
              
              
            
              
              
              
            
            
              <p><h2 id="前言">前言</h2>
<p>本章主要简述Java中面向对象的三大特性，基本数据结构，六大基本原则。作为博客的第一篇文章，略显简单，不过对于我而言，却是向前迈出了一大步。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/flowers-g5952415a3_1280.jpg" alt="img" loading="lazy"></figure>

                
              <p>
            
          
        
        
        <div class="post-button text-center">
          <a class="btn language" data-lan="read-more" href="https://philosopherzb.github.io/post/java-ji-chu-zhi-shi/" rel="contents">
            阅读全文 »
          </a>
        </div>
        
      </div>
      
        <footer class="post-footer">
          <div class="post-eof"></div>
        </footer>
      
    </div>
  </article>
  
            
            
<div class="page bg-color">
  <ul class="pagination-ul">
    
      <li class="pagination-dir">
        <a href="https://philosopherzb.github.io/page/3/">
          <i class="fa fa-angle-left"></i>
        </a>
      </li>
    
    
      
        <li class="pagination-li ">
            <a href="/page/../">
              1
            </a>
        </li>
      
        <li class="pagination-li ">
            <a href="/page/2">
              2
            </a>
        </li>
      
        <li class="pagination-li ">
            <a href="/page/3">
              3
            </a>
        </li>
      
        <li class="pagination-li pagination-active">
            <a href="/page/4">
              4
            </a>
        </li>
      
    
    
  </ul>
</div>
          </section>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <span id="busuanzi_container_site_pv">浏览数 <span id="busuanzi_value_site_pv"></span> 次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">访客数 <span id="busuanzi_value_site_uv"></span> 人</span>
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> ©2019 | Theme By <a
        href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      
    </div>
  </footer>
  
  
  <div class="pisces back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
  
  <div class="bg-img">
    <img src="https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/1580483397838.jpeg" />
  </div>
  
  
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
    back2TopText = document.querySelector('#back_to_top_text'),
    drawerBox = document.querySelector('#drawer_box'),
    rightSideBar = document.querySelector('.sidebar'),
    viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {

    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener('scroll', function (e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });


  let hasCacu = false;
  window.addEventListener('resize', function (e) {
    calcuHeight();
  });

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      jQuery.Velocity(rightSideBar, 'stop');
      jQuery.Velocity(viewport, 'stop');
      jQuery.Velocity(rightMotions, 'stop');
      if (open) {
        jQuery.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function () {
            jQuery.Velocity(rightMotions, transitionDir, {});
          }
        })
        jQuery.Velocity(viewport, openProp, {
          duration: MOTION_TIME
        });
      } else {
        jQuery.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function () {
            jQuery.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        jQuery.Velocity(viewport, closeProp, {
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'true'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target", "_blank");
      }
    })
  }

  let faSearch = document.querySelector('#fa_search');
  faSearch && faSearch.addEventListener('click', function () {
    document.querySelector('#search_mask').style = ''
  })

  // 代码高亮
  hljs.initHighlightingOnLoad();
  
  // 离开当前页title变化
  var leaveTitle = "";
  if (leaveTitle) {
    document.addEventListener('visibilitychange', function () {
      if (document.visibilityState == 'hidden') {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }

</script>

<link rel="stylesheet" href="/media/css/jquery.fancybox.css" />
<script src="/media/js/jquery.fancybox.js"></script>

<script>
  let images = document.querySelectorAll('.section img');
  images.forEach(image => {
    var parent = image.parentElement;
    var next = image.nextElementSibling;
    parent.removeChild(image);
    var aelem = document.createElement('a');
    aelem.href = image.src;
    aelem.dataset['fancybox'] = 'images';
    aelem.dataset['rel'] = 'fancybox-button';
    aelem.classList.add('fancybox');
    aelem.appendChild(image);
    parent.insertBefore(aelem, next);
  })
</script>

  </div>
</body>

<div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/kafka-shen-ru-li-jie-zhi-broker-qing-qiu-liu-cheng/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述kafka broker请求流程。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/nature-21474001_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;broker请求流程详解&#34;&gt;Broker请求流程详解&lt;/h2&gt;
&lt;h3 id=&#34;reactor-模型&#34;&gt;Reactor 模型&lt;/h3&gt;
&lt;p&gt;在介绍kafka的broker通信前，有必要简述一下reactor(响应式)模型。Reactor核心是基于事件驱动（IO多路复用），整体架构流程图如下所示(源自Doug Lea)：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230316001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;整个模型中所有的输入都由一个Reactor进行接受，随后通过一个dispatch loop（即acceptor）轮询将事件推送至不同的工作线程处理器进行相关逻辑处理。&lt;/li&gt;
&lt;li&gt;在这个架构中，Acceptor 线程只是用来进行请求分发，所以非常轻量级，因此会有很高的吞吐量。而那些工作线程则可以根据实际系统负载情况动态的调节系统负载能力，从而达到请求处理的平衡性。&lt;/li&gt;
&lt;li&gt;多核处理时，还可以针对reactor进行池化处理(pool)，来提高IO效率。在此过程中，每个Reactor都有自己的选择器，线程处理器及分发轮询器，由主acceptor将数据分发给其他reactors。如下图所示：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230316002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;broker-处理流程&#34;&gt;Broker 处理流程&lt;/h3&gt;
&lt;p&gt;在kafka中，集群中的每个broker都面临着巨量的网络请求，这个时候如果使用单线程或者多线程进行网络连接处理，那吞吐量将难以达到期望值。此时，上文所说的reactor模型便有了应用场景。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230316003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在Kafka的架构中，会有很多客户端向Broker端发送请求，Kafka 的 Broker 端有个 SocketServer 组件，主要负责和客户端建立连接，并将相关请求通过Acceptor转发给对应的处理器线程池；而网络连接池(RequestHandlerPool)则主要负责真实的逻辑处理。&lt;/p&gt;
&lt;p&gt;SocketServer 组件是 Kafka 超高并发网络通信层中最重要的子模块。它包含 Acceptor 线程、Processor 线程和 RequestChannel 等对象，都是网络通信的重要组成部分。它主要实现了 Reactor 设计模式，用来处理外部多个 Clients（这里的 Clients 可能包含 Producer、Consumer 或其他 Broker）的并发请求，并负责将处理结果封装进 Response 中，返还给 Clients。&lt;/p&gt;
&lt;p&gt;其中Acceptor 线程采用轮询的方式将入站请求公平地发到所有网络线程中，网络线程池默认大小是 3个，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求，可以通过Broker 端参数 num.network.threads（可适当的设置为CPU核数*2，这个值过低时可能会出现因网络空闲太低而缺失副本。）来进行修改。&lt;/p&gt;
&lt;p&gt;关于网络线程处理流程如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230316004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;当网络线程拿到请求后，会将请求放入到一个共享请求队列中。Broker 端还有个 IO 线程池，负责从该队列中取出请求，执行真正的处理。如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。&lt;/p&gt;
&lt;p&gt;IO 线程池中的线程负责执行具体的请求逻辑，默认是8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求，可以通过Broker 端参数 num.io.threads（可设置为broker磁盘个数*2）调整。&lt;/p&gt;
&lt;p&gt;Purgatory组件是用来缓存延时请求（Delayed Request）的。比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 acks=all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。&lt;/p&gt;
&lt;h4 id=&#34;socketserver&#34;&gt;SocketServer&lt;/h4&gt;
&lt;p&gt;负责管理Acceptor 线程、Processor线程和 RequestChannel等对象。&lt;/p&gt;
&lt;p&gt;源码地址：&lt;a href=&#34;https://github.com/apache/kafka&#34;&gt;点击此处跳转github-kafka源码地址&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 文件地址：core/src/main/scala/kafka/network/SocketServer.scala
class SocketServer(val config: KafkaConfig,
                   val metrics: Metrics,
                   val time: Time,
                   val credentialProvider: CredentialProvider,
                   val apiVersionManager: ApiVersionManager)
  extends Logging with KafkaMetricsGroup with BrokerReconfigurable {
  // 共享队列长度，即网络阻塞之前可容纳的等待数。由broker端的queued.max.requests参数控制，默认值500
  private val maxQueuedRequests = config.queuedMaxRequests

  private val nodeId = config.brokerId

  private val logContext = new LogContext(s&amp;quot;[SocketServer listenerType=${apiVersionManager.listenerType}, nodeId=$nodeId] &amp;quot;)

  this.logIdent = logContext.logPrefix

  private val memoryPoolSensor = metrics.sensor(&amp;quot;MemoryPoolUtilization&amp;quot;)
  private val memoryPoolDepletedPercentMetricName = metrics.metricName(&amp;quot;MemoryPoolAvgDepletedPercent&amp;quot;, MetricsGroup)
  private val memoryPoolDepletedTimeMetricName = metrics.metricName(&amp;quot;MemoryPoolDepletedTimeTotal&amp;quot;, MetricsGroup)
  memoryPoolSensor.add(new Meter(TimeUnit.MILLISECONDS, memoryPoolDepletedPercentMetricName, memoryPoolDepletedTimeMetricName))
  private val memoryPool = if (config.queuedMaxBytes &amp;gt; 0) new SimpleMemoryPool(config.queuedMaxBytes, config.socketRequestMaxBytes, false, memoryPoolSensor) else MemoryPool.NONE
 
   // data-plane
  // 处理数据面请求的 processor线程池 
  private val dataPlaneProcessors = new ConcurrentHashMap[Int, Processor]()
  // 处理数据面请求的 acceptor线程池，一个监听器对应一个acceptor线程
  private[network] val dataPlaneAcceptors = new ConcurrentHashMap[EndPoint, Acceptor]()
  // 处理数据面的requestChannel对象
  val dataPlaneRequestChannel = new RequestChannel(maxQueuedRequests, DataPlaneMetricPrefix, time, apiVersionManager.newRequestMetrics)
  
  // control-plane
  // 处理控制面请求的 processor，只一个
  private var controlPlaneProcessorOpt : Option[Processor] = None
  // 处理控制面请求的 acceptor，只一个
  private[network] var controlPlaneAcceptorOpt : Option[Acceptor] = None
  // 处理控制面的requestChannel对象
  val controlPlaneRequestChannelOpt: Option[RequestChannel] = config.controlPlaneListenerName.map(_ =&amp;gt;
    new RequestChannel(20, ControlPlaneMetricPrefix, time, apiVersionManager.newRequestMetrics))

  private var nextProcessorId = 0
  val connectionQuotas = new ConnectionQuotas(config, time, metrics)
  private var startedProcessingRequests = false
  private var stoppedProcessingRequests = false

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;requestchannel&#34;&gt;RequestChannel&lt;/h4&gt;
&lt;p&gt;负责管理Processor，并作为传输request和response的中转站。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 文件地址：core/src/main/scala/kafka/network/RequestChannel.scala
class RequestChannel(val queueSize: Int,
                     val metricNamePrefix: String,
                     time: Time,
                     val metrics: RequestChannel.Metrics) extends KafkaMetricsGroup {
  import RequestChannel._
  // 共享请求阻塞队列
  private val requestQueue = new ArrayBlockingQueue[BaseRequest](queueSize)
  // processor 线程池
  private val processors = new ConcurrentHashMap[Int, Processor]()
  val requestQueueSizeMetricName = metricNamePrefix.concat(RequestQueueSizeMetric)
  val responseQueueSizeMetricName = metricNamePrefix.concat(ResponseQueueSizeMetric)

  newGauge(requestQueueSizeMetricName, () =&amp;gt; requestQueue.size)

  newGauge(responseQueueSizeMetricName, () =&amp;gt; {
    processors.values.asScala.foldLeft(0) {(total, processor) =&amp;gt;
      total + processor.responseQueueSize
    }
  })
  // 添加processor线程 
  def addProcessor(processor: Processor): Unit = {
    if (processors.putIfAbsent(processor.id, processor) != null)
      warn(s&amp;quot;Unexpected processor with processorId ${processor.id}&amp;quot;)

    newGauge(responseQueueSizeMetricName, () =&amp;gt; processor.responseQueueSize,
      Map(ProcessorMetricTag -&amp;gt; processor.id.toString))
  }
  // 删除processor线程 
  def removeProcessor(processorId: Int): Unit = {
    processors.remove(processorId)
    removeMetric(responseQueueSizeMetricName, Map(ProcessorMetricTag -&amp;gt; processorId.toString))
  }

  /** Send a request to be handled, potentially blocking until there is room in the queue for the request */
  // 发送请求到队列中，如果空间不足将会处于阻塞状态
  def sendRequest(request: RequestChannel.Request): Unit = {
    requestQueue.put(request)
  }
  // 关闭连接
  def closeConnection(
    request: RequestChannel.Request,
    errorCounts: java.util.Map[Errors, Integer]
  ): Unit = {
    // This case is used when the request handler has encountered an error, but the client
    // does not expect a response (e.g. when produce request has acks set to 0)
    updateErrorMetrics(request.header.apiKey, errorCounts.asScala)
    sendResponse(new RequestChannel.CloseConnectionResponse(request))
  }

  def sendResponse(
    request: RequestChannel.Request,
    response: AbstractResponse,
    onComplete: Option[Send =&amp;gt; Unit]
  ): Unit = {
    updateErrorMetrics(request.header.apiKey, response.errorCounts.asScala)
    sendResponse(new RequestChannel.SendResponse(
      request,
      request.buildResponseSend(response),
      request.responseNode(response),
      onComplete
    ))
  }

  def sendNoOpResponse(request: RequestChannel.Request): Unit = {
    sendResponse(new network.RequestChannel.NoOpResponse(request))
  }

  def startThrottling(request: RequestChannel.Request): Unit = {
    sendResponse(new RequestChannel.StartThrottlingResponse(request))
  }

  def endThrottling(request: RequestChannel.Request): Unit = {
    sendResponse(new EndThrottlingResponse(request))
  }

  /** Send a response back to the socket server to be sent over the network */
  // 将响应结果发回socket服务，并通过网络传输
  private[network] def sendResponse(response: RequestChannel.Response): Unit = {
    if (isTraceEnabled) {
      val requestHeader = response.request.headerForLoggingOrThrottling()
      val message = response match {
        case sendResponse: SendResponse =&amp;gt;
          s&amp;quot;Sending ${requestHeader.apiKey} response to client ${requestHeader.clientId} of ${sendResponse.responseSend.size} bytes.&amp;quot;
        case _: NoOpResponse =&amp;gt;
          s&amp;quot;Not sending ${requestHeader.apiKey} response to client ${requestHeader.clientId} as it&#39;s not required.&amp;quot;
        case _: CloseConnectionResponse =&amp;gt;
          s&amp;quot;Closing connection for client ${requestHeader.clientId} due to error during ${requestHeader.apiKey}.&amp;quot;
        case _: StartThrottlingResponse =&amp;gt;
          s&amp;quot;Notifying channel throttling has started for client ${requestHeader.clientId} for ${requestHeader.apiKey}&amp;quot;
        case _: EndThrottlingResponse =&amp;gt;
          s&amp;quot;Notifying channel throttling has ended for client ${requestHeader.clientId} for ${requestHeader.apiKey}&amp;quot;
      }
      trace(message)
    }

    response match {
      // We should only send one of the following per request
      case _: SendResponse | _: NoOpResponse | _: CloseConnectionResponse =&amp;gt;
        val request = response.request
        val timeNanos = time.nanoseconds()
        request.responseCompleteTimeNanos = timeNanos
        if (request.apiLocalCompleteTimeNanos == -1L)
          request.apiLocalCompleteTimeNanos = timeNanos
      // For a given request, these may happen in addition to one in the previous section, skip updating the metrics
      case _: StartThrottlingResponse | _: EndThrottlingResponse =&amp;gt; ()
    }

    val processor = processors.get(response.processor)
    // The processor may be null if it was shutdown. In this case, the connections
    // are closed, so the response is dropped.
    if (processor != null) {
      processor.enqueueResponse(response)
    }
  }

  /** Get the next request or block until specified time has elapsed */
  // 在过期时间之前一直阻塞获取下一个请求
  def receiveRequest(timeout: Long): RequestChannel.BaseRequest =
    requestQueue.poll(timeout, TimeUnit.MILLISECONDS)

  /** Get the next request or block until there is one */
  // 一直阻塞获取下一个请求
  def receiveRequest(): RequestChannel.BaseRequest =
    requestQueue.take()

  def updateErrorMetrics(apiKey: ApiKeys, errors: collection.Map[Errors, Integer]): Unit = {
    errors.forKeyValue { (error, count) =&amp;gt;
      metrics(apiKey.name).markErrorMeter(error, count)
    }
  }

  def clear(): Unit = {
    requestQueue.clear()
  }

  def shutdown(): Unit = {
    clear()
    metrics.close()
  }

  def sendShutdownRequest(): Unit = requestQueue.put(ShutdownRequest)

}

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;acceptor-线程&#34;&gt;Acceptor 线程&lt;/h4&gt;
&lt;p&gt;Reactor模型中，有一种重要的Dispatcher角色，主要用来接受外部请求，并进行分发操作；这个角色也被称为Acceptor。在kafka中的，每个broker端的每个SocketServer实例只会创建一个Acceptor线程，这个Acceptor线程主要用来创建连接，并分发请求给Processor线程处理。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 文件地址：core/src/main/scala/kafka/network/SocketServer.scala
private[kafka] class Acceptor(val endPoint: EndPoint,
                              val sendBufferSize: Int,
                              val recvBufferSize: Int,
                              nodeId: Int,
                              connectionQuotas: ConnectionQuotas,
                              metricPrefix: String,
                              time: Time,
                              logPrefix: String = &amp;quot;&amp;quot;) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {

  this.logIdent = logPrefix
  // 创建nio selector对象，用来检查一个或多个NIO Channel的状态是否处于可读、可写
  private val nioSelector = NSelector.open()
  // broker 端创建对应的socketServer channel实例，并注册到selector上。
  val serverChannel = openServerSocket(endPoint.host, endPoint.port)
  // 创建processors 线程池
  private val processors = new ArrayBuffer[Processor]()
  // processors启动标志
  private val processorsStarted = new AtomicBoolean
  // 阻塞状态记录器
  private val blockedPercentMeter = newMeter(s&amp;quot;${metricPrefix}AcceptorBlockedPercent&amp;quot;,
    &amp;quot;blocked time&amp;quot;, TimeUnit.NANOSECONDS, Map(ListenerMetricTag -&amp;gt; endPoint.listenerName.value))
  private var currentProcessorIndex = 0
  private[network] val throttledSockets = new mutable.PriorityQueue[DelayedCloseSocket]()

  // 延迟关闭socket
  private[network] case class DelayedCloseSocket(socket: SocketChannel, endThrottleTimeMs: Long) extends Ordered[DelayedCloseSocket] {
    override def compare(that: DelayedCloseSocket): Int = endThrottleTimeMs compare that.endThrottleTimeMs
  }
  
    /**
   * Accept loop that checks for new connection attempts
   * 循环检查是否有新连接进入，如果有的话就给其分配处理器
   */
  def run(): Unit = {
    // 注册  OP_ACCEPT
    serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)
    // 等待 Acceptor启动完成
    startupComplete()
    try {
      while (isRunning) {
        try {
          // 循环检查是否有可用的新连接  
          acceptNewConnections()
          // 关闭连接
          closeThrottledConnections()
        }
        catch {
          // We catch all the throwables to prevent the acceptor thread from exiting on exceptions due
          // to a select operation on a specific channel or a bad request. We don&#39;t want
          // the broker to stop responding to requests from other clients in these scenarios.
          case e: ControlThrowable =&amp;gt; throw e
          case e: Throwable =&amp;gt; error(&amp;quot;Error occurred&amp;quot;, e)
        }
      }
    } finally {
      debug(&amp;quot;Closing server socket, selector, and any throttled sockets.&amp;quot;)
      CoreUtils.swallow(serverChannel.close(), this, Level.ERROR)
      CoreUtils.swallow(nioSelector.close(), this, Level.ERROR)
      throttledSockets.foreach(throttledSocket =&amp;gt; closeSocket(throttledSocket.socket))
      throttledSockets.clear()
      shutdownComplete()
    }
  }
  
    /**
   * Listen for new connections and assign accepted connections to processors using round-robin.
   * 轮询监听并分配连接给处理器
   */
  private def acceptNewConnections(): Unit = {
    // 每500毫秒获取一次就绪的IO事件  
    val ready = nioSelector.select(500)
    // 如果存在就绪的IO事件
    if (ready &amp;gt; 0) {
      // 获取selector中的key  
      val keys = nioSelector.selectedKeys()
      val iter = keys.iterator()
      while (iter.hasNext &amp;amp;&amp;amp; isRunning) {
        try {
          val key = iter.next
          iter.remove()

          // 如果key可接受数据
          if (key.isAcceptable) {
            // 针对key创建socket连接  
            accept(key).foreach { socketChannel =&amp;gt;
              // Assign the channel to the next processor (using round-robin) to which the
              // channel can be added without blocking. If newConnections queue is full on
              // all processors, block until the last one is able to accept a connection.
              var retriesLeft = synchronized(processors.length)
              var processor: Processor = null
              do {
                retriesLeft -= 1
                // 指定处理线程processor
                processor = synchronized {
                  // adjust the index (if necessary) and retrieve the processor atomically for
                  // correct behaviour in case the number of processors is reduced dynamically
                  currentProcessorIndex = currentProcessorIndex % processors.length
                  processors(currentProcessorIndex)
                }
                // 递增当前处理器索引
                currentProcessorIndex += 1
              } while (!assignNewConnection(socketChannel, processor, retriesLeft == 0))
            }
          } else
            throw new IllegalStateException(&amp;quot;Unrecognized key state for acceptor thread.&amp;quot;)
        } catch {
          case e: Throwable =&amp;gt; error(&amp;quot;Error while accepting connection&amp;quot;, e)
        }
      }
    }
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;processor-线程&#34;&gt;Processor 线程&lt;/h4&gt;
&lt;p&gt;Processor线程负责核心的逻辑处理。&lt;/p&gt;
&lt;p&gt;核心参数说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;newConnections 队列: 是一个阻塞队列，主要用来保存要创建的新连接信息，也就是SocketChannel 对象，其队列长度大小为20(源码中直接硬编码了)。每当 Processor 线程接收到新的连接请求时，都会将对应的 SocketChannel 对象放入队列，等到后面创建连接时，从该队列中获取 SocketChannel，然后注册新的连接。&lt;/li&gt;
&lt;li&gt;inflightResponse 队列：是一个临时的 Response 队列， 当 Processor 线程将 Repsonse 返回给 Client 之后，要将 Response 放入该队列。它存在的意义：由于有些 Response 回调逻辑要在 Response 被发送回 Request 发送方后，才能执行，因此需要暂存到临时队列。&lt;/li&gt;
&lt;li&gt;ResponseQueue 队列：它主要是存放需要返回给Request 发送方的所有 Response 对象。通过源码得知：每个 Processor 线程都会维护自己的 Response 队列。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;  // 文件地址：core/src/main/scala/kafka/network/SocketServer.scala
  private val newConnections = new ArrayBlockingQueue[SocketChannel](connectionQueueSize)
  private val inflightResponses = mutable.Map[String, RequestChannel.Response]()
  private val responseQueue = new LinkedBlockingDeque[RequestChannel.Response]()
  
  override def run(): Unit = {
    // 等待processor线程启动完成  
    startupComplete()
    try {
      while (isRunning) {
        try {
          // setup any new connections that have been queued up
          // 配置新的已就绪连接（将newConnections 里的channel取出来注册到selector中）；
          // 为了确保及时处理现有通道的流量和连接关闭的通知，每次迭代处理的连接数是有限的。
          configureNewConnections()
          // register any new responses for writing
          // selector将response通过网络发出，并将其存入inflightResponses 用作后续调用
          processNewResponses()
          // 执行nio poll，获取socketChannel上已就绪的IO事件
          poll()
          // 将接收到的请求放入request阻塞队列中
          processCompletedReceives()
          // 为了inflightResponses 中成功发送的response执行回调逻辑
          processCompletedSends()
          // 将断开连接的response从inflightResponses 中移除
          processDisconnected()
          // 关闭超过配额限制的连接
          closeExcessConnections()
        } catch {
          // We catch all the throwables here to prevent the processor thread from exiting. We do this because
          // letting a processor exit might cause a bigger impact on the broker. This behavior might need to be
          // reviewed if we see an exception that needs the entire broker to stop. Usually the exceptions thrown would
          // be either associated with a specific socket channel or a bad request. These exceptions are caught and
          // processed by the individual methods above which close the failing channel and continue processing other
          // channels. So this catch block should only ever see ControlThrowables.
          case e: Throwable =&amp;gt; processException(&amp;quot;Processor got uncaught exception.&amp;quot;, e)
        }
      }
    } finally {
      debug(s&amp;quot;Closing selector - processor $id&amp;quot;)
      CoreUtils.swallow(closeAll(), this, Level.ERROR)
      shutdownComplete()
    }
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;kafkarequesthandler-核心逻辑处理器&#34;&gt;KafkaRequestHandler 核心逻辑处理器&lt;/h4&gt;
&lt;p&gt;KafkaRequestHandler 是kafka中真正的逻辑处理代码。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 文件地址：core/src/main/scala/kafka/server/KafkaRequestHandler.scala
// IO线程池
class KafkaRequestHandlerPool(val brokerId: Int,
                              val requestChannel: RequestChannel,
                              val apis: ApiRequestHandler,// 具体逻辑处理器
                              time: Time,
                              numThreads: Int,// 线程数
                              requestHandlerAvgIdleMetricName: String,
                              logAndThreadNamePrefix : String) extends Logging with KafkaMetricsGroup {
   // 可动态扩展
  private val threadPoolSize: AtomicInteger = new AtomicInteger(numThreads)
  /* a meter to track the average free capacity of the request handlers */
  private val aggregateIdleMeter = newMeter(requestHandlerAvgIdleMetricName, &amp;quot;percent&amp;quot;, TimeUnit.NANOSECONDS)

  // 线程数组
  this.logIdent = &amp;quot;[&amp;quot; + logAndThreadNamePrefix + &amp;quot; Kafka Request Handler on Broker &amp;quot; + brokerId + &amp;quot;], &amp;quot;
  val runnables = new mutable.ArrayBuffer[KafkaRequestHandler](numThreads)
  for (i &amp;lt;- 0 until numThreads) {
    createHandler(i)
  }
  
  // 创建IO处理线程，即KafkaRequestHandler
  def createHandler(id: Int): Unit = synchronized {
    runnables += new KafkaRequestHandler(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)
    KafkaThread.daemon(logAndThreadNamePrefix + &amp;quot;-kafka-request-handler-&amp;quot; + id, runnables(id)).start()
  }
  
// IO线程  
class KafkaRequestHandler(id: Int,
                          brokerId: Int,
                          val aggregateIdleMeter: Meter,
                          val totalHandlerThreads: AtomicInteger,
                          val requestChannel: RequestChannel,
                          apis: ApiRequestHandler,
                          time: Time) extends Runnable with Logging {
  this.logIdent = s&amp;quot;[Kafka Request Handler $id on Broker $brokerId], &amp;quot;
  private val shutdownComplete = new CountDownLatch(1)
  private val requestLocal = RequestLocal.withThreadConfinedCaching
  @volatile private var stopped = false

  def run(): Unit = {
    while (!stopped) {
      // We use a single meter for aggregate idle percentage for the thread pool.
      // Since meter is calculated as total_recorded_value / time_window and
      // time_window is independent of the number of threads, each recorded idle
      // time should be discounted by # threads.
      val startSelectTime = time.nanoseconds

      // 从requestChannel获取请求
      val req = requestChannel.receiveRequest(300)
      val endTime = time.nanoseconds
      // 统计线程空闲时间
      val idleTime = endTime - startSelectTime
      // 更新线程空闲百分比指标
      aggregateIdleMeter.mark(idleTime / totalHandlerThreads.get)

      req match {
        // 关闭请求  
        case RequestChannel.ShutdownRequest =&amp;gt;
          debug(s&amp;quot;Kafka request handler $id on broker $brokerId received shut down command&amp;quot;)
          completeShutdown()
          return

        // 正常请求
        case request: RequestChannel.Request =&amp;gt;
          try {
            request.requestDequeueTimeNanos = endTime
            trace(s&amp;quot;Kafka request handler $id on broker $brokerId handling request $request&amp;quot;)
            // 真正开始处理相关逻辑
            apis.handle(request, requestLocal)
          } catch {
            case e: FatalExitError =&amp;gt;
              completeShutdown()
              Exit.exit(e.statusCode)
            case e: Throwable =&amp;gt; error(&amp;quot;Exception when handling request&amp;quot;, e)
          } finally {
            request.releaseBuffer()
          }

        case null =&amp;gt; // continue
      }
    }
    completeShutdown()
  }

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;完整处理流程&#34;&gt;完整处理流程&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;SocketServer 中的Acceptor 线程接受clients的请求。&lt;/li&gt;
&lt;li&gt;Acceptor 线程会创建 NIO Selector 对象及 ServerSocketChannel 实例，并将其与 OP_ACCEPT 事件注册到 Selector 多路复用器上。&lt;/li&gt;
&lt;li&gt;与此同时，Acceptor 线程还会创建默认大小为3的 Processor 线程池，（可通过broker端参数：num.network.threads进行修改） 。&lt;/li&gt;
&lt;li&gt;Acceptor线程开始轮询监听，如果有新的请求对象 SocketChannel 进入，便会将其放入到连接队列中（newConnections），同时会触发一个processor线程进行处理。&lt;/li&gt;
&lt;li&gt;Processor 线程向 SocketChannel 注册 OP_READ/OP_WRITE 事件，同时，轮询获取已就绪的IO事件。&lt;/li&gt;
&lt;li&gt;Processor 线程会根据Channel中获取已经完成的 Receive 对象，构建 Request 对象，并将其存入到 Requestchannel 的 RequestQueue 请求队列中 。&lt;/li&gt;
&lt;li&gt;KafkaRequestHandler 线程循环地从请求队列中获取 Request 实例，然后交由KafkaApis 的 handle 方法，执行真正的请求处理逻辑，并最终将数据存储到磁盘中。&lt;/li&gt;
&lt;li&gt;待处理完请求后，KafkaRequestHandler 线程会将 Response 对象放入 Processor 线程的 Response 队列。&lt;/li&gt;
&lt;li&gt;Processor 线程通过 Request 中的 ProcessorID 不停地从 Response 队列中来定位并取出 Response 对象，并返还给 Request 发送方。&lt;/li&gt;
&lt;/ol&gt;
">kafka深入理解之Broker请求流程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/kafka-shen-ru-li-jie-zhi-ke-yong-xing-yu-chi-jiu-xing-bao-zheng/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述kafka可用性与持久化保证。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-71208_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;kafka体系架构&#34;&gt;kafka体系架构&lt;/h2&gt;
&lt;h3 id=&#34;总览&#34;&gt;总览&lt;/h3&gt;
&lt;p&gt;标准的kafka集群中一般包含多个broker，若干个producer，若干个consumer，以及一个zookeeper集群。&lt;/p&gt;
&lt;p&gt;Kafka 中的message以topic为单位进行归类，producer负责将消息发送到特定的topic（发送到 Kafka 集群中的每一条消息都要指定一个topic），而consumer负责订阅topic并进行消费。&lt;/p&gt;
&lt;p&gt;topic只是一个逻辑上的概念，每个主题都会被划分为多个partition，partition是实际存在的存储介质，消息在单个partition中有序。&lt;/p&gt;
&lt;p&gt;架构图如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;消息传递语义message-delivery-semantics&#34;&gt;消息传递语义（Message Delivery Semantics）&lt;/h3&gt;
&lt;p&gt;关于producer与consumer之间消息传递保证，kafka提供了如下三种语义（需要注意的是，此过程分为发布消息的持久化保证及消费消息的保证）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At most once：消息可能会丢失，但绝不会重传。&lt;/li&gt;
&lt;li&gt;At least once：消息绝不会丢失，但可能会重传。&lt;/li&gt;
&lt;li&gt;Exactly once：每条消息会传递一次且仅有一次，这正是用户真正所需要的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;发送消息持久化保证&#34;&gt;发送消息持久化保证&lt;/h4&gt;
&lt;p&gt;针对发送消息的持久化保证：在 kafka-0.11.0.0 之前，如果生产者没有收到表明消息已提交的响应，那么消息将会被重发，这仅提供了At least once传递语义，因为如果原始请求实际上已经成功，则在重新发送期间消息可能会再次写入日志。&lt;/p&gt;
&lt;p&gt;在 kafka-0.11.0.0 之后，Kafka 生产者开始支持幂等交付选项，以保证重新发送不会导致日志中出现重复条目。 为实现这个目标，broker会为每个生产者分配一个 ID，并使用生产者与每条消息一起发送的序列号对消息进行去重操作。&lt;/p&gt;
&lt;p&gt;同样从 kafka-0.11.0.0 开始，生产者支持使用类似事务(transaction-like)的语义将消息发送到多个主题分区的能力；即，所有消息都已成功写入，或者都没有（原子性）。&lt;/p&gt;
&lt;h4 id=&#34;消费消息的保证&#34;&gt;消费消息的保证&lt;/h4&gt;
&lt;p&gt;关于consumer读取消息时，该如何处理消息和更新位置的几个场景如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;consumer可以读取消息，然后将其位置保存在日志中，最后处理消息。在这种情况下，消费者进程可能会在保存其位置之后但在保存其消息处理的输出之前崩溃，而接管处理的进程却会从保存的位置开始，即使该位置之前的一些消息尚未处理。 这对应于“At most once”语义，因为在消费者失败的情况下，消息可能不会被处理。&lt;/li&gt;
&lt;li&gt;consumer可以读取消息，处理消息，最后保存它的位置。 在这种情况下，消费者进程可能会在处理消息之后但在保存其位置之前崩溃；这样的话，当一个新进程接管它收到的前几条消息时，这些消息实际已经被处理了。这对应于消费者失败情况下的“At least once”语义。 在许多情况下，消息有一个主键，因此更新是幂等的（两次接收相同的消息只会用另一个自身的副本覆盖记录）。&lt;/li&gt;
&lt;li&gt;关于如何保证“Exactly once”，当从 Kafka 主题消费并生产到另一个主题时（如在 Kafka Streams 应用程序中），可以利用上面提到的 kafka-0.11.0.0 中新的事务生产者功能。消费者的位置作为消息存储在主题中，与此同时，在和接收处理数据的输出主题相同的事务中将偏移量写入 Kafka。 如果传输中止，消费者的位置将恢复到其旧值，并且输出主题的生成数据将不会对其他消费者可见，当然，这具体取决于他们的“隔离级别”。 在默认的“read_uncommitted”隔离级别中，所有消息对消费者都是可见的，即使它们是中止事务的一部分，但在“read_committed”中，消费者将只返回来自已提交事务的消息（以及任何非事务消息）。&lt;/li&gt;
&lt;li&gt;写入外部系统时，限制在于需要将消费者的位置与实际存储为输出的内容相协调。实现这一点的经典方法是在存储消费者位置和输出之间引入两阶段提交。但是通过让消费者将其偏移量与其输出存储在同一位置可以让其中的处理更简单与更通用化。这种方式是比较友好的，因为消费者可能想要写入的许多输出系统不支持两阶段提交。举个例子，Kafka Connect 连接器，它将所读取的数据和数据的 offset 一起写入到 HDFS，以保证数据和 offset 都被更新，或者两者都不被更新。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;副本replication&#34;&gt;副本（Replication）&lt;/h3&gt;
&lt;p&gt;kafka为每个主题的分区提供了备份副本功能（可在服务端进行相关配置）；当集群中的某个服务宕机时，副本能够自动进行故障转移，以保证数据的可用性（不丢失，提供容灾能力）。&lt;/p&gt;
&lt;p&gt;创建副本的单位是 topic 的 partition ，正常情况下，每个分区都有一个 leader 和零或多个 followers 。总的副本数包含 leader及followers，被称为副本因子。所有的读写操作都由 leader 处理。一般 partition 的数量都比 broker 的数量多的多，各分区的 leader 均匀的分布在 brokers 中。所有的 followers 节点都同步 leader 节点的日志，日志中的消息和偏移量都和 leader 中的一致。（当然，在任何给定时间，leader 节点的日志末尾时可能有几个消息尚未被备份完成）。&lt;/p&gt;
&lt;p&gt;如下图所示，Kafka 集群中有4个 broker，某个主题中有3个分区，且副本因子（即副本个数）也为3，如此每个分区便有1个 leader 副本和2个 follower 副本。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315005.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;选举算法leader-election&#34;&gt;选举算法（Leader Election）&lt;/h3&gt;
&lt;p&gt;kafka分区的核心便是副本日志（replicated log），这同样也是分布式系统中最重要的基础元素之一（容灾）。&lt;/p&gt;
&lt;p&gt;副本日志按照一系列有序的值（通常是编号为 0、1、2、…) 进行建模。有很多方法可以实现这一点，但最简单和最快的方法是由 leader 节点选择需要提供的有序的值，只要 leader 节点还存活，所有的 follower 只需要拷贝数据并按照 leader 节点的顺序排序。&lt;/p&gt;
&lt;p&gt;理想情况中，如果leader永远存活，那么也就不需要follower了；然而实际生产环境中依旧可能出现机器宕机的场景（随着系统越大，机器越多，概率也将越高）；因此，为了应对这种情形，需要从存活的followers中选择一个新的leader，但是followers本身数据可能会落后于leader或者crash掉，在这种情况下，有必要选择数据最全的follower（up-to-date follower）作为新的leader。&lt;/p&gt;
&lt;p&gt;在这个过程中，有一个基本原则：一条数据如果明确返回给客户端为已提交（committed），则当leader crash掉后出现的新leader必须拥有刚刚已提交过的所有消息。这时候便需要做出权衡：如果leader在表明一条消息已提交（committed）前等待更多的follower进行确认，那么leader宕机后便有更多的follower可以作为新的leader，但与此同时吞吐率也会有所下降。&lt;/p&gt;
&lt;p&gt;一种非常常见的leader election算法便是“Majority Vote”。在这种模式下，假设拥有2f+1个副本（包含leader和follower），如果需要确保f+1个副本收到消息，且在这f+1个副本中选择一个作为新的leader，那么fail的副本不能超过f个。这是因为在f+1个副本中，任意一个都拥有最新的所有备份数据。&lt;/p&gt;
&lt;p&gt;“Majority Vote”有一个非常好的特性：那就是系统的延迟只取决于最快的服务器；当然其劣势便是需要更多的副本来保证数据的完整性（所能允许fail的副本相对太少）。例如：如果要容忍1个follower宕机，那便需要3个及以上副本；如果要容忍2个follower宕机，那便需要5个及以上副本；也就是说，在生产环境下为了保证较高的容错程度，必须要有大量的Replica，而大量的Replica又会在大数据量下导致性能的急剧下降，且这种方式对于资源也过于浪费，毕竟生产资源很珍贵。一般情况下，这种算法用于Zookeeper之类的共享集群配置的系统中而很少在需要存储大量数据的系统中使用。&lt;/p&gt;
&lt;p&gt;实际上，Leader Election算法非常多，比如Zookeeper的Zab, Raft和Viewstamped Replication。而Kafka所使用的Leader Election算法更像微软的PacificA算法。&lt;/p&gt;
&lt;p&gt;kafka采用的选举算法与“Majority Vote”有所不同，它会在zookeeper中动态的维护一组ISR，这些副本基本与leader保持一致（未同步的副本将会被踢出ISR），一般情况下只有ISR中的副本才有机会成为新的leader。&lt;/p&gt;
&lt;p&gt;在这种模式下，对于f+1个副本，一个分区能在保证不丢失已经committed的消息的前提下容忍f个副本发生故障。在大多数应用场景中，这种模式是非常有利的。而在实际中，为了冗余f个副本发生故障，Majority Vote和ISR在commit前需要等待的Replica数量是一样的（例如在一次故障恢复中，“Majority Vote”的 quorum 需要三个备份节点和一次确认，而ISR 需要两个备份节点和一次确认），但是ISR需要的总副本数几乎是Majority Vote的一半。&lt;/p&gt;
&lt;p&gt;关于kafka另一个重要的特性设计便是其并不需要崩溃节点在拥有完好无损的数据下进行恢复，简而言之，kafka允许丢失部分数据（数据不一致性）。&lt;/p&gt;
&lt;p&gt;关于分布式系统中可用性与一致性之间的权衡，往往取决于实际的业务场景需求（如资金类业务需要强一致性，用户活动跟踪只需保证可用性等）。&lt;/p&gt;
&lt;p&gt;当kafka中的发生了all replica die时，它提供了两种恢复性方案（可用性与一致性抉择，不止kafka有此等困境，其余框架一样会遇到这种艰难的选择）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;等待 ISR 中的副本恢复并选择此副本作为新的leader（希望它仍然拥有所有数据）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择第一个恢复过来的副本作为leader（不一定在 ISR 中）。&lt;/p&gt;
&lt;p&gt;第一种方案中，如果等待 ISR 中副本恢复，那么只要这些副本一直处于宕机状态，kafka将始终不可用。如果ISR副本被破坏或它们的数据丢失，kafka便彻底宕机了。&lt;/p&gt;
&lt;p&gt;第二种方案中，如果一个非同步副本从宕机状态中恢复并且允许它成为leader，那么它的数据将成为新的可信任来源，即使它不能保证拥有每条已提交的消息。&lt;/p&gt;
&lt;p&gt;默认情况下，从 kafka-0.11.0.0 版本开始，Kafka 选择第一个策略并倾向于等待一致的副本。可以使用配置属性 unclean.leader.election.enable 更改此行为，以支持正常运行时间优于一致性的用例。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;节点存活与ack机制可用性与持久性&#34;&gt;节点存活与ack机制（可用性与持久性）&lt;/h3&gt;
&lt;p&gt;kafka为节点定义了一个 “in sync” 状态，区别于 “alive” 和 “failed” 。Leader 会追踪所有 “in sync” 的节点。如果有节点挂掉了，或是写超时，或是心跳超时，leader 就会把它从同步副本列表（in sync replicas，缩写为ISR）中移除。同步超时和写超时的时间由 replica.lag.time.max.ms 配置确定。&lt;/p&gt;
&lt;p&gt;kafka定义节点处于“in sync”状态的的条件如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点必须维护和 ZooKeeper 的会话连接，Zookeeper 可以通过心跳机制来检查每个节点的连接。&lt;/li&gt;
&lt;li&gt;如果是 follower 节点，它必须能及时的同步 leader 的写操作，并且延时不能太久。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分布式系统中，kafka只尝试处理 “fail/recover” 模式的故障，即节点突然停止工作，然后又恢复（节点可能不知道自己曾经挂掉）的状况。Kafka 没有处理所谓的 “Byzantine” 故障，即一个节点出现了随意响应和恶意响应（可能由于 bug 或 非法操作导致）。&lt;/p&gt;
&lt;p&gt;当分区上的所有ISR都将消息保存至log中时，该消息可以被视为已提交，只有已提交的消息才会被消费者所消费。这意味着消费者不必担心当leader fail时，可能会看到丢失的消息。&lt;/p&gt;
&lt;p&gt;另一方面，producer可以选择等待或不提交消息，这取决于他们对延迟和持久性之间的权衡，此功能由producer中的ACK机制实现。请注意，主题具有ISR的“最小数量”设置，当生产者请求确认消息已写入完整的ISR集时，会检查该设置。如果生产者请求不那么严格的确认，则可以提交和消费消息，即使同步副本的数量低于最小值（例如，它可以低至仅leader）。&lt;/p&gt;
&lt;p&gt;在任何时候，只要至少有一个同步中的节点存活，kafka中的消息就不会丢失；这保证了在短暂的故障转移后，kafka仍具有可用性，不过在网络分区的场景中，可能无法保持可用。&lt;/p&gt;
&lt;p&gt;关于ack机制如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;acks = 0，如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障）。此配置可以获得最高的吞吐量。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应；一旦消息无法写入leader分区副本(比如网络原因、leader节点崩溃),生产者会收到一个错误响应，当生产者接收到该错误响应之后，为了避免数据丢失，会尝试重新发送数据（前提是配置了重试次数），这种方式的吞吐量取决于使用的是异步发送还是同步发送。在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录依旧会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;acks = all 这意味着leader将等待完整的同步副本（ISR）集以确认记录（此时如果ISR同步副本的个数小于min.insync.replicas的值，消息将不会被写入.），这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，相当于acks = -1的设置。此配置最安全，但延迟相对来说也最高。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;关于最小同步副本配置：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka的Broker端提供了一个参数min.insync.replicas，它明确指定了数据要被同步到多少个副本才算真正的成功写入，此参数一般与acks=all配合使用，可以获得更好的持久性保证。该值默认为1，生产环境设定为一个大于1的值可以提升消息的持久性（例如复制因子为3则可以设置该参数为2）。 因为如果同步副本的数量低于该配置值，则生产者会收到错误响应，从而确保消息不丢失。&lt;/li&gt;
&lt;li&gt;当min.insync.replicas=2且acks=all时，如果此时ISR列表只有[1,2],3被踢出ISR列表，只需要保证两个副本同步了，生产者就会收到成功响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;当min.insync.replicas=2，如果此时ISR列表只有[1],2和3被踢出ISR列表，那么当acks=all时，则不能成功写入数；当acks=0或者acks=1可以成功写入数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315010.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;如果acks=all且min.insync.replicas=2，此时ISR列表为[1,2,3]，这种情况下kafka还是会等到所有的同步副本都同步了消息，才会向生产者发送成功响应的ack。因为min.insync.replicas=2只是一个最低限制，即同步副本少于该配置值，才会抛异常，而acks=all，是需要保证所有的ISR列表的副本都同步了才可以发送成功响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315011.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">kafka深入理解之可用性与持久性保证</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/xiao-xi-dui-lie-yu-kafka/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述消息队列以及kafka整体架构。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-547363_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;消息队列message-queue&#34;&gt;消息队列(message queue)&lt;/h2&gt;
&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;消息队列是一种进程间通信或同一进程的不同线程间的通信方式；针对如今微服务或云架构，则指代服务间的异步通信方式。&lt;/p&gt;
&lt;p&gt;在现代云架构或微服务架构中，应用程序被分解为多个规模较小且易于开发、部署和维护的构建块。消息队列可以为这些分布式应用程序提供通信与协调；同时，消息队列也可以显著的简化分离应用编码，并提高性能、可靠性和可扩展性等。&lt;/p&gt;
&lt;h3 id=&#34;消息投递模式&#34;&gt;消息投递模式&lt;/h3&gt;
&lt;h4 id=&#34;端到端point-to-point&#34;&gt;端到端(Point-to-point)&lt;/h4&gt;
&lt;p&gt;在端到端消息模式中，一条消息将会一直存储在队列中，直到被消费者所接收；且，发送者必须要知道消费者的一些关键信息，例如：将要发送消息的队列名或者特定的队列管理器名。&lt;/p&gt;
&lt;p&gt;此模式中，消息队列将会提供一个临时存储消息的轻量级缓冲区，并允许微服务连接到队列以发送和接收消息的终端节点；这种情况下，消息的规模一般较小，如请求，恢复，错误消息及明文消息等；同时一条消息只能由一个接收者处理一次。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;发布订阅publishsubscribe&#34;&gt;发布订阅(Publish/Subscribe)&lt;/h4&gt;
&lt;p&gt;发布订阅模式中，一条消息由发送者推送至特定的主题(topic)，随后所有订阅了该topic的消费者都将收到同一条广播消息。&lt;/p&gt;
&lt;p&gt;消息主题的订阅者通常会执行不同的功能，并可以同时对消息执行不同的操作。发布者无需知道谁在使用广播的信息，而订阅者也无需知道消息来自哪里。这种消息收发模式与端到端稍有不同，在端到端中，发送消息的组件通常知道发送的目的地。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;消息队列优势&#34;&gt;消息队列优势&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;解耦：在分布式系统中，同一份数据可能要分发给不同的程序进行处理；例如订单生成后，要扣库存，加积分；此时如果由订单服务直接调用库存服务及积分服务的接口，将会让订单服务变得十分臃肿，且不利于后续扩展（比如再加一个支付服务）。这时便可以加入消息队列，采用发布订阅模式，订单服务只需将消息发送至指定topic即可，其他服务选择性订阅。这样便将系统业务进行了解耦操作，增加了系统的可扩展性。&lt;/li&gt;
&lt;li&gt;异步通信：消息队列天然支持异步操作（所有的消息都会存储在队列中，消费者可以延迟处理），针对分布式系统中的异步操作，可采用消息队列进行处理。&lt;/li&gt;
&lt;li&gt;削峰填谷：针对高并发大数据的场景，消息队列可以有效地做到削峰填谷。数据推送高峰时，将由消息队列暂存所有的数据，等到数据推送低谷时，由消费者逐步消费所有的数据。必要时，也可以额外的增加消费者进行数据处理。&lt;/li&gt;
&lt;li&gt;缓冲：消息队列通过一个缓冲层来帮助任务最高效率的执行；写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。&lt;/li&gt;
&lt;li&gt;跨平台：消息队列支持跨平台消息处理，只需要发送者及消费者约定数据格式即可。例如，由Java发送消息，go消费消息。&lt;/li&gt;
&lt;li&gt;灵活性与可扩展性：在高流量期间，可以通过动态的扩展机器来接受更多的消息，防止高并发冲击服务，导致服务挂掉。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka&#34;&gt;kafka&lt;/h2&gt;
&lt;h3 id=&#34;简介-2&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Kafka 是由 Linkedin 公司开发的，它是一个分布式的，支持多分区、多副本，基于 Zookeeper 的消息流平台，它同时也是一款开源的基于发布订阅模式的消息引擎系统；&lt;/p&gt;
&lt;p&gt;Kafka由服务端及客户端组成，且服务端和客户端可以通过高性能的TCP网络协议进行通讯。关于kafka的部署环境，无论本地还是云环境中的裸机，虚拟机或者容器都可以支持。&lt;/p&gt;
&lt;h3 id=&#34;基本术语&#34;&gt;基本术语&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;生产者(Producer)：向kafka中的主题(topic)发布消息事件的客户端应用程序被称为生产者。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消费者(Consumer)：订阅了kafka消息事件所在的主题(topic)的客户端应用程序称为消费者。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;主题(Topic)：用于存储同一类消息事件；打个简单的比喻：主题类似于文件系统中的文件夹，而消息事件则类似于文件夹中的文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消息(Message)：kafka中的数据单元被称为消息，也可以叫记录(record)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;偏移量(Offset)：是一种元数据，且是一个不断递增的整数值；当消费者处理完消息后，将会提交offset+1到broker中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;broker： 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，并为消息设置偏移量，同时持久化消息到磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分区(Partition)：在一个主题中可以存在一个或多个分区，每个分区中消息有序；同一主题中的多个分区可以位于不同机器上，方便后续扩容操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;副本(Replica)：消息的备份称为副本，在创建主题时可以指定副本数量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重平衡(Rebalance)：当消费组(多个消费者将会形成一个消费组)中的某个消费者实例挂掉或者新增一个消费者实例时，其他消费者实例可以自动地重新分配订阅主题，这个过程叫重平衡。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AR与ISR：AR即可分配副本 Assigned Replicas；而所有与leader副本保持一定同步状态的副本（包含leader副本）构成ISR（In-Sync Replicas）；ISR集合是AR集合中的一个子集。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ISR的伸缩：leader 副本负责维护和跟踪 ISR 集合中所有 follower 副本的滞后状态，当 follower 副本落后太多或失效时，leader 副本会把它从 ISR 集合中剔除。如果 OSR（Out-Sync Replicas） 集合中有 follower 副本“追上”了 leader 副本，那么 leader 副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当 leader 副本发生故障时，只有在 ISR 集合中的副本才有资格被选举为新的 leader，而在 OSR 集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。&lt;/p&gt;
&lt;p&gt;replica.lag.time.max.ms ： 这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔，默认10s。&lt;/p&gt;
&lt;p&gt;unclean.leader.election.enable：是否允许 Unclean 领导者选举。开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;HW与LW：HW（High Watermark）俗称高水位，它标识了一个特定的偏移量(offset)，消费者只能拉取此偏移量之前的数据；LW（Low Watermark）俗称低水位，它同样标识了一个特定的偏移量(offset)，一般为AR集合中最小的LSO值；LW值的增长与副本的拉取或删除请求息息相关。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LSO：LSO 是LogStartOffset的缩写，一般情况下，日志文件的起始偏移量 logStartOffset 等于第一个日志分段的 baseOffset，但这并不是绝对的，logStartOffset 的值可以通过 DeleteRecordsRequest 请求(比如使用 KafkaAdminClient 的 deleteRecords()方法、使用 kafka-delete-records.sh 脚本、日志的清理和截断等操作）进行修改。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LEO：LEO是 LogEndOffset 的缩写，它标识当前日志文件中下一条待写入消息的 offset，如下图中 offset 为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的 offset 值加1。分区 ISR 集合中的每个副本都会维护自身的 LEO，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314010.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;发送者，broker集群，消费者基本协作结构图&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314011.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314011.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主题剖析结构图&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;一个两节点的 kafka 集群支持的 2 个消费组的四个分区 (P0-P3)。消费者 A 有两个消费者实例，消费者 B 有四个消费者实例。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;基本特性&#34;&gt;基本特性&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;高吞吐、低延迟：收发消息快是kafka最重要的特性之一，即使在非常廉价的机器上，kafka也可以轻松达到每秒几十万条消息的传输速率，且此过程中最低延迟仅有几毫秒；一般可以用来做实时日志聚合。&lt;/li&gt;
&lt;li&gt;持久化：kafka中的所有消息都会被其持久化存储在文件系统中；在这个过程中，kafka采用顺序写磁盘及直接写页缓存的机制提高IO效率（顺序写磁盘的速度接近于随机写内存的速度：&lt;a href=&#34;https://queue.acm.org/detail.cfm?id=1563874&#34;&gt;点击此处跳转文章页面&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;水平扩容(Scale out)：kafka提供分区机制以达到动态扩容的效果，即增加分区数（不支持减少分区操作）；&lt;/li&gt;
&lt;li&gt;分区容错(Partition-tolerance)：即使集群中的某个节点挂掉，kafka仍然可以提供可用性（可用性与一致性间的冲突，kafka目前采用的是ISR机制进行了部分妥协）。&lt;/li&gt;
&lt;li&gt;核心API：Producer API，Consumer API，Streams API，Connect API，Admin API&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;生产者producer&#34;&gt;生产者(Producer)&lt;/h3&gt;
&lt;h4 id=&#34;简介-3&#34;&gt;简介&lt;/h4&gt;
&lt;p&gt;生产者无需经过路由便可将消息发送至主分区所在的服务器上；为了实现这个功能，所有的kafka服务器节点都能够响应这样的元数据请求：哪些服务器存活，主题的主分区位于哪台服务器上。&lt;/p&gt;
&lt;p&gt;对于生产者而言，只需要执行发送请求，消息将会自动根据路由规则分配到不同的分区上。&lt;/p&gt;
&lt;p&gt;消息路由规则：如果指定了 partition，则直接使用；如果未指定 partition 但指定了 key，则通过对 key 的 value 进行hash 选出一个 partition（形如：Math.abs(key.hashCode()) % partitions.size()）； 如果partition 和 key 都未指定，便会轮询选出一个 partition。&lt;/p&gt;
&lt;h4 id=&#34;整体流程架构&#34;&gt;整体流程架构&lt;/h4&gt;
&lt;p&gt;整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程（发送线程）。&lt;/p&gt;
&lt;p&gt;在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator，也称为消息收集器）中。&lt;/p&gt;
&lt;p&gt;Sender 线程负责从 RecordAccumulator 中获取消息并将其发送到 Kafka 中。&lt;/p&gt;
&lt;p&gt;RecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗以提升性能。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230315003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;序列化器&#34;&gt;序列化器&lt;/h5&gt;
&lt;p&gt;生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka；在消费者侧同样需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象。网络传输过程中，序列化是必须的操作。自定义时需要实现org.apache.kafka.common.serialization.Serializer&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package org.apache.kafka.common.serialization;

import org.apache.kafka.common.header.Headers;

import java.io.Closeable;
import java.util.Map;

/**
 * 一个用于转换对象为字节的接口
 *
 * 实现此接口的类应具有不带参数的构造函数
 * 
 * @param &amp;lt;T&amp;gt; Type to be serialized from.
 */
public interface Serializer&amp;lt;T&amp;gt; extends Closeable {

    /**
     * 配置当前类，此方法一般是在创建 KafkaProducer 实例的时候调用的，主要用来确定编码类型。
     * @param configs configs in key/value pairs
     * @param isKey whether is for key or value
     */
    default void configure(Map&amp;lt;String, ?&amp;gt; configs, boolean isKey) {
        // intentionally left blank
    }

    /**
     * 转换数据为字节数组（执行序列化操作）
     * 可以进行编解码，如果 Kafka 客户端提供的几种序列化器都无法满足应用需求，
     * 则可以选择使用如 Avro、JSON、Thrift、ProtoBuf 和 Protostuff 等通用的序列化工具来实现，
     * 或者使用自定义类型的序列化器来实现。  
     *
     * @param topic topic associated with data
     * @param data typed data
     * @return serialized bytes
     */
    byte[] serialize(String topic, T data);

    /**
     * 转换数据为字节数组（执行序列化操作）
     * 可以进行编解码，如果 Kafka 客户端提供的几种序列化器都无法满足应用需求，
     * 则可以选择使用如 Avro、JSON、Thrift、ProtoBuf 和 Protostuff 等通用的序列化工具来实现，
     * 或者使用自定义类型的序列化器来实现。  
     *
     * @param topic topic associated with data
     * @param headers headers associated with the record
     * @param data typed data
     * @return serialized bytes
     */
    default byte[] serialize(String topic, Headers headers, T data) {
        return serialize(topic, data);
    }

    /**
     * 关闭序列化器
     * 注意：此方法必须是幂等的，因为它可能会被多次调用。
     */
    @Override
    default void close() {
        // intentionally left blank
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;分区器&#34;&gt;分区器&lt;/h5&gt;
&lt;p&gt;分区器的作用就是为消息分配partition。如果消息 ProducerRecord 中没有指定 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值；或者依赖轮询分配partition（可参考消息路由规则）。Kafka 中提供的默认分区器是 org.apache.kafka.clients.producer.internals.DefaultPartitioner，它实现了 org.apache.kafka.clients.producer.Partitioner 接口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package org.apache.kafka.clients.producer.internals;

import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.utils.Utils;

import java.util.Map;

/**
 * 默认的分区策略器
 * &amp;lt;ul&amp;gt;
 * &amp;lt;li&amp;gt;如果记录中指定了分区，则直接使用
 * &amp;lt;li&amp;gt;如果未制定分区，但存在key，则基于key的hash值选择一个分区（拥有相同 key 的消息会被写入同一个分区，前提是分区数不会变更）
 * &amp;lt;li&amp;gt;如果分区和key都不存在，则选择在批处理已满时更改的粘性分区（轮询操作）。
 * 
 * See KIP-480 for details about sticky partitioning.
 */
public class DefaultPartitioner implements Partitioner {

    private final StickyPartitionCache stickyPartitionCache = new StickyPartitionCache();

    public void configure(Map&amp;lt;String, ?&amp;gt; configs) {}

    /**
     * 计算将要发送消息的分区
     *
     * @param topic The topic name
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        return partition(topic, key, keyBytes, value, valueBytes, cluster, cluster.partitionsForTopic(topic).size());
    }

    /**
     * 计算将要发送消息的分区
     *
     * @param topic The topic name
     * @param numPartitions The number of partitions of the given {@code topic}
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster,
                         int numPartitions) {
        if (keyBytes == null) {
            return stickyPartitionCache.partition(topic, cluster);
        }
        // 基于key 的hash值选择一个翻去
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }

    public void close() {}
  
    /**
     * 轮询选择分区
     */
    public void onNewBatch(String topic, Cluster cluster, int prevPartition) {
        stickyPartitionCache.nextPartition(topic, cluster, prevPartition);
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;package org.apache.kafka.clients.producer;

import org.apache.kafka.common.Configurable;
import org.apache.kafka.common.Cluster;

import java.io.Closeable;

/**
 * 分区器接口，自定义分区器时，需要实现此接口。
 */
public interface Partitioner extends Configurable, Closeable {

    /**
     * 计算将要发送消息的分区
     *
     * @param topic The topic name
     * @param key The key to partition on (or null if no key)
     * @param keyBytes The serialized key to partition on( or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes The serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);

    /**
     * 关闭分区器时执行相关操作
     */
    public void close();


    /**
     * 通知分区器有一个已创建的新批处理数据。当时用粘性分区器时，次方法会自动为新批处理数据选择一个粘性分区。
     * @param topic The topic name
     * @param cluster The current cluster metadata
     * @param prevPartition The partition previously selected for the record that triggered a new batch
     */
    default public void onNewBatch(String topic, Cluster cluster, int prevPartition) {
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;拦截器&#34;&gt;拦截器&lt;/h5&gt;
&lt;p&gt;生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。自定义时需要实现org.apache.kafka.clients.producer. ProducerInterceptor&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package org.apache.kafka.clients.producer;

import org.apache.kafka.common.Configurable;

/**
 * 一个插件接口，允许拦截（并可能改变）生产者发布到kafka集群中的记记录
*/
public interface ProducerInterceptor&amp;lt;K, V&amp;gt; extends Configurable {
    /**
     * 将消息序列化及分区（如果分区未指定）前对消息进行相关定制化处理。
     * @param record the record from client or the record returned by the previous interceptor in the chain of interceptors.
     * @return producer record to send to topic/partition
     */
    public ProducerRecord&amp;lt;K, V&amp;gt; onSend(ProducerRecord&amp;lt;K, V&amp;gt; record);

    /**
     * 当发送到服务器的记录已被确认，或者在发送到服务器之前发送记录失败时调用此方法。
     * 此方法通常在调用用户callback之前调用
     * 此方法通常运行在 Producer 的 background I/O线程中，因此这个方法中的实现代码逻辑越简单越好，否则会影响消息的发送速度。
     * 
     * This method will generally execute in the background I/O thread, so the implementation should be reasonably fast.
     * Otherwise, sending of messages from other threads could be delayed.
     *
     * @param metadata The metadata for the record that was sent (i.e. the partition and offset).
     *                 If an error occurred, metadata will contain only valid topic and maybe
     *                 partition. If partition is not given in ProducerRecord and an error occurs
     *                 before partition gets assigned, then partition will be set to RecordMetadata.NO_PARTITION.
     *                 The metadata may be null if the client passed null record to
     *                 {@link org.apache.kafka.clients.producer.KafkaProducer#send(ProducerRecord)}.
     * @param exception The exception thrown during processing of this record. Null if no error occurred.
     */
    public void onAcknowledgement(RecordMetadata metadata, Exception exception);

    /**
     * 用于关闭拦截器时执行逻辑，例如清理相关资源等
     */
    public void close();
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;处理顺序&#34;&gt;处理顺序&lt;/h5&gt;
&lt;p&gt;拦截器-&amp;gt;序列化器-&amp;gt;分区器；KafkaProducer 在将消息序列化和计算分区之前会调用生产者拦截器的 onSend() 方法来对消息进行相应的定制化操作。然后生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka。最后可能会被发往分区器为消息分配分区。&lt;/p&gt;
&lt;h3 id=&#34;消费者consumer&#34;&gt;消费者(Consumer)&lt;/h3&gt;
&lt;h4 id=&#34;简介-4&#34;&gt;简介&lt;/h4&gt;
&lt;p&gt;kafka consumer 订阅感兴趣的主题，同时向其所在的主分区发送fetch请求，获取需要进行消费的消息；需要注意的是，此过程中，consumer的每个请求都需要在partition中指定offset，从而消费从offset处开始的message。因此，consumer对offset的控制便尤为重要，可以依此来进行回退重消费操作。&lt;/p&gt;
&lt;h4 id=&#34;关于offset&#34;&gt;关于offset&lt;/h4&gt;
&lt;p&gt;大多数消息系统都在 broker 上保存被消费消息的元数据。也就是说，当消息被传递给 consumer，broker 要么立即在本地记录该事件，要么等待 consumer 的确认后再记录。这是一种相当直接的选择，而且事实上对于单机服务器来说，也没其它地方能够存储这些状态信息。&lt;/p&gt;
&lt;p&gt;由于大多数消息系统用于存储的数据结构规模都很小，所以这也是一个很实用的选择，因为只要 broker 知道哪些消息被消费了，就可以在本地立即进行删除，一直保持较小的数据量。&lt;/p&gt;
&lt;p&gt;然而，此过程中要一直保持broker与consumer的数据一致性不是一件容易的事；例如consumer已消费了数据，但是回执给broker时出现网络错误导致broker没有删除本地记录，这时消息便有可能会重复消费；并且这种记录操作对于broker而言也是一个不小的性能负担（首先对其加锁，确保该消息只被发送一次，然后将其永久的标记为 consumed，以便将其移除）。&lt;/p&gt;
&lt;p&gt;为了应对上述问题，Kafka 使用了完全不同的方式来解决消息丢失问题。&lt;/p&gt;
&lt;p&gt;首先Kafka 的 topic 被分割成了一组完全有序的 partition，其中每一个 partition 在任意给定的时间内只能被每个订阅了这个 topic 的 consumer group中的一个 consumer 消费。这意味着 partition 中 每一个 consumer 的位置仅仅是一个数字，即下一条要消费的消息的 offset。这使得被消费的消息的状态信息相当少，每个 partition 只需要一个数字。这个状态信息还可以作为周期性的 checkpoint。这以非常低的代价实现了和消息确认机制等同的效果。&lt;/p&gt;
&lt;p&gt;这种方式还有一个附加的好处，那就是consumer 可以回退到之前的 offset 来再次消费之前的数据，这个操作违反了队列的基本原则，但事实证明对大多数 consumer 来说这是一个必不可少的特性。 例如，如果 consumer 的代码有 bug，并且在 bug 被发现前已经有一部分数据被消费了，那么 consumer 可以在 bug 修复后通过回退到之前的 offset 来再次消费这些数据。需要注意的是，对于重复消费的消息要保持幂等操作。&lt;/p&gt;
&lt;h4 id=&#34;push-vs-pull&#34;&gt;Push vs Pull&lt;/h4&gt;
&lt;p&gt;关于消息的推送拉取，kafka采用的是：Producer push数据到broker，Consumer从broker pull数据。针对消费者而言，无论是pull-based还是push-based都有各自的优缺点。&lt;/p&gt;
&lt;p&gt;pull-based：数据传输速率由Consumer控制，可防止服务因大量数据冲击而宕机，同时也简化了broker的设计；且，此模式中，Producer可以达到最大化量产消息。当然，其缺点就是如果 broker 中没有数据，consumer 可能会在一个紧密的循环中结束轮询，实际上却是在忙于等待数据的到达。为了避免 busy-waiting，kafka在 pull 请求中加入参数，使得 consumer 在一个“long pull”中阻塞等待，直到数据到来（还可以选择等待给定字节长度的数据来确保传输长度）。&lt;/p&gt;
&lt;p&gt;push-based：消息能最快的被指定消费者所消费，但是相应的broker设计将会更复杂，且数据传输速率过大时，容易冲击消费者服务，导致其宕机无法提供服务。&lt;/p&gt;
">消息队列与kafka</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/kafka-an-zhuang-andshi-yong-andpei-zhi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述kafka安装，使用以及spring-kafka配置信息。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-6278825_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;win10下部署kafka&#34;&gt;Win10下部署kafka&lt;/h2&gt;
&lt;p&gt;主要涉及Java，zookeeper，kafka，步骤如下。&lt;/p&gt;
&lt;h3 id=&#34;java安装&#34;&gt;Java安装&lt;/h3&gt;
&lt;p&gt;JDK下载：&lt;a href=&#34;https://www.oracle.com/java/technologies/javase-downloads.html&#34;&gt;点此此处跳转官网下载页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;安装过程比较简单，基本都是下一步即可，唯一需要注意的是环境变量的设置；安装完后效果如下图所示（注意：Java安装路径不要太深（目录过多），同时文件夹命名不要存在空格，否则将导致kafka部署失败）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314001.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;zookeeper安装&#34;&gt;zookeeper安装&lt;/h3&gt;
&lt;p&gt;下载地址：&lt;a href=&#34;https://zookeeper.apache.org/releases.html&#34;&gt;点击此处跳转官网下载页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;找一个稳定的版本下载即可：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;下载后解压到一个目录：eg: D:\Program\zookeeper\zookeeper-3.4.14&lt;/li&gt;
&lt;li&gt;在zookeeper-3.4.14目录下，新建两个文件夹，并命名(eg: data,log)，(路径：D:\Program\zookeeper\zookeeper-3.4.14\data,D:\Program\zookeeper\zookeeper-3.4.14\log)&lt;/li&gt;
&lt;li&gt;进入Zookeeper设置目录，eg: D:\Program\zookeeper\zookeeper-3.4.14\conf；复制“zoo_sample.cfg”副本并将副本重命名为“zoo.cfg”；在任意文本编辑器（eg：记事本）中打开zoo.cfg；找到并编辑dataDir=D:\Program\zookeeper\zookeeper-3.4.14\data；dataLogDir=D:\Program\zookeeper\zookeeper-3.4.14\log&lt;/li&gt;
&lt;li&gt;进入D:\Program\zookeeper\zookeeper-3.4.14\bin目录，双击zkServer.cmd即可运行zk。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;kafka安装&#34;&gt;kafka安装&lt;/h3&gt;
&lt;p&gt;下载地址：&lt;a href=&#34;http://kafka.apache.org/downloads.html&#34;&gt;点击此处跳转官网下载页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2.8之后kafka支持不依赖zookeeper启动：&lt;a href=&#34;https://kafka.apache.org/quickstart&#34;&gt;点击此处跳转详细说明页面&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314004.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;下载后解压缩。eg: D:\Program\kafka_2.13-2.7.0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建立一个空文件夹 logs. eg: D:\Program\kafka_2.13-2.7.0\logs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进入config目录，编辑 server.properties文件(eg: 用“写字板”打开)。；找到并编辑log.dirs=D:\Program\kafka_2.13-2.7.0\logs；找到并编辑zookeeper.connect=localhost:2181。表示本地运行。(Kafka会按照默认，在9092端口上运行，并连接zookeeper的默认端口：2181)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;运行：命令行下切入D:\Program\kafka_2.13-2.7.0目录，随后执行如下命令即可（注意先开启zookeeper）：.\bin\windows\kafka-server-start.bat .\config\server.properties&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可能存在的报错：&lt;/p&gt;
&lt;p&gt;输入行太长。 命令语法不正确：目录树太深了，减少几个目录即可。&lt;/p&gt;
&lt;p&gt;找不到或无法加载主类 Files\java\jdk8\lib;D:\Program：此错误由目录存在空格所导致。解决：找到D:\Program\kafka_2.13-2.7.0\bin\windows，用编辑器（eg：记事本）打开kafka-run-class.bat，查看配置是否有加上双引号&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314005.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;如果加了双引号仍然无法启动，那可以去查看java安装路径中的文件夹是否存在空格，如果存在，将空格去掉即可。&lt;/p&gt;
&lt;p&gt;启动图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;简单kafka命令&#34;&gt;简单kafka命令&lt;/h2&gt;
&lt;p&gt;部分kafka命令，基于win10（如果非win系统，使用bin目录下的.sh即可）&lt;/p&gt;
&lt;h3 id=&#34;创建topic两个副本-四个分区&#34;&gt;创建topic（两个副本。四个分区）&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 2 --partitions 4 --topic testTopic  
$ bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3 --topic topic_test( Kafka 版本 &amp;gt;= 2.2 支持此方式（推荐）)  
$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;查看topic&#34;&gt;查看topic&lt;/h3&gt;
&lt;p&gt;查看topic列表：kafka-topics.bat --list --zookeeper localhost:2181&lt;/p&gt;
&lt;p&gt;查看topic详情：bin/kafka-topics.sh --zookeeper host12:2181  --describe --topic ltopicName&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
Topic:quickstart-events  PartitionCount:1    ReplicationFactor:1 Configs:
Topic: quickstart-events Partition: 0    Leader: 0   Replicas: 0 Isr: 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;清除Kafka topic下所有消息：kafka-topics.sh --zookeeper zookeeper地址:端口 --delete --topic topic_name&lt;/p&gt;
&lt;h3 id=&#34;删除topic&#34;&gt;删除topic&lt;/h3&gt;
&lt;p&gt;linux：./bin/kafka-topics  --delete --zookeeper 【zookeeper server】  --topic 【topic name】&lt;/p&gt;
&lt;p&gt;win：kafka-topics.bat --delete --zookeeper localhost:2181 --topic testTopic&lt;/p&gt;
&lt;p&gt;如果kafaka启动时加载的配置文件中server.properties没有配置delete.topic.enable=true，那么此时的删除并不是真正的删除，而是把topic标记为：marked for deletion&lt;/p&gt;
&lt;p&gt;彻底删除topic，可以如下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;删除kafka存储目录（server.properties文件log.dirs配置，默认为&amp;quot;/tmp/kafka-logs&amp;quot;）相关topic目录&lt;/li&gt;
&lt;li&gt;登录zookeeper客户端：命令：./bin/zookeeper-client&lt;/li&gt;
&lt;li&gt;找到topic所在的目录：ls /brokers/topics&lt;/li&gt;
&lt;li&gt;找到要删除的topic，执行命令：rmr /brokers/topics/【topic name】即可，此时topic被彻底删除。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230314007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;发送消息至topic&#34;&gt;发送消息至topic&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
This is my first event
This is my second event
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;消费topic消息&#34;&gt;消费topic消息&lt;/h3&gt;
&lt;p&gt;从头开始查看kafka topic下的数据：kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic_name --from-beginning&lt;/p&gt;
&lt;p&gt;按照偏移量查看topic下数据：kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic_name --offset latest --partition 0&lt;/p&gt;
&lt;p&gt;--offset设置偏移量 latest代表最后 ，可以设置区间，不设置结尾的话默认为查询到latest(最后)&lt;/p&gt;
&lt;p&gt;--partition 设置分区 使用偏移量查询时一定要设置分区才能查询&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
This is my first event
This is my second event
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spring-kafka属性配置&#34;&gt;spring-kafka属性配置&lt;/h2&gt;
&lt;p&gt;spring已经封装了kafka，所以在springboot项目中可以非常便捷的集成kafka，引入其依赖，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.kafka&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-kafka&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;${last.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;文档地址：&lt;a href=&#34;https://docs.spring.io/spring-kafka/docs/current/reference/html/&#34;&gt;点击此处跳转官网页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;属性配置：&lt;a href=&#34;https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-application-properties.html#spring.kafka.admin.client-id&#34;&gt;点击此处跳转说明页面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;producer的配置参数&#34;&gt;producer的配置参数&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;#procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
#acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
#acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
#acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，这相当于acks = -1的设置。
#可以设置的值为：all(-1), 0, 1
spring.kafka.producer.acks=1
 
#每当多个记录被发送到同一分区时，生产者将尝试将记录一起批量处理为更少的请求， 
#这有助于提升客户端和服务器上的性能，此配置控制默认批量大小（以字节为单位），默认值为16384
spring.kafka.producer.batch-size=16384
 
#以逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接
spring.kafka.producer.bootstrap-servers
 
#生产者可用于缓冲等待发送到服务器的记录的内存总字节数，默认值为33554432
spring.kafka.producer.buffer-memory=33554432
 
#ID在发出请求时传递给服务器，用于服务器端日志记录
spring.kafka.producer.client-id
 
#生产者生成的所有数据的压缩类型，此配置接受标准压缩编解码器（&#39;gzip&#39;，&#39;snappy&#39;，&#39;lz4&#39;），
#它还接受&#39;uncompressed&#39;以及&#39;producer&#39;，分别表示没有压缩以及保留生产者设置的原始压缩编解码器，
#默认值为producer
spring.kafka.producer.compression-type=producer
 
#key的Serializer类，实现类实现了接口org.apache.kafka.common.serialization.Serializer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
 
#值的Serializer类，实现类实现了接口org.apache.kafka.common.serialization.Serializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
 
#如果该值大于零时，表示启用重试失败的发送次数
spring.kafka.producer.retries
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;consumer的配置参数&#34;&gt;consumer的配置参数&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;#当&#39;enable.auto.commit&#39;为true时，该配置表示消费者offset自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
spring.kafka.consumer.auto-commit-interval;
 
#当Kafka中没有初始偏移量或者服务器上不再存在当前偏移量时该怎么办，默认值为latest，表示自动将偏移重置为最新的偏移量
#可选的值为latest, earliest, none
spring.kafka.consumer.auto-offset-reset=latest;
 
#以逗号分隔的主机：端口对列表，用于建立与Kafka群集的初始连接。
spring.kafka.consumer.bootstrap-servers;
 
#ID在发出请求时传递给服务器;用于服务器端日志记录。
spring.kafka.consumer.client-id;
 
#如果为true，则消费者的偏移量将在后台定期提交，默认值为true(2.3后默认为false)
spring.kafka.consumer.enable-auto-commit=true;
 
#如果没有足够的数据立即满足“fetch.min.bytes”给出的要求，服务器在回答获取请求之前将阻塞的最长时间（以毫秒为单位）
#默认值为500
spring.kafka.consumer.fetch-max-wait;
 
#服务器应以字节为单位返回获取请求的最小数据量，默认值为1，对应的kafka的参数为fetch.min.bytes。
spring.kafka.consumer.fetch-min-size;
 
#用于标识此使用者所属的使用者组的唯一字符串。
spring.kafka.consumer.group-id;
 
#心跳与消费者协调员之间的预期时间（以毫秒为单位），默认值为3000
spring.kafka.consumer.heartbeat-interval;
 
#密钥的反序列化器类，实现类实现了接口org.apache.kafka.common.serialization.Deserializer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
 
#值的反序列化器类，实现类实现了接口org.apache.kafka.common.serialization.Deserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
 
#一次调用poll()操作时返回的最大记录数，默认值为500
spring.kafka.consumer.max-poll-records;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;listener的配置参数&#34;&gt;listener的配置参数&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;#侦听器的AckMode
#当enable.auto.commit的值设置为false时，该值会生效；为true时不会生效
spring.kafka.listener.ack-mode;
 
#在侦听器容器中运行的线程数
spring.kafka.listener.concurrency;
 
#轮询消费者时使用的超时（以毫秒为单位）
spring.kafka.listener.poll-timeout;
 
#当ackMode为“COUNT”或“COUNT_TIME”时，偏移提交之间的记录数
spring.kafka.listener.ack-count;
 
#当ackMode为“TIME”或“COUNT_TIME”时，偏移提交之间的时间（以毫秒为单位）
spring.kafka.listener.ack-time;
&lt;/code&gt;&lt;/pre&gt;
">kafka安装&使用&配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/min-gan-shu-ju-jia-mi-fang-an/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述一种基于云服务的敏感数据加密设计方案。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sunset-1117008_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;h3 id=&#34;需求描述&#34;&gt;需求描述&lt;/h3&gt;
&lt;p&gt;为了防止敏感数据泄露，造成资产损失，故需要对相关数据进行加密处理；同时，允许部分加密数据支持模糊搜索。&lt;/p&gt;
&lt;h2 id=&#34;详细设计&#34;&gt;详细设计&lt;/h2&gt;
&lt;h3 id=&#34;总体设计&#34;&gt;总体设计&lt;/h3&gt;
&lt;p&gt;加密服务提供针对敏感数据存储的加密能力，用于防止因外部或内部安全威胁所导致的数据泄露问题，从而提高数据安全的防护水平。&lt;/p&gt;
&lt;p&gt;基本功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础安全保障：加解密从根本上夯实了数据安全性。对敏感字段加密后，可以有效防止数据库内容被直接盗取。且密钥以租户维度隔离，有效解决应用的水平权限隔离问题。&lt;/li&gt;
&lt;li&gt;数据库内容和密钥存储管理分离：接入方只存储加密数据，不保存密钥。只需接入本产品提供的SDK即可（实现细节将由SDK处理）。这在增强安全系数的同时，也简化了开发者管理、存储密钥的成本。&lt;/li&gt;
&lt;li&gt;安全与服务平滑性兼得：SDK提供智能的、丰富的api可以自动识别数据库中存量密文的版本、自动加密、解密。接入方引入SDK后，可以做到在不停服务的条件下进行密钥升级。&lt;/li&gt;
&lt;li&gt;接入简单便捷：加解密方案不依赖硬件，只需要引入加解密SDK即可，对数据库无特殊要求，使用成本、改造成本低。&lt;/li&gt;
&lt;li&gt;保证数据完整性传输：所有接口都将使用非对称加密RSA进行签名校验，保证了数据的完整性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;整体业务流程&#34;&gt;整体业务流程&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;接入方使用&#34;&gt;接入方使用&lt;/h4&gt;
&lt;p&gt;引入加解密SDK，初始化client后，直接调用对应的函数即可。&lt;/p&gt;
&lt;h4 id=&#34;加解密云服务&#34;&gt;加解密云服务&lt;/h4&gt;
&lt;p&gt;1、允许用户输入应用级别的RSA公私钥，应用公私钥功能：应用使用私钥加签数据，云服务使用公钥验签数据。此值支持变更。&lt;/p&gt;
&lt;p&gt;2、自动生成云服务RSA公私钥，云服务公私钥功能：云服务使用私钥加签数据，应用使用公钥验签数据。此值不支持变更。&lt;/p&gt;
&lt;p&gt;3、自动生成AES密钥（外部获取此值时，将会被RSA加密），此密钥不展示。此值支持变更。&lt;/p&gt;
&lt;p&gt;4、自动生成伪随机码（日期+雪花算法生成），用于验伪操作，客户端需持有此参数并传递。此值支持变更。&lt;/p&gt;
&lt;p&gt;5、自动生成appid，用于唯一标识一个应用（同一个客户允许存在多个appid），云服务前缀+雪花算法生成。&lt;/p&gt;
&lt;p&gt;6、appId加version为组合唯一索引；其中version默认为0，每次变更AES密钥时，version+1。&lt;/p&gt;
&lt;p&gt;7、允许设置过期时间（默认90天），最大有效期（默认120天，必须大于过期时间）；单位：天。主要用于客户端本地缓存的有效时长。&lt;/p&gt;
&lt;p&gt;8、允许设置滑动窗口（默认4）大小及压缩长度（默认3）；用于加密search类型的数据。&lt;/p&gt;
&lt;h3 id=&#34;整体技术方案&#34;&gt;整体技术方案&lt;/h3&gt;
&lt;h4 id=&#34;关于算法&#34;&gt;关于算法&lt;/h4&gt;
&lt;p&gt;对称加密与非对称加密混合使用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;云服务自动生成出一对秘钥pub/pri。将私钥保密，将公钥公开。&lt;/li&gt;
&lt;li&gt;接入方请求云服务时，拿到云服务的公钥pub。&lt;/li&gt;
&lt;li&gt;云服务通过AES计算出一个对称加密的秘钥X。 然后使用应用公钥将X进行加密。&lt;/li&gt;
&lt;li&gt;接入方发送加签请求到云服务获取加密后的秘钥X，云服务对请求进行验签，通过了方才返回秘钥X。&lt;/li&gt;
&lt;li&gt;接入方得到加密后的秘钥X，便可以使用应用私钥解密，得到AES秘钥。&lt;/li&gt;
&lt;li&gt;之后便可以使用AES秘钥进行敏感数据的加解密操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：接入方不需要额外的开发，只需引入云服务SDK，并调用对应的接口即可。&lt;/p&gt;
&lt;h5 id=&#34;rsa&#34;&gt;RSA&lt;/h5&gt;
&lt;p&gt;将用于签名（保证数据完整性）及加密（保证数据安全性）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;开放平台签名算法名称&lt;/th&gt;
&lt;th&gt;标准签名算法名称&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;RSA2&lt;/td&gt;
&lt;td&gt;SHA256WithRSA&lt;/td&gt;
&lt;td&gt;强制要求 RSA 密钥的长度至少为 2048&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RSA&lt;/td&gt;
&lt;td&gt;SHA1WithRSA&lt;/td&gt;
&lt;td&gt;对 RSA 密钥的长度不限制，推荐使用 2048 位以上&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由于计算能力的飞速发展，从安全性角度考虑，云服务推荐使用 SHA256WithRSA 的签名算法。该算法在摘要算法上比 SHA1WithRSA 有更强的安全能力。&lt;/p&gt;
&lt;p&gt;注意避免公私钥混用：不同签名算法的签名密钥是隔离的。由于同时提供了两套签名算法，若选择了特定的签名算法，请保证使用对应的私钥签名，同时使用对应的云服务公钥进行验签。&lt;/p&gt;
&lt;h5 id=&#34;aes&#34;&gt;AES&lt;/h5&gt;
&lt;p&gt;将用于加解密敏感数据，此数据传输时，会被RSA加密保护，算法特性如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;加密算法使用“AES/CBC/PKCS5Padding”&lt;/li&gt;
&lt;li&gt;加密用的初始向量会直接编码到加密数据中, 因此相同数据内容多次加密的结果不同&lt;/li&gt;
&lt;li&gt;不同应用使用不同的秘钥，不同应用间加密数据无法解密（以appId作为区分）&lt;/li&gt;
&lt;li&gt;支持秘钥升级, 密文中会包含加密密文用的秘钥版本，更新后支持老版本密文解密（appId + version 获取唯一AES秘钥）&lt;/li&gt;
&lt;li&gt;传输过程AES秘钥将会被应用RSA公钥加密，返回时需要使用应用RSA私钥解密。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;加密类型&#34;&gt;加密类型&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;phone&lt;/th&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;simple&lt;/th&gt;
&lt;th&gt;search&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;描述&lt;/td&gt;
&lt;td&gt;手机号&lt;/td&gt;
&lt;td&gt;有规律的数字，例如身份证&lt;/td&gt;
&lt;td&gt;普通文本类型&lt;/td&gt;
&lt;td&gt;支持模糊搜索的文本类型&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;1、phone，id为有规律的数字, 其加密算法只支持使用尾号后4位搜索。如13912345678的手机号加密后可用5678搜索。&lt;/p&gt;
&lt;p&gt;2、接入方如果存在phone，id类的加密类型，建议增加一列检索串（创建索引），用于匹配搜索（List&lt;code&gt;&amp;lt;DO&amp;gt;&lt;/code&gt; objects =  SELECT * FROM table WHERE phone=‘encryptedData’）；如果不想增加额外的检索串，也可以在原有的加密手机号字段上建立前缀索引，可缩短一定的模糊匹配查询时间；当然也可以在加密手机号字段上直接建立普通索引，因为加密后的索引串会放在整个加密字符的最前方（List&lt;code&gt;&amp;lt;DO&amp;gt;&lt;/code&gt; objects =  SELECT * FROM table WHERE phone like ‘encryptedData%’）。关于如何截取检索串可在附录中查看。&lt;/p&gt;
&lt;p&gt;3、simple类型只进行加密，不支持模糊搜索。&lt;/p&gt;
&lt;p&gt;4、search类型支持模糊搜索，基本实现原理是根据4位英文字符（半角），2个中文字符（全角）为一个检索条件。将一个字段拆分为多个。&lt;/p&gt;
&lt;p&gt;比如：test123，使用4个字符为一组的加密方式。切割结果为：[test, est1, st12, t123]，第一组 test，第二组est1，第三组st12，第四组 t123… 依次类推，如果需要检索 所有包含 检索条件4个字符的数据 比如：test，加密字符后通过key like “%partial%” 查库。&lt;/p&gt;
&lt;p&gt;因为密文检索开启后 密文长度会膨胀几倍以上，如果没有强需求建议不开启。&lt;/p&gt;
&lt;p&gt;使用这种方式存在一定的代价：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持模糊查询加密方式，产出的密文比较长；&lt;/li&gt;
&lt;li&gt;支持的模糊查询子句长度必须大于等于4个英文/数字，或者2个汉字。不支持过短的查询(出于安全考虑)；&lt;/li&gt;
&lt;li&gt;如果数据本身长度不够4个数字或2个汉字, 则此时输入全文即可搜索.  如: 原始数据为&amp;quot;安&amp;quot;的, 使用&amp;quot;安&amp;quot;调用平台搜索接口即可获取搜索用文本；&lt;/li&gt;
&lt;li&gt;返回的结果列表中有可能有多余的结果，需要增加筛选的逻辑：对记录先解密，再筛选；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;加密格式&#34;&gt;加密格式&lt;/h4&gt;
&lt;p&gt;注意：其中 Index 是检索信息，同一份数据多次加密后的结果都不会变。&lt;/p&gt;
&lt;p&gt;手机号(phone)和身份证(id)格式，其中手机号(phone)分隔符：SEP=$；身份证(id)分隔符：SEP=#&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;Index&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;EncryptedData&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;search类文本，SEP=~&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;EncryptedData&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;Index&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;simple类文本，SEP=~&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;EncryptedData&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;th&gt;SEP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;加密样例&#34;&gt;加密样例&lt;/h4&gt;
&lt;p&gt;加密算法支持模糊搜索(可选)，模糊加密的数据比一般加密更长一些，大概长度扩大 10-15 倍。&lt;/p&gt;
&lt;p&gt;加密数据的示例如下：&lt;/p&gt;
&lt;p&gt;phone(手机号)加密方式，加密类型：phone&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;手机号&lt;/th&gt;
&lt;th&gt;13012345678&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;支持搜索的密文&lt;/td&gt;
&lt;td&gt;$mMHmK1rfa+OZ23eYhO1AUQ==$q6cFTUyW6SuJD2NReTUVBQ==$1$$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;后四位手机号&lt;/td&gt;
&lt;td&gt;5678&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5678检索串&lt;/td&gt;
&lt;td&gt;mMHmK1rfa+OZ23eYhO1AUQ==&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;身份证加密方式，加密类型：id&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;身份证&lt;/th&gt;
&lt;th&gt;200300190002039898&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;支持搜索的密文&lt;/td&gt;
&lt;td&gt;#uJfxXOF0EJ+6V8H51L9rdg==#ao/gDujB17PTObfSjeAOvl/YxmScgYuxQPl2wokwlec=#1##&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;后四位身份证&lt;/td&gt;
&lt;td&gt;9898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9898检索串&lt;/td&gt;
&lt;td&gt;uJfxXOF0EJ+6V8H51L9rdg==&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;普通文本加密方式，加密类型：simple&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;地址&lt;/th&gt;
&lt;th&gt;浙江省杭州市滨江区星耀城&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;支持搜索的密文&lt;/td&gt;
&lt;td&gt;~thzORLtQtSKYQZW2UFvM64bMN5NhDPb8PSRZ5KNLtl3ZJ+sIYfzMN5gxPy7+ba4o~1~&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;支持搜索的文本加密方式，加密类型：search&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;域名&lt;/th&gt;
&lt;th&gt;www.test.hostname.com&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;支持搜索的密文&lt;/td&gt;
&lt;td&gt;~J/7ro/3scxjvrPXFB5+OxxOZdv45iqXbkP4doNfcEAo=~Q9bpt3Na0G8oOwOe1i9y+Eanjg7Tfr5U3vcYuMyC2iZi7ciYfvC+bNP6pS29uUPpo4L3spYx~1~~&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;需要查询的字符&lt;/td&gt;
&lt;td&gt;test.hostname&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test.hostname检索串&lt;/td&gt;
&lt;td&gt;1i9y+Eanjg7Tfr5U3vcYuMyC2iZi7ciYfvC+bNP6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;加密长度&#34;&gt;加密长度&lt;/h4&gt;
&lt;p&gt;加密后由于增加了密文信息, 将比原文要长, 各种常见字段加密后的数据长度参考表如下:&lt;/p&gt;
&lt;p&gt;注: 当发生加密秘钥version字段变更时, 密文长度可能会发生变化. 建议设计字段时在表中字段上加10个左右字符。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据类型&lt;/th&gt;
&lt;th&gt;密文长度（支持搜索）&lt;/th&gt;
&lt;th&gt;密文长度（不支持搜索）（使用simple类型加密）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;phone（手机号）&lt;/td&gt;
&lt;td&gt;54&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;id（身份证为例）&lt;/td&gt;
&lt;td&gt;74&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;文本数据（5字符，全汉字）&lt;/td&gt;
&lt;td&gt;46&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;文本数据（10字符，全汉字）&lt;/td&gt;
&lt;td&gt;86&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;文本数据（20字符，全汉字）&lt;/td&gt;
&lt;td&gt;170&lt;/td&gt;
&lt;td&gt;92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;文本数据（40字符，全汉字）&lt;/td&gt;
&lt;td&gt;334&lt;/td&gt;
&lt;td&gt;176&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;数据库设计&#34;&gt;数据库设计&lt;/h2&gt;
&lt;h3 id=&#34;数据库ddl&#34;&gt;数据库DDL&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;-- DROP TABLE IF EXISTS `tb_app_config_aes`;
CREATE TABLE `tb_app_config_aes`
(
  `id`             bigint(20)  NOT NULL AUTO_INCREMENT COMMENT &#39;自增主键&#39;,
  `app_id`         varchar(64) NOT NULL COMMENT &#39;应用id，用于唯一标识应用；生成规则：云服务前缀+雪花算法生成&#39;,
  `aes_key`        char(24)    NOT NULL COMMENT &#39;aes秘钥,固定长度&#39;,
  `secret_version` bigint(16)  NOT NULL COMMENT &#39;版本号，用于升级aesKey&#39;,
  `is_delete`      tinyint(1)  NOT NULL DEFAULT 0 COMMENT &#39;删除标识，0-未删除，1-已删除&#39;,
  `create_time`    datetime    NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `modify_time`    datetime    NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  PRIMARY KEY (`id`),
  unique key `unique_index_app_id_secret_version` (`app_id`, `secret_version`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8 COMMENT =&#39;AES秘钥配置表&#39;;
  
-- DROP TABLE IF EXISTS `tb_app_config_rsa`;
CREATE TABLE `tb_app_config_rsa`
(
  `id`                         bigint(20)    NOT NULL AUTO_INCREMENT COMMENT &#39;自增主键&#39;,
  `app_id`                     varchar(64)   NOT NULL COMMENT &#39;应用id，用于唯一标识应用；生成规则：云服务前缀+雪花算法生成&#39;,
  `tenant_id`                  varchar(128)  NOT NULL COMMENT &#39;租户id&#39;,
  `tenant_name`                varchar(255)  NOT NULL COMMENT &#39;租户名称&#39;,
  `app_pub_key`                varchar(512)  NOT NULL COMMENT &#39;应用公钥，用于验签接口，同时加密AES秘钥&#39;,
  `das_pub_key`                varchar(512)  NOT NULL COMMENT &#39;云服务公钥，用于接入方验签&#39;,
  `das_pri_key`                varchar(2048) NOT NULL COMMENT &#39;云服务私钥，云服务使用此私钥进行加签&#39;,
  `encrypt_slide_size`         int(3)        NOT NULL DEFAULT 4 COMMENT &#39;滑动窗口大小&#39;,
  `encrypt_index_compress_len` int(3)        NOT NULL DEFAULT 3 COMMENT &#39;密文滑窗压缩长度&#39;,
  `random_num`                 varchar(64)   NOT NULL COMMENT &#39;伪随机码，生成规则：日期+雪花算法生成&#39;,
  `invalid_time`               int(4)        NOT NULL DEFAULT 90 COMMENT &#39;过期时间，单位：天，默认90天&#39;,
  `max_invalid_time`           int(4)        NOT NULL DEFAULT 120 COMMENT &#39;最大有效期，单位：天，默认120天；必须大于invalidTime&#39;,
  `is_delete`                  tinyint(1)    NOT NULL DEFAULT 0 COMMENT &#39;删除标识，0-未删除，1-已删除&#39;,
  `create_time`                datetime      NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
  `modify_time`                datetime      NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
  PRIMARY KEY (`id`),
  unique key `unique_index_app_id` (`app_id`),
  unique key `unique_index_tenant_id` (`tenant_id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8 COMMENT =&#39;RSA秘钥配置表&#39;;

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;附录&#34;&gt;附录&lt;/h2&gt;
&lt;h3 id=&#34;rsa公私钥生成代码-java版&#34;&gt;RSA公私钥生成代码-java版&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;import java.security.KeyPair;
import java.security.KeyPairGenerator;
import java.security.NoSuchAlgorithmException;
import java.security.PrivateKey;
import java.security.PublicKey;
import java.security.SecureRandom;
import java.util.Base64;
 
/**
 * @author philosopherZB
 * @date 2022/1/13
 */
public class GenerateKeyUtils {
    private static KeyPair KEY_PAIR_INSTANCE = null;
    private static String ALGORITHM = &amp;quot;RSA&amp;quot;;
    private static Integer KEY_LENGTH = 2048;
 
    /**
     * 生成默认公钥--algorithm=RSA; keyLength=2048
     *
     * @return publicKey
     * @throws NoSuchAlgorithmException 算法不存在异常
     */
    public static String genDefaultPublicKey() throws NoSuchAlgorithmException {
        return genPublicKey(ALGORITHM, KEY_LENGTH);
 
    }
 
    /**
     * 生成默认私钥--algorithm=RSA; keyLength=2048
     *
     * @return privateKey
     * @throws NoSuchAlgorithmException 算法不存在异常
     */
    public static String genDefaultPrivateKey() throws NoSuchAlgorithmException {
        return genPrivateKey(ALGORITHM, KEY_LENGTH);
    }
 
    /**
     * @param algorithm 标准的算法名: https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html
     * @param keyLength 指定长度
     * @return publicKey
     * @throws NoSuchAlgorithmException 算法不存在异常
     */
    public static String genPublicKey(String algorithm, int keyLength) throws NoSuchAlgorithmException {
        PublicKey publicKey = getKeyPairInstance(algorithm, keyLength).getPublic();
        return Base64.getEncoder().encodeToString(publicKey.getEncoded());
 
    }
 
    /**
     * @param algorithm 标准的算法名: https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html
     * @param keyLength 指定长度
     * @return privateKey
     * @throws NoSuchAlgorithmException 算法不存在异常
     */
    public static String genPrivateKey(String algorithm, int keyLength) throws NoSuchAlgorithmException {
        PrivateKey privateKey = getKeyPairInstance(algorithm, keyLength).getPrivate();
        return Base64.getEncoder().encodeToString(privateKey.getEncoded());
    }
 
    /**
     * getKeyPairInstance
     *
     * @param algorithm 标准的算法名: https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html
     * @param keyLength 指定长度
     * @return KeyPair
     * @throws NoSuchAlgorithmException 算法不存在异常
     */
    private static KeyPair getKeyPairInstance(String algorithm, int keyLength) throws NoSuchAlgorithmException {
        if (KEY_PAIR_INSTANCE == null) {
            KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(algorithm);
            SecureRandom secureRandom = new SecureRandom();
            keyPairGenerator.initialize(keyLength, secureRandom);
            KEY_PAIR_INSTANCE = keyPairGenerator.generateKeyPair();
        }
 
        return KEY_PAIR_INSTANCE;
    }
 
    public static void main(String[] args) throws NoSuchAlgorithmException {
        System.out.println(&amp;quot;publicKey: &amp;quot; + genPublicKey(&amp;quot;RSA&amp;quot;, 2048));
        System.out.println(&amp;quot;privateKey: &amp;quot; + genPrivateKey(&amp;quot;RSA&amp;quot;, 2048));
 
        System.out.println(&amp;quot;default publicKey: &amp;quot; + genDefaultPublicKey());
        System.out.println(&amp;quot;default privateKey: &amp;quot; + genDefaultPrivateKey());
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;检索串提取代码示例-java版&#34;&gt;检索串提取代码示例-java版&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public static String extractIndex(String encryptedData) {
    if (encryptedData == null || encryptedData.length() &amp;lt; 4) {
        return null;
    }
    char sepInData = encryptedData.charAt(0);
    if (encryptedData.charAt(encryptedData.length() - 2) != sepInData) {
        return null;
    }
    String[] parts = StringUtils.split(encryptedData, sepInData);
    if (sepInData == &#39;$&#39; || sepInData == &#39;#&#39;) {
        return parts[0];
    } else {
        return parts[1];
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;sdk使用样例-java版&#34;&gt;SDK使用样例-java版&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    String privateKey = &amp;quot;MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDGbO1R5OQ0Ff27V+k1FuPBnKMqwC3c0HFnAFu0ZUWH5FTyfkMahhsRntg7/uLk2QM1v0rx7kEdd/ExhOs5z68nO8xbyX/YbC+DX/NH3IsvNRrDU+xfpZdnuMT3bjtlGsasTIOK8S3DlHfiGpO4HPgeY7mBfduBaPStmJFLMM4Xpg3piD4r8mmq+2dAIhq6vX8GpwVqap0XLk8TcYY5h8WQ0FTbTSbRUNN/+YHmlwbEJVa+NR8qaUoo75/WHeVgjNlZ8SAfdjMt1oVWmibSiKYDr1JBVZrPD4CjBy6UR9jDrTxTrwmGsvHUzE3ZThPJZvJEWVXHbMCTs4KReUds/UcPAgMBAAECggEAXSsAM5e53wsEXFbm1VquDlax9nzODASDes3cQZPblfcMO+A1OdsGErv25BTGDJYo/6+WTQqF4IRU5991Y2u03kMhrWdrc/84QANpg7B2WfAhZN2e+zoRYU5MjbFgihSMfJJgoXik+FRaBfxcp/JSPlKs47RowNa7LFeawSdlXYxy+eXCouYomGe0aCPACKfHRyBWDRCf+eK/UwXRcmiyHi8hXOa/IfsaBsZNLtHR3rFod4x+hZUoIJAuXpupc2KW4qsK8ImW9BDcx2p2EO6iggw6MZMZkIo7NRHf3aaaLfpVsebjHm5lBF95ptVUP4CFpfoNevn3y09D4nhGjBP7AQKBgQDnZIcX+XJDykYES10jClxKndibhLYN9zNp7FOiin1Sfd5tUux+VXNEocWSMIqz8wuuI6kyrigwa0E2Kis3QANLizsaOu39jCW5kAHFm19txG3IgntPix95qADl9fQAO1Y3Nbh+zL43FH8f0s066L3V9bTvmZ6rN9vf8GF/xHrfLwKBgQDbhuUop370RhFbgN1CIFM6m6gio7pft7NW6YLyn4yXa/vbpw7c7B+c5TA1ru9maaXlF+Sff5WtLVK10czghDOdI0B5qrm62+TEhOEk7C6dgNsCdaHuDzqA2MYEmq4HJhoXrwM+xvzrlCwNZQ1AIRQWKdceKK9YgEnZQXQU9TEeIQKBgQCfPELrcLH9jLlaQzK45mxUvQNPIqjWO4OaJRP5CyzrE8t5mFM/LTbByEHaNKV+6IblM41AXzExAN5DlAlhYB/kYNAvYNZeYY+kf0F4509ojoCuN3z8ZFUot0DG/9cGQc829zUbrXJJHUXOdJbfL0NUdl4pdKIIWcxp81ZlQqT76QKBgHMlCzfKux1XTy1mpydTGzSnhoY8yLoB+dBBhQzLwQt/eUhaFMKuG1rJIANYcXuPOJO0d5dtbU27cyGpHMQ6s3PdlKj8cpTfV9v4MruSIlU8zCM7Hidm13HTwfGSTGu1gYQgqRwZdXn/ayfPdCbJ8uY5JftMrcRG7fVFjqSbgxrhAoGAVPNPW/QOVarHZDCVJi0XtOhl1g6oR51FGkOZ13SEuu8271v0PxcP55Hib6WvCPDOFB75oPaa1HmQs/WL41RCFMlELH/DhwEEkd2hLFmou4AiiB+M2DQODxagyINOx0RGd7FZuhiIWQTocqXj2PV71gkn5q4pIGKLsk1aklLTKXY=&amp;quot;;
    String dasPubKey = &amp;quot;MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAiPNXFw6tQyfpNi63OoR5E+VR+KS4Sy1+1EFNiHTIc/f5AXXZtmo8CVTgAM8X7a2GHLMwRqjH1JZ/2Da9HHn8zHdEtSAbObxMtTKPrnQOG5NrTuA3hfRb/4N00iZZ2KZMr5fTXJ4824VMr2/fQZySwDd0bOPTmrNnlHLu6ErFvfJwjQqbhWVC1VhRkGzvT81O2SM+ALuTnbgoFGqFyaUE9YUP57COA/Hw4Yz+GmQkHxs9ELPvikFSGdBdptDvHQ2dTprskRW8UU/v0XjVED8jeayiqKxJFn2Yejq43eqkH+SV6c9R1jE39qhMyEX7hVvzSMcyvONSo5Za4R5zLqap4wIDAQAZ&amp;quot;;
    // 初始化一次即可（单例模式）
    SecurityClient securityClient =
            new DefaultSecurityClient(&amp;quot;http://127.0.0.1:8999&amp;quot;, &amp;quot;cloud20220209651316091208540160&amp;quot;, privateKey, &amp;quot;20220209651322386368110592&amp;quot;, dasPubKey);
    try {
        // 加密类型: TYPE_PHONE-手机号; TYPE_ID-id; TYPE_SIMPLE-普通加密；TYPE_SEARCH-支持搜索的加密
        // version 为AES版本号，可从云服务中查看
        String encryptData = securityClient.encrypt(&amp;quot;www.test.hostname.com&amp;quot;, SecurityConstants.TYPE_SEARCH, 1L);
        System.out.println(&amp;quot;encryptData: &amp;quot; + encryptData);

        boolean isEncryptData = securityClient.isEncryptData(encryptData, SecurityConstants.TYPE_SEARCH);
        System.out.println(&amp;quot;isEncryptData: &amp;quot; + isEncryptData);

        String decryptData = securityClient.decrypt(encryptData, SecurityConstants.TYPE_SEARCH, 1L);
        System.out.println(&amp;quot;decryptData: &amp;quot; + decryptData);

        String searchData = securityClient.search(&amp;quot;test.hostname&amp;quot;, SecurityConstants.TYPE_SEARCH, 1L);
        System.out.println(&amp;quot;searchData: &amp;quot; + searchData);
    } catch (DasSecurityException e) {
        e.printStackTrace();
    }
}

&lt;/code&gt;&lt;/pre&gt;
">敏感数据加密方案</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/fen-bu-shi-shi-wu-xiang-jie/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述单事务到分布式事务的转变以及对应分布式事务解决方案。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/iceland-1768744_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;事务演变&#34;&gt;事务演变&lt;/h2&gt;
&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;随着业务的不断发展以及业务复杂度的提升，传统单体服务逐渐暴露出了一些问题，如开发效率低、可维护性差、架构扩展难、部署不灵活等。因此，走上分布式微服务是一条必然的道路。&lt;/p&gt;
&lt;p&gt;在分布式中，每个服务便是一个独立的进程，各个服务间可单独迭代，互不影响，甚至可以用不同的语言开发，只需事先定义好对接规范即可。&lt;/p&gt;
&lt;p&gt;分布式很好地解决了单体服务的一些问题，但随之而来的便是一系列分布式难题。本篇将要讲述的便是分布式事务这个问题。&lt;/p&gt;
&lt;h3 id=&#34;本地事务&#34;&gt;本地事务&lt;/h3&gt;
&lt;p&gt;本地事务，一般也被称之为数据库事务。它主要功能是将多条SQL语句当做一个整体来处理，保证这一个整体要么执行成功，要么执行失败。&lt;/p&gt;
&lt;p&gt;比较典型的例子就是转账服务了：A转账100给B，那么对应有A-100和B+100两条语句，事务必须保证这两条语句的整体性，否则就会出现A-100，但B没有增加100的场景。&lt;/p&gt;
&lt;p&gt;上述例子体现了事务的一个重要特性：原子性。事实上，事务具备四个基本特性：原子性，一致性，隔离性，永久性；通常也简称为ACID特性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Atomicity(原子性)：一个事务便是一个整体，是不可再被分隔的最小独立单元；在一个事务中的操作，要么同时成功，要么同时失败，不会存在部分成功，部分失败的场景。&lt;/li&gt;
&lt;li&gt;Consistency(一致性)：在事务开始前以及结束后，数据库的完整性没有被破坏。完整性包括约束、级联、触发器及其任意组合。&lt;/li&gt;
&lt;li&gt;Isolation(隔离性)：数据库允许事务并发执行读写，为了防止出现多个事务并发写导致数据不一致，便有了隔离性。&lt;/li&gt;
&lt;li&gt;Durability(持久性)：事务提交后，数据将会被永久地保存，即使系统故障也不会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;隔离级别：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Isolation Level&lt;/th&gt;
&lt;th&gt;Dirty Reads&lt;/th&gt;
&lt;th&gt;Non-Repeatable Reads&lt;/th&gt;
&lt;th&gt;Phantom Reads&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Read uncommitted&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read committed(Sql server, Oracle)&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Repeatable reads(Mysql)&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Serializable&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Dirty reads：A事务可以读到B事务还未提交的数据。&lt;/li&gt;
&lt;li&gt;Non-repeatable read：A事务读取一行数据，B事务后续修改了这行数据，A事务再次读取这行数据，结果得到的数据不同。&lt;/li&gt;
&lt;li&gt;Phantom reads：A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者删除已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次多/少了一些行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意1：mysql默认使用RR隔离级别，这是由于binlog的格式问题（statement-记录修改的SQL语句,row-记录每行实际数据的变更,mixed-前面两种混合）所导致的，在5.0之前binlog只有statement一种格式，而主从复制时，这会导致数据的不一致。&lt;/p&gt;
&lt;p&gt;注意2：其他数据库选用RC隔离级别，是由于RR隔离级别增加了间隙锁，会增加发生死锁的概率；同时，条件列未命中索引时，会锁全表，RC只会锁行。&lt;/p&gt;
&lt;p&gt;注意3：RC隔离级别下，主从复制需要采用binlog的row格式，基于行的复制，这样不会出现主从不一致问题。&lt;/p&gt;
&lt;h3 id=&#34;分布式事务&#34;&gt;分布式事务&lt;/h3&gt;
&lt;p&gt;随着业务量的增加，单体服务所能承载的数据量越来越多，系统的运行速度逐渐下降，这时候便需要进行服务独立化（微服务）。&lt;/p&gt;
&lt;p&gt;比如跨行转账，或者本行跨服务转账等都是比较典型的分布式场景；这里的每个服务都有自己独立的数据库，为了避免服务不可用，网络连接异常等情造成的数据不一致，分布式事务便应运而生了。&lt;/p&gt;
&lt;p&gt;分布式事务的本质是为了多服务之间事务的正确执行，是对本地事务的一个扩展，但它只遵循部分ACID规范。所以，有必要介绍下分布式事务中的CAP定理与BASE理论。&lt;/p&gt;
&lt;h4 id=&#34;cap定理&#34;&gt;CAP定理&lt;/h4&gt;
&lt;p&gt;在理论计算机科学中，CAP定理(CAP theorem)，又被称为&lt;a href=&#34;https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/&#34;&gt;布鲁尔定理(Brewer&#39;s theorem)&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consistency(一致性)：此处指的是强一致性；它要求分布式系统中一个服务的写操作成功后，其他服务的读操作都是刚刚写入的数据（最新数据）。&lt;/li&gt;
&lt;li&gt;Availability(可用性)：非故障服务节点收到请求后必须给予响应（非最新数据）。&lt;/li&gt;
&lt;li&gt;Partition-tolerance(分区容错性)：分布式系统在遇到任何网络分区故障时，仍然可以对外提供服务，除非整个分布式系统宕机。（ Gilbert and Lync describe partitions: the network will be allowed to lose arbitrarily many messages sent from one node to another）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;网络分区：在分布式系统中，不同的节点分布在不同的子网络中，由于一些特殊的原因，这些子节点之间出现了网络不通的状态，但他们的内部子网络是正常的。从而导致了整个系统的环境被切分成了若干个孤立的区域，这就是分区。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;cap定理验证&#34;&gt;CAP定理验证&lt;/h4&gt;
&lt;p&gt;事实上，在分布式系统中，CAP三者是无法同时存在的，且由于分布式的缘故，分区容灾是必须存在的。&lt;/p&gt;
&lt;p&gt;为了验证CAP定理，假设网络中存在两个节点N1和N2，它们之间网络互通，其中N1上存在服务A和独立数据库D1，N2上存在服务B和独立数据库D2。此时，A和B是分布式系统中的一部分，同时对外提供相关服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性要求A，B服务中的数据是一致的，即D1=D2。&lt;/li&gt;
&lt;li&gt;可用性要求不管是请求A还是B都可以得到确认的响应。&lt;/li&gt;
&lt;li&gt;分区容灾则是指出现网络故障或其他异常场景时，都不会影响A，B之间的正常运行，除非服务本身宕机。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在分布式系统中，网络通信时最常见的，就比如上述N1与N2之间；现在假设N1与N2因网络故障而无法通信，为了支持这种网络异常，即要满足分区容灾，那么如果还要同时满足一致性与可用性是否可行了？&lt;/p&gt;
&lt;p&gt;可以简单模拟一下：当N1与N2断开网络时，一个请求抵达服务A，更新了D1上的一条数据；此时为了一致性要求，需要将该条更新数据同步至服务B上的数据库D2，但由于网络故障，两个服务无法通信，此时便面临两种选择。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;牺牲一致性，保证可用性；当下次请求服务B时响应旧的数据。&lt;/li&gt;
&lt;li&gt;牺牲可用性，保证一致性；阻塞等待网络恢复，将数据更新至服务B。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cap抉择&#34;&gt;CAP抉择&lt;/h4&gt;
&lt;p&gt;CAP三者究竟该如何选择，才能满足业务需求，这是每个分布式系统架构中都需要考虑。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CA(一致性与可用性)：如果选择CA，那么就需要一种非常严格的强一致性协议来进行保障；且，不允许出现网络故障或节点错误，否则整个系统将会不可用。显然，CA不是很适合分布式系统。&lt;/li&gt;
&lt;li&gt;CP(一致性与分区容灾)：CP保证了数据的一致性，但由于P的存在，某些时候一个请求将会被无限延长。&lt;/li&gt;
&lt;li&gt;AP(可用性与分区容灾)：AP保证了可用性，但却丢失了数据的一致性，在某些场景（银行转账服务）中是难以忍受的。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;base理论&#34;&gt;BASE理论&lt;/h4&gt;
&lt;p&gt;由上述CAP定理中可以知道，分布式系统是无法同时满足三者的，只能从中取二。由于分布式系统中网络环境的不可信，分区容灾是必选的；其次可用性保证了用户体验，除开一些需要强一致性的场景(支付，转账等)，应该先选；但如果没有一致性，分布式系统也就失去了存在的意义。&lt;/p&gt;
&lt;p&gt;针对此种场景，可以对CAP中的强一致性做一定的让步，有些时候，我们只关注数据的最终一致性即可。于是，BASE理论便诞生了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basically Available(基本可用)：相对高可用而言，基本可用要求系统即使出现了重大故障，仍然能够提供一些基本型的服务。例如响应时间上的损失以及功能上的损失(熔断，降级)。&lt;/li&gt;
&lt;li&gt;Soft state(软状态)：软状态是相对原子性(硬状态，即多个节点间的数据完全一致)而言的。该状态允许数据存在中间状态，并认为该状态并不影响系统的整体可用性，即允许系统在多个不同节点的数据同步存在一定的延时。（注意：对于软状态,我们允许中间状态存在，但不可能一直是中间状态，必须要有个期限，系统保证在没有后续更新的前提下,在这个期限后,系统最终返回上一次更新操作的值,从而达到数据的最终一致性,这个容忍期限（不一致窗口的时间）取决于通信延迟，系统负载，数据复制方案设计，复制副本个数等，DNS是一个典型的最终一致性系统。）&lt;/li&gt;
&lt;li&gt;Eventually consisten(最终一致性)：相对强一致性而言，最终一致性仅仅要求数据在经过一段合理的延时后（软状态），最终抵达一致即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于最终一致性的变种模型，一般在实践中，五种模式会组合使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因果一致性(Causal consistency)：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。与此同时，和节点A没有因果关系的节点C则没有这样的限制。&lt;/li&gt;
&lt;li&gt;读己所写(Read your writes)：一个节点总能访问自己更新过的最新值，是因果一致性的特定形式。&lt;/li&gt;
&lt;li&gt;会话一致性(session consistency)：系统保证在一个有效的会话中实现读己所写(Read your writes)。&lt;/li&gt;
&lt;li&gt;单调读一致性(Monotonic read consistency)：节点A从系统中读到一个数据项D的某个值V后，节点A后续对数据项D的访问都不会返回比值V更旧的值。&lt;/li&gt;
&lt;li&gt;单调写一致性(Monotonic write consistency)：系统需保证来自同一个节点的写操作被顺序执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;h3 id=&#34;概要-2&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;因为业务的多样性与复杂性，再加上分布式事务解决方案也并未银弹，所以，在实际开发中，应该以本身业务作为作出发点，选择最适合自己的方案。&lt;/p&gt;
&lt;h3 id=&#34;二阶段提交协议&#34;&gt;二阶段提交协议&lt;/h3&gt;
&lt;p&gt;在分布式系统中，为了保证多节点间事务的正确执行，便需要一个协调者来管理参与事务的所有节点，确保操作结果符合执行预期。其中，XA便是一个典型的分布式事务处理协议。&lt;/p&gt;
&lt;p&gt;XA协议是由X/Open组织提出的分布式事务处理规范，它主要定义了(全局)事务管理器TM和(局部)资源管理器RM之间的接口；是通过二阶段提交协议来保证强一致性的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一阶段(prepare)：事务管理者TM(协调者)向资源管理者RM(参与者)发送prepare请求，RM(参与者)进行预提交并将结果响应给TM。&lt;/li&gt;
&lt;li&gt;第二阶段(commit/rollback)：如果所有RM(参与者)预提交结果都为成功，则TM(协调者)向所有RM(参与者)发送commit请求，否则发送rollback请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;二阶段提交协议虽然为强一致性提出了一套解决方案，但需要注意的是，其中也有几个不可忽略的缺点。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同步阻塞：TM(协调者)控制着所有RM(参与者)的操作(准备与实际提交)，这个过程是同步的，TM(协调者)必须等待所有的RM(参与者)返回操作结果才能进行下一步操作；如果在这个过程中有其他请求进来，将会被阻塞。&lt;/li&gt;
&lt;li&gt;单点故障：无论是TM(协调者)还是RM(参与者)发生故障，整个流程都将会陷入无限期等待中。&lt;/li&gt;
&lt;li&gt;数据不一致：极端情况下，prepare成功，但commit出现部分提交，部分宕机，便会导致数据不一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;三阶段提交协议&#34;&gt;三阶段提交协议&lt;/h3&gt;
&lt;p&gt;三阶段提交协议是二阶段提交协议的改良版本，它增加了超时机制用来解决同步阻塞问题；实际上是将第一阶段prepare拆分为canCommit和preCommit两个阶段。&lt;/p&gt;
&lt;p&gt;preCommit阶段，TM(协调者)在发送真正的commit请求之前，会再次检查各个RM(参与者)的状态，以确保它们的状态一致。&lt;/p&gt;
&lt;p&gt;当然，某些极端场景下，同样会出现数据不一致；如：第三阶段的commit出现机器宕机。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310005.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;tcc&#34;&gt;TCC&lt;/h3&gt;
&lt;p&gt;在二阶段提交协议，资源管理者RM负责准备、提交与回滚，而事务管理者TM则负责协调所有RM具体进行哪些操作；资源管理者RM有很多种实现方式，其中TCC(Try-Confirm-Cancel)便是资源管理者的一种服务化的实现。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Try阶段：尝试执行，完成业务检查（一致性），预留业务资源（隔离性）。&lt;/li&gt;
&lt;li&gt;Confirm阶段：真正的执行具体业务操作，保证幂等。&lt;/li&gt;
&lt;li&gt;Cancel阶段：回滚操作，释放try阶段预留的业务资源，保证幂等。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;关于TCC理论及设计可参考：&lt;a href=&#34;https://www.sofastack.tech/blog/seata-tcc-theory-design-realization/&#34;&gt;点击此处跳转文章页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关于TCC使用场景可参考：&lt;a href=&#34;https://www.sofastack.tech/blog/seata-tcc-applicable-models-scenarios/&#34;&gt;点击此处跳转文章页面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;saga&#34;&gt;Saga&lt;/h3&gt;
&lt;p&gt;saga会将一个长事务(long lived transaction)拆分为多个短事务，然后saga自己进行调度管理。saga有点类似于tcc，但是没有try阶段。&lt;/p&gt;
&lt;p&gt;当流程出现异常导致部分事务执行失败时，saga会进行补偿操作。此时saga有两种选择：backward recovery 和 forward recovery。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;逆向恢复(backward recovery)：即回滚操作，将之前所有成功的节点进行回滚，以达到数据一致的目的。&lt;/li&gt;
&lt;li&gt;正向恢复(forward recovery)：根据save-point尽最大努力不断重试，以达到数据一致的目的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;sagas论文地址：&lt;a href=&#34;https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf&#34;&gt;点击此处跳转论文页面&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;重试补偿模式&#34;&gt;重试补偿模式&lt;/h3&gt;
&lt;p&gt;在实际业务开发中，可以针对某些特定的业务添加额外的消息表记录失败信息，后续定时地进行补偿操作。例如京东订单成功后会发送邮件信息，此时可简单的拆分为订单服务与邮件服务，时序图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;开源分布式事务框架&#34;&gt;开源分布式事务框架&lt;/h2&gt;
&lt;h3 id=&#34;rocketmq&#34;&gt;RocketMQ&lt;/h3&gt;
&lt;p&gt;从4.3版本开始提供基于2PC(二阶段提交协议)加补偿机制的分布式事务消息，其中补偿机制主要针对2PC过程超时或失败的场景。可参考：&lt;a href=&#34;http://rocketmq.apache.org/rocketmq/the-design-of-transactional-message/&#34;&gt;点击此处跳转页面&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230310008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;生产者发送半消息(half message)至MQ服务端。&lt;/li&gt;
&lt;li&gt;如果发送半消息成功，则执行本地事务。&lt;/li&gt;
&lt;li&gt;基于本地事务的执行结果发送commit或rollback消息到MQ服务端。&lt;/li&gt;
&lt;li&gt;如果commit/rollback消息丢失或者生产者在执行本地事务时处于pended状态，MQ服务端将会发送检查消息到同组(same group)的每个生产者获取事务消息的状态(CommitTransaction,RollbackTransaction,Unknown)。&lt;/li&gt;
&lt;li&gt;生产者基于本地事务状态恢复commit/rollback消息。&lt;/li&gt;
&lt;li&gt;已提交的消息会被MQ服务端分发给消费者，而回滚类消息则会被丢弃。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意1：半消息(half message)是无法被消费的，因为它位于一个独立的内部half-topic中，对消费者是不可见的；commit过程相当于从half-topic中取出消息进行重新投递。&lt;/p&gt;
&lt;p&gt;注意2：使用事务消息功能将会降低rocketMQ的执行效率，因为写过程被放大了。&lt;/p&gt;
&lt;h3 id=&#34;tcc-transaction&#34;&gt;TCC-Transaction&lt;/h3&gt;
&lt;p&gt;基于TCC模式开发的分布式事务框架，具体可参考：&lt;a href=&#34;https://github.com/changmingxie/tcc-transaction&#34;&gt;点击此处跳转官网地址&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;servicecomb-saga&#34;&gt;ServiceComb-Saga&lt;/h3&gt;
&lt;p&gt;servicecomb-saga是servicecomb中的一部分，比之tcc而言少了一个try操作，更加轻量化，具体可参考：&lt;a href=&#34;https://github.com/apache/servicecomb-saga-actuator&#34;&gt;点击此处跳转官网地址&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;seata&#34;&gt;Seata&lt;/h3&gt;
&lt;p&gt;阿里开源的分布式事务解决方案，致力于提供高性能和简单易用，包括AT，TCC，SAGA以及XA事务模式。具体可参考：&lt;a href=&#34;http://seata.io/zh-cn/&#34;&gt;点击此处跳转官网地址&lt;/a&gt;&lt;/p&gt;
">分布式事务详解</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/bash-tiao-jian-pan-duan-xiang-jie/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述bash条件判断规则语法。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/rocks-1757593_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;条件判断&#34;&gt;条件判断&lt;/h2&gt;
&lt;h3 id=&#34;if结构&#34;&gt;if结构&lt;/h3&gt;
&lt;p&gt;if是最常用的条件判断结构，只有符合给定条件时，才会执行指定的命令。它的语法如下。&lt;/p&gt;
&lt;p&gt;注意：如果写在同一行，关键字之间需要使用分号隔离。分号是 Bash 的命令分隔符&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if commands; then
  commands
[elif commands; then
  commands...]
[else
  commands]
fi

# 例子 判断环境变量$USER是否等于root
if test $USER = &amp;quot;root&amp;quot;; then
  echo &amp;quot;Hello root.&amp;quot;
else
  echo &amp;quot;You are not root.&amp;quot;
fi

# 单行书写例子
if true; then echo &#39;hello world&#39;; fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if后面可以跟任意数量的命令。这时，所有命令都会执行，但是判断真伪只看最后一个命令，即使前面所有命令都失败，只要最后一个命令返回0，就会执行then的部分。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if false; i=3; true; then echo &#39;hello world&#39;; fi
echo ${i}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;test命令&#34;&gt;test命令&lt;/h3&gt;
&lt;p&gt;if结构的判断条件，一般使用test命令，有三种形式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 写法一
test expression
# 写法二
[ expression ]
# 写法三
[[ expression ]]

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;三种形式是等价的，但是第三种形式还支持正则判断，前两种不支持。&lt;/p&gt;
&lt;p&gt;expression是一个表达式。这个表达式为真，test命令执行成功（返回值为0）；表达式为伪，test命令执行失败（返回值为1）。&lt;/p&gt;
&lt;p&gt;注意：第二种和第三种写法，[ ]与内部的表达式之间必须有空格。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;read i
# 写法一
if test ${i} == 1 ; then
  echo &amp;quot;input param: ${i}&amp;quot;
fi
# 写法二
if [ ${i} == 1 ] ; then
   echo &amp;quot;input param: ${i}&amp;quot;
fi
# 写法三
if [[ ${i} == 1 ]] ; then
   echo &amp;quot;input param: ${i}&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;判断表达式&#34;&gt;判断表达式&lt;/h2&gt;
&lt;p&gt;[[ ]]使用在条件判断中，能够防止脚本中的许多逻辑错误。比如，&amp;amp;&amp;amp;、||、&amp;lt; 和 &amp;gt; 操作符能够正常存在于 [[ ]] 条件判断结构中，但是如果出现在 [ ] 结构中的话，会报错。&lt;/p&gt;
&lt;p&gt;执行的时候，需要用bash test.sh；因为[[]]是bash脚本中的命令（bash是sh的增强版本）。&lt;/p&gt;
&lt;p&gt;注意：[[  ]]中操作符与变量之间需要有空格，否则会被当做一个变量处理。&lt;/p&gt;
&lt;h3 id=&#34;文件判断&#34;&gt;文件判断&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[ -a file ]：如果 file 存在，则为true。&lt;/li&gt;
&lt;li&gt;[ -b file ]：如果 file 存在并且是一个块（设备）文件，则为true。&lt;/li&gt;
&lt;li&gt;[ -c file ]：如果 file 存在并且是一个字符（设备）文件，则为true。&lt;/li&gt;
&lt;li&gt;[ -d file ]：如果 file 存在并且是一个目录，则为true。&lt;/li&gt;
&lt;li&gt;[ -e file ]：如果 file 存在，则为true。&lt;/li&gt;
&lt;li&gt;[ -f file ]：如果 file 存在并且是一个普通文件，则为true。&lt;/li&gt;
&lt;li&gt;[ -g file ]：如果 file 存在并且设置了组 ID，则为true。&lt;/li&gt;
&lt;li&gt;[ -G file ]：如果 file 存在并且属于有效的组 ID，则为true。&lt;/li&gt;
&lt;li&gt;[ -h file ]：如果 file 存在并且是符号链接，则为true。&lt;/li&gt;
&lt;li&gt;[ -k file ]：如果 file 存在并且设置了它的“sticky bit”，则为true。&lt;/li&gt;
&lt;li&gt;[ -L file ]：如果 file 存在并且是一个符号链接，则为true。&lt;/li&gt;
&lt;li&gt;[ -N file ]：如果 file 存在并且自上次读取后已被修改，则为true。&lt;/li&gt;
&lt;li&gt;[ -O file ]：如果 file 存在并且属于有效的用户 ID，则为true。&lt;/li&gt;
&lt;li&gt;[ -p file ]：如果 file 存在并且是一个命名管道，则为true。&lt;/li&gt;
&lt;li&gt;[ -r file ]：如果 file 存在并且可读（当前用户有可读权限），则为true。&lt;/li&gt;
&lt;li&gt;[ -s file ]：如果 file 存在且其长度大于零，则为true。&lt;/li&gt;
&lt;li&gt;[ -S file ]：如果 file 存在且是一个网络 socket，则为true。&lt;/li&gt;
&lt;li&gt;[ -t fd ]：如果 fd 是一个文件描述符，并且重定向到终端，则为true。 这可以用来判断是否重定向了标准输入／输出错误。&lt;/li&gt;
&lt;li&gt;[ -u file ]：如果 file 存在并且设置了 setuid 位，则为true。&lt;/li&gt;
&lt;li&gt;[ -w file ]：如果 file 存在并且可写（当前用户拥有可写权限），则为true。&lt;/li&gt;
&lt;li&gt;[ -x file ]：如果 file 存在并且可执行（有效用户有执行／搜索权限），则为true。&lt;/li&gt;
&lt;li&gt;[ file1 -nt file2 ]：如果 FILE1 比 FILE2 的更新时间最近，或者 FILE1 存在而 FILE2 不存在，则为true。&lt;/li&gt;
&lt;li&gt;[ file1 -ot file2 ]：如果 FILE1 比 FILE2 的更新时间更旧，或者 FILE2 存在而 FILE1 不存在，则为true。&lt;/li&gt;
&lt;li&gt;[ FILE1 -ef FILE2 ]：如果 FILE1 和 FILE2 引用相同的设备和 inode 编号，则为true。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;file=/opt/shellScriptDir/test1.sh
if [[ -e ${file} &amp;amp;&amp;amp; -a ${file} ]]; then
    echo &amp;quot;${file} exist&amp;quot;
    if [[ -f ${file} ]]; then
        echo &amp;quot;${file} is normal file&amp;quot;
    fi
    if [[ -d ${file} ]]; then
        echo &amp;quot;${file} is directory&amp;quot;
    fi
    if [[ -r ${file} ]]; then
        echo &amp;quot;${file} is readable&amp;quot;
    fi
    if [[ -w ${file} ]]; then
        echo &amp;quot;${file} is writable&amp;quot;
    fi
    if [[ -x ${file} ]]; then
        echo &amp;quot;${file} is executable/searchable&amp;quot;
    fi
else
    echo &amp;quot;${file} not exist&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：上述判断中，如果使用的是单个中括号[]时，$file需要用双引号括起来，否则判断将会失误。因为当$file为空时，-e会判断为真，如果放在双引号中，返回的是空字符串，[ -e &amp;quot;&amp;quot; ]会判断为伪。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 下面的例子会输出 not exist
file=
if [ -e &amp;quot;${file}&amp;quot; ]; then
    echo &amp;quot;${file} exist&amp;quot;
else
    echo &amp;quot;${file} not exist&amp;quot;
fi

# 下面的例子会输出 exist
file=
if [ -e ${file} ]; then
    echo &amp;quot;${file} exist&amp;quot;
else
    echo &amp;quot;${file} not exist&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;字符串判断&#34;&gt;字符串判断&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[ string ]：如果string不为空（长度大于0），则判断为真。&lt;/li&gt;
&lt;li&gt;[ -n string ]：如果字符串string的长度大于零，则判断为真。&lt;/li&gt;
&lt;li&gt;[ -z string ]：如果字符串string的长度为零，则判断为真。&lt;/li&gt;
&lt;li&gt;[ string1 = string2 ]：如果string1和string2相同，则判断为真。&lt;/li&gt;
&lt;li&gt;[ string1 == string2 ] 等同于[ string1 = string2 ]。&lt;/li&gt;
&lt;li&gt;[ string1 != string2 ]：如果string1和string2不相同，则判断为真。&lt;/li&gt;
&lt;li&gt;[ string1 &#39;&amp;gt;&#39; string2 ]：如果按照字典顺序string1排列在string2之后，则判断为真。&lt;/li&gt;
&lt;li&gt;[ string1 &#39;&amp;lt;&#39; string2 ]：如果按照字典顺序string1排列在string2之前，则判断为真。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，test命令内部的&amp;gt;和&amp;lt;，必须用引号引起来（或者是用反斜杠转义，或者使用双中括号）。否则，它们会被 shell 解释为重定向操作符。&lt;/p&gt;
&lt;p&gt;字符串判断时，变量要放在双引号之中，比如[ -n &amp;quot;$COUNT&amp;quot; ]，否则变量替换成字符串以后，test命令可能会报错，提示参数过多。另外，如果不放在双引号之中，变量为空时，命令会变成[ -n ]，这时会判断为真。如果放在双引号之中，[ -n &amp;quot;&amp;quot; ]就判断为伪。&lt;/p&gt;
&lt;p&gt;如果不想使用双引号，也可以使用双括号。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;str=fwfw
if [[ -z ${str} ]]; then
    echo &amp;quot;${str} length =0&amp;quot;
elif [[ -n ${str} ]]; then
    echo &amp;quot;${str} length &amp;gt;0&amp;quot;
    if [[ ${str} = &amp;quot;fwfw&amp;quot; ]]; then
        echo &amp;quot;${str} exist&amp;quot;
    fi
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;整数判断&#34;&gt;整数判断&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;[ integer1 -eq integer2 ]：如果integer1等于integer2，则为true。&lt;/li&gt;
&lt;li&gt;[ integer1 -ne integer2 ]：如果integer1不等于integer2，则为true。&lt;/li&gt;
&lt;li&gt;[ integer1 -le integer2 ]：如果integer1小于或等于integer2，则为true。&lt;/li&gt;
&lt;li&gt;[ integer1 -lt integer2 ]：如果integer1小于integer2，则为true。&lt;/li&gt;
&lt;li&gt;[ integer1 -ge integer2 ]：如果integer1大于或等于integer2，则为true。&lt;/li&gt;
&lt;li&gt;[ integer1 -gt integer2 ]：如果integer1大于integer2，则为true。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;a=10
b=20
if [ ${a} -lt ${b} ]
then
    echo &amp;quot;${a} &amp;lt; ${b}&amp;quot;
else
    echo &amp;quot;${a} &amp;gt;= ${b}&amp;quot;
fi

# 使用双中括号，效果一致
if [[ ${a} &amp;lt; ${b} ]]
then
    echo &amp;quot;${a} &amp;lt; ${b}&amp;quot;
else
    echo &amp;quot;${a} &amp;gt;= ${b}&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;正则判断&#34;&gt;正则判断&lt;/h3&gt;
&lt;p&gt;[[ expression ]]这种判断形式，支持正则表达式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# regex是一个正则表示式，=~是正则比较运算符。
[[ string =~ regex ]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;read input
if [[ ${input} =~ [0-9] ]]; then
    echo &amp;quot;match num value = ${input}&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;逻辑运算&#34;&gt;逻辑运算&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;AND运算：符号&amp;amp;&amp;amp;，也可使用参数-a。&lt;/li&gt;
&lt;li&gt;OR运算：符号||，也可使用参数-o。&lt;/li&gt;
&lt;li&gt;NOT运算：符号!。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;## 使用双中括号，可以直接在命令内容拼接逻辑运算符
read input
if [[ ${input} =~ [0-9] &amp;amp;&amp;amp; ${input} == 3 ]]; then
    echo &amp;quot;match num value = ${input}&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;amp;&amp;amp; 和 || 也被称作命令控制操作符，可以用来聚合多个逻辑运算命令。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;file=/opt/shellScriptDir/temp
[[ -d  ${file} ]] || echo &amp;quot;${file} not exist&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;算术判断&#34;&gt;算术判断&lt;/h3&gt;
&lt;p&gt;bash提供了(( ... ))作为算术条件，用于进行算术运算的判断。&lt;/p&gt;
&lt;p&gt;注意，算术判断不需要使用test命令，而是直接使用((...))结构。这个结构的返回值，决定了判断的真伪。&lt;/p&gt;
&lt;p&gt;如果算术计算的结果是非零值，则表示判断成立。这一点跟命令的返回值正好相反，需要小心。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 输出match num value true
if [[ 0 ]]; then
    echo &amp;quot;match num value true&amp;quot;
else
    echo &amp;quot;value false&amp;quot;
fi

# 输出value false
if (( 0 )); then
    echo &amp;quot;match num value true&amp;quot;
else
    echo &amp;quot;value false&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(( ... ))可以用作变量赋值，赋值完成后将会返回变量的值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 输出match num value: 1
if (( var=1 )); then
    echo &amp;quot;match num value: ${var}&amp;quot;
else
    echo &amp;quot;value false&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;case结构判断&#34;&gt;case结构判断&lt;/h3&gt;
&lt;p&gt;case结构用于多值判断，可以为每个值指定对应的命令，跟包含多个elif的if结构等价，但是语义更好。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 语法格式
# expression是一个表达式，pattern是表达式的值或者一个模式，可以有多条，
# 用来匹配多个值，每条以两个分号（;）结尾。
case expression in
  pattern )
    commands ;;
  pattern )
    commands ;;
  ...
esac

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 简单实例
echo &amp;quot;input value[1-3]: &amp;quot;
read input
case ${input} in
    1) echo &amp;quot;read value is 1&amp;quot;;;
    2) echo &amp;quot;read value is 2&amp;quot;;;
    3) echo &amp;quot;read value is 3&amp;quot;;;
    *) echo &amp;quot;read value is not match: ${input}&amp;quot;;;
esac

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;case的匹配模式可以使用各种通配符，类似于下方所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a)：匹配a。&lt;/li&gt;
&lt;li&gt;a|b)：匹配a或b。&lt;/li&gt;
&lt;li&gt;[[:alpha:]])：匹配单个字母。&lt;/li&gt;
&lt;li&gt;???)：匹配3个字符的单词。&lt;/li&gt;
&lt;li&gt;*.txt)：匹配.txt结尾。&lt;/li&gt;
&lt;li&gt;*)：匹配任意输入，通过作为case结构的最后一个模式。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# 匹配数值，单个字符，两个字符
echo &amp;quot;input value[number or character]: &amp;quot;
read input
case ${input} in
    [0-9]) echo &amp;quot;read number value is: ${input}&amp;quot;;;
    [[:lower:]] | [[:upper:]]) echo &amp;quot;read character value is: ${input}&amp;quot;;;
    ??) echo &amp;quot;read double input value is: ${input}&amp;quot;;;
    *) echo &amp;quot;read value is not match: ${input}&amp;quot;;;
esac

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bash 4.0之前，case结构只能匹配一个条件，然后就会退出case结构。Bash 4.0之后，允许匹配多个条件，这时可以用;;&amp;amp;终止每个条件块。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo &amp;quot;input character value: &amp;quot;
read input
case ${input} in
  [[:upper:]])    echo &amp;quot;&#39;${input}&#39; is upper case.&amp;quot; ;;&amp;amp;
  [[:lower:]])    echo &amp;quot;&#39;${input}&#39; is lower case.&amp;quot; ;;&amp;amp;
  [[:alpha:]])    echo &amp;quot;&#39;${input}&#39; is alphabetic.&amp;quot; ;;&amp;amp;
  [[:digit:]])    echo &amp;quot;&#39;${input}&#39; is a digit.&amp;quot; ;;&amp;amp;
  [[:graph:]])    echo &amp;quot;&#39;${input}&#39; is a visible character.&amp;quot; ;;&amp;amp;
  [[:punct:]])    echo &amp;quot;&#39;${input}&#39; is a punctuation symbol.&amp;quot; ;;&amp;amp;
  [[:space:]])    echo &amp;quot;&#39;${input}&#39; is a whitespace character.&amp;quot; ;;&amp;amp;
  [[:xdigit:]])   echo &amp;quot;&#39;${input}&#39; is a hexadecimal digit.&amp;quot; ;;&amp;amp;
esac

&lt;/code&gt;&lt;/pre&gt;
">Bash条件判断详解</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/shell-ji-ben-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述shell基本知识。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/nature-2147400_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;h3 id=&#34;简介-2&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。&lt;/p&gt;
&lt;p&gt;Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。&lt;/p&gt;
&lt;p&gt;Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本（故此处也沿用该说明），需要注意的是：shell 和 shell script 是两个不同的概念。&lt;/p&gt;
&lt;p&gt;查看安装的shell信息，两种查看方式任选一种键入回车即可得到相关信息。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ls -l /bin/*sh
cat /etc/shells

&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230307001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;基本语法bash&#34;&gt;基本语法（Bash）&lt;/h2&gt;
&lt;h3 id=&#34;变量&#34;&gt;变量&lt;/h3&gt;
&lt;h4 id=&#34;基础变量&#34;&gt;基础变量&lt;/h4&gt;
&lt;p&gt;创建变量时，需遵循如下规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。&lt;/li&gt;
&lt;li&gt;不允许出现空格及标点符号。&lt;/li&gt;
&lt;li&gt;不能使用bash里的关键字（可用help命令查看保留关键字）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;变量声明的语法如下（注意：等号两边不能存在空格，读取时使用$符）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;variable=vlaue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 简单例子
# 变量 a 赋值为字符串 hello
a=hello
# $a 等效于 ${a}，加花括号是为了帮助解释器识别变量的边界
# 如：echo $a_world 将不会输出内容，因为变量a_world不存在
# 但是可以使用echo ${a}_world，将会输出hello_world
echo ${a}

# 变量值包含空格，就必须放在引号里面        
b=&amp;quot;world shell&amp;quot;
echo ${b}

# 变量值可以引用其他变量的值
c=&amp;quot;${a} ${b} !&amp;quot;
echo ${c}

# 变量值可以使用转义字符
d=&amp;quot;\t content \n&amp;quot;
echo ${d}

# 变量值可以是命令的执行结果
e=$(ls -l /bin/*sh)
echo ${e}

# 变量值可以是数学运算的结果
f=$((4 * 5))
echo ${f}

# 变量重复赋值，后面的赋值将会覆盖前面的赋值
foo=1
foo=2
echo ${foo}

# 变量的值是变量，如果需要输出，可以使用${!varname}愈发
myvar=USER
echo ${!myvar}

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;特殊变量&#34;&gt;特殊变量&lt;/h4&gt;
&lt;p&gt;Bash（是shell的一个增强版本）提供了一些特殊变量，特殊变量的值由shell预定义，用户不用进行赋值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$?: 表示上一个命令的退出码，用来判断上一个命令是否执行成功，0表示成功，非0表示失败。&lt;/li&gt;
&lt;li&gt;$$: 表示当前shell的进程id，也可以用来命名临时文件&lt;/li&gt;
&lt;li&gt;$_: 表示上个命令的最后一个参数&lt;/li&gt;
&lt;li&gt;$!: 表示最近一个后台执行的异步命令的进程id&lt;/li&gt;
&lt;li&gt;$0: 表示当前shell的名称（在命令直接执行时）或者脚本名（在脚本中执行时）&lt;/li&gt;
&lt;li&gt;$-: 表示当前shell的启动参数&lt;/li&gt;
&lt;li&gt;$@ $#: 表示脚本中的参数数量（两者不同之处：在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 &amp;quot; * &amp;quot; 等价于 &amp;quot;1 2 3&amp;quot;（传递了一个参数），而 &amp;quot;@&amp;quot; 等价于 &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot;（传递了三个参数）。）&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# $? 例子
ls -l /bin/bash
echo $?
ls -l notexistfile
echo $?
# 输出结果
-rwxr-xr-x 1 root root 1183448 Jun 18  2020 /bin/bash
0
ls: cannot access &#39;notexistfile&#39;: No such file or directory
2

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;变量默认值&#34;&gt;变量默认值&lt;/h4&gt;
&lt;p&gt;Bash 提供四个特殊语法，跟变量的默认值有关，目的是保证变量不为空。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;${varname:-word} 语法含义：如果变量varname存在且不为空，则返回它的值，否则返回word。它的目的是返回一个默认值，比如${count:-0}表示变量count不存在时返回0。&lt;/li&gt;
&lt;li&gt;${varname:=word} 语法含义：如果变量varname存在且不为空，则返回它的值，否则将它设为word，并且返回word。它的目的是设置变量的默认值，比如${count:=0}表示变量count不存在时返回0，且将count设为0。&lt;/li&gt;
&lt;li&gt;${varname:+word} 语法含义：如果变量名存在且不为空，则返回word，否则返回空值。它的目的是测试变量是否存在，比如${count:+1}表示变量count存在时返回1（表示true），否则返回空值。&lt;/li&gt;
&lt;li&gt;${varname:?message} 语法含义：如果变量varname存在且不为空，则返回它的值，否则打印出varname: message，并中断脚本的执行。如果省略了message，则输出默认的信息“parameter null or not set.”。它的目的是防止变量未定义，比如${count:?&amp;quot;undefined!&amp;quot;}表示变量count未定义时就中断执行，抛出错误，返回给定的报错信息undefined!。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;echo ${a:-0}
echo ${a:=word}
echo ${a:+1}
echo ${b:?&amp;quot;undefined!&amp;quot;}
# 输出结果
0
word
1
./test1.sh: line 5: b: undefined!

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;变量命令&#34;&gt;变量命令&lt;/h4&gt;
&lt;p&gt;declare命令可以声明一些特殊类型的变量，为变量设置一些限制，比如声明只读类型的变量和整数类型的变量。&lt;/p&gt;
&lt;p&gt;declare语法格式：declare OPTION VARIABLE=value，命令的主要参数（OPTION）如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a：声明数组变量。&lt;/li&gt;
&lt;li&gt;-f：输出所有函数定义。&lt;/li&gt;
&lt;li&gt;-F：输出所有函数名。&lt;/li&gt;
&lt;li&gt;-i：声明整数变量。&lt;/li&gt;
&lt;li&gt;-l：声明变量为小写字母。&lt;/li&gt;
&lt;li&gt;-p：查看变量信息。&lt;/li&gt;
&lt;li&gt;-r：声明只读变量。&lt;/li&gt;
&lt;li&gt;-u：声明变量为大写字母。&lt;/li&gt;
&lt;li&gt;-x：该变量输出为环境变量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;readonly命令等同于declare -r，用来声明只读变量，不能改变变量值，也不能unset变量。&lt;/p&gt;
&lt;p&gt;let命令声明变量时，可以直接执行算术表达式。&lt;/p&gt;
&lt;h4 id=&#34;数组变量&#34;&gt;数组变量&lt;/h4&gt;
&lt;p&gt;数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小。&lt;/p&gt;
&lt;p&gt;与大部分编程语言类似，数组元素的下标由 0 开始。&lt;/p&gt;
&lt;p&gt;Shell 数组用括号来表示，元素用&amp;quot;空格&amp;quot;符号分割开，语法格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array_name=(value1 value2 ... valuen)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 数组例子
array_test=(&amp;quot;hello&amp;quot; &amp;quot;world&amp;quot; &amp;quot;shell&amp;quot;)
echo ${array_test[2]}
# 获取所有元素
echo ${array_test[@]}
echo ${array_test[*]}

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;字符串变量进阶例子&#34;&gt;字符串变量&amp;lt;进阶例子&amp;gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;var=&amp;quot;opt/temp/test.sh&amp;quot;
# 字符串长度
echo ${#var}

# 截取字符串 ${varname:offset:length}: 从位置offset开始（从0开始计算），长度为length
echo ${var:0:3}
# 如果省略length，则从位置offset开始，一直返回到字符串的结尾。
echo ${var:0}
# 如果offset为负值，表示从字符串的末尾开始算起。
# 注意，负数前面必须有一个空格（如果不想写空格，可以填0），以防止与${variable:-word}的变量的设置默认值语法混淆。
# 这时，如果还指定length，则length不能小于零。
echo ${var: -16:3}
echo ${var: -13}
echo ${var:0-16:3}
echo ${var:0-13}

# 输出大写
echo ${var^^}
# 输出小写
echo ${var,,}

# 匹配删除字符串
# 匹配模式pattern可以使用*、?、[]等通配符。

# ${variable#pattern}
# 如果 pattern 匹配变量 variable 的开头，删除最短匹配（非贪婪匹配）的部分，返回剩余部分
# #*/ 表示从左边开始删除第一个 / 号及左边的所有字符，即删除opt/，结果为：temp/test.sh
echo ${var#*/}

# ${variable##pattern}
# 如果 pattern 匹配变量 variable 的开头，删除最长匹配（贪婪匹配）的部分，返回剩余部分
# ##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符，即删除opt/temp/，结果为：test.sh
echo ${var##*/}

# ${variable%pattern}
# 如果 pattern 匹配变量 variable 的结尾，删除最短匹配（非贪婪匹配）的部分，返回剩余部分
# %/* 表示从右边开始，删除第一个 / 号及右边的字符，即删除/test.sh，结果：opt/temp
echo ${var%/*}

# ${variable%%pattern}
# 如果 pattern 匹配变量 variable 的结尾，删除最长匹配（贪婪匹配）的部分，返回剩余部分
# %%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符，即删除/temp/test.sh，结果：opt
echo ${var%%/*}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;算术运算符&#34;&gt;算术运算符&lt;/h3&gt;
&lt;h4 id=&#34;算术表达式&#34;&gt;算术表达式&lt;/h4&gt;
&lt;p&gt;((...))语法可以进行整数的算术运算。该表达式可以忽略内部的空格，在其内部可以使用()改变运算顺序。输出结果时，需要在前面加上$符。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a=2
echo $(( ${a} + 2 ))
# 可以不使用$或者${}（花括号是为了确定边界）引用变量
echo $(( + 2))

# 赋值
i=$((a + 2))
echo &amp;quot;i= ${i}&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;expr命令同样支持算是运算，其可以使用变量替换。&lt;/p&gt;
&lt;p&gt;注意：表达式与运算符之间需要有空格，否则会被当做字符串输出。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a=2
expr ${a} + 2

# 赋值，两种方式都可进行赋值，``符号位于esc键下方，并非单引号
b=$(expr ${a} + 2)
c=`expr ${a} + 2`
echo &amp;quot;b= ${b}&amp;quot;
echo &amp;quot;c= ${c}&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;((...))语法支持的算术运算符如下。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;+：加法&lt;/li&gt;
&lt;li&gt;-：减法&lt;/li&gt;
&lt;li&gt;*：乘法&lt;/li&gt;
&lt;li&gt;/：除法（整除）&lt;/li&gt;
&lt;li&gt;%：余数&lt;/li&gt;
&lt;li&gt;**：指数&lt;/li&gt;
&lt;li&gt;++：自增运算（作为前缀是先运算后返回值，作为后缀是先返回值后运算）&lt;/li&gt;
&lt;li&gt;--：自减运算（作为前缀是先运算后返回值，作为后缀是先返回值后运算）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;进制数值&#34;&gt;进制数值&lt;/h4&gt;
&lt;p&gt;Bash 的数值默认都是十进制，但是在算术表达式中，也可以使用其他进制。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number：没有任何特殊表示法的数字是十进制数（以10为底）。&lt;/li&gt;
&lt;li&gt;0number：八进制数。&lt;/li&gt;
&lt;li&gt;0xnumber：十六进制数。&lt;/li&gt;
&lt;li&gt;base#number：base进制的数。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;echo $((016))
echo $((0xee))
echo $((2#00000011))

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;位运算&#34;&gt;位运算&lt;/h4&gt;
&lt;p&gt;Bash 支持二进制位运算符&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt;&amp;lt;：位左移运算，把一个数字的所有位向左移动指定的位。&lt;/li&gt;
&lt;li&gt;&amp;gt;&amp;gt;：位右移运算，把一个数字的所有位向右移动指定的位。&lt;/li&gt;
&lt;li&gt;&amp;amp;：位的“与”运算，对两个数字的所有位执行一个AND操作。&lt;/li&gt;
&lt;li&gt;|：位的“或”运算，对两个数字的所有位执行一个OR操作。&lt;/li&gt;
&lt;li&gt;~：位的“否”运算，对一个数字的所有位取反。&lt;/li&gt;
&lt;li&gt;!：逻辑“否”运算&lt;/li&gt;
&lt;li&gt;^：位的异或运算（exclusive or），对两个数字的所有位执行一个异或操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;逻辑运算&#34;&gt;逻辑运算&lt;/h4&gt;
&lt;p&gt;Bash 支持逻辑运算符&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt;/-lt：小于&lt;/li&gt;
&lt;li&gt;&amp;gt;/-gt：大于&lt;/li&gt;
&lt;li&gt;&amp;lt;=/-le：小于或相等&lt;/li&gt;
&lt;li&gt;&amp;gt;=/ge：大于或相等&lt;/li&gt;
&lt;li&gt;==/-eq：相等&lt;/li&gt;
&lt;li&gt;!=/-ne：不相等&lt;/li&gt;
&lt;li&gt;&amp;amp;&amp;amp;：逻辑与&lt;/li&gt;
&lt;li&gt;||：逻辑或&lt;/li&gt;
&lt;li&gt;expr1?expr2:expr3：三元条件运算符。若表达式expr1的计算结果为非零值（算术真），则执行表达式expr2，否则执行表达式expr3。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;赋值与求值运算&#34;&gt;赋值与求值运算&lt;/h4&gt;
&lt;p&gt;逗号,在$((...))内部是求值运算符，执行前后两个表达式，并返回后一个表达式的值。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo $((foo = 1 + 2, 3 * 4))
echo ${foo}
# 输出
12
3

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;赋值运算如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parameter = value：简单赋值。&lt;/li&gt;
&lt;li&gt;parameter += value：等价于parameter = parameter + value。&lt;/li&gt;
&lt;li&gt;parameter -= value：等价于parameter = parameter – value。&lt;/li&gt;
&lt;li&gt;parameter *= value：等价于parameter = parameter * value。&lt;/li&gt;
&lt;li&gt;parameter /= value：等价于parameter = parameter / value。&lt;/li&gt;
&lt;li&gt;parameter %= value：等价于parameter = parameter % value。&lt;/li&gt;
&lt;li&gt;parameter &amp;lt;&amp;lt;= value：等价于parameter = parameter &amp;lt;&amp;lt; value。&lt;/li&gt;
&lt;li&gt;parameter &amp;gt;&amp;gt;= value：等价于parameter = parameter &amp;gt;&amp;gt; value。&lt;/li&gt;
&lt;li&gt;parameter &amp;amp;= value：等价于parameter = parameter &amp;amp; value。&lt;/li&gt;
&lt;li&gt;parameter |= value：等价于parameter = parameter | value。&lt;/li&gt;
&lt;li&gt;parameter ^= value：等价于parameter = parameter ^ value。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;echo $((foo = 3))
echo $((foo *= 2))
# 输出
3
6

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;流程控制&#34;&gt;流程控制&lt;/h2&gt;
&lt;h3 id=&#34;条件判断&#34;&gt;条件判断&lt;/h3&gt;
&lt;p&gt;1、简单if语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 简单if语句
if condition
then
    command
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、if else语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# if else语句
if condition
then
    command
else
    command
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、if else-if else语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# if else-if else语句
if condition1
then
    command1
elif condition2 
then 
    command2
else
    commandN
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 例子
a=10
b=20
# [[ ]]使用在条件判断中，能够防止脚本中的许多逻辑错误。比如，&amp;amp;&amp;amp;、||、&amp;lt; 和 &amp;gt; 操作符能够正常存在于 [[ ]] 条件判断结构中，但是如果出现在 [ ] 结构中的话，会报错。
# 执行的时候，需要用bash test.sh；因为[[]]是bash脚本中的命令（bash是sh的增强版本）。
if [[ ${a} &amp;lt; ${b} ]]
then
    echo &amp;quot;a &amp;lt; b&amp;quot;
else
    echo &amp;quot;a &amp;gt;= b&amp;quot;
fi

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;循环语句&#34;&gt;循环语句&lt;/h3&gt;
&lt;p&gt;Bash 提供三种循环语法for、while和until。&lt;/p&gt;
&lt;p&gt;while循环有一个判断条件，只要符合条件，就不断循环执行指定的语句。关键字do可以跟while不在同一行，这时两者之间不需要使用分号分隔。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while condition; do
  commands
done

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;until循环与while循环恰好相反，只要不符合判断条件（判断条件失败），就不断循环执行指定的语句。一旦符合判断条件，就退出循环。关键字do可以与until不写在同一行，这时两者之间不需要分号分隔。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;until condition; do
  commands
done

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for...in循环用于遍历列表中的每一项。关键词do可以跟for写在同一行，两者使用分号分隔。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for variable in list
do
  commands
done

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for循环支持C语言的循环语法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# expression1用来初始化循环条件，expression2用来决定循环结束的条件，
# expression3在每次循环迭代的末尾执行，用于更新值。
# 注意，循环条件放在双重圆括号之中。另外，圆括号之中使用变量，不必加上美元符号$。
for (( expression1; expression2; expression3 )); do
  commands
done

# 等同于下述表达式
(( expression1 ))
while (( expression2 )); do
  commands
  (( expression3 ))
done

# 例子
for (( i=0; i&amp;lt;5; i=i+1 )); do
  echo $i
done

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bash 提供了两个内部命令break和continue，用来在循环内部跳出循环。&lt;/p&gt;
&lt;p&gt;break命令立即终止循环，程序继续执行循环块之后的语句，即不再执行剩下的循环。&lt;/p&gt;
&lt;p&gt;continue命令立即终止本轮循环，开始执行下一轮循环。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# break
a=(first second third)
for i in ${a[*]}; do
    echo ${i}
    if [[ ${i} == &amp;quot;first&amp;quot; ]]; then break; fi
done

# continue
a=(first second third)
for i in ${a[*]}; do
    if [[ ${i} == &amp;quot;second&amp;quot; ]]; then continue; fi
    echo ${i}
done

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;函数&#34;&gt;函数&lt;/h2&gt;
&lt;p&gt;函数（function）是可以重复使用的代码片段，有利于代码的复用。它与别名（alias）的区别是，别名只适合封装简单的单个命令，函数则可以封装复杂的多行命令。&lt;/p&gt;
&lt;p&gt;函数总是在当前 Shell 执行，这是跟脚本的一个重大区别，Bash 会新建一个子 Shell 执行脚本。如果函数与脚本同名，函数会优先执行。但是，函数的优先级不如别名，即如果函数与别名同名，那么别名优先执行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 第一种
fn() {
  # codes
}
# 第二种
function fn() {
  # codes
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;$1~$9：函数的第一个到第9个的参数。如果函数的参数多于9个，那么第10个参数可以用${10}的形式引用，以此类推&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;printParam(){
    echo &amp;quot;first param is $1&amp;quot;
}
printParam wqrwq

function log_msg(){
    echo &amp;quot;[$(date &#39;+%F %T&#39;)]: $@&amp;quot;
}
log_msg this is sample log message

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;函数体内支持局部变量的声明。同时，也支持修改全局变量。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function fn(){
    local str=paramValue
    echo &amp;quot;local: str=${str}&amp;quot;
}
fn
echo &amp;quot;global: str=${str}&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
">Shell基本知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/python3-ji-ben-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述python3脚本知识。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-209956_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;h3 id=&#34;简介-2&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言（计算机编程语言）。&lt;/p&gt;
&lt;p&gt;Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色的语法结构。&lt;/p&gt;
&lt;p&gt;注意：python3与python2具备较大的差别，他们之间并不完全兼容。&lt;/p&gt;
&lt;p&gt;Python的优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简单和明确，做一件事只有一种方法。&lt;/li&gt;
&lt;li&gt;学习曲线低，跟其他很多语言相比，Python更容易上手。&lt;/li&gt;
&lt;li&gt;开放源代码，拥有强大的社区和生态圈。&lt;/li&gt;
&lt;li&gt;解释型语言，天生具有平台可移植性。&lt;/li&gt;
&lt;li&gt;支持两种主流的编程范式（面向对象编程和函数式编程）都提供了支持。&lt;/li&gt;
&lt;li&gt;可扩展性和可嵌入性，可以调用C/C++代码，也可以在C/C++中调用Python。&lt;/li&gt;
&lt;li&gt;代码规范程度高，可读性强，适合有代码洁癖和强迫症的人群。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Python的缺点主要集中在以下几点。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行效率稍低，因此计算密集型任务可以由C/C++编写。&lt;/li&gt;
&lt;li&gt;代码无法加密，但是现在很多公司都不销售卖软件而是销售服务，这个问题会被淡化。&lt;/li&gt;
&lt;li&gt;在开发时可以选择的框架太多（如Web框架就有100多个），有选择的地方就有错误。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;基本语法&#34;&gt;基本语法&lt;/h2&gt;
&lt;h3 id=&#34;变量&#34;&gt;变量&lt;/h3&gt;
&lt;h4 id=&#34;基础变量&#34;&gt;基础变量&lt;/h4&gt;
&lt;p&gt;创建变量时，需遵循以下规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一个字符必须是字母表中字母或下划线 _ 。&lt;/li&gt;
&lt;li&gt;标识符的其他的部分由字母、数字和下划线组成。&lt;/li&gt;
&lt;li&gt;标识符对大小写敏感。&lt;/li&gt;
&lt;li&gt;不能使用python保留字。&lt;/li&gt;
&lt;li&gt;python3支持中文作为变量名，非 ASCII 标识符也是允许的。（不建议使用中文作为变量名）&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# 查看关键字
import keyword
var = keyword.kwlist
print(var)

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;注释与编码&#34;&gt;注释与编码&lt;/h4&gt;
&lt;p&gt;单行注释使用#号，多行注释可以使用&#39;&#39;&#39;或者&amp;quot;&amp;quot;&amp;quot;，python3编码默认为utf-8（可以修改）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 单行注释信息
&amp;quot;&amp;quot;&amp;quot;
多行注释
&amp;quot;&amp;quot;&amp;quot;

# 修改编码
# -*- coding: GBK -*-

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;语法结构&#34;&gt;语法结构&lt;/h4&gt;
&lt;p&gt;python对于代码块需要使用缩进来表示，缩进的空格数是可变的，但是同一个代码块中的缩进需要保持一致，一般使用4个空格。&lt;/p&gt;
&lt;p&gt;为了方便后期维护，在代码之间可以适当的使用空行进行代码功能隔离。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a = &amp;quot;12&amp;quot;
if n := len(a) &amp;gt; 1:
    print(&amp;quot;True&amp;quot;)
else:
    print(&amp;quot;False&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;python中关于一条语句过长需要换行的写法如下（使用反斜杠\）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var = &amp;quot;var1&amp;quot; \
    &amp;quot;var2&amp;quot; \
    &amp;quot;var3&amp;quot;
print(var)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;python支持多行语句并做一行处理&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import sys; x = &#39;runoob&#39;; sys.stdout.write(x + &#39;\n&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;基本数据类型&#34;&gt;基本数据类型&lt;/h2&gt;
&lt;p&gt;Python3有六个标准的数据类型：Number，String，List，Tuple，Set，Dictionary。&lt;/p&gt;
&lt;p&gt;其中不可变数据：Number，String，Tuple&lt;/p&gt;
&lt;p&gt;可变数据：List，Set，Dictionary&lt;/p&gt;
&lt;h3 id=&#34;number数字&#34;&gt;Number（数字）&lt;/h3&gt;
&lt;p&gt;python3支持int(长整型，相当于python2的Long)，float，bool(python2没有布尔值；1等于True，0等于False，可用于算术运算)，complex(复数)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 可以使用type或者isinstance函数判断变量类型。
# type()不会认为子类是一种父类类型。即type事先不知道变量类型。
# isinstance()会认为子类是一种父类类型。即isinstance事先知道变量类型。
a, b, c, d = 1, 2.2, False, 4+1j
print(type(a), type(b), type(c), type(d))
print(isinstance(a, int))

# bool 算术运算
a = True
b, c, d = a + 1, a - 1, a * 10
print(a, b, c, d)

# 强制转换
a = &amp;quot;1&amp;quot;
print(a, int(a), bool(a), float(a))

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;string字符串&#34;&gt;String（字符串）&lt;/h3&gt;
&lt;p&gt;python3使用&#39;&#39;或者&amp;quot;&amp;quot;定义字符串，使用反斜杠\转义特殊字符，也可以使用r让反斜杠不转义；连接字符串用+号，重复字符串用*号。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a = &amp;quot;test\ncontent&amp;quot;
b = r&amp;quot;test\ncontent&amp;quot;
print(a)
print(b)
print(b + b)
print(b*3)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;字符串的截取语法：variable[头下标:尾下标]，规则为左闭右开区间；&lt;/p&gt;
&lt;p&gt;从左往右，头下标从0开始（0可省略）；从右往左，尾下标从-1开始（注意：由于左闭右开原则，-1并不会取到最后一位字符，如需取最后一位字符，需将尾下标置空）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a = &amp;quot;test content&amp;quot;
print(a[:5])
print(a[0:5])
print(a[-12:-1])
print(a[-12:])

# 判断字符是否在目标字符串中
print(&amp;quot;te&amp;quot; in a)
print(&amp;quot;t&amp;quot; not in a)

# 字符串格式化
a = &amp;quot;%s, %d&amp;quot; % (&amp;quot;weq&amp;quot;, 2)
print(a)

# 使用f-string进行格式化，可以不用%s之类的转换符（python版本需要3.6及以上）
a = &amp;quot;content&amp;quot;
b = f&amp;quot;test {a}&amp;quot;
print(b)
print(f&amp;quot;{1+2=}&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;tuple元组&#34;&gt;Tuple（元组）&lt;/h3&gt;
&lt;p&gt;元组使用()进行赋值，使用逗号分隔不同元素；()中可以存在不同类型的元素，如数字，字符串，嵌套元组等。&lt;/p&gt;
&lt;p&gt;元组的索引与截取规则与字符串一致，可参考3.2节内容。&lt;/p&gt;
&lt;p&gt;注意：元组中的元素是不能被修改的；只包含一个元素时，需要在元素后面添加逗号，否则括号会被当作运算符使用&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tup = (&amp;quot;www&amp;quot;, 12306, 99.99, 1, 2, 3)
tup2 = (&amp;quot;test&amp;quot;,)
print(tup)
print(tup[:2])
print(tup[-1:])
print(tup + tup2)
print(tup * 2)
print(&amp;quot;www&amp;quot; in tup)

# 元组截取时，支持第三个参数：步长
print(tup[0:6:2])

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;list列表&#34;&gt;List（列表）&lt;/h3&gt;
&lt;p&gt;列表与元组规则基本一致，不过列表使用[]进行赋值，且其中的元素是可以被修改的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list1 = [&amp;quot;www&amp;quot;, 12306, 99.99, 1, 2, 3]
list2 = [&amp;quot;test&amp;quot;]
print(list1)
print(list1[:2])
print(list1[-1:])
print(list1 + list2)
print(list1 * 2)
print(&amp;quot;www&amp;quot; in list1)

# 截取时，支持第三个参数：步长
print(list1[0:6:2])

# 修改列表元素
list2[0] = &amp;quot;update&amp;quot;
print(list2)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;借助内置函数，列表也可以被当做堆栈（后进先出）或者队列（先进先出）使用。&lt;/p&gt;
&lt;p&gt;注意：列表用作队列时相对比较低效。因为在列表的末尾添加和弹出元素非常快，但是在列表的开头插入或弹出元素却很慢 (因为所有的其他元素都必须移动一位)。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 列表作为堆栈，利用append函数添加一个元素到堆栈的顶端，利用pop函数从堆栈顶部取出一个元素
stack = [1, 2, 3]
stack.append(4)
stack.append(5)
print(stack)
stack.pop()
print(stack)

# 列表作为队列，需要借助collections.deque操作列表两端
from collections import deque

queue = deque([1, 2, 3])
queue.append(4)
queue.append(5)
print(queue)
queue.popleft()
print(queue)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;python中的列表推导式：列表推导式提供了一个更简单的创建列表的方法。常见的用法是把某种操作应用于序列或可迭代对象的每个元素上，然后使用其结果来创建列表，或者通过满足某些特定条件元素来创建子序列。&lt;/p&gt;
&lt;p&gt;列表推导式的结构是由一对方括号所包含的以下内容组成：一个表达式，后面跟一个 for 子句，然后是零个或多个 for 或 if 子句。 其结果将是一个新列表，由对表达式依据后面的 for 和 if 子句的内容进行求值计算而得出。&lt;/p&gt;
&lt;p&gt;注意：如果表达式是一个元组，那么其必须加上括号。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 简单列表推导式
t = [x * 2 for x in range(3)]
print(t)

list_x = [1, 3, 5]
list_y = [2, 4, 6]
print([x * y for x in list_x for y in list_y])

fresh_str = [&#39;  f   &#39;, &#39;  r&#39;, &#39;w   &#39;]
print([x.strip() for x in fresh_str])

# 组合两个列表中的不同元素，将返回一个列表，列表中的元素类型是元组
t = [(x, y) for x in [1, 2, 3] for y in [2, 1, 3] if x != y]
print(t)

# 嵌套列表推导式
list_1 = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]
t = [[row[i] for row in list_1] for i in range(4)]
print(t)

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;set集合&#34;&gt;Set（集合）&lt;/h3&gt;
&lt;p&gt;集合是由不重复元素组成的无序的集。它的基本用法包括成员检测和消除重复元素。集合对象也支持像 联合，交集，差集，对称差分等数学运算。&lt;/p&gt;
&lt;p&gt;使用{}花括号或&lt;a href=&#34;https://docs.python.org/zh-cn/3.9/library/stdtypes.html#set&#34;&gt;set()&lt;/a&gt; 函数可以用来创建集合。注意：要创建一个空集合只能用 set() 而不能用 {}，因为后者是创建一个空字典。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 去重
sites = {&amp;quot;www&amp;quot;, &amp;quot;12306&amp;quot;, &amp;quot;com&amp;quot;, &amp;quot;www&amp;quot;}
print(sites)
print(&amp;quot;www&amp;quot; in sites)

# 运算
a = set(&amp;quot;abcd&amp;quot;)
b = set(&amp;quot;defg&amp;quot;)
print(a &amp;amp; b)
print(a | b)
print(a ^ b)
# a集合包含的元素而b集合不包含
print(a - b)

# 集合支持推导式
a = {x for x in &#39;abcdefg&#39; if x not in &#39;abc&#39;}
print(a)

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;dictionary字典&#34;&gt;Dictionary（字典）&lt;/h3&gt;
&lt;p&gt;字典（dictionary）是Python中另一个非常有用的内置数据类型。&lt;/p&gt;
&lt;p&gt;列表是有序的对象集合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。&lt;/p&gt;
&lt;p&gt;字典是一种映射类型，字典用 { } 标识，它是一个无序的 键(key) : 值(value) 的集合。&lt;/p&gt;
&lt;p&gt;键(key)必须使用不可变类型。&lt;/p&gt;
&lt;p&gt;在同一个字典中，键(key)必须是唯一的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 字典，类比如json，或者map，是一个kv键值对的集合
dict_test = {&#39;name&#39;: &#39;hello&#39;, &#39;age&#39;: 100}
# 获取字典的值
print(dict_test[&#39;name&#39;])
print(dict_test.get(&#39;age&#39;))
# 获取键值对
for k, v in dict_test.items():
    print(k, v)
  
# 使用dict函数构造字典
d = dict([(&#39;name&#39;, &#39;jack&#39;), (&#39;age&#39;, 100)])
print(d)
d2 = dict(name=&#39;tom&#39;, age=90)
print(d2)

# 字典支持推导式
a = {x: x * 2 for x in (1, 2, 3)}
print(a)

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;流程控制&#34;&gt;流程控制&lt;/h2&gt;
&lt;h3 id=&#34;条件判断&#34;&gt;条件判断&lt;/h3&gt;
&lt;p&gt;if 语法如下所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个条件后面要使用冒号 :，表示接下来是满足条件后要执行的语句块。&lt;/li&gt;
&lt;li&gt;使用缩进来划分语句块，相同缩进数的语句在一起组成一个语句块。&lt;/li&gt;
&lt;li&gt;在Python中没有switch – case语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# 语法格式
if condition_1:
    statement_block_1
elif condition_2:
    statement_block_2
else:
    statement_block_3
  
# 简单实例
var = 10
if var &amp;gt; 10:
    print(&amp;quot;value(&amp;quot; + str(var) + &amp;quot;) grate than 10&amp;quot;)
elif var == 10:
    print(&amp;quot;value(&amp;quot; + str(var) + &amp;quot;) equals 10&amp;quot;)
else:
    print(&amp;quot;value(&amp;quot; + str(var) + &amp;quot;) less than 10&amp;quot;)  
  
# := 赋值表达式运算符，又称海象运算符（python3.8）
a = &amp;quot;12&amp;quot;
if n := len(a) &amp;gt; 1:
    print(&amp;quot;True&amp;quot;)
else:
    print(&amp;quot;False&amp;quot;)  

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;循环语句&#34;&gt;循环语句&lt;/h3&gt;
&lt;p&gt;break（终止循环）及continue（跳过本次循环）用于流程控制。pass是空语句，是为了保持程序结构的完整性。&lt;/p&gt;
&lt;p&gt;while语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 简单例子
var = 1
while var &amp;lt; 3:
    print(&amp;quot;value: &amp;quot; + str(var))
    var += 1
  
# pass占位语句
while True:
    pass  

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for语句（break（终止循环）及continue（跳过本次循环）用于流程控制）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 简单例子
# 列表 for循环
list1 = [&amp;quot;first&amp;quot;, &#39;second&#39;, 123, 45.6]
print(len(list1))
for var in list1:
    print(var, end=&amp;quot;; &amp;quot;)
  
# 获取索引及其值
for i, v in enumerate(list1):
    print(i, v)   
  
# 多个list，使用zip函数聚合
list2 = [&#39;map&#39;, &#39;json&#39;, &#39;session&#39;, &#39;cookie&#39;]
for q1, q2, in zip(list1, list2):
    print(&#39;param1={0}, param2={1}&#39;.format(q1, q2))
  
# 内置的range函数可以遍历数字序列
# 简单range，
for i in range(3):
    print(i)
# 指定区间
for i in range(1, 3):
    print(i)
# 指定区间及步长
for i in range(1, 10, 2):
    print(i)
  
# 迭代器
list3 = [&amp;quot;good&amp;quot;, &amp;quot;fire&amp;quot;, &amp;quot;hello&amp;quot;]
it = iter(list2)
print(next(it))
for var in it:
    print(var)  

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;函数&#34;&gt;函数&lt;/h2&gt;
&lt;h3 id=&#34;函数-2&#34;&gt;函数&lt;/h3&gt;
&lt;p&gt;函数是组织好的，可重复使用的，用来实现单一，或相关联功能的代码段。函数能提高应用的模块性，和代码的重复利用率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;函数代码块以 def 关键词开头，后接函数标识符名称和圆括号 ()。&lt;/li&gt;
&lt;li&gt;任何传入参数和自变量必须放在圆括号中间，圆括号之间可以用于定义参数。&lt;/li&gt;
&lt;li&gt;函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。&lt;/li&gt;
&lt;li&gt;函数内容以冒号 : 起始，并且缩进。&lt;/li&gt;
&lt;li&gt;return [表达式] 结束函数，选择性地返回一个值给调用方，不带表达式的 return 相当于返回 None。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# 可变对象传递给函数，将会改变其中的值；不可变对象传递不会改变值（如果修改，则返回一个新的变量）
def test_n(var):
    var[0] = 3

test1 = [2, 3]
test_n(test1)
print(test1)

# 必需参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样。
def test_1(var):
    print(var)

test_1(1)

# 关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。
# 使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。
def test_2(var1, var2):
    print(var1, var2)

test_2(var2=2, var1=1)

# 默认参数：调用函数时，如果没有传递参数，则会使用默认参数
# 默认参数最好使用不可变数据类型，否则可能会出现超出预期的场景
def test_3(var1, var2=2):
    print(var1, var2)

test_3(1)

# 不定长参数: 当需要一个函数能处理比当初声明时更多的参数时，这些参数就叫做不定长参数
# *表示一个元组
def test_4(var1, *var2):
    print(var1)
    print(var2)

test_4(1, 10, 20, 30)

# **表示一个字典
def test_4(var1, **var2):
    print(var1)
    print(var2)

test_4(1, a=10, b=20, c=30)

# 文档字符串
# 第一行应该是对象目的的简要概述。为简洁起见，它不应显式声明对象的名称或类型，因为这些可通过其他方式获得（除非名称恰好是描述函数操作的动词）。这一行应以大写字母开头，以句点结尾。
# 如果文档字符串中有更多行，则第二行应为空白，从而在视觉上将摘要与其余描述分开。后面几行应该是一个或多个段落，描述对象的调用约定，它的副作用等。
def test_5():
    &amp;quot;&amp;quot;&amp;quot;Do nothing, but document it.

    No, really, it doesn&#39;t do anything
    &amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;test&amp;quot;)

print(test_5.__doc__)

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;匿名函数&#34;&gt;匿名函数&lt;/h3&gt;
&lt;p&gt;python 使用 lambda 来创建匿名函数。&lt;/p&gt;
&lt;p&gt;所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;lambda 只是一个表达式，函数体比 def 简单很多。&lt;/li&gt;
&lt;li&gt;lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。&lt;/li&gt;
&lt;li&gt;lambda 函数拥有自己的命名空间，且不能访问自己参数列表之外或全局命名空间里的参数。&lt;/li&gt;
&lt;li&gt;虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# lambda函数
# 语法
lambda [arg1 [,arg2,.....argn]]:expression

# 简单例子
sum_result = lambda a1, a2: a1 + a2
print(sum_result(2, 3))

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;错误与异常&#34;&gt;错误与异常&lt;/h2&gt;
&lt;h3 id=&#34;异常&#34;&gt;异常&lt;/h3&gt;
&lt;p&gt;即使语句或表达式在语法上是正确的，但在尝试执行时，它仍可能会引发错误。在执行时检测到的错误被称为异常，异常不一定会导致严重后果。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 简单异常
print(3 / 0)
# 输出
Traceback (most recent call last):
  File &amp;quot;D:/knowledge/python/pycharm/pythonProject/learn/test.py&amp;quot;, line 123, in &amp;lt;module&amp;gt;
    print(3 / 0)
ZeroDivisionError: division by zero

# 处理异常
def test_6(x, y):
    try:
        x / y
    except Exception as msg:
        print(msg)

test_6(3, 0)

# try finally， finally语句中的代码始终都会执行
def test_7(x, y):
    try:
        x / y
    except ZeroDivisionError as msg:
        print(msg)
    finally:
        print(&amp;quot;finally exec&amp;quot;)

test_7(3, 0)

# raise抛出异常
raise Exception(&amp;quot;raise exception&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个 &lt;a href=&#34;https://docs.python.org/zh-cn/3.9/reference/compound_stmts.html#try&#34;&gt;try&lt;/a&gt; 语句可能有多个 except 子句，以指定不同异常的处理程序。 最多会执行一个处理程序。 处理程序只处理相应的 try 子句中发生的异常，而不处理同一 try 语句内其他处理程序中的异常。 一个 except 子句可以将多个异常命名为带括号的元组。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 一个except多个异常
try:
    expression
except (RuntimeError, OSError, TypeError):
    pass
  
# 多个except
# 最后的 except 子句可以省略异常名，以用作通配符。但请谨慎使用，因为以这种方式很容易掩盖真正的编程错误！
# 它还可用于打印错误消息，然后重新引发异常（同样允许调用者处理异常）   
import sys
try:
    f = open(&#39;myfile.txt&#39;)
    s = f.readline()
    i = int(s.strip())
except OSError as err:
    print(&amp;quot;OS error: {0}&amp;quot;.format(err))
except ValueError:
    print(&amp;quot;Could not convert data to an integer.&amp;quot;)
except:
    print(&amp;quot;Unexpected error:&amp;quot;, sys.exc_info()[0])
    raise 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用with语句可以自动关闭流&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# with关键字会自动关闭文件,try捕获异常输出
try:
    with open(&#39;/opt/pythonDir/temp.txt&#39;, &#39;w+&#39;) as f:
        f.write(&amp;quot;test content&amp;quot;)
    print(f.close())
except IOError as err:
    print(&amp;quot;exception: {0}&amp;quot;.format(err))

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;面向对象&#34;&gt;面向对象&lt;/h2&gt;
&lt;h3 id=&#34;python中的类&#34;&gt;python中的类&lt;/h3&gt;
&lt;p&gt;类实例化后，可以使用其属性，实际上，创建一个类之后，可以通过类名访问其属性。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 创建类
class FirstClass:
    name = &amp;quot;python&amp;quot;

    def fn(self):
        print(self.name)
        return &amp;quot;hello world&amp;quot;


# 实例化类
first_class = FirstClass()
# 调用变量
print(&amp;quot;name: &amp;quot;, first_class.name)
# 调用函数
print(&amp;quot;function: &amp;quot;, first_class.fn())

# 定义初始化函数
class People:
    # 基本属性
    name = &amp;quot;&amp;quot;
    age = 0
    # 使用双下划线定义私有属性，其无法被类外部所访问
    __private_attribute = &amp;quot;private_attribute&amp;quot;

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def speak(self):
        print(&amp;quot;{0} speak: {1}, {2}&amp;quot;.format(self.name, self.age, self.__private_attribute))

    def action(self):
        print(&amp;quot;base class action&amp;quot;)


# people = People(&amp;quot;Jack&amp;quot;, 100)
# people.speak()

# 继承类
class Employee(People):
    profession = &amp;quot;&amp;quot;

    def __init__(self, name, age, profession):
        People.__init__(self, name, age)
        self.profession = profession

    def speak(self):
        print(&amp;quot;{0} speak: {1}, {2}&amp;quot;.format(self.name, self.age, self.profession))

    # 重写toString方法
#   def __str__(self):
#       return &amp;quot;Employee:{name: %s, age: %d, profession: %s}&amp;quot; % (self.name, self.age, self.profession)

    # 重写toString方法（使用f-string格式化）
    def __str__(self):
        return f&amp;quot;Employee:(name: {self.name}, age: {self.age}, profession: {self.profession})&amp;quot;

teacher = Employee(&amp;quot;Tom&amp;quot;, 40, &amp;quot;teacher&amp;quot;)
teacher.speak()
teacher.action()
print(teacher.name)

json_str = json.dumps(teacher.__dict__)
print(json_str)
teacher2 = json.loads(json_str)
print(teacher2)

&lt;/code&gt;&lt;/pre&gt;
">python3基本知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/lua-ji-ben-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Lua脚本知识。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/tianjin-2185510_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;简介与安装&#34;&gt;简介与安装&lt;/h2&gt;
&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Lua是一个强大，高效且轻量化的嵌入式脚本语言，由 clean C（标准 C 和 C++ 间共通的子集）实现成一个库，支持过程编程，面向对象编程，函数编程以及数据驱动编程，以此来供任何需要的程序使用。&lt;/p&gt;
&lt;p&gt;同时，作为一门扩展式语言，Lua 没有 &amp;quot;main&amp;quot; 程序的概念：它只能 嵌入 一个宿主程序中工作，该宿主程序被称为 被嵌入程序 或者简称 宿主 。 宿主程序可以调用函数执行一小段 Lua 代码，可以读写 Lua 变量，可以注册 C 函数让 Lua 代码调用。依靠 C 函数，Lua 可以共享相同的语法框架来定制编程语言，从而适用不同的领域。&lt;/p&gt;
&lt;p&gt;这也是其设计目的：为了给应用程序提供灵活的可扩展及定制化功能。&lt;/p&gt;
&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;
&lt;p&gt;linux/mac安装lua，命令如下，第四行根据系统自行选择，可在&lt;a href=&#34;http://www.lua.org/ftp&#34;&gt;官网地址&lt;/a&gt;中获取最新的lua下载信息。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -R -O http://www.lua.org/ftp/lua-5.*.*.tar.gz
tar zxf lua-5.*.*.tar.gz
cd lua-5.*.*
make linux/macosx test
make install

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;windows下载LuaForWindows（双击安装即可）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Github下载地址：&lt;a href=&#34;https://github.com/rjpcomputing/luaforwindows/releases&#34;&gt;点击此处跳转下载页面&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Google下载地址 : &lt;a href=&#34;https://code.google.com/p/luaforwindows/downloads/list&#34;&gt;点击此处跳转下载页面&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306010.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;
&lt;h3 id=&#34;值与类型&#34;&gt;值与类型&lt;/h3&gt;
&lt;p&gt;Lua 是一门动态类型语言，这意味着变量没有类型，只有值才有类型；值可以存储在变量中，作为参数传递或者返回。&lt;/p&gt;
&lt;p&gt;Lua 中有八种基本类型：nil、boolean、number、string、function、userdata、thread 和 table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;数据类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;nil&lt;/td&gt;
&lt;td&gt;NIL是值nil的类型，用于与其他值区分；通常用来表示一个有意义的值不存在时的状态。如果用于条件判断，其等同于boolean中的false。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;boolean&lt;/td&gt;
&lt;td&gt;包含两个值：true和false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;number&lt;/td&gt;
&lt;td&gt;整数及实数(浮点数)：标准Lua使用64位整数及双精度(64位)浮点数；小型机器和嵌入式系统可以使用32位整数及单精度(32位)浮点数。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;不可变的字节序列(字符串)，可以使用双引号(&amp;quot;&amp;quot;)，单引号(&#39;&#39;)，双中括号([[]])表示&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;function&lt;/td&gt;
&lt;td&gt;由C或者Lua编写的函数&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;userdata&lt;/td&gt;
&lt;td&gt;存储在变量中的C语言数据，用户数据类型的值是一个内存块，分为：完全用户数据：指一块由Lua管理的内存对应的对象；轻量用户数据：一个简单的C指针。Lua可使用元表(metatable)对userdata进行操作;如若需要修改用户数据中的值，只能通过C API进行处理，这保证了数据仅被宿主机所控制。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;thread&lt;/td&gt;
&lt;td&gt;一个独立的执行序列，主要用于实现协程(coroutine)。注意：Lua中的线程与操作系统没有任何关系，因此，它可以为那些不支持原生线程的系统提供协程支持。线程跟协程的区别：线程可以同时多个运行，而协程任意时刻只能运行一个，并且处于运行状态的协程只有被挂起（suspend）时才会暂停。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;table&lt;/td&gt;
&lt;td&gt;一个关联数组，是Lua中唯一的数据结构。它可被用于表示普通数组、序列、符号表、集合、记录、图、树等等。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;错误处理&#34;&gt;错误处理&lt;/h3&gt;
&lt;p&gt;由于 Lua 是一门嵌入式扩展语言，其所有行为均源于宿主程序中代码对某个 Lua 库函数的调用（如果是单独使用 Lua 时，那么Lua 程序就是宿主程序）。因此，在编译或运行 Lua 代码块的过程中，无论何时发生错误，控制权都返回给宿主，由宿主负责采取恰当的措施（比如打印错误消息）。&lt;/p&gt;
&lt;p&gt;在Lua中的可以通过asset函数或者error函数处理错误。&lt;/p&gt;
&lt;p&gt;asset函数首先会检查第一个参数，如果没有问题则不做任何事情，否则输出第二个参数作为错误信息。使用样例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 错误处理
local function add(i, j)
    assert(type(i) == &amp;quot;number&amp;quot;, &amp;quot;i 不是一个数字&amp;quot;)
	assert(type(j) == &amp;quot;number&amp;quot;, &amp;quot;j 不是一个数字&amp;quot;)
	return i + j
end
print(add(rd, 1))
-- 输出
lua: demo.lua:3: i 不是一个数字
stack traceback:
	[C]: in function &#39;assert&#39;
	demo.lua:3: in function &#39;add&#39;
	demo.lua:7: in main chunk
	[C]: ?

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;error函数：error (message [, level])，显式地抛出一个错误，内容为参数message，&lt;/p&gt;
&lt;p&gt;Level参数指示获得错误的位置: Level=1[默认]：为调用error位置(文件+行号)；Level=2：指出哪个调用error的函数的函数；Level=0:不添加错误位置信息。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error(&#39;error msg..&#39;)
--输出
lua: demo.lua:1: error msg..
stack traceback:
	[C]: in function &#39;error&#39;
	demo.lua:1: in main chunk
	[C]: ?

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果需要在 Lua 中捕获这些错误，可以使用 &lt;a href=&#34;https://www.bookstack.cn/read/lua-5.3/2.md#pdf-pcall&#34;&gt;pcall&lt;/a&gt; 或&lt;a href=&#34;https://www.bookstack.cn/read/lua-5.3/2.md#pdf-xpcall&#34;&gt;xpcall&lt;/a&gt;在 保护模式 下调用一个函数。&lt;/p&gt;
&lt;p&gt;使用xpcall或pcall时，需要提供一个 消息处理函数 用于错误抛出时调用。该函数需接收原始的错误消息，并返回一个新的错误消息。&lt;/p&gt;
&lt;p&gt;它在错误发生后栈尚未展开时调用，因此可以利用栈来收集更多的信息，比如通过探知栈来创建一组栈回溯信息。同时，该处理函数也处于保护模式下，所以该函数内发生的错误会再次触发它（递归）。如果递归太深，Lua 会终止调用并返回一个合适的消息。&lt;/p&gt;
&lt;h3 id=&#34;垃圾收集&#34;&gt;垃圾收集&lt;/h3&gt;
&lt;p&gt;Lua采用了自动内存管理（类似于Java）。这意味着使用者不用操心新创建的对象需要的内存如何分配出来，也不用考虑在对象不再被使用后怎样释放它们所占用的内存。&lt;/p&gt;
&lt;p&gt;Lua 运行了一个 垃圾收集器 来收集所有 死对象（即在 Lua 中不可能再访问到的对象）来完成自动内存管理的工作。&lt;/p&gt;
&lt;p&gt;Lua 中所有用到的内存，如：字符串、表、用户数据、函数、线程、内部结构等，都服从自动管理。&lt;/p&gt;
&lt;p&gt;Lua 实现了一个增量标记-扫描收集器。它使用这两个数字来控制垃圾收集循环：垃圾收集器间歇率 和 垃圾收集器步进倍率。这两个数字都使用百分数为单位（例如：值 100 在内部表示 1 ）。&lt;/p&gt;
&lt;p&gt;垃圾收集器间歇率控制着收集器需要在开启新的循环前要等待多久。增大这个值会减少收集器的积极性。当这个值比 100 小的时候，收集器在开启新的循环前不会有等待。设置这个值为 200 就会让收集器等到总内存使用量达到之前的两倍时才开始新的循环。&lt;/p&gt;
&lt;p&gt;垃圾收集器步进倍率控制着收集器运作速度相对于内存分配速度的倍率。增大这个值不仅会让收集器更加积极，还会增加每个增量步骤的长度。不要把这个值设得小于 100 ，那样的话收集器就工作的太慢了以至于永远都干不完一个循环。默认值是 200 ，这表示收集器以内存分配的“两倍”速工作。&lt;/p&gt;
&lt;p&gt;如果将步进倍率设为一个非常大的数字（比程序可能用到的字节数还大 10% ），收集器的行为就像一个 stop-the-world 收集器。接着若把间歇率设为 200 ，收集器的行为就和过去的 Lua 版本一样了：每次 Lua 使用的内存翻倍时，就做一次完整的收集。&lt;/p&gt;
&lt;p&gt;通过在 C 中调用 lua_gc或在 Lua 中调用collectgarbage ([opt [, arg]])来控制自动内存管理。通过参数 opt 它提供了一组不同的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;collectgarbage(&amp;quot;collect&amp;quot;): 做一次完整的垃圾收集循环。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;count&amp;quot;): 以 K 字节数为单位返回 Lua 使用的总内存数。 这个值有小数部分，所以只需要乘上 1024 就能得到 Lua 使用的准确字节数（除非溢出）。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;restart&amp;quot;): 重启垃圾收集器的自动运行。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;setpause&amp;quot;): 将 arg 设为收集器的 间歇率。 返回 间歇率 的前一个值。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;setstepmul&amp;quot;): 返回 步进倍率 的前一个值。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;step&amp;quot;): 单步运行垃圾收集器。 步长&amp;quot;大小&amp;quot;由 arg 控制。 传入 0 时，收集器步进（不可分割的）一步。 传入非 0 值， 收集器收集相当于 Lua 分配这些多（K 字节）内存的工作。 如果收集器结束一个循环将返回 true 。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;stop&amp;quot;): 停止垃圾收集器的运行。 在调用重启前，收集器只会因显式的调用运行。&lt;/li&gt;
&lt;li&gt;collectgarbage(&amp;quot;isrunning&amp;quot;): 返回表示收集器是否工作的布尔值。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;demoTable = {&amp;quot;LUa&amp;quot;, &amp;quot;shell&amp;quot;, &amp;quot;python&amp;quot;, &amp;quot;Java&amp;quot;, &amp;quot;ruby&amp;quot;}
print(collectgarbage(&amp;quot;count&amp;quot;))
demoTable = nil

print(collectgarbage(&amp;quot;count&amp;quot;))
print(collectgarbage(&amp;quot;collect&amp;quot;))
print(collectgarbage(&amp;quot;count&amp;quot;))
-- 输出
21.0859375
21.1123046875
0
19.498046875

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;协程coroutine&#34;&gt;协程（coroutine）&lt;/h3&gt;
&lt;p&gt;Lua中的协程也被称作协同式多线程，代表了一段独立执行的线程。它与线程非常的类似：拥有独立的堆栈、局部变量、指令指针，同时又与其他协程共享全局变量。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.create()&lt;/td&gt;
&lt;td&gt;创建一个协程。其唯一的参数是该协程的主函数。create 函数只负责新建一个协程并返回其句柄（一个 thread 类型的对象）；而不会启动该协程。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.resume()&lt;/td&gt;
&lt;td&gt;执行一个协程。第一次调用coroutine.resume时，第一个参数应传入coroutine.create返回的线程对象，然后协程从其主函数的第一行开始执行。传递给coroutine.resume的其他参数将作为协程主函数的参数传入。协程启动之后，将一直运行到它终止或调用coroutine.yield。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.yield()&lt;/td&gt;
&lt;td&gt;挂起协程，让出执行权。一般与resume配合使用。协程挂起时，对应的最近coroutine.resume函数会立刻返回，即使该挂起操作发生在内嵌函数调用中（即不在主函数，但在主函数直接或间接调用的函数内部）。在协程挂起的情况下，coroutine.resume也会返回 true，并加上传给coroutine.yield的参数。当下次重启同一个协程时，协程会接着从挂起点继续执行。此时，此前挂起点处对coroutine.yield的调用会返回，返回值为传给coroutine.resume的第一个参数之外的其他参数。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.status()&lt;/td&gt;
&lt;td&gt;查看线程状态：dead，suspended，running&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.warp()&lt;/td&gt;
&lt;td&gt;与create类似，也是创建一个协程。不同之处在于，它不返回协程本身，而是返回一个函数。调用这个函数将启动该协程。传递给该函数的任何参数均当作coroutine.resume的额外参数。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coroutine.running()&lt;/td&gt;
&lt;td&gt;返回一个running协程的协程号。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;协程样例及步骤解释：&lt;/p&gt;
&lt;p&gt;1、函数foo加载，协程co创建。&lt;/p&gt;
&lt;p&gt;2、第15行print执行，由coroutine.resume触发执行co协程。&lt;/p&gt;
&lt;p&gt;2.1、接着打印第7行数据，对应输出结果第28行。&lt;/p&gt;
&lt;p&gt;2.2、随后第8行调用函数foo，开始执行第2行，打印结果为第29行&lt;/p&gt;
&lt;p&gt;2.3、最后第3行执行，协程被挂起，打印结果对应第30行。&lt;/p&gt;
&lt;p&gt;注意：yield调用后的返回值为下次resume同一协程时的输入参数。对应第8行的r。&lt;/p&gt;
&lt;p&gt;3、第16行执行，打印协程状态，为suspended（挂起）。&lt;/p&gt;
&lt;p&gt;4、第18行执行，resume同一协程，输入参数“r”对应第8行的local r，也即第3行yield挂起后的返回值。&lt;/p&gt;
&lt;p&gt;4.1、第9行打印，对应结果为第32行。&lt;/p&gt;
&lt;p&gt;4.2、第10行执行，协程挂起，返回r，s两个值，作为下次resume时可输入的值。&lt;/p&gt;
&lt;p&gt;5、第21行执行，resume同一协程，输入参数“x”，“y”，对应第10行的local r，s。&lt;/p&gt;
&lt;p&gt;5.1、第11行执行，打印协程内容，对接结果为第35行。&lt;/p&gt;
&lt;p&gt;5.2、协程结束，打印结果为第36行。&lt;/p&gt;
&lt;p&gt;6、第22执行，显示协程已dead（死亡），对应结果为第37行。&lt;/p&gt;
&lt;p&gt;7、第24行执行，resume协程，开始提示，协程已经dead，对应结果为第38行。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function foo (a)
  print(&amp;quot;foo&amp;quot;, a)
  return coroutine.yield(2*a)
end

co = coroutine.create(function (a,b)
      print(&amp;quot;co-body&amp;quot;, a, b)
      local r = foo(a+1)
      print(&amp;quot;co-body&amp;quot;, r)
      local r, s = coroutine.yield(a+b, a-b)
      print(&amp;quot;co-body&amp;quot;, r, s)
      return b, &amp;quot;end&amp;quot;
end)

print(&amp;quot;main&amp;quot;, coroutine.resume(co, 1, 10))
print(coroutine.status(co))

print(&amp;quot;main&amp;quot;, coroutine.resume(co, &amp;quot;r&amp;quot;))
print(coroutine.status(co))

print(&amp;quot;main&amp;quot;, coroutine.resume(co, &amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;))
print(coroutine.status(co))

print(&amp;quot;main&amp;quot;, coroutine.resume(co, &amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;))
print(coroutine.status(co))

-- 输出
co-body	1	10
foo	2
main	true	4
suspended
co-body	r
main	true	11	-9
suspended
co-body	x	y
main	true	10	end
dead
main	false	cannot resume dead coroutine
dead

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;基本语法&#34;&gt;基本语法&lt;/h2&gt;
&lt;h3 id=&#34;变量&#34;&gt;变量&lt;/h3&gt;
&lt;p&gt;在Lua中的进行赋值操作，是不需要指定类型的。如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 简单赋值
z = 1
print(z)
-- 多重赋值，同时也支持多重返回值
a,b = 3,4
print(a)
print(b)
return a,b

-- 本地（局部）变量赋值
local x,y=5,6
print(x)
print(y)
-- 交换数据
x,y = y,x
print(x)
print(y)

-- 代码块
do
    local str = &amp;quot;world&amp;quot;
	print(str)
end

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;表达式&#34;&gt;表达式&lt;/h3&gt;
&lt;p&gt;在Lua中的表达式基本与高级语言相差无几，如下：&lt;/p&gt;
&lt;p&gt;操作符&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;算术运算符：+ - * / ^ (加减乘除幂)&lt;/li&gt;
&lt;li&gt;关系运算符：&amp;lt; &amp;gt; &amp;lt;= &amp;gt;= == ~=&lt;/li&gt;
&lt;li&gt;逻辑运算符：and or not&lt;/li&gt;
&lt;li&gt;连接运算符：..&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有几个操作符需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a ~= b 即 a 不等于 b&lt;/li&gt;
&lt;li&gt;a ^ b 即 a 的 b 次方&lt;/li&gt;
&lt;li&gt;a .. b 将 a 和 b 作为字符串连接&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优先级：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;^&lt;/li&gt;
&lt;li&gt;not -(负号)&lt;/li&gt;
&lt;li&gt;*/&lt;/li&gt;
&lt;li&gt;+-&lt;/li&gt;
&lt;li&gt;..&lt;/li&gt;
&lt;li&gt;&amp;lt; &amp;gt; &amp;lt;= &amp;gt;= ~= ==&lt;/li&gt;
&lt;li&gt;and&lt;/li&gt;
&lt;li&gt;or&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;控制流&#34;&gt;控制流&lt;/h3&gt;
&lt;p&gt;Lua以if for while等来进行流程控制，具体如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- if语句
local num = &amp;quot;21&amp;quot;
if (tonumber(num)~=nil) then
    print(&amp;quot;tonumber result: &amp;quot;..tonumber(num))
else
    print(&amp;quot;tonumber result is not number&amp;quot;)
end

-- for语句
-- 三个数字分别表示初始值，终止值，步长
for i = 2, 10, 2 do
    print(i)
end
-- i，v分别表示数组对应的索引及值，注意：Lua中的数组是从1开始排序
demoTable = {&amp;quot;LUa&amp;quot;, &amp;quot;shell&amp;quot;, &amp;quot;python&amp;quot;, &amp;quot;Java&amp;quot;, &amp;quot;ruby&amp;quot;}
for i,v in ipairs(demoTable) do
    print(i)
    print(v)
end

-- while语句
local i = 0
while i &amp;lt; 2 do
    print(i)
	i = i + 1
	if (i == 1) then break end
end

&lt;/code&gt;&lt;/pre&gt;
">Lua基本知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/mysql-ri-zhi-xi-tong/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述MySQL日志系统，包括InnoDB引擎日志。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hd-wallpaper-2836301_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;日志系统&#34;&gt;日志系统&lt;/h2&gt;
&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;日志是mysql数据库的重要组成部分，记录着数据库运行期间的各种信息；其中包括错误日志，查询日志，慢查询日志，二进制日志等。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;日志类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Error log&lt;/td&gt;
&lt;td&gt;mysql启动、运行、停止期间发生的问题记录&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;General query log&lt;/td&gt;
&lt;td&gt;客户端建立连接以及期间发生的所有sql操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Slow query log&lt;/td&gt;
&lt;td&gt;记录执行时间过长或没有使用索引的查询语句&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Binary log&lt;/td&gt;
&lt;td&gt;记录数据库的变动操作，如insert，create，alert等语句，所以该日志也可用于主从复制。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Relay log&lt;/td&gt;
&lt;td&gt;中继日志一般用于接受复制源的数据变动（主从复制时会用到）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DDL log (metadata log)&lt;/td&gt;
&lt;td&gt;记录了执行DDL语句的元数据操作&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Engine log&lt;/td&gt;
&lt;td&gt;引擎会有自己的额外日志&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;错误日志&#34;&gt;错误日志&lt;/h3&gt;
&lt;p&gt;错误日志包含了数据库启动和宕机时的记录；除此之外，它还包含服务启动、运行、宕机时的一些诊断性日志如errors,warnings和notes等。&lt;/p&gt;
&lt;p&gt;一般情况下，错误日志有助于检查数据库运行状态，查看日志文件语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;%log_error%&#39;;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;查询日志&#34;&gt;查询日志&lt;/h3&gt;
&lt;p&gt;查询日志记录了mysql服务实例的所有操作，如select,delete,insert等；一般情况，该日志不会被打开，避免造成mysql性能下降。查看该日志文件的语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;%general_log%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;慢查询日志&#34;&gt;慢查询日志&lt;/h3&gt;
&lt;p&gt;慢查询日志由执行时间超过long_query_time的sql语句组成，且必须有至少min_examined_row_limit行数据被检查过。&lt;/p&gt;
&lt;p&gt;慢查询日志可以有效的跟踪执行时间过长或者没有使用索引的查询语句。查看语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 查看日志文件
show variables like &#39;%slow_query_log%&#39;;
-- 查看参数值
show variables like &#39;%long_query_time%&#39;;
show variables like &#39;%min_examined_row_limit%&#39;;

-- log_quries_not_using_indexes 是否将不使用索引的查询语句记录到慢查询日志中，无论查询速度有多快。
SET GLOBAL log_queries_not_using_indexes=ON;
show variables like &#39;log_queries_not_using_indexes&#39;;

-- 如果log_quries_not_using_indexes处于开启状态，那么mysql还提供了log_throttle_queries_not_using_indexes 用来控制每分钟写入多少条数据
show variables like &#39;log_throttle_queries_not_using_indexes&#39;;

-- 日志的输出格式，FILE或者table
show variables like &#39;log_output&#39;;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;中继日志&#34;&gt;中继日志&lt;/h3&gt;
&lt;p&gt;中继日志一般用于主从复制，基本结构与binlog一致。&lt;/p&gt;
&lt;h3 id=&#34;元数据日志&#34;&gt;元数据日志&lt;/h3&gt;
&lt;p&gt;元数据日志记录了通过数据库定义的能够影响表分区的语句操作，例如： ALTER TABLE t3 DROP PARTITION p2；mysql必须确保分区被完全移除，且该分区位于table t3的分区列表中的定义也被移除。为了防止在移除分区操作时机器宕机导致的移除失败，元数据日志便诞生了，因为其记录了具体的语句操作，mysql完全可以根据这些语句重新进行移除操作。&lt;/p&gt;
&lt;h3 id=&#34;二进制日志&#34;&gt;二进制日志&lt;/h3&gt;
&lt;p&gt;二进制日志记录了对mysql数据库执行更新的所有操作，需要注意的是不包括查询类操作，如select，show等；同时，某些操作本身可能并未对数据库进行修改，但这些操作仍然会被写入二进制日志，如update一条不存在的数据（update t set a=1 where a=2）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 查看二进制日志是否开启，默认情况下是关闭的
show variables like &#39;%log_bin%&#39;;

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;作用&#34;&gt;作用&lt;/h4&gt;
&lt;p&gt;二进制日志的具体用途如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;恢复(recovery)：二进制日志包含数据所有的更新操作，一旦数据库宕机，完全可以根据二进制日志进行备份恢复。如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。&lt;/li&gt;
&lt;li&gt;复制(replication)：一般与relay log配合使用，进行主从复制操作。&lt;/li&gt;
&lt;li&gt;审计(audit)：可以检查该日志来判断是否有注入攻击。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;配置&#34;&gt;配置&lt;/h4&gt;
&lt;p&gt;二进制日志默认是关闭状态，需要手动配置才能开启。mysql配置文件为/etc/my.cnf，使用vim编辑该文件，键入如下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# binlog
# 指明存储文件位置
log-bin=/temp/mysql-bin.log
# 设置binlog清理时间
expire-logs-days=14
# 每个文件的大小
max-binlog-size=512M
# mysql集群的服务id
server-id=1

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# 参数说明
log_bin：设置此参数表示启用binlog功能，并指定路径名称

log_bin_index：设置此参数是指定二进制索引文件的路径与名称

expire-logs-days：设置binlog清理时间（手动清理：purge master logs before &#39;2010-02-16 00:00:00&#39;;）

binlog_do_db：此参数表示只记录指定数据库的二进制日志

binlog_ignore_db：此参数表示不记录指定的数据库的二进制日志

max_binlog_cache_size：此参数表示binlog使用的内存最大的尺寸

binlog_cache_size：此参数表示binlog使用的内存大小，可以通过状态变量binlog_cache_use和binlog_cache_disk_use来帮助测试。
binlog_cache_use：使用二进制日志缓存的事务数量
binlog_cache_disk_use:使用二进制日志缓存但超过binlog_cache_size值并使用临时文件来保存事务中的语句的事务数量

max_binlog_size：Binlog最大值，最大和默认值是1GB，该设置并不能严格控制Binlog的大小，尤其是Binlog比较靠近最大值而又遇到一个比较大事务时，
为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的所有SQL都记录进当前日志，直到事务结束

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# binlog刷盘策略参数配置
sync_binlog：这个参数直接影响mysql的性能和完整性
sync_binlog=0：当事务提交后，Mysql仅仅是将binlog_cache中的数据写入Binlog文件，但不执行fsync操作，而是让Filesystem自行决定什么时候来做同步。此模式相对来说性能最高，但不安全，宕机时容易丢失数据。
sync_binlog=1：每次事务提交时，都将binlog刷入磁盘。此模式最安全，但性能相对偏低。
sync_binlog=n：在进行n次事务提交以后，Mysql将执行一次fsync之类的磁盘同步指令，通知文件系统将Binlog文件缓存刷新到磁盘。如果容许出现数据丢失，可以适当的提高此设置值来获取更好的性能。

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;格式&#34;&gt;格式&lt;/h4&gt;
&lt;p&gt;mysql5.1版本开始引入了额外的binlog格式参数，分别为：STATEMENT，ROW，MIXED。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 查看binlog格式
show variables like &#39;%binlog_format%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;STATEMENT：记录的是逻辑SQL语句，即所有的数据库更新操作。该模式下日志量相对ROW会更少，节省了IO及存储资源，性能相对有所提高。注意：在RC(Read committed，读已提交)隔离级别下，此模式会导致主从复制数据不一致问题（例如：一条删除语句与一条新增语句在两个session中提交，最终master可能是先删除后新增，但slave库复制时可是先新增后删除，导致数据不一致）。解决方案便是RC选择ROW模式，RR（可重复读有间隙锁防止session执行顺序错乱）选择STATEMENT模式。&lt;/li&gt;
&lt;li&gt;ROW：记录表行数据的变更情况，而非单纯的逻辑sql语句。如果binlog格式设置为ROW，那么隔离级别可以设置为RC，以提高并发度；当然随之而来的便是IO及存储资源的增加。&lt;/li&gt;
&lt;li&gt;MIXED：默认依旧使用STATEMENT格式，只在某些情况下使用ROW格式；如：NDB引擎，insert delay语句，临时表，自定义函数等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;引擎日志&#34;&gt;引擎日志&lt;/h3&gt;
&lt;p&gt;事务一般都有ACID四个特性，其中隔离性可以通过锁来实现；原子性，一致性，持久性则需要通过日志系统进行保障。以InnoDB为例，redo log保证了持久性，undo log则保证了原子性。&lt;/p&gt;
&lt;p&gt;InnoDB架构官网链接：&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html&#34;&gt;点击此处跳转官网页面&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;redo-log&#34;&gt;redo log&lt;/h4&gt;
&lt;p&gt;在mysql中，持久性作为事务四大特性之一，需要确保对数据的修改能够永久地保存下来；如果在每次更新数据时都简单地采用直接刷入磁盘的操作，将会导致整个服务性能变得低下。以InnoDB引擎为例，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;InnoDB引擎与磁盘进行交互的基本单位是数据页，一次事务操作可能只修改了几个字节，这个时候将整个数据页刷入磁盘，将会浪费大量的资源。&lt;/li&gt;
&lt;li&gt;一个事务操作可能涉及多个不同的数据页，且当这些数据页在磁盘上不连续时，写入性能也将变得很差（随机IO多了寻址(seek)步骤）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;于是，InnoDB引擎设计了redo log专门记录着事务操作引起的数据变化，确切地说是记录了事务操作对数据页做了哪些修改。&lt;/p&gt;
&lt;p&gt;这个日志与磁盘配合的整个过程，在MySQL中被称之为WAL(Write-Ahead Logging，预写式技术)；WAL会先将记录写入日志，然后在系统空闲的时候或者按照设定的更新策略进行刷磁盘操作(刷脏页，fsync)。&lt;/p&gt;
&lt;h5 id=&#34;redo-log记录形式&#34;&gt;redo log记录形式&lt;/h5&gt;
&lt;p&gt;redo log本身只记录数据页的变更，且采用了大小固定，循环写入的实现方案进行log记录。为了实现循环写入，redo log中设置了两个标志位：checkpoint 和 write pos。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;write pos 表示redo log当前记录的LSN(log sequence number,日志序列号：日志空间中每条日志的结束点，用字节偏移量表示)，即记录写入位置。&lt;/li&gt;
&lt;li&gt;checkpoint 表示脏页（缓存中的数据页被称为脏页）刷盘后对应的redo log所处的LSN，即记录擦除位置。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在进行log记录时，如果write pos追上了checkpoint，那么就表示redo log已经写满了；此时需要停止写入，并运行checkpoint规则进行刷磁盘操作（先更新内存，再将buffer中的脏数据（缓存中的数据被称为脏数据）fsync到磁盘）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;redo-log刷磁盘&#34;&gt;redo log刷磁盘&lt;/h5&gt;
&lt;p&gt;redo log包含两个核心部分，分别是内存中的日志缓冲(redo log buffer)以及磁盘上的日志文件(redo log file)。当执行一条更新sql时，数据会先写入redo log buffer，之后再写入redo log file。&lt;/p&gt;
&lt;p&gt;在计算机操作系统中，用户空间(user space)下的缓存区数据是无法直接写入磁盘的，一般都需要经过内核空间(kernel space)的缓存区(OS Buffer)，之后才能真正写入磁盘。具体流程图如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306005.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在InnoDB中有一个配置参数可以用来控制日志的刷新频率：innodb_flush_log_at_trx_commit。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0（延时写）&lt;/td&gt;
&lt;td&gt;事务提交之后，日志只记录到 log buffer 中，之后每秒写一次日志到缓存（OS Buffer）并刷新（fsync）到磁盘，尚未刷新的日志可能会丢失。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1（实时写，实时刷）&lt;/td&gt;
&lt;td&gt;事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2（实时写，延时刷）&lt;/td&gt;
&lt;td&gt;每次事务提交之后，日志写到 OS Buffer，每秒刷一次到磁盘，尚未刷新的日志可能会丢失。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;redo-log与binlog&#34;&gt;redo log与binlog&lt;/h5&gt;
&lt;p&gt;binlog是mysql服务共有的日志文件，而redo log则是InnoDB独有的日志文件。同时，redo log是基于crash recovery，保证MySQL宕机后的数据恢复（crash-safe）；而binlog是基于point-in-time recovery，保证服务器可以基于时间点对数据进行恢复，或者对数据进行备份。&lt;/p&gt;
&lt;p&gt;注意：单纯的binlog日志系统是不具备crash-safe功能的，因为binlog一般只能提供归档功能（记录了对mysql数据库执行更新的所有操作）。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;以InnoDB引擎对update table set b = 2 where a = 1语句操作为例，其中都会涉及redo log日志和binlog日志，具体流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;查询 a=1 这一行。如果 a=1 这一行所在的数据页本来就在内存中，便直接返回；否则，需要先从磁盘读入内存，然后再返回。&lt;/li&gt;
&lt;li&gt;修改 a=1 这行的b为2，并写入新行。&lt;/li&gt;
&lt;li&gt;引擎将这行新数据更新到内存（InnoDB Buffer Pool）中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。&lt;/li&gt;
&lt;li&gt;sql语句写入 binlog，并把 binlog 刷入磁盘（依据配置的刷盘机制）。&lt;/li&gt;
&lt;li&gt;执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;undo-log&#34;&gt;undo log&lt;/h4&gt;
&lt;p&gt;回滚日志主要是为了保证数据库事务的原子性，当一个事务对数据库进行修改时，InnoDB引擎不仅会记录redo log，还会生成对应的undo log日志；当事务执行失败或者调用rollback时，便可以利用undo log将数据回滚到修改之前的样子。&lt;/p&gt;
&lt;p&gt;关于 undo Log 的存储：InnoDB 中有回滚段(rollback segment)，每个回滚段记录 1024 个 undo log segment，在每个 undo log segment 段中进行申请 undo 页。系统表空间偏移量为 5 的页记录了所有的 rollback segment header 所在的页。&lt;/p&gt;
&lt;p&gt;undo log有两个作用：一是提供回滚，二是实现MVCC；两种格式：insert undo log（记录插入对应的回滚日志） 和 update undo log（记录更新和删除对应的回滚日志）。&lt;/p&gt;
&lt;p&gt;undo log详解可参考：&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/10/01/&#34;&gt;点击此处跳转页面&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;innodb故障恢复&#34;&gt;InnoDB故障恢复&lt;/h4&gt;
&lt;p&gt;由上小节可知，InnoDB事务处理采用的是二阶段提交，因此故障恢复也将依据二阶段进行。&lt;/p&gt;
&lt;p&gt;注意1：binlog的完整性依据不同的日志格式而不同，STATEMENT格式为COMMIT，而ROW格式最后一行会有一个XID event，且5.6.2版本后，mysql还新增了binlog-checknum用于验证binlog的完整性。&lt;/p&gt;
&lt;p&gt;注意2：redo log与binlog有一个共同的数据字段：XID。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据库启动后，InnoDB引擎会根据redo log寻找最近的一次checkpoint位置，随后根据checkpoint对应的LSN(log sequence number,日志序列号)获取需要重做的日志。&lt;/li&gt;
&lt;li&gt;根据redo log回滚未prepared和commit的事务，但对于已经prepared，但未commit的事务，暂时挂起，将其保存到一个链表中。&lt;/li&gt;
&lt;li&gt;mysql读取最后一个binlog文件。binlog文件通常是以固定的文件名加一组连续的编号来命名的，并且将其记录到一个binlog索引文件中，因此索引文件中的最后一个binlog文件即是MySQL将要读取的最后一个binlog文件。&lt;/li&gt;
&lt;li&gt;如果binlog中记录了上次mysql为异常关闭（文件头是否存在标记LOG_EVENT_BINLOG_IN_USE_F），则依次读取binlog中所有的log event，并将所有已提交事务的xid取出归总到一个列表；同时，定位出最后一个完整事务的位置。&lt;/li&gt;
&lt;li&gt;遍历第二步中的列表，判断其是否在第四步中的提交事务列表中，如果是，则提交此事务；否则回滚。&lt;/li&gt;
&lt;li&gt;将最后一个完整事务位置之后的binlog清除，到此故障恢复便已全部完成。&lt;/li&gt;
&lt;/ol&gt;
">MySQL日志系统</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/mysql-jia-gou-yu-explain-yu-suo/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述MySQL架构组件，EXPLAIN语法分析以及各类锁细节。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sea-164989_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;mysql架构&#34;&gt;MySQL架构&lt;/h2&gt;
&lt;h3 id=&#34;架构图&#34;&gt;架构图&lt;/h3&gt;
&lt;h4 id=&#34;国外架构图&#34;&gt;国外架构图&lt;/h4&gt;
&lt;p&gt;图片文章链接：&lt;a href=&#34;https://www.rathishkumar.com/2016/04/understanding-mysql-architecture.html&#34;&gt;点击此处跳转页面&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306001.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;国内架构图&#34;&gt;国内架构图&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;架构层说明&#34;&gt;架构层说明&lt;/h3&gt;
&lt;h4 id=&#34;客户端层&#34;&gt;客户端层&lt;/h4&gt;
&lt;p&gt;mysql是一个标准的cs(client-server)服务器，请求一般由客户主动发起，包括但不限于java，python，php等。&lt;/p&gt;
&lt;h4 id=&#34;服务端层&#34;&gt;服务端层&lt;/h4&gt;
&lt;p&gt;服务层包含了mysql所有的核心功能，具体可分为如下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连接器(Connection Pool)：维护客户端与服务端的连接，认证连接账号密码，确认连接账号的权限。&lt;/li&gt;
&lt;li&gt;查询缓存(Query Cache)：缓存了select语法的结果集，如果命中了缓存则直接返回数据给客户端。注意：mysql8此功能已弃用。&lt;/li&gt;
&lt;li&gt;分析器(Parser)：对即将执行的sql进行分析，包括词法分析(Lexical analysis，判断从字节流生成的单词或标识是否符合规范)和语法分析(Syntactic analys，确保语句符合sql规范)；同时，会创建一个内部的parse-tree结构。&lt;/li&gt;
&lt;li&gt;优化器(Optimizer)：针对内部的parse-tree，mysql可以应用多种优化技术，如重写查询，扫描表的顺序以及选择合适的索引使用等。可以用explain查看分析优化结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;引擎层&#34;&gt;引擎层&lt;/h4&gt;
&lt;p&gt;mysql提供给可插拔式的引擎技术，可根据不同的业务选择不同的引擎。&lt;/p&gt;
&lt;h4 id=&#34;存储层&#34;&gt;存储层&lt;/h4&gt;
&lt;p&gt;实际的物理存储介质。&lt;/p&gt;
&lt;h3 id=&#34;explain语句&#34;&gt;EXPLAIN语句&lt;/h3&gt;
&lt;p&gt;explain可以与select，delete，insert，replace以及update语句一同使用，结果会显示来自优化器（Optimizer）的有关语句执行计划的信息。&lt;/p&gt;
&lt;p&gt;官网链接：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/explain-output.html&#34;&gt;点击此处跳转官网页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;explain输出格式参数如下所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Column&lt;/th&gt;
&lt;th&gt;JSON Name&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;select_id&lt;/td&gt;
&lt;td&gt;select 标识符&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;select_type&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;select 类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;table&lt;/td&gt;
&lt;td&gt;table_name&lt;/td&gt;
&lt;td&gt;输出行对应的表名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;partitions&lt;/td&gt;
&lt;td&gt;partitions&lt;/td&gt;
&lt;td&gt;匹配的分区&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;type&lt;/td&gt;
&lt;td&gt;access_type&lt;/td&gt;
&lt;td&gt;连接/访问类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;possible_keys&lt;/td&gt;
&lt;td&gt;possible_keys&lt;/td&gt;
&lt;td&gt;可供选择的匹配索引&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;key&lt;/td&gt;
&lt;td&gt;key&lt;/td&gt;
&lt;td&gt;实际匹配的索引&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;key_len&lt;/td&gt;
&lt;td&gt;key_length&lt;/td&gt;
&lt;td&gt;所选key的长度&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ref&lt;/td&gt;
&lt;td&gt;ref&lt;/td&gt;
&lt;td&gt;与索引比较的列&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;rows&lt;/td&gt;
&lt;td&gt;rows&lt;/td&gt;
&lt;td&gt;预计要检查多少行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;filtered&lt;/td&gt;
&lt;td&gt;filtered&lt;/td&gt;
&lt;td&gt;通过表条件过滤的行百分比&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Extra&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;额外信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;idjson-name-select_id&#34;&gt;id(JSON name: select_id)&lt;/h4&gt;
&lt;p&gt;select 标识符，是一次查询中select的序列号。当行引用了另一行的联合结果时，此值可以为NULL。当然，它也可以显示联合行的结果，格式类似于：union M,N。其中M，N表示不同的行。&lt;/p&gt;
&lt;h4 id=&#34;select_typejson-name-none&#34;&gt;select_type(JSON name: None)&lt;/h4&gt;
&lt;p&gt;select类型，具体如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;select_type Value&lt;/th&gt;
&lt;th&gt;JSON Name&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SIMPLE&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;简单查询（未使用联合查询及子查询）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PRIMARY&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;多层查询时，外层查询将被标记为primary（如两表做UNION或者存在子查询的外层的表操作为PRIMARY，内层的操作为UNION）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNION&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句没有依赖关系）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DEPENDENT UNION&lt;/td&gt;
&lt;td&gt;dependent (true)&lt;/td&gt;
&lt;td&gt;UNION操作中，查询中处于内层的SELECT（内层的SELECT语句与外层的SELECT语句有依赖关系）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNION RESULT&lt;/td&gt;
&lt;td&gt;union_result&lt;/td&gt;
&lt;td&gt;union查询结果&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUBQUERY&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;子查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DEPENDENT SUBQUERY&lt;/td&gt;
&lt;td&gt;dependent (true)&lt;/td&gt;
&lt;td&gt;依赖于外部查询的子查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DERIVED&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;衍生表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DEPENDENT DERIVED&lt;/td&gt;
&lt;td&gt;dependent (true)&lt;/td&gt;
&lt;td&gt;依赖于另一张表的衍生表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MATERIALIZED&lt;/td&gt;
&lt;td&gt;materialized_from_subquery&lt;/td&gt;
&lt;td&gt;物化子查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNCACHEABLE SUBQUERY&lt;/td&gt;
&lt;td&gt;cacheable (false)&lt;/td&gt;
&lt;td&gt;对于外层的主表，子查询不可被物化，每次都需要计算（耗时操作）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNCACHEABLE UNION&lt;/td&gt;
&lt;td&gt;cacheable (false)&lt;/td&gt;
&lt;td&gt;UNION操作中，内层的不可被物化的子查询（类似于UNCACHEABLE SUBQUERY）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;tablejson-name-table_name&#34;&gt;table(JSON name: table_name)&lt;/h4&gt;
&lt;p&gt;输出行所引用的表。除此之外，它还包括联合查询：union M,N（表示连表查询）；衍生表：derived M（M表的衍生结果，例如子查询的from结果）；子查询：subquery M（M表的子查询结果）。&lt;/p&gt;
&lt;h4 id=&#34;typejson-name-access_type&#34;&gt;type(JSON name: access_type)&lt;/h4&gt;
&lt;p&gt;表的连接查询方式，性能从高到低如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type value&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;system&lt;/td&gt;
&lt;td&gt;表中只有一行，算是一种特殊的const连接类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;const&lt;/td&gt;
&lt;td&gt;单表中最多有一个匹配行，一般是primary key 或者 unique index的检索&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;eq_ref&lt;/td&gt;
&lt;td&gt;多表连接中被驱动表的连接列上有primary key或者unique index的检索&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ref&lt;/td&gt;
&lt;td&gt;与eq_ref类似，但不是使用primary key或者unique index，而是普通索引。也可以是单表上non-unique索引检索&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fulltext&lt;/td&gt;
&lt;td&gt;使用FULLTEXT索引执行连接&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ref_or_null&lt;/td&gt;
&lt;td&gt;与ref类似，区别在于条件中包含对NULL的查询&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;index_merge&lt;/td&gt;
&lt;td&gt;索引合并优化，利用一个表里的N个索引查询,key包含索引列表，key_len则表示这些索引键的最长长度。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;unique_subquery&lt;/td&gt;
&lt;td&gt;in的后面是一个查询primary key\unique字段的子查询，即子查询中使用eq_ref类型查询。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;index_subquery&lt;/td&gt;
&lt;td&gt;in的后面是一个查询普通index字段的子查询，即子查询中使用了ref类型查询。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;range&lt;/td&gt;
&lt;td&gt;单表索引中的范围查询,使用索引查询出单个表中的一些行数据。ref列会变为null&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;index&lt;/td&gt;
&lt;td&gt;等于ALL。它有两种情况：(1)覆盖索引（Extra列会显示 Using index） (2)用索引的顺序做一个全表扫描。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;all&lt;/td&gt;
&lt;td&gt;全表扫描&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code&gt;-- 样例
-- const
SELECT * FROM tbl_name WHERE primary_key=1;
SELECT * FROM tbl_name
  WHERE primary_key_part1=1 AND primary_key_part2=2;

-- eq_ref
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref
SELECT * FROM ref_table WHERE key_column=expr;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column=other_table.column;
SELECT * FROM ref_table,other_table
  WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

-- ref_or_null
SELECT * FROM ref_table
  WHERE key_column=expr OR key_column IS NULL;
  
-- unique_subquery
value IN (SELECT primary_key FROM single_table WHERE some_expr)  

-- index_subquery
value IN (SELECT key_column FROM single_table WHERE some_expr)

-- range
SELECT * FROM tbl_name
  WHERE key_column = 10;
SELECT * FROM tbl_name
  WHERE key_column BETWEEN 10 and 20;
SELECT * FROM tbl_name
  WHERE key_column IN (10,20,30);
SELECT * FROM tbl_name
  WHERE key_part1 = 10 AND key_part2 IN (10,20,30);

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;extrajson-name-none&#34;&gt;Extra(JSON name: None)&lt;/h4&gt;
&lt;p&gt;包含了mysql解析查询的一些额外信息。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type value&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Backword index scan&lt;/td&gt;
&lt;td&gt;优化器可以在InnoDB引擎中使用降序索引，一般与Using index一同出现&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;const row not found&lt;/td&gt;
&lt;td&gt;所要查询的表为空&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Distinct&lt;/td&gt;
&lt;td&gt;mysql正在查询distinct值，因此当它查到匹配行后便会停止继续搜索更多行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;impossible HAVING&lt;/td&gt;
&lt;td&gt;having条件总为false，且无法搜索到任何行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Impossible WHERE&lt;/td&gt;
&lt;td&gt;where条件总为false，且无法搜索到任何行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Impossible WHERE noticed after reading const tables&lt;/td&gt;
&lt;td&gt;mysql读取所有的const（及system）表之后，发现where条件均不满足（即where条件为false）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;no matching row in const table&lt;/td&gt;
&lt;td&gt;对于一个连接查询，结果是一个空表或者没有一条满足唯一索引条件的行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Not exists&lt;/td&gt;
&lt;td&gt;优化器发现内表记录不可能满足where条件（left join，如：SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using filesort&lt;/td&gt;
&lt;td&gt;MySQL 必须执行额外的检查以找出如何按排序顺序检索行。排序是通过根据连接类型遍历所有行并存储排序键和指向与WHERE子句匹配的所有行的指针来完成的。然后对键进行排序，并按排序顺序检索行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using index&lt;/td&gt;
&lt;td&gt;使用索引树中的信息从表中检索列信息，无须额外操作。（覆盖索引）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using index for group-by&lt;/td&gt;
&lt;td&gt;与Using index类似，对于group by列或者distinct列，可以利用索引检索出数据，而不需要去表里查数据、分组、排序、去重等等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using join buffer&lt;/td&gt;
&lt;td&gt;之前的表连接在nested loop之后放进join buffer，再来和本表进行join。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using sort_union,using union,using intersect&lt;/td&gt;
&lt;td&gt;index_merge的三种情况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using temporary&lt;/td&gt;
&lt;td&gt;使用了临时表来存储中间结果集，适用于group by，distinct，或order by列为不同表的列。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using where&lt;/td&gt;
&lt;td&gt;在存储引擎层检索出记录后，在server利用where条件进行过滤，并返回给客户端&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;mysql锁&#34;&gt;MySQL锁&lt;/h2&gt;
&lt;h3 id=&#34;隔离级别&#34;&gt;隔离级别&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Isolation Level（隔离级别）&lt;/th&gt;
&lt;th&gt;Dirty Reads（脏读）&lt;/th&gt;
&lt;th&gt;Non-Repeatable Reads（不可重复读）&lt;/th&gt;
&lt;th&gt;Phantom Reads（幻读）&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Read uncommitted（读未提交）&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read committed(Sql server, Oracle)（读已提交）&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Repeatable reads(Mysql)（可重复读）&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;允许&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Serializable（串行化）&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;td&gt;不允许&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Dirty reads：脏读，A事务可以读到B事务还未提交的数据。&lt;/li&gt;
&lt;li&gt;Non-repeatable read：不可重复读，A事务读取一行数据，B事务后续修改了这行数据，A事务再次读取这行数据，结果得到的数据不同。&lt;/li&gt;
&lt;li&gt;Phantom reads：幻读，A事务通过SELECT ... WHERE得到一些行，B事务插入新行或者删除已有的行使得这些行满足A事务的WHERE条件，A事务再次SELECT ... WHERE结果比上一次多/少了一些行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意1：mysql默认使用RR隔离级别，这是由于binlog的格式问题（statement-记录修改的SQL语句,row-记录每行实际数据的变更,mixed-前面两种混合）所导致的，在5.0之前binlog只有statement一种格式，而主从复制时，这会导致数据的不一致。&lt;/p&gt;
&lt;p&gt;注意2：其他数据库选用RC隔离级别，是由于RR隔离级别增加了间隙锁，会增加发生死锁的概率；同时，条件列未命中索引时，会锁全表，RC只会锁行。&lt;/p&gt;
&lt;p&gt;注意3：RC隔离级别下，主从复制需要采用binlog的row格式，基于行的复制，这样不会出现主从不一致问题。&lt;/p&gt;
&lt;h3 id=&#34;锁分类&#34;&gt;锁分类&lt;/h3&gt;
&lt;h4 id=&#34;按操作数据的类型&#34;&gt;按操作数据的类型&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;共享锁(读锁，Shared Locks，S锁)：在事务要读取一条记录时，需要先获取该记录的S锁。S锁可以在同一时刻被多个事务同时持有；即多个读事务可以并发的进行，但不允许出现写事务。可以用select ...... lock in share mode;的方式手工加上一把S锁。&lt;/li&gt;
&lt;li&gt;独占锁(写锁，排他锁，Exclusive Locks，X锁)：在事务要改动一条记录时，需要先获取该记录的X锁。X锁在同一时刻最多只能被一个事务持有；即当前写事务进行时，不允许其他读事务与写事务出现。X锁的加锁方式有两种，第一种是自动加锁，在对数据进行增删改的时候，都会默认加上一个X锁；还有一种是手工加锁，可以用一个FOR UPDATE给一行数据加上一个X锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;按操作数据的粒度&#34;&gt;按操作数据的粒度&lt;/h4&gt;
&lt;p&gt;粒度：指数据仓库的数据单位中保存数据的细化或综合程度的级别。细化程度越高，粒度级就越小；相反，细化程度越低，粒度级就越大。&lt;/p&gt;
&lt;p&gt;在数据库中为了获取更高的并发度，每次锁定的数据范围越小越好，即锁粒度越低越好。理论上来说，如果只锁定当前操作数据将会获得最大的并发度。&lt;/p&gt;
&lt;p&gt;值得注意的是锁的管理也是需要耗费额外资源。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表级锁(table-level locking)：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）。一般适合查询为主并带有少量更新（读多写少）的应用场景。&lt;/li&gt;
&lt;li&gt;行级锁(row-level locking)：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）。一般适合大量并发更新并带有少量查询（写多读少）的应用场景。&lt;/li&gt;
&lt;li&gt;页级锁(page-level locking)：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般（BDB存储引擎支持页级锁，也支持表级锁）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;按思想维度&#34;&gt;按思想维度&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;乐观锁(Optimistic Lock)：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会根据版本号（一般情况是版本号，也可以使用时间戳等其他控制条件）判断一下在此期间别人有没有去更新这个数据。乐观锁适用于多读的应用类型，这样可以提高吞吐量。&lt;/li&gt;
&lt;li&gt;悲观锁(Pessimistic Lock)：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁，排他锁等，都是在做操作之前先上锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;innodb引擎锁&#34;&gt;InnoDB引擎锁&lt;/h3&gt;
&lt;p&gt;作为mysql服务的默认引擎，其中的锁机制自然也是值得深究的。&lt;/p&gt;
&lt;p&gt;查看表锁争用情况语句：show status like &#39;Table%&#39;;&lt;/p&gt;
&lt;p&gt;查看引擎状态语句：SHOW ENGINE engine_name {STATUS | MUTEX}；例如：SHOW ENGINE INNODB STATUS&lt;/p&gt;
&lt;p&gt;官网链接：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html&#34;&gt;点击此处跳转官网页面&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;innodb表级锁&#34;&gt;InnoDB表级锁&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;自增锁(AUTO-INC Locks)：是一种特殊的表级锁，它仅针对拥有AUTO_INCREMENT行的表。为了保证自增键数据的连续性，每次插入数据的时候，都会给该表加上一个自增锁，直到前一个事务执行成功，后一个事务才能执行。可以通过innodb_autoinc_lock_mode变量指定自增锁模式。&lt;/li&gt;
&lt;li&gt;意向共享锁(intention shared lock，IS锁)：表明一个事务试图给表中的各个行设置共享锁；如果另一个事务要给数据行设置共享锁，则需先获取该行所在的表的IS锁；select ... for share可以设置IS锁。&lt;/li&gt;
&lt;li&gt;意向独占锁(intention exclusive lock，IX锁)：表明一个事务试图给表中的各个行设置独占锁；如果另一个事务要给数据行设置独占锁，则需先获取该行所在的表的IX锁；select ... for update可以设置IX锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于各级别锁的兼容情形如下表所示（如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放）：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;X&lt;/th&gt;
&lt;th&gt;IX&lt;/th&gt;
&lt;th&gt;S&lt;/th&gt;
&lt;th&gt;IS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;X&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IX&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IS&lt;/td&gt;
&lt;td&gt;冲突&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;td&gt;兼容&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;innodb行级锁&#34;&gt;InnoDB行级锁&lt;/h4&gt;
&lt;p&gt;InnoDB中的行级锁是通过锁定索引来实现的，这意味着只有通过索引条件进行检索的语句才会被施加行级锁，否则将使用表级锁。&lt;/p&gt;
&lt;p&gt;注意：只有当执行计划真正使用了索引（用explain分析），才会施加行级锁；多个不同的session如果使用了同一个索引键，将会出现锁冲突场景。&lt;/p&gt;
&lt;p&gt;聚集索引：一般是主键；如果主键不存在则使用不为空的唯一索引；如果主键和非空唯一索引都不存在，将会使用InnoDB引擎内置的6字节rowId（名称：GEN_CLUST_INDEX）。&lt;/p&gt;
&lt;h5 id=&#34;记录锁&#34;&gt;记录锁&lt;/h5&gt;
&lt;p&gt;记录锁(Record Locks)：使用精确匹配(=)锁定一个索引记录，例如：select c1 from t where c1 = 10 for update;锁定成功后，将不允许其他事务对该条记录进行修改删除操作。&lt;/p&gt;
&lt;p&gt;值得注意的是，记录锁实际锁定的是索引（主键索引，唯一索引，普通索引，联合索引等），即使表并没有定义索引（对于这种情况，InnoDB会创建一个隐式的聚集索引并使用该索引来进行记录锁定）。&lt;/p&gt;
&lt;p&gt;通过主键索引或唯一索引对数据进行update操作时，会自动对该行数据添加记录锁。例如：update t_test set test_name = &#39;demo_name&#39; where id = 1;&lt;/p&gt;
&lt;h5 id=&#34;间隙锁&#34;&gt;间隙锁&lt;/h5&gt;
&lt;p&gt;间隙锁(Gap Locks)：使用范围匹配(&amp;gt;,&amp;lt;,between等)并请求共享或独占锁时将会锁定一个索引间隙，例如：select c1 from t where c1 between 10 and 30 for update;锁定成功后，在(10,30)之间的c1值将不允许插入。&lt;/p&gt;
&lt;p&gt;间隙锁锁定的是一个不包括边界的区间，即左开右开区间。&lt;/p&gt;
&lt;p&gt;语句：SELECT * FROM table_name WHERE id = 100 FOR UPDATE;如果id不是索引，则会触发间隙锁，将100之前的区间锁定(验证时更新id=100的数据同样会被阻塞)。&lt;/p&gt;
&lt;p&gt;很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，应该尽量优化业务逻辑，使用相等条件来访问更新数据，避免使用范围条件。&lt;/p&gt;
&lt;p&gt;注意：间隙锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，间隙锁可以预防幻读。&lt;/p&gt;
&lt;h5 id=&#34;临键锁&#34;&gt;临键锁&lt;/h5&gt;
&lt;p&gt;临键锁(Next-Key Locks)：临键锁是记录锁和间隙锁的组合。也可以称之为特殊的间隙锁，它的锁定范围是索引记录及之前的间隙，是一个左开右闭区间。&lt;/p&gt;
&lt;p&gt;使用范围查询并命中了非唯一索引或非主键索引的record记录，此时锁住的就是临键区间。值得注意的是临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。&lt;/p&gt;
&lt;p&gt;假设一个索引值包含10,11,13和20，那么该索引可能的临键锁区间有：(negative infinity, 10]，(10, 11]，(11, 13]，(13, 20]，(20, positive infinity)。&lt;/p&gt;
&lt;p&gt;对于最后一个间隙区间，临键锁会锁定索引中最大值以上的间隙。&lt;/p&gt;
&lt;p&gt;mysql默认行锁类型就是临键锁(Next-Key Locks)。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-Key Locks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。&lt;/p&gt;
&lt;p&gt;注意：临键锁在RC(Read committed)隔离级别下将会被禁用；在RR(Repeatable reads)隔离级别下，临键锁可以预防幻读。&lt;/p&gt;
&lt;h3 id=&#34;innodb-mvcc&#34;&gt;InnoDB MVCC&lt;/h3&gt;
&lt;p&gt;官网链接：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html&#34;&gt;点击此处跳转官网页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;InnoDB multiversion concurrency control(MVCC，多版本并发控制)，主要是为了在RC(Read committed)，RR(Repeatable reads)隔离级别下提高数据库并发性能。&lt;/p&gt;
&lt;p&gt;InnoDB是一个多版本存储引擎，它会将行变动的老版本信息存储下来用于回滚及并发控制。这种特性是基于undo log日志系统实现的；多版本的信息被存储在undo 表空间一个被称作回滚段(rollback segment)的数据结构中。&lt;/p&gt;
&lt;p&gt;当进行并发读写时，InnoDB基于MVCC机制可以达到不加锁的一致性读效果，从而提高并发度；需要注意的是：基于MVCC的读可能会读到老数据，因为快照读会看到在该时间点之前提交的事务所做的更改，而不会看到稍后或未提交的事务所做的更改。&lt;/p&gt;
&lt;p&gt;MVCC简单步骤：当一个读事务产生时，它会进行快照读并生成一个读视图(Read View)，随后根据read view中的记录(trx_ids)访问某个表索引上的记录，通过比较trx_id来确定事务可见性，如果不可见就沿着DB_ROLL_PTR往更老的版本寻找匹配数据。&lt;/p&gt;
&lt;p&gt;如下图所示，事务R开始需要查询表t上的id为1的记录，R开始时事务I已经提交，事务J还在运行，事务K还没开始，这些信息都被记录在了事务R的ReadView中。事务R从索引中找到对应的这条Record[1, C]，对应的trx_id是K，不可见。沿着Rollptr找到Undo中的前一版本[1, B]，对应的trx_id是J，不可见。继续沿着Rollptr找到[1, A]，trx_id是I可见，返回结果。（此段及图片摘自：&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/10/01/&#34;&gt;点击此处跳转文章&lt;/a&gt;）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230306003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;当前读与快照读&#34;&gt;当前读与快照读&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;当前读：返回的永远是最新的数据，一般通过加锁来实现，例如select ... for update；&lt;/li&gt;
&lt;li&gt;快照读：基于MVCC，并由InnoDB多版本存储引擎实现，可以让一个读事务读取多版本中可见的版本数据。&lt;/li&gt;
&lt;li&gt;RR级别下快照读：RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的（除了当前事务本身的更新操作），而早于Read View提交的事务所做的修改均是可见。&lt;/li&gt;
&lt;li&gt;RC级别下快照读：每次快照读时都会生成一个快照和Read View，这也就是为何可以看到其他事务提交的更新的原因。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;innodb行内部存储字段&#34;&gt;InnoDB行内部存储字段&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;DB_TRX_ID：6字节，记录了最后一次行插入或更新事务的事务标识。此外，删除在内部也会被视作更新，即在行中的一个特定位上打上已删除标记。&lt;/li&gt;
&lt;li&gt;DB_ROLL_PTR：7字节，一般被称作回滚指针，它指向回滚段(rollback segment中的回滚日志记录。&lt;/li&gt;
&lt;li&gt;DB_ROW_ID：6字节，行id，随着行新增而自增；如果是由InnoDB自动生成的聚集索引，则索引即为该值；否则，该值不会出现在任何索引中。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;read-view相关属性&#34;&gt;Read View相关属性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;m_ids：表示在生成READVIEW时当前系统中活跃的读写事务的事务id列表，活跃的是指当前系统中那些尚未提交的事务。&lt;/li&gt;
&lt;li&gt;m_up_limit_id：表示在生成READVIEW时当前系统中活跃的读写事务中最小的事务id，也就是trx_ids中的最小值。&lt;/li&gt;
&lt;li&gt;m_low_limit_id：表示生成READVIEW时系统中应该分配给下一个事务的事务id值，由于事务id一般是递增分配的，所以max_trx_id就是trx_ids中最大的那个id再加上1。&lt;/li&gt;
&lt;li&gt;m_creator_trx_id：表示生成该READVIEW的事务id，由于只有在对表中记录做改动（增删改）时才会为事务分配事务id，所以在一个读取数据的事务中的事务id默认为0。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;read-view-可见性判断具体可参见mysql源码&#34;&gt;Read View 可见性判断（具体可参见mysql源码）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如果trx_id = m_creator_trx_id，表示当前读事务正在读取被自己修改过的记录，该版本可以被当前事务访问。&lt;/li&gt;
&lt;li&gt;如果trx_id &amp;lt; m_up_limit_id，表明生成该版本的事务在当前事务生成READVIEW前已经提交了，所以该版本可以被当前事务访问。&lt;/li&gt;
&lt;li&gt;如果trx_id &amp;gt;= m_low_limit_id，表明生成该版本的事务在当前事务生成READVIEW后提交，所以该版本不可被当前事务访问。&lt;/li&gt;
&lt;li&gt;如果 trx_id在m_low_limit_id, m_up_limit_id之间，则需要判断trx_id是否在m_ids列表中；如果存在，则表明事务处于活跃状态，此时是不可见的；否则可见。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/read/read0read.cc
/**
ReadView constructor */
ReadView::ReadView()
    : m_low_limit_id(),
      m_up_limit_id(),
      m_creator_trx_id(),
      m_ids(),
      m_low_limit_no() {
  ut_d(::memset(&amp;amp;m_view_list, 0x0, sizeof(m_view_list)));
  ut_d(m_view_low_limit_no = 0);
}

/**
Opens a read view where exactly the transactions serialized before this
point in time are seen in the view.
@param id		Creator transaction id */

void ReadView::prepare(trx_id_t id) {
  ut_ad(trx_sys_mutex_own());

  m_creator_trx_id = id;

  m_low_limit_no = trx_get_serialisation_min_trx_no();

  m_low_limit_id = trx_sys_get_next_trx_id_or_no();

  ut_a(m_low_limit_no &amp;lt;= m_low_limit_id);

  if (!trx_sys-&amp;gt;rw_trx_ids.empty()) {
    copy_trx_ids(trx_sys-&amp;gt;rw_trx_ids);
  } else {
    m_ids.clear();
  }

  /* The first active transaction has the smallest id. */
  m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id;

  ut_a(m_up_limit_id &amp;lt;= m_low_limit_id);

  ut_d(m_view_low_limit_no = m_low_limit_no);
  m_closed = false;
}

源码地址：https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/include/read0types.h
/** Check whether the changes by id are visible.
@param[in]	id	transaction id to check against the view
@param[in]	name	table name
@return whether the view sees the modifications of id. */
[[nodiscard]] bool changes_visible(trx_id_t id,
                                 const table_name_t &amp;amp;name) const {
ut_ad(id &amp;gt; 0);

if (id &amp;lt; m_up_limit_id || id == m_creator_trx_id) {
  return (true);
}

check_trx_id_sanity(id, name);

if (id &amp;gt;= m_low_limit_id) {
  return (false);

} else if (m_ids.empty()) {
  return (true);
}

const ids_t::value_type *p = m_ids.data();

return (!std::binary_search(p, p + m_ids.size(), id));
}

&lt;/code&gt;&lt;/pre&gt;
">MySQL架构与EXPLAIN与锁</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/es7-jia-gou-yuan-li-ji-xuan-ju-yuan-ma/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述elasticsearch架构组件，读写原理，性能优化以及节点选举和选举流程源码。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-1462655_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;原理概述&#34;&gt;原理概述&lt;/h2&gt;
&lt;h3 id=&#34;基础架构图&#34;&gt;基础架构图&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303025.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;1: Gateway是ES用来存储索引的文件系统。支持多种类型：包括本地文件系统(默认)，分片文件系统，HDFS，S3等。&lt;/p&gt;
&lt;p&gt;2: Distributed Lucene Directory指的是Apach Lucene框架。&lt;/p&gt;
&lt;p&gt;3: Lucene之上是ES的模块，包括：索引模块、搜索模块、映射解析模块以及River模块（river代表数据从其他存储框架（如：mysql）流入ES）。&lt;/p&gt;
&lt;p&gt;4: ES模块之上是 Discovery、Scripting和第三方插件。&lt;/p&gt;
&lt;p&gt;5: 再上层是ES的传输模块和JMX.传输模块支持多种传输协议，如 Thrift、memecached、http，默认使用http。JMX是java的管理框架，用来管理ES应用。&lt;/p&gt;
&lt;p&gt;6: 最上层是ES提供给用户的接口，可以通过RESTful接口或定制的SDK和ES集群进行交互。&lt;/p&gt;
&lt;h2 id=&#34;读写原理&#34;&gt;读写原理&lt;/h2&gt;
&lt;h3 id=&#34;术语介绍&#34;&gt;术语介绍&lt;/h3&gt;
&lt;p&gt;segment file: 类似于倒排索引，但其中包含的数据结构更丰富（Inverted Index, Stored Fields, Document Values, Cache等）；一组segment集合加上commit point便构成了Lucene中的index（动态索引，可类比Java中的动态数组概念，每个segment便是一个数组，commit point便是ArrayList；也类似于Java1.8的ConcurrentHashMap分段概念）。&lt;/p&gt;
&lt;p&gt;commit point: 记录了当前所有可用的segment file文件。数据可被搜索到。&lt;/p&gt;
&lt;p&gt;translog: 持久化地记录了所有还没被刷到磁盘的操作，避免宕机时，数据丢失。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。translog 会每隔 5 秒异步执行或者在每一个请求完成之后执行一次 fsync 操作，将 translog 从缓存刷入磁盘，这个操作比较耗时，如果对数据一致性要求不是很高时建议将索引改为 async ，如果节点宕机时会有 5 秒数据丢失;&lt;/p&gt;
&lt;p&gt;In-memory buffer: ES中的内存缓存，每当索引数据时，都会将数据先存储到该buffer及translog中。&lt;/p&gt;
&lt;p&gt;refresh: 打开或创建一个新的segment的过程，即将数据从内存刷入filesystem cache并清空当前buffer的过程(默认每隔一秒或者buffer满了便会执行该操作)。&lt;/p&gt;
&lt;p&gt;merge: refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。&lt;/p&gt;
&lt;p&gt;flush&amp;amp;commit: 默认每隔30分钟或者translog数据量达到512mb则会触发一次flush操作。此过程会将所有数据刷入硬盘中进行持久化存储。&lt;/p&gt;
&lt;h3 id=&#34;写操作原理&#34;&gt;写操作原理&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303026.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;具体步骤如下：&lt;/p&gt;
&lt;p&gt;1、数据写入buffer及translog中，此时是搜索不到的。&lt;/p&gt;
&lt;p&gt;2、默认每隔一秒或buffer已满，则执行一次refresh操作，将数据刷入filesystem cache生成segment file，此时数据可被搜索，并清空当前的buffer。&lt;/p&gt;
&lt;p&gt;3、translog中的数据存储在os cache中，之后默认每隔5秒会持久化到磁盘中（时间可设置，长短将影响性能）。&lt;/p&gt;
&lt;p&gt;4、重复上述步骤，直到抵达默认的30分钟或者translog达到512mb时（相关参数可配置），便会触发一次flush操作（commit操作）：该操作首先将buffer中现有的数据refresh到os cache中去，并清空buffer；然后将一个commit point写入磁盘文件，里面标识着这个commit point 对应的所有segment file，同时强行将os cache中目前所有的数据都fsync到磁盘文件中去；最后清空现有 translog日志文件，重启一个新的translog，此时flush操作完成。&lt;/p&gt;
&lt;p&gt;额外补充：&lt;/p&gt;
&lt;p&gt;5、删除操作，commit的时候会产生一个.del文件，里面将某个doc标记为delete状态（并非实时删除），搜索时会自动过滤掉标记为删除状态的数据。&lt;/p&gt;
&lt;p&gt;6、更新操作，将原来的doc标识为delete状态，然后重新写入一条新数据即可。&lt;/p&gt;
&lt;p&gt;7、refresh操作会导致segment频繁的生成，这些segment会占据独立的文件句柄/内存/CPU等，且每次搜索时，都要在segment上执行查询，这样会导致整个执行效率变得低下；所以，有必要对segment进行适当的merge操作，此过程会将多个相似大小的segment合并为一个大的segment，并删除那些被标记为删除的document（此时为实际物理删除文件）。&lt;/p&gt;
&lt;p&gt;8、数据一致性由translog保证（丢失数据取决于fsync的时间）；副本一致性则是采用的半同步机制，即主分片写成功后，只需一部分数量（quorum）的副本写入成功即可返回。相关配置wait_for_active_shards的默认值为int( (primary + number_of_replicas) / 2 ) + 1&lt;/p&gt;
&lt;h3 id=&#34;读操作原理&#34;&gt;读操作原理&lt;/h3&gt;
&lt;p&gt;读过程大体上分为查询与取回两个阶段。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;查询阶段&lt;/li&gt;
&lt;li&gt;当一个搜索请求被发送到某个节点时，该节点就变成协调节点。这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。&lt;/li&gt;
&lt;li&gt;首先将广播请求到索引中每一个节点的分片拷贝，查询请求可以被某个主分片或某个副分片处理（这就是为什么更多的副本（当结合更多的硬件）能够增加搜索吞吐率），协调节点将在之后的请求中轮训所有的分片拷贝来分摊负载。&lt;/li&gt;
&lt;li&gt;每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列—也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。&lt;/li&gt;
&lt;li&gt;协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。&lt;/li&gt;
&lt;li&gt;取回阶段&lt;/li&gt;
&lt;li&gt;查询过程得到的排序结果，标记出哪些文档是符合要求的，此时仍然需要获取这些文档返回给客户端。&lt;/li&gt;
&lt;li&gt;协调节点会辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求；每个分片加载并修饰文档，如果有需要的话，接着返回文档给协调节点&lt;/li&gt;
&lt;li&gt;一旦所有的文档都被取回了，协调节点返回结果给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意1：先查后取的过程支持用 from 和 size 参数分页，但是这是有限制的。要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 number_of_shards * (from + size) 排序文档，来找到被包含在 size 里的文档。&lt;/p&gt;
&lt;p&gt;注意2：一般不建议使用深度搜索，这将会耗费大量额外的cpu，内存与带宽（ES默认深度分页限制为10000条，即from + size &amp;lt;=10000）;如果有需要，可以使用scroll进行查询。&lt;/p&gt;
&lt;h2 id=&#34;性能优化&#34;&gt;性能优化&lt;/h2&gt;
&lt;h3 id=&#34;filesystem-cache&#34;&gt;filesystem cache&lt;/h3&gt;
&lt;p&gt;由上述写过程原理可知，ES的数据在filesystem cache中便可被搜索到，那么对应的，如果给予filesystem cache更多的机器内存，让它足以容纳下所有的index segment file，相应的查询效率将会获得长足的提高（内存与磁盘查询效率相差巨大）。同时，如果数据量非常之大，那么ES中应该尽量存储doc_id之类的字段，减少大文本存储（大文本存入分布式文件系统中）。&lt;/p&gt;
&lt;h3 id=&#34;数据预热与冷热分离&#34;&gt;数据预热与冷热分离&lt;/h3&gt;
&lt;p&gt;某些热点数据，可通过缓存预热系统进行提前查询，让其流入filesystem cache中；同时，对冷热数据进行隔离存储，确保热数据一直在filesystem cache。&lt;/p&gt;
&lt;h3 id=&#34;合理的文档设计&#34;&gt;合理的文档设计&lt;/h3&gt;
&lt;p&gt;不要出现复杂性的查询操作，尽量在设计阶段就做一定的冗余，让相关数据在同一个文档中。&lt;/p&gt;
&lt;h3 id=&#34;避免深度分页&#34;&gt;避免深度分页&lt;/h3&gt;
&lt;p&gt;就像读过程原理中所描述，过度的深分页查询，会占用大量的cpu，内存与带宽；如果有对应的需求，可通过scroll api进行查询。&lt;/p&gt;
&lt;h2 id=&#34;节点发现与选举流程源码&#34;&gt;节点发现与选举流程源码&lt;/h2&gt;
&lt;p&gt;节点启动时，便会开始加入集群；启动函数：org.elasticsearch.node.Node.start()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public Node start() throws NodeValidationException {
    // start after transport service so the local disco is known
    // start before cluster service so that it can set initial state on ClusterApplierService
    discovery.start(); 
    clusterService.start();
    // 服务发现函数
    discovery.startInitialJoin();
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查询mater节点；对应函数在discovery.startInitialJoin()中；&lt;br&gt;
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.findMaster()；此处选举id最小的节点是因为es沿用了bully算法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private DiscoveryNode findMaster() {
    logger.trace(&amp;quot;starting to ping&amp;quot;);
    // 开始ping操作，获取当前集群处于活跃状态的节点信息
    // pingAndWait函数实际上调用了org.elasticsearch.discovery.zen.UnicastZenPing.ping()
    // 它会主动从discovery.seed_hosts配置中读取信息（7.*之前的老版本配置为：discovery.zen.ping.unicast.hosts）
    // 最终返回的节点信息中，包含有master信息
    List&amp;lt;ZenPing.PingResponse&amp;gt; fullPingResponses = pingAndWait(pingTimeout).toList();

    // 将本节点也加入 fullPingResponses 中
    final DiscoveryNode localNode = transportService.getLocalNode();
    assert fullPingResponses.stream().map(ZenPing.PingResponse::node).filter(n -&amp;gt; n.equals(localNode)).findAny().isPresent() == false;
    fullPingResponses.add(new ZenPing.PingResponse(localNode, null, this.clusterState()));

    // filter responses
    // 如果配置了discovery.zen.master_election.ignore_non_master_ping（即：masterElectionIgnoreNonMasters）为true将会过滤出所有的主节点信息
    // 默认为false
    final List&amp;lt;ZenPing.PingResponse&amp;gt; pingResponses = filterPingResponses(fullPingResponses, masterElectionIgnoreNonMasters, logger);

    // 遍历列表，将节点认为的主节点信息存入activeMasters
    List&amp;lt;DiscoveryNode&amp;gt; activeMasters = new ArrayList&amp;lt;&amp;gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        // We can&#39;t include the local node in pingMasters list, otherwise we may up electing ourselves without
        // any check / verifications from other nodes in ZenDiscover#innerJoinCluster()
        if (pingResponse.master() != null &amp;amp;&amp;amp; localNode.equals(pingResponse.master()) == false) {
            activeMasters.add(pingResponse.master());
        }
    }

    // 如果ping过程中发现了具备资格成为master的节点，将其存入masterCandidates 
    List&amp;lt;ElectMasterService.MasterCandidate&amp;gt; masterCandidates = new ArrayList&amp;lt;&amp;gt;();
    for (ZenPing.PingResponse pingResponse : pingResponses) {
        if (pingResponse.node().isMasterNode()) {
            masterCandidates.add(new ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion()));
        }
    }

    if (activeMasters.isEmpty()) {
        // 判断是否有足够的候选者，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.hasEnoughMasterNodes()
        if (electMaster.hasEnoughCandidates(masterCandidates)) {
            // 从候选者中选举新的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.electMaster()
            // 选举逻辑比较简单，直接按id排序，随后取出最小id的节点，即为主节点
            final ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates);
            logger.trace(&amp;quot;candidate {} won election&amp;quot;, winner);
            return winner.getNode();
        } else {
            // if we don&#39;t have enough master nodes, we bail, because there are not enough master to elect from
            logger.warn(
                    &amp;quot;not enough master nodes discovered during pinging (found [{}], but needed [{}]), pinging again&amp;quot;,
                    masterCandidates,
                    electMaster.minimumMasterNodes()
            );
            return null;
        }
    } else {
        assert activeMasters.contains(localNode) == false
                : &amp;quot;local node should never be elected as master when other nodes indicate an active master&amp;quot;;
        // lets tie break between discovered nodes
        // 按id进行二级排序，并返回最小id的主节点，对应函数为：org.elasticsearch.discovery.zen.ElectMasterService.tieBreakActiveMasters()
        return electMaster.tieBreakActiveMasters(activeMasters);
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;确认mater节点；对应函数在discovery.startInitialJoin()中；&lt;br&gt;
核心函数为：org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 1.本节点是master
if (transportService.getLocalNode().equals(masterNode)) {
    // 等待足够多的节点加入本节点
    final int requiredJoins = Math.max(0, electMaster.minimumMasterNodes() - 1); // we count as one
    logger.debug(&amp;quot;elected as master, waiting for incoming joins ([{}] needed)&amp;quot;, requiredJoins);
    // masterElectionWaitForJoinsTimeout默认超时时间为30秒，如果超时则直接return
    // 对应函数：org.elasticsearch.discovery.zen.NodeJoinController.waitToBeElectedAsMaster()
    nodeJoinController.waitToBeElectedAsMaster(
        requiredJoins,
        masterElectionWaitForJoinsTimeout,
        new NodeJoinController.ElectionCallback() {
            // 进行master选举
            @Override
            public void onElectedAsMaster(ClusterState state) {
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDone(currentThread);
                }
            }

            // 失败则重新发起加入集群流程
            @Override
            public void onFailure(Throwable t) {
                logger.trace(&amp;quot;failed while waiting for nodes to join, rejoining&amp;quot;, t);
                synchronized (stateMutex) {
                    joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
                }
            }
        }

    );
}

// NodeJoinController.waitToBeElectedAsMaster()
public void waitToBeElectedAsMaster(int requiredMasterJoins, TimeValue timeValue, final ElectionCallback callback) {
    try {
        // check what we have so far..
        // capture the context we add the callback to make sure we fail our own
        // 检查是否已有requiredMasterJoins的节点数
        synchronized (this) {
            assert electionContext != null : &amp;quot;waitToBeElectedAsMaster is called we are not accumulating joins&amp;quot;;
            myElectionContext = electionContext;
            electionContext.onAttemptToBeElected(requiredMasterJoins, wrapperCallback);
            // 如果节点数已达标，将该节点设置为master
            checkPendingJoinsAndElectIfNeeded();
        }

        try {
            // 超时直接return
            if (done.await(timeValue.millis(), TimeUnit.MILLISECONDS)) {
                // callback handles everything
                return;
            }
        } catch (InterruptedException e) {

        }
    } catch (Exception e) {
        logger.error(&amp;quot;unexpected failure while waiting for incoming joins&amp;quot;, e);
        if (myElectionContext != null) {
            failContextIfNeeded(myElectionContext, &amp;quot;unexpected failure while waiting for pending joins [&amp;quot; + e.getMessage() + &amp;quot;]&amp;quot;);
        }
    }
}

// NodeJoinController.checkPendingJoinsAndElectIfNeeded()
private synchronized void checkPendingJoinsAndElectIfNeeded() {
    // 发布clusterState
    electionContext.closeAndBecomeMaster();
}

// NodeJoinController.closeAndBecomeMaster
public synchronized void closeAndBecomeMaster() {
    innerClose();

    Map&amp;lt;JoinTaskExecutor.Task, ClusterStateTaskListener&amp;gt; tasks = getPendingAsTasks(&amp;quot;become master&amp;quot;);
    final String source = &amp;quot;zen-disco-elected-as-master ([&amp;quot; + tasks.size() + &amp;quot;] nodes joined)&amp;quot;;

    // noop listener, the election finished listener determines result
    tasks.put(JoinTaskExecutor.newBecomeMasterTask(), (source1, e) -&amp;gt; {});
    tasks.put(JoinTaskExecutor.newFinishElectionTask(), electionFinishedListener);
    // 提交更新状态的任务
    masterService.submitStateUpdateTasks(source, tasks, ClusterStateTaskConfig.build(Priority.URGENT), joinTaskExecutor);
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;// 本节点不是master
// process any incoming joins (they will fail because we are not the master)
// 拒绝其他节点加入，因为本节点不是master
nodeJoinController.stopElectionContext(masterNode + &amp;quot; elected&amp;quot;);

// send join request
// 发送加入master的请求
final boolean success = joinElectedMaster(masterNode);

synchronized (stateMutex) {
    if (success) {
        // currentMasterNode 为空，或者当选的master不是之前选择的节点，进行重试加入
        DiscoveryNode currentMasterNode = this.clusterState().getNodes().getMasterNode();
        if (currentMasterNode == null) {
            // Post 1.3.0, the master should publish a new cluster state before acking our join request. we now should have
            // a valid master.
            logger.debug(&amp;quot;no master node is set, despite of join request completing. retrying pings.&amp;quot;);
            joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
        } else if (currentMasterNode.equals(masterNode) == false) {
            // update cluster state
            joinThreadControl.stopRunningThreadAndRejoin(&amp;quot;master_switched_while_finalizing_join&amp;quot;);
        }

        joinThreadControl.markThreadAsDone(currentThread);
    } else {
        // failed to join. Try again...
        // 失败则重新发起加入集群流程
        joinThreadControl.markThreadAsDoneAndStartNew(currentThread);
    }
}

private boolean joinElectedMaster(DiscoveryNode masterNode) {
    try {
        // first, make sure we can connect to the master
        transportService.connectToNode(masterNode);
    } catch (Exception e) {
        logger.warn(() -&amp;gt; new ParameterizedMessage(&amp;quot;failed to connect to master [{}], retrying...&amp;quot;, masterNode), e);
        return false;
    }
    int joinAttempt = 0; // we retry on illegal state if the master is not yet ready
    while (true) {
        try {
            logger.trace(&amp;quot;joining master {}&amp;quot;, masterNode);
            // joinTimeout 默认超时时间60s，org.elasticsearch.discovery.zen.MembershipAction.MembershipAction()
            membership.sendJoinRequestBlocking(masterNode, transportService.getLocalNode(), joinTimeout);
            return true;
        } catch (Exception e) {
            final Throwable unwrap = ExceptionsHelper.unwrapCause(e);
            if (unwrap instanceof NotMasterException) {
                // joinRetryAttempts 重试次数，默认3次
                if (++joinAttempt == this.joinRetryAttempts) {
                    logger.info(
                        &amp;quot;failed to send join request to master [{}], reason [{}], tried [{}] times&amp;quot;,
                        masterNode,
                        ExceptionsHelper.detailedMessage(e),
                        joinAttempt
                    );
                    return false;
                }
            } else {
                return false;
            }
        }

        try {
            Thread.sleep(this.joinRetryDelay.millis());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由上述步骤总结如下：&lt;/p&gt;
&lt;p&gt;1、服务启动后，开始进行加入集群操作；&lt;/p&gt;
&lt;p&gt;2、调用ping命令，最终获取一个包含节点基本信息及其所认为的master信息的列表（包括本节点）；&lt;/p&gt;
&lt;p&gt;3、过滤结果列表，将master节点汇总到activeMasters，将master候选者节点汇总到masterCandidates；&lt;/p&gt;
&lt;p&gt;4、判断如果activeMasters不为空，则从activeMasters中选择最小ID的一个节点；否则从candidateMasters中选择，先判断是否有足够的候选者，之后再排序选择ID最小的一个节点作为新的master；&lt;/p&gt;
&lt;p&gt;5、投票阶段，每个节点都向自己认为的master进行joinRequest请求,对应的会产生如下两种情形：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本节点是master：该节点统计发送过来的joinRequest个数，如果在指定的时间（默认30s，可配置）内达到requiredJoins个数，则发布集群信息，并回复joinRequest请求，最后完成选举，否则选举失败；&lt;/li&gt;
&lt;li&gt;本节点不是master：首先，拒绝其他节点的joinRequest，其次向该节点认为的master发送joinRequest请求，并等待，如果在指定的时间（60s，可配置）未收到回复或异常重试3次都失败了则选举失败，之后将重新发起加入集群流程；否则如果收到的回复中没有master信息或者master信息不是之前选择的临时master节点则选举失败，同样会进行重新加入操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意：es使用延迟选举解决了选举过程中不断出现master假死现象（即master由于负载过重而假死，随后第二小id的节点成为master，之后故障节点又恢复再次被选为master，接着又假死...如此循环）；同时，es增加了法定得票人数机制，解决了脑裂（split-brain）问题。&lt;/p&gt;
&lt;p&gt;脑裂指的是集群中出现多个主节点，导致集群割裂的一种异常情况。&lt;/p&gt;
&lt;p&gt;法定个数：有master资格的节点数（官方建议）：n/2 + 1；其中n为有资格成为主节点的节点数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 7.*版本后，discovery.zen.minimum_master_node已不再提供配置，而是由内置的代码处理
private void commonNodeConfig(ElasticsearchNode node, String nodeNames, ElasticsearchNode firstNode) {
    if (node.getVersion().onOrAfter(&amp;quot;7.0.0&amp;quot;)) {
        node.defaultConfig.keySet()
            .stream()
            .filter(name -&amp;gt; name.startsWith(&amp;quot;discovery.zen.&amp;quot;))
            .collect(Collectors.toList())
            .forEach(node.defaultConfig::remove);
        if (nodeNames != null &amp;amp;&amp;amp; node.settings.getOrDefault(&amp;quot;discovery.type&amp;quot;, &amp;quot;anything&amp;quot;).equals(&amp;quot;single-node&amp;quot;) == false) {
            node.defaultConfig.put(&amp;quot;cluster.initial_master_nodes&amp;quot;, &amp;quot;[&amp;quot; + nodeNames + &amp;quot;]&amp;quot;);
        }
        node.defaultConfig.put(&amp;quot;discovery.seed_providers&amp;quot;, &amp;quot;file&amp;quot;);
        node.defaultConfig.put(&amp;quot;discovery.seed_hosts&amp;quot;, &amp;quot;[]&amp;quot;);
    } else {
        node.defaultConfig.put(&amp;quot;discovery.zen.master_election.wait_for_joins_timeout&amp;quot;, &amp;quot;5s&amp;quot;);
        if (nodes.size() &amp;gt; 1) {
            node.defaultConfig.put(&amp;quot;discovery.zen.minimum_master_nodes&amp;quot;, Integer.toString(nodes.size() / 2 + 1));
        }
        if (node.getVersion().onOrAfter(&amp;quot;6.5.0&amp;quot;)) {
            node.defaultConfig.put(&amp;quot;discovery.zen.hosts_provider&amp;quot;, &amp;quot;file&amp;quot;);
            node.defaultConfig.put(&amp;quot;discovery.zen.ping.unicast.hosts&amp;quot;, &amp;quot;[]&amp;quot;);
        } else {
            if (firstNode == null) {
                node.defaultConfig.put(&amp;quot;discovery.zen.ping.unicast.hosts&amp;quot;, &amp;quot;[]&amp;quot;);
            } else {
                firstNode.waitForAllConditions();
                node.defaultConfig.put(&amp;quot;discovery.zen.ping.unicast.hosts&amp;quot;, &amp;quot;[\&amp;quot;&amp;quot; + firstNode.getTransportPortURI() + &amp;quot;\&amp;quot;]&amp;quot;);
            }
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
">ES7架构原理及选举源码</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/es-ji-ben-gai-nian-yu-ji-qun/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述elasticsearch基本结构，术语介绍以及路由算法，分片原理等。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/conifers-1850227_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;
&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;ElasticSearch是一个基于Apach Lucene构建的搜索引擎，其天生便是分布式的，具备极强的可扩展性，除此之外，强大的实时分析特性以及分布式存储都是其不可忽视的优点。&lt;/p&gt;
&lt;p&gt;ES的主旨在于随时可用以及按需扩容。垂直扩容（纵向扩容）：性能更强大的硬件机器；水平扩容（横向扩容）：数量更多的服务器。&lt;/p&gt;
&lt;p&gt;由于硬件限制，现阶段的垂直扩容必然存在一个极限，所以对于ES而言，真正的扩容能力还是来自于水平扩容-为集群增加更多的机器（多节点负载与分布式容灾，同时可以进行PB级别的数据分析）。&lt;/p&gt;
&lt;h3 id=&#34;名词解释&#34;&gt;名词解释&lt;/h3&gt;
&lt;h4 id=&#34;索引存储索引&#34;&gt;索引（存储索引）&lt;/h4&gt;
&lt;p&gt;索引（Index）是ElasticSearch存放数据的地方（为了区分搜索索引，暂且称其为存储索引）。以关系数据库类比的话，ES中的索引相当于数据库（es6之后等同于数据表，参见；1.2.2文档类型-重点注意）的概念。但是与关系数据库相比，ES可以更快速且高效的对索引中的数据进行全文检索。&lt;/p&gt;
&lt;p&gt;究其根本是由于ES/Lucene使用的倒排索引相较于关系数据库中的b-tree，b+tree而言，多了一层内存索引概念（此处的索引指搜索索引，而非存储索引）。&lt;/p&gt;
&lt;p&gt;内存索引是对磁盘索引的一层简化封装，例如：磁盘索引为Alex，Bob，Curl，Abnormal；那么内存索引则为：A，B，C，b，这些简化字段会组成一颗trie tree（前缀树，根据字典顺序升序排列），通过特定的压缩技术（Lucene Finite State Transducers &lt;a href=&#34;https://cs.nyu.edu/~mohri/pub/fla.pdf&#34;&gt;点击此处跳转文档页面&lt;/a&gt;）可以将其尺寸缩小数十倍，使得用内存缓存trie tree变成可能。&lt;/p&gt;
&lt;p&gt;正是基于内存索引的优化，ES/Lucene才能比关系数据库更快的检索出结果；因为其在内存中已经找到了对应的磁盘索引，可以直接根据磁盘索引查询对应的磁盘数据，而关系数据库则需要遍历查找出对应的磁盘索引，之后再根据磁盘索引查询磁盘数据，这中间便多了磁盘的random access次数（一次磁盘random access大概耗时10ms，耗时会随着磁盘硬件的优劣而产生一定的浮动）。&lt;/p&gt;
&lt;p&gt;关于多字段查询，ES/Lucene有两种合并方式：1.skip list实现联合索引的；对跳表中的数据进行快速与运算。2.bitset实现快速合并，进行按位与运算。两种方式的比较可参考：&lt;a href=&#34;https://www.elastic.co/cn/blog/frame-of-reference-and-roaring-bitmaps&#34;&gt;点击此处跳转页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;综上所述，整体效果图如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303015.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;文档类型&#34;&gt;文档类型&lt;/h4&gt;
&lt;p&gt;ES中的索引可以存储许多不同用途的对象，如：学生对象，课程对象等，为了更轻松地区分这些对象，文档类型这个概念便应运而生（可类比于关系数据库中的表）；在实际操作中，为文档划分不同的类型，可以更方便的操作数据。&lt;/p&gt;
&lt;p&gt;注意：划分文档类型时存在一定的限制条件，其中之一便是不同的文档类型对同一字段不能设置为不同的字段类型。例如：学生对象中的课程id是Integer类型，而课程对象中的id是String，这是不行的。详情可参考：&lt;a href=&#34;https://www.elastic.co/guide/cn/elasticsearch/guide/current/mapping.html&#34;&gt;点击此处跳转页面&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;重点注意：es6.0.0之前单个索引可以有多个文档类型，es6.0.0之后单个索引只能有一个文档类型，7.0.0之后文档类型字段已被设置为过期，8.0.0将会完全不支持文档类型字段。原因参见上述注意点。&lt;/p&gt;
&lt;h4 id=&#34;文档及字段&#34;&gt;文档及字段&lt;/h4&gt;
&lt;p&gt;文档（document）是ES中存储的主要实体（类比于关系数据库中的一行数据），而字段则是具体的一对KV组合（类比于关系数据库中的一列数据）。&lt;/p&gt;
&lt;p&gt;需要额外注意的是：字段类型（字符串型，数值型，日期型）决定了ES该执行何种操作，如比较、排序等。&lt;/p&gt;
&lt;p&gt;幸运的是ES可以自动确定字段类型，当然也可以通过模式映射（schema mapping）自定义文档结构。&lt;/p&gt;
&lt;h2 id=&#34;集群概念&#34;&gt;集群概念&lt;/h2&gt;
&lt;h3 id=&#34;节点与集群&#34;&gt;节点与集群&lt;/h3&gt;
&lt;p&gt;ElasticSearch可以作为一个独立的搜索服务器工作。然而，为了能够处理大型数据集并实现高可用容灾功能，我们有必要在多台服务器上部署运行ES。&lt;/p&gt;
&lt;p&gt;一个运行中的ES实例称为一个节点，而集群则是由一个或多个拥有相同cluster.name配置的节点组成，集群中的所有节点共享数据且分担负载。&lt;/p&gt;
&lt;p&gt;一个集群存在一个主节点（选举生成），它负责管理集群范围内的所有变更，如节点的增删，索引的增删等（不涉及文档级别）。&lt;/p&gt;
&lt;p&gt;查看集群健康状态：curl -X GET &amp;quot;localhost:9200/_cluster/health?pretty&amp;quot;&lt;/p&gt;
&lt;p&gt;其中status字段展示了集群的健康状况：green：所有主/副本分片都是正常的；yellow：所有主分片都正常，但并不是所有副本分片都正常；red：所有主/副本分片都不正常。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303016.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;分片概述&#34;&gt;分片概述&lt;/h3&gt;
&lt;p&gt;一个分片是一个底层的工作单元，它只存储了全部数据的一部分。前文所说的索引（存储数据的地方），实际上也是指向一个或多个物理分片的逻辑命名空间。&lt;/p&gt;
&lt;p&gt;每个分片都是一个完整的搜索引擎，也即是一个Lucene实例。应用程序并不需要关注分片的存在，只需跟索引进行交互即可（ES透明处理了分片数据合并的过程）。&lt;/p&gt;
&lt;p&gt;所有的分片都可以存储在集群中的任一节点中，而文档数据则存储在各个分片内，这便是ES集群管理数据的方式。&lt;/p&gt;
&lt;p&gt;一个分片既可以是主分片，也可以是副本分片。索引中的任意文档都归属于一个主分片，所以主分片的数量决定了索引能够保存的最大数据量（Integer.MAX_VALUE-128，这是理论最大值，实际中还与硬件设备、文档大小、文档复杂度，索引和查询文档的方式以及期待的响应时长有关）。&lt;/p&gt;
&lt;p&gt;副本分片主要用于高可用容灾与备份，是对主分片数据的一个拷贝，同时提供搜索和返回文档等读操作。&lt;/p&gt;
&lt;p&gt;注意：扩容时，我们可以通过增加副本分片来提高搜索性能，但如果节点不变的情况下，我们增大副本分片仅仅只能带来容灾备份；这是因为每个分片从节点上获取的资源会变少，所以想增加吞吐量唯有扩展机器资源了。&lt;/p&gt;
&lt;p&gt;设置三个主分片以及一个副本分片（每个主分片都拥有一个副本分片）：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303017.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;修改一个副本分片为两个副本分片：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303018.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;路由算法&#34;&gt;路由算法&lt;/h3&gt;
&lt;p&gt;分布式存储少不了路由算法，在ES中是通过hash算法来确定数据该存储到哪一个节点/分片中的。&lt;/p&gt;
&lt;p&gt;公式：shard = hash(routeKey) % number_of_primary_shards&lt;/p&gt;
&lt;p&gt;其中routeKey是一个随机数，一般情况下默认是文档id，不过也可以直接指定对应的值。&lt;/p&gt;
&lt;p&gt;该公式也表明了主分片数为何只能在创建索引的时候设置，并且不允许被修改（如果被更改，那么之前的数据将无法被查询到，因为路由值已经不同）。&lt;/p&gt;
&lt;h3 id=&#34;集群交互&#34;&gt;集群交互&lt;/h3&gt;
&lt;p&gt;以三节点集群为例，其中包含一个blogs的索引，它对应的设置为：主分片数：2，副本数：2。一般相同分片的副本不会存放在同一节点，如下图：&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ES中的每个节点都有能力处理任意操作请求。&lt;/li&gt;
&lt;li&gt;如果某个节点被指定为接受请求的节点，那么该节点被称为协调节点（coordinating  node）&lt;/li&gt;
&lt;li&gt;为了后续更好的扩展负载，一般使用轮询机制遍历集群中的所有节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303019.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;新建删除文档&#34;&gt;新建/删除文档&lt;/h4&gt;
&lt;p&gt;新建与删除操作需要在主节点操作结束后，才能同步至副本分片中，如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303020.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;操作步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向NODE1发送新建，删除请求。&lt;/li&gt;
&lt;li&gt;NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。&lt;/li&gt;
&lt;li&gt;NODE3上的请求执行成功后，它会将请求并行地转发至NODE1与NODE2上的副本分片。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;额外参数补充：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consistency：一致性。此参数默认配置下进行写操作时，主分片会要求集群中的大部分（规定数量（quorum））分片副本处于活跃可用状态，否则将不会进行写操作。如此设置的目的是为了防止出现网络分区故障时，写操作出现数据不一致的现象。&lt;/li&gt;
&lt;li&gt;规定数量公式：int((primary + number_of_replicas)/2) + 1；其中number_of_replicas指的是设置索引时对应的副本分片数，且只有该值大于1时，规定数量设置才会生效（因为单节点默认配置会影响写操作）。&lt;/li&gt;
&lt;li&gt;consistency参数值：one 表示主分片状态ok即可执行写操作；all 表示主分片及所有副本分片都ok才能进行写操作；quorum 默认设置，表示副本分片达到规定数量即可执行写操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;更新文档&#34;&gt;更新文档&lt;/h4&gt;
&lt;p&gt;更新操作相较于新建/删除多了一个额外的冲突重试步骤，如下图所示；&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303021.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;操作步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向NODE1发送更新请求。&lt;/li&gt;
&lt;li&gt;NODE1通过路由算法得到文档所属的分片P0，于是请求被转发至NODE3（因为P0分片位于NODE3节点上）。&lt;/li&gt;
&lt;li&gt;NODE3从主分片搜索对应的文档数据，修改_source中的内容，并重新存储至主分片上。如果此过程中，文档被另一个进程修改，那么步骤3将会重复执行，直到retry_on_conflict次后放弃。&lt;/li&gt;
&lt;li&gt;NODE3上的请求执行成功后，它会将新版本的文档并行地转发至NODE1与NODE2上的副本分片，重新建立索引。当所有副本分片都返回执行成功时，NODE3节点将向协调节点（NODE1）回执成功，协调节点（NODE1）随后将成功回执给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：主分片并不会将更改请求转发至副本分片，而是将新版本的文档完整的转发过去，且不保证顺序。如果ES转发更改请求，那么由于顺序的不一致，可能导致文档更新有误，从而使错误的数据存储下来。&lt;/p&gt;
&lt;h4 id=&#34;检索文档&#34;&gt;检索文档&lt;/h4&gt;
&lt;p&gt;ES可以从主分片或者副本分片中得到需要搜素的文档，如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303022.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;操作步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向NODE1发送更新请求。&lt;/li&gt;
&lt;li&gt;NODE1通过路由算法得到文档所属的分片P0，分片P0的副本分片存在所有节点上，在这种情况下（轮询机制），它将请求转发至NODE2。&lt;/li&gt;
&lt;li&gt;NODE2将文档返回给NODE1，NODE1再将文档返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：在处理读请求时，协调节点在每次请求时都会通过轮询机制遍历所有节点来达到负载均衡。这也是步骤2会从NODE2获取数据的原因。&lt;/p&gt;
&lt;p&gt;在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。&lt;/p&gt;
&lt;h4 id=&#34;批量操作文档&#34;&gt;批量操作文档&lt;/h4&gt;
&lt;p&gt;ES批量操作与单文档操作基本一致。区别在于协调节点会将整个文档分解为每个分片的多文档请求，并将这些请求转发至每个参与节点。&lt;/p&gt;
&lt;p&gt;使用单个 mget 请求取回多个文档所需的步骤顺序：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向 Node 1 发送 mget 请求。&lt;/li&gt;
&lt;li&gt;Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303023.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;bulk API 操作步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端向 Node 1 发送 bulk 请求。&lt;/li&gt;
&lt;li&gt;Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。&lt;/li&gt;
&lt;li&gt;主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303024.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">ES基本概念与集群</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/cpu-biao-sheng-wen-ti-pai-cha/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述运行中的Java程序导致的CPU飙升问题排查过程和方法。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/hot-air-balloon-1756150_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;cpu飙升问题排查&#34;&gt;CPU飙升问题排查&lt;/h2&gt;
&lt;h3 id=&#34;问题描述&#34;&gt;问题描述&lt;/h3&gt;
&lt;p&gt;线上系统突然运行缓慢，CPU飙升，甚至到100%，以及Full GC次数过多，接着就是各种报警：例如接口超时报警等。此时急需快速线上排查问题。&lt;/p&gt;
&lt;h3 id=&#34;问题排查&#34;&gt;问题排查&lt;/h3&gt;
&lt;p&gt;不管什么问题，既然是CPU飙升，肯定是查一下耗CPU的线程，然后看看GC。&lt;/p&gt;
&lt;h4 id=&#34;排查步骤&#34;&gt;排查步骤&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;执行“top”命令：查看所有进程占系统CPU的排序。极大可能排第一个的就是咱们的java进程（COMMAND列，也可以直接使用top -p &lt;code&gt;pgrep -d,java&lt;/code&gt;查看系统中JAVA进程的CPU占用情况）。PID那一列就是进程号。&lt;/li&gt;
&lt;li&gt;执行“top -Hp 进程号”命令：查看java进程下的所有线程占CPU的情况。&lt;/li&gt;
&lt;li&gt;执行“printf &amp;quot;%x\n 10&amp;quot;命令 ：后续查看线程堆栈信息展示的都是十六进制，为了找到咱们的线程堆栈信息，咱们需要把线程号转成16进制。例如,printf &amp;quot;%x\n 10-》打印：a，那么在jstack中线程号就是0xa.&lt;/li&gt;
&lt;li&gt;执行 “jstack 进程号 | grep 线程ID” 查找某进程下-》线程ID（jstack堆栈信息中的nid）=0xa的线程堆栈信息。如果“&amp;quot;VM Thread&amp;quot; os_prio=0 tid=0x00007f871806e000 nid=0xa runnable”，第一个双引号圈起来的就是线程名，如果是“VM Thread”这就是虚拟机GC回收线程了&lt;/li&gt;
&lt;li&gt;执行“jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一次统计）”，查看某进程GC持续变化情况，如果发现返回中FGC很大且一直增大-》确认Full GC! 也可以使用“jmap -heap 进程ID”查看一下进程的堆内存是不是要溢出了，特别是老年代内存使用情况，一般是达到阈值(具体看垃圾回收器和启动时配置的阈值)进程就会Full GC。&lt;/li&gt;
&lt;li&gt;执行“jmap -dump:format=b,file=filename 进程ID”，导出某进程下内存heap输出到文件中。可以通过jvisualvm查看（直接双击打开jvisualvm.exe，点击文件-&amp;gt;装入，在文件类型那一栏选择堆，选择要分析的dump文件，打开）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：jmap会导致JVM的停止（您的应用程序已停止。获得准确的堆转储的唯一实用方法是在创建转储时停止所有应用程序活动。这是“简短”暂停还是“长时间”暂停取决于要转储多少。如果使用“ -dump”，则将转储整个堆，包括不可达的对象。如果使用“-dump：live”，则只会转储可访问的对象……但这（至少）需要标记堆以找出可访问的对象。但是，如果要转储千兆字节大小的堆，则期望暂停时间以分钟而不是秒为单位。）。&lt;/p&gt;
&lt;h4 id=&#34;原因分析&#34;&gt;原因分析&lt;/h4&gt;
&lt;h5 id=&#34;内存消耗过大导致full-gc次数过多&#34;&gt;内存消耗过大，导致Full GC次数过多&lt;/h5&gt;
&lt;p&gt;执行步骤1-5：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程-》上一节步骤2&lt;/li&gt;
&lt;li&gt;通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。--》上一节步骤5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;确定是Full GC,接下来找到具体原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生成大量的对象，导致内存溢出-》执行步骤6，查看具体内存对象占用情况。&lt;/li&gt;
&lt;li&gt;内存占用不高，但是Full GC次数还是比较多，此时可能是代码中手动调用 System.gc()导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;代码中有大量消耗cpu的操作导致cpu过高系统运行缓慢&#34;&gt;代码中有大量消耗CPU的操作，导致CPU过高，系统运行缓慢；&lt;/h5&gt;
&lt;p&gt;执行步骤1-4：在步骤4jstack，可直接定位到代码行。例如某些复杂算法，甚至算法BUG，无限循环递归等等。&lt;/p&gt;
&lt;h5 id=&#34;由于锁使用不当导致死锁&#34;&gt;由于锁使用不当，导致死锁。&lt;/h5&gt;
&lt;p&gt;执行步骤1-4： 如果有死锁，会直接提示。关键字：deadlock.步骤四，会打印出业务死锁的位置。&lt;/p&gt;
&lt;p&gt;造成死锁的原因：最典型的就是2个线程互相等待对方持有的锁。&lt;/p&gt;
&lt;h5 id=&#34;随机出现大量线程访问接口缓慢&#34;&gt;随机出现大量线程访问接口缓慢。&lt;/h5&gt;
&lt;p&gt;代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；平时消耗的CPU不多，而且占用的内存也不高。&lt;/p&gt;
&lt;p&gt;思路：首先找到该接口，通过压测工具不断加大访问力度，大量线程将阻塞于该阻塞点。&lt;/p&gt;
&lt;p&gt;执行步骤1-4，如下，找到业务代码阻塞点，这里业务代码使用了TimeUnit.sleep()方法，使线程进入了TIMED_WAITING(期限等待)状态。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;http-nio-8080-exec-4&amp;quot; #31 daemon prio=5 os_prio=31 tid=0x00007fd08d0fa000 nid=0x6403 waiting on condition [0x00007000033db000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)-》期限等待
 at java.lang.Thread.sleep(Native Method)
 at java.lang.Thread.sleep(Thread.java:340)
 at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
 at com.*.user.controller.UserController.detail(UserController.java:18)-》业务代码阻塞点
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;某个线程由于某种原因而进入waiting状态此时该功能整体不可用但是无法复现&#34;&gt;某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；&lt;/h5&gt;
&lt;p&gt;执行步骤1-4：jstack多查询几次，每次间隔30秒，对比一直停留在parking 导致的WAITING状态的线程。例如CountDownLatch倒计时器，使得相关线程等待-&amp;gt;AQS-&amp;gt;LockSupport.park()。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;Thread-0&amp;quot; #11 prio=5 os_prio=31 tid=0x00007f9de08c7000 nid=0x5603 waiting on condition [0x0000700001f89000]
java.lang.Thread.State: WAITING (parking) -&amp;gt;无期限等待
at sun.misc.Unsafe.park(Native Method)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
at com.*.SyncTask.lambda$main$0(SyncTask.java:8)-》业务代码阻塞点
at com.*.SyncTask$$Lambda$1/1791741888.run(Unknown Source)
at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt;
">CPU飙升问题排查</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/zabbix54-cai-ji-ri-zhi-jin-xing-ding-ding-gao-jing/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述zabbix5.4采集日志进行钉钉告警&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/landscape-1192669_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;配置钉钉机器人&#34;&gt;配置钉钉机器人&lt;/h2&gt;
&lt;p&gt;电脑版钉钉，选中对应的钉钉群，点击群设置---&amp;gt;智能群助手---&amp;gt;添加机器人---&amp;gt;自定义---&amp;gt;添加。&lt;/p&gt;
&lt;p&gt;安全设置根据需要自行选择（演示选择的是自定义关键词），需要记住对应的Webhook（用作python脚本调接口使用）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302016.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;配置zabbix&#34;&gt;配置zabbix&lt;/h2&gt;
&lt;h3 id=&#34;zabbix-server配置&#34;&gt;zabbix-server配置&lt;/h3&gt;
&lt;p&gt;使用命令查找对应的告警配置文件目录。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat /etc/zabbix/zabbix_server.conf | grep AlertScripts
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303001.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;find / -name alertscripts
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303002.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;找到告警目录后，使用cd命令，切入该目录，并执行vi dingding.py。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303003.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;dingding.py内容如下（钉钉文档：&lt;a href=&#34;https://developers.dingtalk.com/document/app/custom-robot-access&#34;&gt;点击此处跳转页面&lt;/a&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3.8
#coding:utf-8
#zabbix dingding alert
import requests,json,sys,os,datetime
webhook=&amp;quot;https://oapi.dingtalk.com/robot/send?access_token=******&amp;quot;
user=sys.argv[1]
text=sys.argv[3]
data={
    &amp;quot;msgtype&amp;quot;: &amp;quot;text&amp;quot;,
    &amp;quot;text&amp;quot;: {
        &amp;quot;content&amp;quot;: text
    },
    &amp;quot;at&amp;quot;: {
        &amp;quot;atMobiles&amp;quot;: [
            user
        ],
        &amp;quot;isAtAll&amp;quot;: False
    }
}
headers = {&#39;Content-Type&#39;: &#39;application/json&#39;}
x=requests.post(url=webhook,data=json.dumps(data),headers=headers)
print(x.status_code)
print(x.text)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：代码的第一句（#!/usr/bin/env python3.8）中的 python3.8取决于系统安装的python版本，使用whereis  python进行查看。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303004.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;随后使用如下命令进行权限设置（如若未设置，将无法执行脚本文件）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost alertscripts]# chmod 755 dingding.py 
[root@localhost alertscripts]# chown zabbix.zabbix dingding.py

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;测试时，前两个参数，随便填，最后的文本内容需要加上在钉钉机器人配置时设置的关键词。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost alertscripts]# ./dingding.py 123 wrq &amp;quot;{monitor,test}&amp;quot;
200
{&amp;quot;errcode&amp;quot;:0,&amp;quot;errmsg&amp;quot;:&amp;quot;ok&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303005.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;问题：可能出现一些安装包不存在，比如requests，使用pip3 list 查看安装了哪些包。如果没有安装requests，可以执行pip3 install requests进行安装。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;zabbix-web配置&#34;&gt;zabbix-web配置&lt;/h3&gt;
&lt;h4 id=&#34;在已添加的主机上在创建一个监控项&#34;&gt;在已添加的主机上在创建一个监控项&lt;/h4&gt;
&lt;p&gt;logrt[&amp;quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&amp;quot;,,,,skip,]&lt;br&gt;
表示匹配/var/log/testlog/zabbix20210715.0.log文件进行日志信息采集。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;在已添加的主机上在创建一个触发器&#34;&gt;在已添加的主机上在创建一个触发器&lt;/h4&gt;
&lt;p&gt;find(/zabbix-agent/logrt[&amp;quot;/var/log/testlog/^zabbix.[0-9]{8}.[0-9]{1}.log$&amp;quot;,,,,skip,],#10,,&amp;quot;HIGH&amp;quot;)=1&lt;br&gt;
表示匹配/var/log/testlog/zabbix20210715.0.log文件中的HIGH字段进行告警触发。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;在管理界面添加一个媒体类型&#34;&gt;在管理界面添加一个媒体类型&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;在配置界面的动作操作中添加一个触发器动作&#34;&gt;在配置界面的动作操作中添加一个触发器动作&lt;/h4&gt;
&lt;p&gt;条件选择触发器名称匹配。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303010.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;随后点击操作&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303011.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;配置信息如下：
业务告警（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303012.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;故障恢复（monitor）
主机: {HOST.NAME1}
时间: {EVENT.DATE} {EVENT.TIME}
级别: {TRIGGER.SEVERITY}
触发器: {TRIGGER.NAME}
监控器: {ITEM.NAME1}; {ITEM.KEY1}
监控内容: {ITEM.VALUE}（{ITEM.LASTVALUE}）
状态: {TRIGGER.STATUS}
项目：{TRIGGER.KEY1} 
事件ID：{EVENT.ID}
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303013.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;上述操作中，需要注意的是Send to users选项，该选项对应的值需与媒体类型关联。比如上面选择的用户是Admin，那么需要在管理界面选择用户Admin进行媒体类型的添加。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230303014.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;拼接地址调转zabbix指定界面&#34;&gt;拼接地址调转zabbix指定界面&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;// 拼接地址调转zabbix指定界面
String t = &amp;quot;http://localhost:8096/index.php?request=zabbix.php%3Faction%3Dhost.dashboard.view%26hostid%3D10435&amp;amp;name=Admin&amp;amp;password=zabbix&amp;amp;autologin=1&amp;amp;enter=Sign+in&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
">zabbix5.4采集日志进行钉钉告警</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/wsl2-and-docker-and-zabbix/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述如何安装wsl2，docker以及zabbix。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/forest-1072828_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;install-wsl-update-to-wsl2&#34;&gt;Install WSL &amp;amp; update to WSL2&lt;/h2&gt;
&lt;p&gt;WSL，全名：Windows Subsystem for Linux，是一个运行在windows系统上的Linux子系统，它支持绝大部分的Linux功能，避免了安装虚拟机。&lt;/p&gt;
&lt;h3 id=&#34;安装前的一些必要项&#34;&gt;安装前的一些必要项&lt;/h3&gt;
&lt;p&gt;确保计算机开启了虚拟化技术这项配置，开机进入BIOS界面，选择configuration-》Intel Virtual Technology进行开启即可。&lt;/p&gt;
&lt;p&gt;使用WSL2的系统版本必须为windows10，且对应的最低版本要求如下（win+R，输入winver回车即可查看本机系统版本）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For x64 systems: Version 1903 or higher, with Build 18362 or higher.&lt;/li&gt;
&lt;li&gt;For ARM64 systems: Version 2004 or higher, with Build 19041 or higher&lt;/li&gt;
&lt;li&gt;Builds版本低于 18362 是不支持 WSL 2的。 &lt;a href=&#34;https://www.microsoft.com/zh-cn/software-download/windows10&#34;&gt;点击此处可跳转下载地址&lt;/a&gt; 下载最新的windows进行更新。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安装wsl&#34;&gt;安装WSL&lt;/h3&gt;
&lt;p&gt;以管理员的权限打开powershell（右击左下角的win logo选择即可），键入如下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;命令执行之后，重启电脑即可完成WSL的安装。&lt;/p&gt;
&lt;p&gt;下载WSL2最新的安装包进行更新。&lt;a href=&#34;https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi&#34;&gt;点击此处可跳转下载地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载完成后，双击运行即可。&lt;/p&gt;
&lt;p&gt;将wsl2设置为默认版本，输入命令：wsl --set-default-version 2&lt;/p&gt;
&lt;h3 id=&#34;安装liunx操作系统&#34;&gt;安装Liunx操作系统&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://aka.ms/wslstore&#34;&gt;点击此处可跳转下载地址&lt;/a&gt;选择一款系统点击get进行安装。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302009.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;等待计算机自动安装完成后，左击桌面左下角的win logo，选择刚刚安装的操作系统。第一次进入需要等待几分钟，随后创建一个用户即可登录使用了。&lt;/p&gt;
&lt;p&gt;点击左下方任务栏上的搜索按钮，在搜索框中输入“终端”，选择虚拟机打开。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302010.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;可以在powershell中的键入wsl --list --verbose查看版本信息&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302011.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;额外：可以安装Windows Terminal，便于多界面管理终端。&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/terminal/get-started&#34;&gt;点击此处可跳转下载地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;wls官方地址：&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-win10&#34;&gt;点击此处可跳转&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;启动报错时可参考：&lt;a href=&#34;https://appuals.com/wsl-fails-to-start-error-4294967295/&#34;&gt;点击此处可跳转&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;docker-desktop-for-windows&#34;&gt;Docker desktop for windows&lt;/h2&gt;
&lt;h3 id=&#34;安装docker&#34;&gt;安装Docker&lt;/h3&gt;
&lt;p&gt;安装完WSL2后，&lt;a href=&#34;https://docs.docker.com/docker-for-windows/wsl/#download&#34;&gt;点击此处可跳转下载地址&lt;/a&gt;下载docker安装包，随后直接双击安装即可。&lt;/p&gt;
&lt;p&gt;注意1：docker默认安装在C盘目录下，如果需要迁移，需要进行如下操作：&lt;/p&gt;
&lt;p&gt;以管理员身份打开cmd窗口，然后运行命令：mklink /j &amp;quot;C:\Program Files\Docker&amp;quot; &amp;quot;D:\Program Files\Docker&amp;quot;，在此之前要先创建&amp;quot;D:\Program Files\Docker&amp;quot;目录。最后安装docker即可。（ mklink /j 表示创建一个链接）&lt;/p&gt;
&lt;p&gt;注意2：docker镜像文件默认存储在wsl中，也就是系统盘，可以通过如下命令进行迁移（需要先创建对应的文件目录D:\Program Files\wsl\data）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- 导出文件
wsl --export docker-desktop-data &amp;quot;D:\Program Files\wsl\data\docker-desktop-data.tar&amp;quot;
wsl --export docker-desktop &amp;quot;D:\Program Files\wsl\data\docker-desktop.tar&amp;quot;
-- 注销原来的文件
wsl --unregister docker-desktop
wsl --unregister docker-desktop-data
-- 数据导入新文件中
wsl --import docker-desktop-data &amp;quot;D:\Program Files\wsl\data&amp;quot; &amp;quot;D:\Program Files\wsl\data\docker-desktop-data.tar&amp;quot; --version 2
wsl --import docker-desktop &amp;quot;D:\Program Files\wsl\data&amp;quot; &amp;quot;D:\Program Files\wsl\data\docker-desktop.tar&amp;quot; --version 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意3：在docker的设置界面，需要开启与虚拟机的集成。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302012.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;zabbix54&#34;&gt;Zabbix5.4&lt;/h2&gt;
&lt;h3 id=&#34;安装zabbix&#34;&gt;安装zabbix&lt;/h3&gt;
&lt;p&gt;在docker中安装监控工具zabbix，操作步骤如下（官网地址：&lt;a href=&#34;https://www.zabbix.com/documentation/current/manual/installation/containers&#34;&gt;点击此处可跳转&lt;/a&gt;）：&lt;/p&gt;
&lt;h4 id=&#34;创建docker容器专用网关&#34;&gt;创建docker容器专用网关&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;docker network create --subnet 172.20.0.0/16 --ip-range 172.20.240.0/20 zabbix-net
docker network create -d bridge zabbix-net
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;运行一个空的mysql80服务实例&#34;&gt;运行一个空的mysql8.0服务实例&lt;/h4&gt;
&lt;p&gt;注意：` 符号为windows中powershell下的换行符，位于ESC键下方&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --name mysql-server -t `
      -e MYSQL_DATABASE=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_USER=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_PASSWORD=&amp;quot;zabbix_pwd&amp;quot; `
      -e MYSQL_ROOT_PASSWORD=&amp;quot;root_pwd&amp;quot; `
      --network=zabbix-net `
      -d mysql:8.0 `
      --character-set-server=utf8 --collation-server=utf8_bin
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;运行zabbix-java-gateway实例版本为ubuntu-latest&#34;&gt;运行zabbix-java-gateway实例，版本为ubuntu-latest&lt;/h4&gt;
&lt;p&gt;版本标签含义如下：&lt;/p&gt;
&lt;p&gt;latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本（如果docker pull的时候不输入TAG，将会默认使用该标签）&lt;/p&gt;
&lt;p&gt;alpine-latest: 基于Alpine Linux镜像的zabbix组件最终稳定版本&lt;/p&gt;
&lt;p&gt;ubuntu-latest: 基于Ubuntu镜像的zabbix组件最终稳定版本&lt;/p&gt;
&lt;p&gt;alpine-5.4-latest: 基于Alpine Linux镜像的zabbix5.4组件最终次要版本&lt;/p&gt;
&lt;p&gt;ubuntu-5.4-latest: 基于Ubuntu镜像的zabbix5.4组件最终次要版本&lt;/p&gt;
&lt;p&gt;alpine-5.4.*: 基于Alpine Linux镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2&lt;/p&gt;
&lt;p&gt;ubuntu-5.4.*: 基于Ubuntu镜像的zabbix5.4组件不同次要版本, * 表示不同的子版本，如5.4.1, 5.4.2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --name zabbix-java-gateway -t `
      --network=zabbix-net `
      --restart unless-stopped `
      -d zabbix/zabbix-java-gateway:ubuntu-latest
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;运行zabbix-server-mysql服务并将其与mysql服务关联&#34;&gt;运行zabbix-server-mysql服务，并将其与mysql服务关联&lt;/h4&gt;
&lt;p&gt;注意：zabbix服务实例向主机公开10051/TCP端口（Zabbix Trapper）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --name zabbix-server-mysql -t `
      -e DB_SERVER_HOST=&amp;quot;mysql-server&amp;quot; `
      -e MYSQL_DATABASE=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_USER=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_PASSWORD=&amp;quot;zabbix_pwd&amp;quot; `
      -e MYSQL_ROOT_PASSWORD=&amp;quot;root_pwd&amp;quot; `
      -e ZBX_JAVAGATEWAY=&amp;quot;zabbix-java-gateway&amp;quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      -p 10051:10051 `
      --restart unless-stopped `
      -d zabbix/zabbix-server-mysql:ubuntu-latest
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;运行zabbix-web-nginx-mysql服务并将其与mysql及zabbix-server-mysql关联&#34;&gt;运行zabbix-web-nginx-mysql服务，并将其与mysql及zabbix-server-mysql关联&lt;/h4&gt;
&lt;p&gt;注意：至此zabbix服务已在本机的8096端口暴露。&lt;/p&gt;
&lt;p&gt;在docker镜像中nginx的默认端口是8080而非80，可进入镜像的/etc/zabbix/nginx.conf查看，命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker ps
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat nginx.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;docker run --name zabbix-web-nginx-mysql -t `
      -e ZBX_SERVER_HOST=&amp;quot;zabbix-server-mysql&amp;quot; `
      -e DB_SERVER_HOST=&amp;quot;mysql-server&amp;quot; `
      -e MYSQL_DATABASE=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_USER=&amp;quot;zabbix&amp;quot; `
      -e MYSQL_PASSWORD=&amp;quot;zabbix_pwd&amp;quot; `
      -e MYSQL_ROOT_PASSWORD=&amp;quot;root_pwd&amp;quot; `
      --network=zabbix-net `
      --link mysql-server:mysql `
      --link zabbix-server-mysql:zabbix-server `
      -p 8096:8080 `
      --restart unless-stopped `
      -d zabbix/zabbix-web-nginx-mysql:ubuntu-latest
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;运行zabbix-agent服务并关联zabbix-server配置在同一个网桥下&#34;&gt;运行zabbix-agent服务，并关联zabbix-server（配置在同一个网桥下）&lt;/h4&gt;
&lt;p&gt;注意：web界面Configuration中的Hosts配置中的Name必须与/etc/zabbix/zabbix_agentd.conf中的hostName保持一致，命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker ps
# root权限进入
sudo docker exec -it --user root CONTAINER ID  /bin/bash
cd /etc/zabbix
cat zabbix_agentd.conf

web界面Configuration中的Hosts配置中的IP address为zabbix-agent容器所在的地址，命令如下：
docker network ls
docker network inspect NETWORK ID（指第一步中创建zabbix-net对应的id值）
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302013.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302014.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302015.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;docker run --name zabbix-agent `
      -e ZBX_HOSTNAME=&amp;quot;zabbix-agent&amp;quot; `
      -e ZBX_SERVER_HOST=&amp;quot;zabbix-server-mysql&amp;quot; `
      -e ZBX_SERVER_PORT=10051 `
      --network=zabbix-net `
      --link zabbix-server-mysql:zabbix-server-mysql `
      -p 10050:10050 `
      -d zabbix/zabbix-agent:ubuntu-latest

显示所有ip地址
docker inspect -f &#39;{{.Name}} - {{.NetworkSettings.IPAddress }}&#39; $(docker ps -aq)
显示zabbix-agen ip地址
docker inspect -f &#39;{{.Name}} - {{.NetworkSettings.IPAddress }}&#39; zabbix-agent
&lt;/code&gt;&lt;/pre&gt;
">WSL2 & Docker & Zabbix</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/linux-chang-yong-ming-ling/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Linux中常用的一些操作命令。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-440520_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;scp传输文件&#34;&gt;SCP（传输文件）&lt;/h2&gt;
&lt;p&gt;将win10 D盘temp目录下的文件传输到199.199.199.199的root目录下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp D:\temp\***.tar root@199.199.199.199:/root

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将199.199.199.199的root目录下文件传输到win10 D盘temp目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp root@199.199.199.199:/root/***.txt D:\temp\

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;tar解压缩&#34;&gt;TAR（解压缩）&lt;/h2&gt;
&lt;p&gt;压缩指定目录下的文件（注意：win为 \，linux为 /）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tar -cvzf  D:\temp\***.tar &amp;quot;D:\temp\***&amp;quot;
# -l   压 缩文件时，把LF字符 置换成LF+CR字 符。
# -ll   压 缩文件时，把LF+CR字 符置换成LF字符。
tar -cvzf -ll  D:\temp\***.tar &amp;quot;D:\temp\***&amp;quot;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;解压指定目录下的文件到指定目录（注意：win为 \，linux为 /）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; tar -zxvf /root/***.tar -C /opt/temp/

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;mv移动文件&#34;&gt;MV（移动文件）&lt;/h2&gt;
&lt;p&gt;移动目录下的所有文件至指定目录下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mv  /root/temp/*       /opt/temp/

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;find-whereis查询文件&#34;&gt;FIND $ WHEREIS（查询文件）&lt;/h2&gt;
&lt;p&gt;查询文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find / -name agent
whereis agent
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;dos2unix转换格式&#34;&gt;DOS2UNIX（转换格式）&lt;/h2&gt;
&lt;p&gt;在win系统中写的shell脚本移动至linux执行时，会提示错误：line 2: $&#39;\r&#39;: command not found，这是因为win系统下的换行符为\r\n，而linux系统的为\n，所以需要进行格式转换。&lt;/p&gt;
&lt;p&gt;单个，或多个文件格式转换&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dos2unix filename1, filename2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将指定目录下的所有sh结尾的文件进行格式转换&lt;/p&gt;
&lt;p&gt;注意：一定要有{}，标示参数；以“;”结尾； {} 和\之间一定要有一个空格&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find /apps/cws -name &amp;quot;*.sh&amp;quot; -exec dos2unix {} \;   

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可以使用xargs命令，不过xargs命令需要和管道符结合使用，并且xargs命令将所有的传入的数据当作一个参数处理。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;find /opt/temp/ -name &amp;quot;*.sh&amp;quot; | xargs dos2unix
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ps进程状态process-status&#34;&gt;PS（进程状态process status）&lt;/h2&gt;
&lt;p&gt;显示所有进程信息，连同命令行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ps -ef
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;列出目前正在内存中的程序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ps aux
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过指定名称列出当前正在内存中的程序的状态(grep命令用于查找符合条件的字符串)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ps aux | grep name
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;top任务管理器&#34;&gt;TOP（任务管理器）&lt;/h2&gt;
&lt;p&gt;top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;top
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sudo操作命令&#34;&gt;SUDO（操作命令）&lt;/h2&gt;
&lt;p&gt;用于切换用户&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 切换至root用户登录
sudo -i
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;rz传输文件&#34;&gt;RZ（传输文件）&lt;/h2&gt;
&lt;p&gt;使用finalshell软件时，在命令窗口输入rz可以直接选择外部文件传入服务器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rz
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;df查看磁盘占用情况&#34;&gt;DF（查看磁盘占用情况）&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;df -hT
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;du查看目录占用空间&#34;&gt;DU（查看目录占用空间）&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;du -sh /* |sort -nr
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;firewall防火墙&#34;&gt;Firewall（防火墙）&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;# 安装防火墙
yum install firewalld firewalld-config
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Firewall开启常见端口命令：

firewall-cmd --zone=public--add-port=80/tcp --permanent

firewall-cmd --zone=public--add-port=443/tcp --permanent

firewall-cmd --zone=public --add-port=22/tcp--permanent

firewall-cmd --zone=public --add-port=9000/tcp --permanent

firewall-cmd --zone=public--add-port=53/udp --permanent

Firewall关闭常见端口命令：

firewall-cmd --zone=public--remove-port=80/tcp --permanent

firewall-cmd --zone=public--remove-port=443/tcp --permanent

firewall-cmd --zone=public--remove-port=22/tcp --permanent

firewall-cmd --zone=public--remove-port=21/tcp --permanent

firewall-cmd --zone=public--remove-port=53/udp --permanent

批量添加区间端口：

firewall-cmd --zone=public--add-port=4400-4600/udp --permanent

firewall-cmd --zone=public--add-port=4400-4600/tcp --permanent

开启防火墙命令：

systemctl start firewalld.service

重启防火墙命令：

firewall-cmd --reload  或者   service firewalld restart

查看端口列表：

firewall-cmd --permanent --list-port
firewall-cmd --list-all

禁用防火墙：

systemctl stop firewalld

设置开机启动：

systemctl enable firewalld

停止并禁用开机启动：

sytemctl disable firewalld

查看状态：

systemctl status firewalld或者firewall-cmd --state

&lt;/code&gt;&lt;/pre&gt;
">Linux常用命令</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/centos7-ji-ben-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Centos7系统相关的操作及命令介绍。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-1802337_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;图形命令切换&#34;&gt;图形/命令切换&lt;/h2&gt;
&lt;h3 id=&#34;图形界面进入命令行&#34;&gt;图形界面进入命令行&lt;/h3&gt;
&lt;p&gt;右击或者在application中打开终端，输入：init 3，即可进入命令行；也可以直接ctrl+alt+f2，进入命令行。&lt;/p&gt;
&lt;h3 id=&#34;命令行进入图形界面&#34;&gt;命令行进入图形界面&lt;/h3&gt;
&lt;p&gt;输入：init 5或者：startx，即可进入图形界面。&lt;/p&gt;
&lt;p&gt;不过由 startx 再进入命令行会无法进入，可以重新输入：init 5，&lt;/p&gt;
&lt;p&gt;重启一下x window，然后再输入：init 3，便可进入命令行。&lt;/p&gt;
&lt;h3 id=&#34;设置开机进入x-window还是命令行&#34;&gt;设置开机进入x window还是命令行&lt;/h3&gt;
&lt;p&gt;命令行状态下，root管理员，键入：cat /etc/inittab，&lt;/p&gt;
&lt;p&gt;根据提示输入：systemctl get-default，可查看当前进入为那种状态。&lt;/p&gt;
&lt;p&gt;如若需要更改可以输入：systemctl set-default multi-user.target------命令行&lt;/p&gt;
&lt;p&gt;systemctl set-default graphical.target------图形界面&lt;/p&gt;
&lt;h2 id=&#34;日期相关&#34;&gt;日期相关&lt;/h2&gt;
&lt;p&gt;1、指令太长的时候，可以使用反斜杠 () 来跳脱[Enter]符号，使指令连续到下一 行。注意！反斜杠后就立刻接回车，才能跳脱。&lt;/p&gt;
&lt;p&gt;2、linux区分大小写！！！&lt;/p&gt;
&lt;p&gt;3、ls -al 列出『自己家目录(~)』下的『所有隐藏档不相关的文件属性』&lt;/p&gt;
&lt;p&gt;4、显示当前语系：echo $LANG&lt;/p&gt;
&lt;p&gt;5、日期：date(正常显示)，date +%y/%m/%d(年月日显示)，date +%H:%M(时钟显示)&lt;/p&gt;
&lt;p&gt;6、万年历：cal [month][year]&lt;/p&gt;
&lt;p&gt;7、计算器：bc，如需显示小数，在键入bc之后，输入：scale=4,（数字4表示小数有4位）退出键入：quit&lt;/p&gt;
&lt;p&gt;8、在指令列模式里面下达指令时，会有两种主要的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种是该指令会直接显示结果然后回到命令提示字符等待下一个指令的输入；&lt;/li&gt;
&lt;li&gt;一种是进入到该指令的环境，直到结束该指令才回到命令提示字符的环境。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;常用快捷键&#34;&gt;常用快捷键&lt;/h2&gt;
&lt;p&gt;1、Tab键，可进行 [[命令补全]] 和 [[档案补齐]]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如在ca后面连续按两下  Tab，即可查看补全的命令。&lt;/li&gt;
&lt;li&gt;而档案补齐可以在 ls -al /.bash后面连续按两下Tab，可进行查看。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2、Ctrl+C组合键，即先按下Ctrl不放，再按下C键，便可终止运行的命令。&lt;/p&gt;
&lt;p&gt;比如：键入：find / 之后会不停的搜寻，此时，可以使用Ctrl+C来终止运行；不过如果是在进行很重要的指令，则不要急着使用组合键终止命令。&lt;/p&gt;
&lt;p&gt;3、Ctrl+D组合键，相当于exit，如果使用，可直接退出文字接口。&lt;/p&gt;
&lt;p&gt;4、使用man（manual 操作说明的简写），当需要知道某一个命令的详细指令的时候可以使用。比如：man date，如需退出，按下q即可，翻页按空格键。&lt;/p&gt;
&lt;p&gt;5、当使用man date之后，界面左上角会出现DATE(1)，其中的括号中的1的概念如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 用户在shell环境中可以操作的指令或可执行文件（重要）&lt;/li&gt;
&lt;li&gt;2 系统核心可呼叫的函数与工具等&lt;/li&gt;
&lt;li&gt;3 一些常用的函数(function)与函式库(library)，大部分为C的函式库(libc)&lt;/li&gt;
&lt;li&gt;4 装置档案的说明，通常在/dev下的档案&lt;/li&gt;
&lt;li&gt;5 配置文件或者是某些档案的格式 （重要）&lt;/li&gt;
&lt;li&gt;6 游戏(games)&lt;/li&gt;
&lt;li&gt;7 惯例与协议等，例如Linux文件系统、网络协议、ASCII code等等的说明&lt;/li&gt;
&lt;li&gt;8 系统管理员可用的管理指令 （重要）&lt;/li&gt;
&lt;li&gt;9 跟kernel有关的文件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;6、在man page页面可有如下快捷键操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;空格键              向下翻一页

[Page Down]    向下翻一页

[Page Up]         向上翻一页

[Home]            去到第一页

[End]                去到最后一页

/string              向『下』搜寻 string 这个字符串，如果要搜寻 date 的话，就输入 /date

?string              向『上』搜寻 string 这个字符串

n, N                  利用 / 或 ? 来搜寻字符串时，可以用 n 来继续下一个搜寻 (不论是 / 或?) ，

可以利用 N 来进行『反向』搜寻。举例来说，我以 /date 搜寻 date 字符串，

那么可以 n 继续往下查询，用 N 往上查询。 若以 ?date 向上查询 date 字符串，

那我可以用 n 继续『向上』 查询，用 N 反向查询。

q                      结束这次的 man page
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;7、查看与【man】这个指令相关的的说明文件：&lt;/p&gt;
&lt;p&gt;命令行键入：man -f man   等同于whatis man&lt;/p&gt;
&lt;p&gt;8、利用关键词将说明文件里面只要含有man那个字眼的(不见得是完整字符串) 就将他取出：命令行键入：man -k man  等同于apropos man&lt;/p&gt;
&lt;h2 id=&#34;infopage及nano&#34;&gt;InfoPage及nano&lt;/h2&gt;
&lt;p&gt;1、info page&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;info与man的用途其实差不多，都是用来查询指令的用法或者是档案的格式。

但是与man page一口气输出一堆信息不同的是，info page则是将文件数据拆成

一个一个的段落，每个段落用自己的页面来撰写， 并且在各个页面中还有类似网

页的『超链接』来跳到各不同的页面中，每个独立的 页面也被称为一个节点(node)

命令行键入：info info
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、出现的第一行里面的数据意义为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;File：代表这个info page的资料是来自info.info档案所提供的；

Node：代表目前的这个页面是属亍Top节点。 意思是info.info内

含有很多信息，而Top仅是 info.info档案内的一个节点内容而已；

Next：下一个节点的名称为Getting Started，你也可以按『N』到下个节点去；

Up：回到上一层的节点总揽画面，你也可以按下『U』回到上一层；

Prev：前一个节点。但由于Top是info.info的第一个节点，所以上面没有前一个节点的信息
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、info page页面快捷键操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;空格键                 向下翻一页

[Page Down]       向下翻一页

[Page Up]            向上翻一页

[tab]                    在 node 之间移劢，有 node 的地方，通常会以 * 显示。

[Enter]                 当光标在 node 上面时，按下 Enter 可以进入该 node 。

b                         移动光标到该 info 画面当中的第一个 node 处

e                         移动光标到该 info 画面当中的最后一个 node 处

n                         前往下一个 node 处

p                         前往上一个 node 处

u                         向上移动一层

s(/)                      在 info page 当中进行搜寻

h                         显示求助选单

?                         指令一览表

q                         结束这次的 info page
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、说明文档所在地。架设一些其他的服务，或想要利用一整组软件来达成某项功能时&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;键入：cd /usr/share/doc

即可进入doc文件夹下方，有很多文档的说明。（实践中未找到？？？）
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5、超简单文书编辑器： nano&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[ctrl]-G：   取得联机帮助(help)，很有用的！

[ctrl]-X：   离开naon软件，若有修改过档案会提示是否需要储存喔！

[ctrl]-O：   储存档案，若你有权限的话就能够储存档案了；

[ctrl]-R：   从其他档案读入资料，可以将某个档案的内容贴在本档案中；

[ctrl]-W：  搜寻字符串，这个也是径有帮助的指令喔！

[ctrl]-C：   说明目前光标所在处的行数与列数等信息；

[ctrl]-_：    可以直接输入行号，让光标快速移动到该行；

[alt]-Y：    校正语法功能开启或关闭(单击开、再单击关)

[alt]-M：   可以支持鼠标来移动光标的功能
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;6、关机&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;重新启动，关机： reboot, halt, poweroff

键入：man shutdown  查看具体细节。

常用的是：shutdown -h now 立即关机

shutdown -r now  立即重启

init 0           立即关机

init 6           立即重启

reboot         立即重启
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;linux文件属性&#34;&gt;Linux文件属性&lt;/h2&gt;
&lt;p&gt;root登陆后，键入ls -al&lt;/p&gt;
&lt;p&gt;-rw-r--r--  1 root  root  2272  Jul  5 09:50  initial-setup-ks.cfg&lt;/p&gt;
&lt;p&gt;[权限]  [连结数]  [拥有者]  [群组]  [档案容量]  [ 修改日期 ] [檔名]&lt;/p&gt;
&lt;p&gt;1、 第一栏代表这个档案的类型与权限(permission)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-rw-r--r--    其中一共有十个字符。

第一个字符表示档案类型，第二，三，四表示档案拥有者权限

第五，六，七表示档案所属群组的权限，第八，九，十表示其他人的权限
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、第一个字符代表这个档案是『目录、档案或链接文件等等』：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;当为[ d ]则是目录；

当为[ - ]则是档案；

若是[ l ]则表示为连结档(link file)；

若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；

若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。其中，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[ r ]代表可读 (read)、

[ w ]代表可写(write)、

[ x ]代表可执行(execute)。

要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、第二栏表示有多少档名连结到此节点(i-node)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;每个档案都会将他的权限与属性记录到文件系统的i-node中，

不过，我们使用的目录树却是使用文件名来记录的， 因此每个档名

就会连结到一个i-node！这个属性记录的，就是有多少不同的档

名连结到相同的一个i-node了。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5、第三栏表示这个档案(或目录)的『拥有者账号』&lt;/p&gt;
&lt;p&gt;6、第四栏表示这个档案的所属群组&lt;/p&gt;
&lt;p&gt;7、第五栏为这个档案的容量大小，默认单位为bytes&lt;/p&gt;
&lt;p&gt;8、第六栏为这个档案的建档日期或者是最近的修改日期&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这一栏的内容分别为日期(月/日)及时间。如果这个档案

被修改的时间距离现在太久了，那么时间部分会仅显示年份而已。

显示完整的时间格式，可以利用ls的选顷，

亦即：『ls -al --full-time』就能够显示出完整的时间格式
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;9、第七栏为这个档案的档名&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;如果档名之前多一个『 . 』，则代表这个档案为『隐藏档』
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;设置变更&#34;&gt;设置变更&lt;/h2&gt;
&lt;p&gt;1、改变所属群组, chgrp&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这个指令就是change group的缩写

chgrp [-R] dirname/filename ...

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案、目录

都更新成为这个群组之意。常常用在变更某一目录内所有的档案之情况

chgrp users initial-setup-ks.cfg

chgrp testing initial-setup-ks.cfg（错误信息：invalid group name `testing&#39;）

只有当你要改变的那个文件或者目录中有要改变成的对应群组，才能改变，否则报错，找不到

比如此次实例中的群组就在/etc/group中存在root和users群组，但不存在testing群组
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、改变档案拥有者, chown&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;这个指令就是change owner的缩写

跟概念群组一样，这里要注意的是， 用户必项是已经存在系统中的账号，

也就是在/etc/passwd 这个档案中有纪录的用户名称才能改变。

chown [-R] 账号名称 档案或目录

chown [-R] 账号名称:组名 档案或目录

选项与参数：

-R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有档案都变更

chown bin initial-setup-ks.cfg

chown还可以顺便直接修改群组的名称，中间使用冒号(也可以使用点)，前面为拥有者，后面为群组

chown bin:users initial-setup-ks.cfg

chown bin.users initial-setup-ks.cfg

有时候需要变更档案的拥有者，最常见的例子就是在复制档案给你之外的其他人时

cp 来源档案 目标文件
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（cp .bashrc .bashrc_test ）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;先复制一下，然后在更改复制了的使用者，群组。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、改变权限, chmod&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;权限的设定方法有两种， 分别可以使用数字或者是符号来进行权限的变更

数字类型改变档案权限。

Linux档案的基本权限就有九个，分别是owner/group/others三种身份各有自己的 read/write/execute权限

可以使用数字来代表各个权限，如下

r:4 ，w:2， x:1

每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，

例如当权限为： [rwxrwx---] 分数则是：

owner = rwx = 4+2+1 = 7

group = rwx = 4+2+1 = 7

others= --- = 0+0+0 = 0

符号类型改变档案权限

九个权限分别是(1)user (2)group (3)others三种身份啦！那么我们就可以藉由u, g, o来代表三种身份的权限！

此外， a 则代表 all 亦即全部的身份！那么读写的权限就可以写成r, w, x

其中+表示加入，-表示减去，=表示设定

chmod a+w initial-setup-ks.cfg   设定该档案u，g，o都具有w（写）权限

chmod a-w initial-setup-ks.cfg   设定该档案u，g，o都去掉w（写）权限

chmod u=rwx,go=rw initial-setup-ks.cfg   设定该档案u具有rwx权限，go都具有rw权限
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、『 su - yy 』这个指令来变换身份，只能进入普通账户，进入root需要重新输入密码&lt;/p&gt;
&lt;p&gt;5、『 cat ~/.bashrc 』就可以看到该档案的内容。 (cat 是将一个档案内容读出来的指令)&lt;/p&gt;
&lt;p&gt;6、Linux目录配置的依据--FHS（Filesystem Hierarchy Standard 文件系统阶层标准）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;主要有以下四个类型：

可分享的：可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据，是能够分享给网络上其他主机挂载用的目录。

不可分享的：自己机器上面运作的装置档案或者是与程序有关的socket档案等，由与仅与自身机器有关，所以当然就不适合分享给其他主机了。

不变的：有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等。

可变动的：经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等 。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;7、FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/ (root, 根目录)：与开机系统有关；

/usr (unix software resource)：与软件安装/执行有关；

/var (variable)：与系统运作过程有关
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;目录及文件&#34;&gt;目录及文件&lt;/h2&gt;
&lt;p&gt;1、相对路径与绝对路径：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;绝对路径：路径的写法『一定由根目录 / 写起』，例如： /usr/share/doc 这个目录。

相对路径：路径的写法『不是由 / 写起』，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写：『cd ../man』这就是相对路径的写法啦！相对路径意指『相对于目前工作目录的路径！』
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、目录的相关操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;『.』                代表此层目录

『..』               代表上一层目录

『-』               代表前一个工作目录

『~』              代表『目前用户身份』所在的家目录

『~yy』           代表yy这个用户的家目录(yy是个账号名称)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;常见处理目录的指令(可用man查看)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd：变换目录              （Change Directory）

pwd：显示当前目录        （Print Working Directory）

-P(大写)  ：显示出确实的路径，而非使用链接 (link) 路径。

mkdir：建立一个新的目录

mkdir [-mp] 目录名

-m ：配置文件案的权限！直接设定，不需要看预设权限 (umask) 的脸色

-p ：帮助你直接将所需要的目录(包含上层目录)递归建立起来

rmdir： 删除一个空的目录

-p ：连同上层『空的』目录也一起删除
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、执行文件路径的变量： $PATH&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a、不同身份使用者预设的PATH不同，默认能够随意执行的指令也不同(如root与yy)

b、PATH是可以修改的，所以一般使用者还是可以通过修改PATH来执行某些位于/sbin或/usr/sbin下的指令来查询

c、使用绝对路径或相对路径直接指定某个指令的文件名来执行，会比搜寻PATH来的正确

d、指令应该要放置到正确的目录下，执行才会比较方便

e、本目录(.)最好不要放到PATH当中
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、复制、删除与移动： cp, rm, mv&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cp (复制档案或目录)

[root@localhost]# cp /.bashrc /tmp/bashrc  &amp;lt;==将.bashrc复制到/tmp下，并更名为bashrc

[root@localhost tmp]# cp /var/log/wtmp .  &amp;lt;==将wtmp复制到当前目录，最后的『.』不要忘了！

在不加任何选项的情况下，档案的某些属性/权限会改变

这是个很重要的特性！而且连档案建立的时间也不一样了！

如果想要将档案的所有特性都一起复制过来，加上 -a 便可以了

[root@localhost tmp]# cp -r /etc/ /tmp     &amp;lt;==如果为目录，则不能直接复制，需加上-r，与此同时，档案与目录的权限也可能会被改变，这个时候可以用『 cp -a /etc /tmp 』来下达指令！尤其是在备份的情况下！
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;cp 有种种的文件属性与权限的特性，所以，在复制时，须了解到：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a、是否需要完整的保留来源档案的信息？

b、来源档案是否为连结档 (symbolic link file)？

c、来源档是否为特殊的档案，例如 FIFO, socket 等？

d、来源文件是否为目录？

rm (移除档案或目录)

[root@localhost tmp]# rm -i bashrc  &amp;lt;==加上 -i 选项便会主动询问，避免删除到错误的档名！

[root@localhost tmp]# rm -i bashrc* &amp;lt;==通过通配符『*』的帮忙，将/tmp底下开头为bashrc的档名通通删除。通配符『*』代表的是 0 到无穷多个任意字符。&lt;/code&gt;&lt;/pre&gt;
">Centos7基本知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/idea-shu-xing-ji-cha-jian-pei-zhi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述IDEA常用的一些配置以及相关插件，搭配使用或可提升编码效率。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/valley-90388_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;idea统一设置&#34;&gt;IDEA统一设置&lt;/h2&gt;
&lt;p&gt;为保证大家有统一的代码规范和IDE行为，现对IDEA的设置进行统一说明。需要指出的是，下列的IDEA设置，均在默认设置的基础上进行个性化变更的。&lt;/p&gt;
&lt;p&gt;使用IDEA的自动格式化，对所有源文件以及配置文件进行格式化后提交。（IDEA默认的快捷键为：Ctrl + Alt + L，mac系统为:command + option + L）。&lt;/p&gt;
&lt;p&gt;使用IDEA的优化导入类和包进行import语句的合理排列。（IDEA的默认快捷键为：Ctrl + Alt + O，mac系统为:command + option + O）。&lt;/p&gt;
&lt;h3 id=&#34;配置类&#34;&gt;配置类&lt;/h3&gt;
&lt;p&gt;配置类的设置入口为File-&amp;gt;Settings,下面所说的所有配置，都是在这个菜单下进行的。&lt;/p&gt;
&lt;h4 id=&#34;导包优化配置&#34;&gt;导包优化配置&lt;/h4&gt;
&lt;p&gt;进行优化导入包时，可能会出现几个通包路径下的类出现折叠成*的情况，这是违反通用编码规约的（存在导错包的情形）。因此，在进行导包优化之前，请设置IDEA的自动折叠功能为999，如下图所示：&lt;/p&gt;
&lt;p&gt;依次进入Editor-&amp;gt;Code Style-&amp;gt;Java 将Class count to use import ‘*’这一项后面的数值改为999&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301031.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;文件编码配置&#34;&gt;文件编码配置&lt;/h4&gt;
&lt;p&gt;依次进入Editor-&amp;gt;File Encodings，将所有字符集设置，调整为UTF-8，并且将UTF-8的pom设置为no pom，如下图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301032.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;换行符统一配置&#34;&gt;换行符统一配置&lt;/h4&gt;
&lt;p&gt;统一使用Unix风格的换行符，找到Editor-&amp;gt;Code Style-&amp;gt;Line separator，设置成Unix and OS X(\n)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301033.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;个性化配置&#34;&gt;个性化配置&lt;/h4&gt;
&lt;p&gt;一些个性化的简单配置。&lt;/p&gt;
&lt;h5 id=&#34;字体配置如下editor-font&#34;&gt;字体配置如下Editor-&amp;gt;Font：&lt;/h5&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301034.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;git配置如下version-control-git需要事先安装git找到对应的bin目录即可&#34;&gt;git配置如下Version Control-&amp;gt;Git(需要事先安装git，找到对应的bin目录即可)：&lt;/h5&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301035.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;序列化时未引入序列化id报警配置如下editor-inspections&#34;&gt;序列化时未引入序列化id报警配置如下Editor-&amp;gt;Inspections：&lt;/h5&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301036.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;类头自动加载注释配置如下Editor-&amp;gt;File and Code Templates：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301037.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;插件类&#34;&gt;插件类&lt;/h3&gt;
&lt;p&gt;为简化开发步骤，并且让大家在沟通一些插件功能时，可以用统一的语言，现对开发时使用的基本插件进行下列约定，请开发前，在IDEA中安装下列插件。&lt;/p&gt;
&lt;h4 id=&#34;lombok插件&#34;&gt;Lombok插件&lt;/h4&gt;
&lt;p&gt;开发过程中，编写JavaBean，需要些大量的get set方法，虽然IDEA有快捷键可以生成这些方法，但是对于整体代码的整洁度，多多少少还是有一些影响。&lt;/p&gt;
&lt;p&gt;所以，在开发过程中，我们会大量用到Lombok，在编译期自动生成get set方法，equals方法以及hashcode方法。&lt;/p&gt;
&lt;p&gt;该插件，可以自动识别@Data等注解，让代码IDEA能够对自动生成的方法进行导航。并且在编写代码时，能够自动对get,set方法进行提示补全。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301038.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;maven-helper插件&#34;&gt;Maven Helper插件&lt;/h4&gt;
&lt;p&gt;编写pom过程中，总会遇到各种各样的依赖问题，Maven Helper插件，提供了一种mvn dependency:tree之外的解决方案。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301039.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;安装插件后，在打开pom文件，可以看到多了Dependency Analyzer标签。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301040.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;可以方便地找到冲突的依赖,并且支持以图形化的形式查看依赖树。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301041.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;free-mybatis-plugin插件&#34;&gt;Free Mybatis plugin插件&lt;/h4&gt;
&lt;p&gt;用于Mybatis接口与xml文件的快速跳转。安装插件后，可以在接口中直接跳转到对应mybatis xml配置文件的对应方法上。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301042.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301043.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301044.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;alibaba-java-coding-guidelines插件&#34;&gt;Alibaba Java Coding Guidelines插件&lt;/h4&gt;
&lt;p&gt;使用“Alibaba Java Coding Guidelines”，插件，对工程下所有代码进行扫描。一期暂定消除所有Blocker与Critial的错误，同时Major的错误不得超过50个。&lt;/p&gt;
&lt;p&gt;在有些情况下，必然会产生警告（比如无法避免的泛型转原始类型），在确认不会产生意外错误时，使用@SuppressWarning 来抑制警告。若如此做，代码评审时，会对此注解进行重点关注。所以务必确保该注解不被滥用。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301045.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;直接右击项目，选择编码规约扫描&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301046.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;findbugs插件&#34;&gt;FindBugs插件&lt;/h4&gt;
&lt;p&gt;对工程下所有代码进行扫描，检查存在的bug。&lt;a href=&#34;https://plugins.jetbrains.com/plugin/3847-findbugs-idea/versions&#34;&gt;点击此处跳转下载页面&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301047.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301048.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;find-sec-bugs为FindBugs-IDEA的扩展库，可以增加额外的扫描结果。&lt;a href=&#34;https://find-sec-bugs.github.io/download.htm&#34;&gt;点击此处跳转下载页面&lt;/a&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;20&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301049.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;visualvm-launcher插件&#34;&gt;VisualVM Launcher插件&lt;/h4&gt;
&lt;p&gt;运行java程序的时候启动visualvm，方便查看jvm的情况 比如堆内存大小的分配&lt;/p&gt;
&lt;p&gt;某个对象占用了多大的内存，jvm调优必备工具。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;21&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301050.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;配置如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;22&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301051.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;使用如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;23&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301052.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;jclasslib插件&#34;&gt;jclasslib插件&lt;/h4&gt;
&lt;p&gt;查看java字节码插件，相比于命令行的javap -v className更加方便。直接在idea的插件中搜索并下载即可。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;24&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301053.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;使用时，先选择需要查看字节码的java类，之后选择View -&amp;gt; Show Bytecode With jclasslib即可打开字节码视图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;25&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301054.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;26&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301055.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;bashsupport插件&#34;&gt;bashsupport插件&lt;/h4&gt;
&lt;p&gt;支持bash编码，智能提示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;27&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301056.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;配置启动项，选择git安装目录中的bash.exe即可。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;28&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301057.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;29&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301058.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;编写完成后，直接右击run便可看到执行结果。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;30&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301059.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">IDEA属性及插件配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-zhong-de-chang-yong-pai-xu-suan-fa/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述java中常用的一些排序算法极其实现代码，如二分查找，快速排序，堆排，归并排序，冒泡排序等。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/lake-192979_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;java中的常用算法&#34;&gt;Java中的常用算法&lt;/h2&gt;
&lt;h3 id=&#34;术语说明及排序图表&#34;&gt;术语说明及排序图表&lt;/h3&gt;
&lt;p&gt;稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面（如果我们只对一串数字排序，那么稳定与否确实不重要，因为一串数字的属性是单一的，就是数字值的大小。但是排序的元素往往不只有一个属性，例如我们对一群人按年龄排序，但是人除了年龄属性还有身高体重属性，在年龄相同时如果不想破坏原先身高体重的次序，就必须用稳定排序算法.）；&lt;/p&gt;
&lt;p&gt;不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；&lt;/p&gt;
&lt;p&gt;内排序：所有排序操作都在内存中完成；&lt;/p&gt;
&lt;p&gt;外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；&lt;/p&gt;
&lt;p&gt;时间复杂度： 一个算法执行所耗费的时间。&lt;/p&gt;
&lt;p&gt;空间复杂度：运行完一个程序所需内存的大小。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302005.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;二分查找&#34;&gt;二分查找&lt;/h3&gt;
&lt;p&gt;又称折半查找，要求待查找的列表有序，每次取中间位置的值与待查关键字比较，如果中间位置的值比关键字大，则在列表前半部分循环此查找过程，否则在列表后半部分循环此查找过程。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    // 正常二分查找
    int[] array = {1, 2, 3, 4, 5, 6};
    int a = 3;
    System.out.println(binarySerach(array, a));

    // 寻找左侧边界的二分查找
    int[] array_left = {1, 2, 2, 4, 4, 6};
    int a_left = 2;
    System.out.println(binarySerachForLeftBound(array_left, a_left));

    // 寻找右侧边界的二分查找
    int[] array_right = {1, 2, 2, 5, 5, 6};
    int a_right = 5;
    System.out.println(binarySerachForRightBound(array_right, a_right));
}

/**
 * 二分查找,如果存在，则输出待查找数据在数组中的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerach(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &amp;lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &amp;lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &amp;lt;= high) {
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，返回其在数组中所在的下标
        if (numbers[middle] == target) {
            return middle;
        } else if (numbers[middle] &amp;gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &amp;lt; target) {
            low = middle + 1;
        }
    }
    return -1;
}

/**
 * 寻找左侧边界的二分查找,如果存在，则输出待查找数据在数组中最左侧的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerachForLeftBound(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &amp;lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &amp;lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &amp;lt;= high) {
        // 匹配返回下标
        if (numbers[low] == target) {
            return low;
        }
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，将其下标赋给high，往左侧缩小边界
        if (numbers[middle] == target) {
            high = middle;
        } else if (numbers[middle] &amp;gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &amp;lt; target) {
            low = middle + 1;
        }
    }
    return -1;
}

/**
 * 寻找左侧边界的二分查找,如果存在，则输出待查找数据在数组中最右侧的下标值，否则返回-1
 *
 * @param numbers 指定查询数组
 * @param target  待查找数据
 * @return 查找结果
 */
private static int binarySerachForRightBound(int[] numbers, int target) {
    int low = 0;
    int high = numbers.length - 1;
    int middle;
    // 此处用 &amp;lt;= 是因为high = numbers.length - 1
    // 如果high = numbers.length，则此处需要使用 &amp;lt;,同时返回结果需要更改为 return numbers[low] == target ? low : -1;
    while (low &amp;lt;= high) {
        // (low + high)/2，如果low + high大于Integer的MAX_VALUE会发生整型溢出
        // 使用low + (high - low) / 2可以防止整型溢出。
        middle = low + (high - low) / 2;
        // 匹配目标值，将其下标+1赋给low，往右侧边界缩小
        if (numbers[middle] == target) {
            low = middle + 1;
        } else if (numbers[middle] &amp;gt; target) {
            high = middle - 1;
        } else if (numbers[middle] &amp;lt; target) {
            low = middle + 1;
        }
    }
    // 匹配返回下标
    return numbers[high] == target ? high : -1;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;冒泡排序&#34;&gt;冒泡排序&lt;/h3&gt;
&lt;p&gt;比较前后相邻的两个的数据，如果前面数据大于后面数据，则将两个数据所在位置交换。步骤如下（以从小到大为例）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比较相邻的元素。如果第一个比第二个大，就交换它们两个；&lt;/li&gt;
&lt;li&gt;对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；&lt;/li&gt;
&lt;li&gt;针对所有的元素重复以上的步骤，除了最后一个；&lt;/li&gt;
&lt;li&gt;重复步骤1~3，直到排序完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] numbers = {4, 2, 5, 3, 7, 9, 1};
    bubbleSort3(numbers);
    for (int number : numbers) {
        System.out.println(number);
    }
}

// 从小到大
private static void bubbleSort(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = 0; i &amp;lt; numbers.length; i++) {
        for (int j = 0; j &amp;lt; numbers.length - 1 - i; j++) {
            if (numbers[j] &amp;gt; numbers[j + 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j + 1];
                numbers[j + 1] = temp;
            }
        }
    }
}

// 优化，去掉多余排序
private static void bubbleSort2(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = 0; i &amp;lt; numbers.length; i++) {
        // 排序标识
        boolean isSorted = true;
        for (int j = 0; j &amp;lt; numbers.length - 1 - i; j++) {
            if (numbers[j] &amp;gt; numbers[j + 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j + 1];
                numbers[j + 1] = temp;
                // 存在交换过程，继续排序
                isSorted = false;
            }
        }
        if (isSorted) {
            break;
        }
    }
}

//从大到小
private static void bubbleSort3(int[] numbers) {
    if (numbers.length == 0) {
        return;
    }
    for (int i = numbers.length - 1; i &amp;gt; 0; i--) {
        for (int j = numbers.length - 1; j &amp;gt; numbers.length - 1 - i; j--) {
            if (numbers[j] &amp;gt; numbers[j - 1]) {
                int temp = numbers[j];
                numbers[j] = numbers[j - 1];
                numbers[j - 1] = temp;
            }
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;选择排序&#34;&gt;选择排序&lt;/h3&gt;
&lt;p&gt;每一次从待排序的数据元素中选出最小（最大）的一个元素，存放在序列的起始（末尾）位置，直到全部待排序数据排完。&lt;/p&gt;
&lt;p&gt;选择排序是不稳定的排序方法，比如序列[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始状态：无序区为R[1..n]，有序区为空；&lt;/li&gt;
&lt;li&gt;第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；&lt;/li&gt;
&lt;li&gt;n-1趟结束，数组有序化了&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {2, 3, 1, 5, 4};
    selectSort(array);
    System.out.println(Arrays.toString(array));
}

private static void selectSort(int[] array) {
    if (array.length == 0) {
        return;
    }
    int minIndex;
    for (int i = 0; i &amp;lt; array.length; i++) {
        minIndex = i;
        for (int j = i + 1; j &amp;lt; array.length; j++) {
            if (array[minIndex] &amp;gt; array[j]) {
                minIndex = j;
            }
        }
        if (minIndex != i) {
            int temp = array[minIndex];
            array[minIndex] = array[i];
            array[i] = temp;
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;插入排序&#34;&gt;插入排序&lt;/h3&gt;
&lt;p&gt;通过构建有序序列，对于未排序的数据，在已排序的数据中从后向前扫描，找到相应的位置并插入。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从第一个元素开始，该元素可以认为已经被排序；&lt;/li&gt;
&lt;li&gt;取出下一个元素，在已经排序的元素序列中从后向前扫描；&lt;/li&gt;
&lt;li&gt;如果该元素（已排序）大于新元素，将该元素移到下一位置；&lt;/li&gt;
&lt;li&gt;重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；&lt;/li&gt;
&lt;li&gt;将新元素插入到该位置后；&lt;/li&gt;
&lt;li&gt;重复步骤2~5。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {3, 1, 2, 5, 4};
    binaryInsertSort(array);
    System.out.println(Arrays.toString(array));
}

// 直接插入
private static void insertSort(int[] array) {
    for (int i = 1; i &amp;lt; array.length; i++) {
        // 待插入数据
        int insertVal = array[i];
        // 待插入数据的前一个数据
        int insertIndex = i - 1;
        // insertIndex &amp;gt;= 0防止数组越界
        while (insertIndex &amp;gt;= 0 &amp;amp;&amp;amp; insertVal &amp;lt; array[insertIndex]) {
            // 如果插入数据比已排序数据要小，则将已排序数据向后移动一位
            array[insertIndex + 1] = array[insertIndex];
            // 同时，让insertIndex向前移动一位
            insertIndex--;
        }
        // 插入指定位置
        array[insertIndex + 1] = insertVal;
    }
}

// 折半插入
private static void binaryInsertSort(int[] array) {
    int temp;
    int low, high, middle;
    for (int i = 1; i &amp;lt; array.length; i++) {
        // 待插入数据
        temp = array[i];
        // 二分查找合适的插入位置
        // 左边默认为已排序
        low = 0;
        // 右边终点取已排序数组的索引
        high = i - 1;
        while (low &amp;lt;= high) {
            // 无符号右移一位，等同于/2
            middle = (low + high) &amp;gt;&amp;gt;&amp;gt; 1;
            if (array[middle] &amp;gt; temp) {
                high = middle - 1;
            } else {
                // 等于的情形包含在此，因为相等的话，插入数据在其左边，右边都是一致的
                low = middle + 1;
            }
        }
        // 已排序的所有数据向后移动
//        for (int j = i - 1; j &amp;gt;= high + 1; j--) {
//            array[j + 1] = array[j];
//        }
        if (i - (high + 1) &amp;gt;= 0) {
            System.arraycopy(array, high + 1, array, high + 1 + 1, i - (high + 1));
        }
        // 插入元素
        array[high + 1] = temp;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;希尔排序&#34;&gt;希尔排序&lt;/h3&gt;
&lt;p&gt;又称缩小增量排序，它按一定的增量（gap=lengh/2 -&amp;gt; gap=gap/2,也称希尔增量）进行分组，对每一组数据进行直接插入排序，直至增量减为1，所有分组再次合并为一个，接着对这个最终分组进行直接插入排序，即可得到排序结果。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选择一个增量序列t1，t2，…，tk，其中ti&amp;gt;tj，tk=1；&lt;/li&gt;
&lt;li&gt;按增量序列个数k，对序列进行k 趟排序；&lt;/li&gt;
&lt;li&gt;每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {2, 3, 1, 5, 4};
    shellSort(array);
    System.out.println(Arrays.toString(array));
}

// 希尔排序
private static void shellSort(int[] array) {
    if (array.length == 0) {
        return;
    }
    // 无符号右移1位，等同/2
    int gap = array.length &amp;gt;&amp;gt;&amp;gt; 1;
    while (gap &amp;gt; 0) {
        for (int i = gap; i &amp;lt; array.length; i++) {
            // 待插入数据
            int insertVal = array[i];
            // 待插入数据的前一个数据
            int insertIndex = i - gap;
            // insertIndex &amp;gt;= 0防止数组越界
            while (insertIndex &amp;gt;= 0 &amp;amp;&amp;amp; insertVal &amp;lt; array[insertIndex]) {
                // 如果插入数据比已排序数据要小，则将已排序数据向后移动一位
                array[insertIndex + gap] = array[insertIndex];
                // 同时，让insertIndex向前移动一位
                insertIndex -= gap;
            }
            // 插入指定位置
            array[insertIndex + gap] = insertVal;
        }
        // 无符号右移1位，等同/2
        gap &amp;gt;&amp;gt;&amp;gt;= 1;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;归并排序&#34;&gt;归并排序&lt;/h3&gt;
&lt;p&gt;归并排序（MERGE-SORT）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把长度为n的输入序列分成两个长度为n/2的子序列；&lt;/li&gt;
&lt;li&gt;对这两个子序列分别采用归并排序；&lt;/li&gt;
&lt;li&gt;将两个排序好的子序列合并成一个最终的排序序列。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {2, 1, 3, 9, 5, 8, 4, 6};
    System.out.println(Arrays.toString(mergeSort(array)));
}

private static int[] mergeSort(int[] array) {
    // 只有一位或者没有数据时，直接返回原数组
    if (array.length &amp;lt; 2) {
        return array;
    }
    // 无符号右移（此处必为正数，效果与右移一致），等同于/2
    int middle = array.length &amp;gt;&amp;gt;&amp;gt; 1;
    int[] left = Arrays.copyOfRange(array, 0, middle);
    int[] right = Arrays.copyOfRange(array, middle, array.length);
    return merge(mergeSort(left), mergeSort(right));
}

private static int[] merge(int[] left, int[] right) {
    // 合并之后的数组
    int[] result = new int[left.length + right.length];
    for (int index = 0, i = 0, j = 0; index &amp;lt; result.length; index++) {
        // 左侧数组已经全部放入结果数组中,将右侧数组数据直接递增放入
        if (i &amp;gt;= left.length) {
            result[index] = right[j++];
        } else if (j &amp;gt;= right.length) {
            // 右侧数组已经全部放入结果数组中,将左侧数组数据直接递增放入
            result[index] = left[i++];
        } else if (left[i] &amp;gt; right[j]) {
            // 左侧数组中的数据比右侧数组中的数据值大,将右侧数组数据直接放入，随后递增
            result[index] = right[j++];
        } else {
            // 左侧数组中的数据比右侧数组中的数据值小,将左侧数组数据直接放入，随后递增
            result[index] = left[i++];
        }
    }
    return result;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;快速排序&#34;&gt;快速排序&lt;/h3&gt;
&lt;p&gt;快速排序由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。&lt;/p&gt;
&lt;p&gt;注意：在此过程中需要先选取一个关键值作为基准值，这样比基准值小的都在左边，大的都在右边。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从数列中挑出一个元素，称为 “基准”（pivot）；&lt;/li&gt;
&lt;li&gt;重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；&lt;/li&gt;
&lt;li&gt;递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302007.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    quickSort(array, 0, array.length - 1);
    System.out.println(Arrays.toString(array));
}

// 填坑法
private static void quickSort(int[] array, int start, int end) {
    if (array.length &amp;lt; 1 || start &amp;lt; 0 || end &amp;gt;= array.length || start &amp;gt; end) {
        return;
    }
    int i = start;
    int j = end;
    // 基准值
    int pivot = array[i];
    // 左右两边同时扫描，直到两者交错
    while (i &amp;lt;= j) {
        // 从右边寻找比基准值小的数
        while (array[j] &amp;gt; pivot) {
            j--;
        }
        // 从左边寻找比基准值大的数
        while (array[i] &amp;lt; pivot) {
            i++;
        }
        // 此处已找到比基准值大的数（左边），比基准值小的数（右边），两者进行交换
        if (i &amp;lt;= j) {
            swap(array, i, j);
            i++;
            j--;
        }
    }
    // 左边再做排序，直到只剩下一个数，则退出递归
    if (start &amp;lt; j) {
        quickSort(array, start, j);
    }
    // 右边再做排序，直到只剩下一个数，则退出递归
    if (end &amp;gt; i) {
        quickSort(array, i, end);
    }
}

private static void swap(int[] array, int i, int j) {
    if (i != j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;堆排序&#34;&gt;堆排序&lt;/h3&gt;
&lt;p&gt;堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆分为大根堆和小根堆，是完全二叉树。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；&lt;/li&gt;
&lt;li&gt;将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&amp;lt;=R[n]；&lt;/li&gt;
&lt;li&gt;由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    heapSort(array);
    System.out.println(Arrays.toString(array));
}

private static void heapSort(int[] array) {
    int length = array.length;
    if (length &amp;lt; 1) {
        return;
    }
    buildMaxHeap(array, length);
    while (length &amp;gt; 0) {
        swap(array, 0, length - 1);
        length--;
        adjustHeap(array, 0, length);
    }
}

private static void buildMaxHeap(int[] array, int length) {
    // 从最后一个非叶子节点开始向上构建最大堆
    for (int i = (length / 2 - 1); i &amp;gt;= 0; i--) {
        adjustHeap(array, i, length);
    }
}

private static void adjustHeap(int[] array, int i, int length) {
    int maxIndex = i;
    // 如果有左子树，且左子树大于父节点，则将最大指针指向左子树
    if (i * 2 &amp;lt; length &amp;amp;&amp;amp; array[i * 2] &amp;gt; array[maxIndex]) {
        maxIndex = i * 2;
    }
    // 如果有右子树，且右子树大于父节点，则将最大指针指向右子树
    if (i * 2 + 1 &amp;lt; length &amp;amp;&amp;amp; array[i * 2 + 1] &amp;gt; array[maxIndex]) {
        maxIndex = i * 2 + 1;
    }
    // 如果父节点不是最大值，则将父节点与最大值交换，并递归调整与父节点交换的位置
    if (maxIndex != i) {
        swap(array, maxIndex, i);
        adjustHeap(array, maxIndex, length);
    }
}

private static void swap(int[] array, int i, int j) {
    if (i != j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;计数排序&#34;&gt;计数排序&lt;/h3&gt;
&lt;p&gt;计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。&lt;/p&gt;
&lt;p&gt;计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;找出待排序的数组中最大和最小的元素；&lt;/li&gt;
&lt;li&gt;统计数组中每个值为i的元素出现的次数，存入数组C的第i项；&lt;/li&gt;
&lt;li&gt;对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；&lt;/li&gt;
&lt;li&gt;反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    CountingSort(array);
    System.out.println(Arrays.toString(array));
}

private static void CountingSort(int[] array) {
    if (array.length &amp;lt; 1) {
        return;
    }
    int bias, min = array[0], max = array[0];
    for (int i = 1; i &amp;lt; array.length; i++) {
        if (array[i] &amp;gt; max)
            max = array[i];
        if (array[i] &amp;lt; min)
            min = array[i];
    }
    bias = 0 - min;
    int[] bucket = new int[max - min + 1];
    Arrays.fill(bucket, 0);
    for (int anArray : array) {
        bucket[anArray + bias]++;
    }
    int index = 0, i = 0;
    while (index &amp;lt; array.length) {
        if (bucket[i] != 0) {
            array[index] = i - bias;
            bucket[i]--;
            index++;
        } else
            i++;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;桶排序&#34;&gt;桶排序&lt;/h3&gt;
&lt;p&gt;桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。&lt;/p&gt;
&lt;p&gt;桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序。&lt;/p&gt;
&lt;p&gt;注意：如果递归使用桶排序为各个桶排序，则当桶数量为1时要手动减小BucketSize增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人为设置一个BucketSize，作为每个桶所能放置多少个不同数值（例如当BucketSize==5时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放100个3）；&lt;/li&gt;
&lt;li&gt;遍历输入数据，并且把数据一个一个放到对应的桶里去；&lt;/li&gt;
&lt;li&gt;对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序；&lt;/li&gt;
&lt;li&gt;从不是空的桶里把排好序的数据拼接起来。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    Integer[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    ArrayList&amp;lt;Integer&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(array.length);
    Collections.addAll(list, array);
    System.out.println(bucketSort(list, array.length));
}

private static ArrayList&amp;lt;Integer&amp;gt; bucketSort(ArrayList&amp;lt;Integer&amp;gt; array, int bucketSize) {
    if (array == null || array.size() &amp;lt; 2)
        return array;
    int max = array.get(0), min = array.get(0);
    // 找到最大值最小值
    for (Integer i : array) {
        if (i &amp;gt; max)
            max = i;
        if (i &amp;lt; min)
            min = i;
    }
    int bucketCount = (max - min) / bucketSize + 1;
    ArrayList&amp;lt;ArrayList&amp;lt;Integer&amp;gt;&amp;gt; bucketArr = new ArrayList&amp;lt;&amp;gt;(bucketCount);
    ArrayList&amp;lt;Integer&amp;gt; resultArr = new ArrayList&amp;lt;&amp;gt;();
    for (int i = 0; i &amp;lt; bucketCount; i++) {
        bucketArr.add(new ArrayList&amp;lt;&amp;gt;());
    }
    for (Integer i : array) {
        bucketArr.get((i - min) / bucketSize).add(i);
    }
    for (int i = 0; i &amp;lt; bucketCount; i++) {
        if (bucketSize == 1) { // 如果带排序数组中有重复数字时
            resultArr.addAll(bucketArr.get(i));
        } else {
            if (bucketCount == 1) {
                bucketSize--;
            }
            ArrayList&amp;lt;Integer&amp;gt; temp = BucketSort(bucketArr.get(i), bucketSize);
            resultArr.addAll(temp);
        }
    }
    return resultArr;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;基数排序&#34;&gt;基数排序&lt;/h3&gt;
&lt;p&gt;基数排序(radix sort)属于&amp;quot;分配式排序&amp;quot;(distribution sort)，又称&amp;quot;桶子法&amp;quot;(bucket sort)或bin sort，顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些&amp;quot;桶&amp;quot;中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为O (nlog(r)m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。&lt;/p&gt;
&lt;p&gt;基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。步骤如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得数组中的最大数，并取得位数；&lt;/li&gt;
&lt;li&gt;arr为原始数组，从最低位开始取每个位组成radix数组；&lt;/li&gt;
&lt;li&gt;对radix进行计数排序（利用计数排序适用于小范围数的特点）；&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    int[] array = {3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48, 1};
    radixSort(array);
    System.out.println(Arrays.toString(array));
}

private static void radixSort(int[] array) {
    if (array == null || array.length &amp;lt; 2) {
        return;
    }
    // 1.先算出最大数的位数；
    int max = array[0];
    for (int i = 1; i &amp;lt; array.length; i++) {
        max = Math.max(max, array[i]);
    }
    int maxDigit = 0;
    while (max != 0) {
        max /= 10;
        maxDigit++;
    }
    int mod = 10, div = 1;
    ArrayList&amp;lt;ArrayList&amp;lt;Integer&amp;gt;&amp;gt; bucketList = new ArrayList&amp;lt;ArrayList&amp;lt;Integer&amp;gt;&amp;gt;();
    for (int i = 0; i &amp;lt; 10; i++) {
        bucketList.add(new ArrayList&amp;lt;&amp;gt;());
    }
    for (int i = 0; i &amp;lt; maxDigit; i++, mod *= 10, div *= 10) {
        for (int j : array) {
            int num = (j % mod) / div;
            bucketList.get(num).add(j);
        }
        int index = 0;
        for (ArrayList&amp;lt;Integer&amp;gt; buckets : bucketList) {
            for (Integer bucket : buckets) {
                array[index++] = bucket;
            }
            buckets.clear();
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
">Java中的常用排序算法</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-zhong-yin-yong-andioandlei-jia-zai-anddui-xiang-chuang-jian-guo-cheng/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中的四种引用类型，JavaIO类型（BIO，NIO，AIO），Java类加载机制以及Hotspot JVM虚拟机对象的探究。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/boat-1014711_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;四种引用&#34;&gt;四种引用&lt;/h2&gt;
&lt;h3 id=&#34;强引用&#34;&gt;强引用&lt;/h3&gt;
&lt;p&gt;把一个对象复制给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，这时，GC不会对其进行回收（造成OOM的主要原因之一）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 强引用
String str = &amp;quot;test&amp;quot;;
// 取消强引用
str = null;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;软引用&#34;&gt;软引用&lt;/h3&gt;
&lt;p&gt;软引用需要使用SoftReference类来实现，对于软引用对象来说，当系统内存足够时不会对其进行回收，反之则进行回收。通常应用在对内存敏感的程序中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 软引用
SoftReference&amp;lt;String&amp;gt; softReference = new SoftReference&amp;lt;&amp;gt;(&amp;quot;test&amp;quot;);

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;弱引用&#34;&gt;弱引用&lt;/h3&gt;
&lt;p&gt;弱引用需要使用WeakReference类来实现，它比软引用生存周期更短，对于弱引用对象来说，只要垃圾回收机制一运行，不管JVM内存空间是否充足，都会对其进行回收。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 弱引用
WeakReference&amp;lt;String&amp;gt; weakReference = new WeakReference&amp;lt;&amp;gt;(&amp;quot;test&amp;quot;);

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;虚引用&#34;&gt;虚引用&lt;/h3&gt;
&lt;p&gt;虚引用需要使用PhantomReference类来实现，它不能单独使用，必须与引用队列联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 虚引用
ReferenceQueue&amp;lt;String&amp;gt; queue = new ReferenceQueue&amp;lt;&amp;gt;();
PhantomReference&amp;lt;String&amp;gt; pr = new PhantomReference&amp;lt;&amp;gt;(&amp;quot;test&amp;quot;, queue);

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;java中的io&#34;&gt;Java中的I/O&lt;/h2&gt;
&lt;h3 id=&#34;bioblock-io&#34;&gt;BIO（Block IO）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同步阻塞式IO，一般指平常所用的IO类。&lt;/li&gt;
&lt;li&gt;一个请求对应一个响应，为了合理的利用资源，可以使用多线程（线程池）。&lt;/li&gt;
&lt;li&gt;此IO一般针对并发量较小的场景（&amp;lt;1000）。&lt;/li&gt;
&lt;li&gt;BIO操作的对象是流（Stream）。&lt;/li&gt;
&lt;li&gt;比如：在ATM机上取钱，只能一个一个的取，前面有人的时候，需要等待；取钱的时候，需要本人进行相关取钱操作（取出之后拿到钱才走）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nionew-io&#34;&gt;NIO（New IO）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同步非阻塞式IO。&lt;/li&gt;
&lt;li&gt;利用Channel（通道）通讯，实现了多路复用。&lt;/li&gt;
&lt;li&gt;核心组件：Buffer（缓冲区），Channel（通道），Selector（选择器）&lt;/li&gt;
&lt;li&gt;NIO操作的对象是缓存区（Buffer）。&lt;/li&gt;
&lt;li&gt;基本运行流程：当Channel发生新连接、就绪读，就绪写的时候，首先会在Selector上注册相应的事件，生成一个与Channel绑定的selectKey；其次由一个线程轮询selectKey集合，利用操作系统底层的函数select() 或者 epoll（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是iocp）去操作系统查询IO是否就绪，如果就绪则执行相应的事件处理器（通过selectKey找到Channel，然后利用与Channel绑定的buffer进行实际读写）。&lt;/li&gt;
&lt;li&gt;比如：在银行大厅取钱，对于前面是否有人等候，只需要隔一段时间去问一下大堂经理是否可以取钱就可以了，不需要一直去排队（这段时间可以做其他事）；取钱的时候，需要柜员进行相关操作，同时也需要保证你也在柜员面前（不能离开，不然柜员可能会找不到你，然后钱就没有实际拿到手里了）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aioasynchronous-io&#34;&gt;AIO（Asynchronous IO）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;异步非阻塞式IO。&lt;/li&gt;
&lt;li&gt;其实现是基于事件以及回调机制。&lt;/li&gt;
&lt;li&gt;AIO与NIO有点相似，不过对于实际读写而言，AIO是交给操作系统底层自己去完成的，完成之后会返回一个IO完成的回调消息。&lt;/li&gt;
&lt;li&gt;比如：同样是去银行取钱，不过这次你是让朋友去帮忙取的，你朋友会帮你排队，然后取钱，接着把钱给你，并告诉你已经取好了。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;io阶段&#34;&gt;IO阶段&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;IO中对于读写一般分为两个阶段：就绪读写（准备数据）以及实际读写（真正读写数据）。&lt;/li&gt;
&lt;li&gt;对应上面取钱例子而言，就绪读写指的是排队，实际读写指的是取钱操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;同步异步&#34;&gt;同步，异步&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;同步指的是操作的时候，需要等待当前任务返回结果；异步则相反，它不需要等待当前任务返回，通常情况下是依赖于事件，回调机制来实现任务间的次序关系。&lt;/li&gt;
&lt;li&gt;同步，异步对于IO而言指的是实际读写阶段；对应取钱例子而言，就是真正取钱操作（同步，自己取钱；异步，朋友帮忙取钱）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;阻塞非阻塞&#34;&gt;阻塞，非阻塞&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;阻塞指的是如果任务在执行，当前线程会阻塞，需要等待任务执行完，这期间该线程不能执行其他任务；非阻塞则是说在一个任务执行期间，线程不会阻塞，可以执行其他任务。&lt;/li&gt;
&lt;li&gt;阻塞，非阻塞对于IO而言指的是就绪读写阶段；对应取钱例子而言，就是排队等候（阻塞，排队没带手机，只能干等着；非阻塞，排队带了手机，可以一边玩手机一边排队）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jvm类加载&#34;&gt;JVM类加载&lt;/h2&gt;
&lt;h3 id=&#34;类加载机制&#34;&gt;类加载机制&lt;/h3&gt;
&lt;p&gt;JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301027.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;1、加载：在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口（注意：不一定非得从Class文件中获取，也可以从ZIP（如jar，war）中读取，或者在运行时计算生成（动态代理），或者由其他文件转换而来（如JSP转换为Class））。&lt;/p&gt;
&lt;p&gt;2、验证：确保Class文件字节流中所包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。&lt;/p&gt;
&lt;p&gt;3、准备：正式为类变量分配内存并为其设置初始值，即在方法区中分配这些变量所使用的内存空间。需要注意这里所说的初始值概念，比如说一个类变量定义为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static int port = 8080;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么此变量在准备阶段所谓的设置初始值，是设置其为0，而不是8080。将port赋值为8080的put static 指令是程序被编译后，存放于类构造器&lt;code&gt;&amp;lt;Client&amp;gt;&lt;/code&gt;方法中的。&lt;/p&gt;
&lt;p&gt;但如果变量声明如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static final int port = 8080;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么在编译期间，会为port生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将port赋值为8080.&lt;/p&gt;
&lt;p&gt;4、解析：此阶段指虚拟机将常量池中的符号引用替换为直接引用的过程。&lt;/p&gt;
&lt;p&gt;符号引用：与虚拟机实现的布局无关，引用的目标不一定要已经加载至内存中。各种虚拟机的内存布局可以不一致，但它们能接受的符号引用必须一致，因为符号引用的字面量形式明确的定义在java虚拟机规范的Class文件格式中。、&lt;/p&gt;
&lt;p&gt;直接引用：是可以直接指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄，如果存在直接引用，那么引用的目标必定已经在内存中存在。&lt;/p&gt;
&lt;p&gt;5、初始化：此阶段开始真正执行类中定义的java程序代码，即开始开始执行类构造器&lt;code&gt;&amp;lt;client&amp;gt;&lt;/code&gt;方法。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;client&amp;gt;&lt;/code&gt;方法是由编译器自动收集类中的类静态变量赋值以及静态语句块中的语句合并而成的。虚拟机会保证子&lt;code&gt;&amp;lt;client&amp;gt;&lt;/code&gt;执行之前，父&lt;code&gt;&amp;lt;client&amp;gt;&lt;/code&gt;已经执行完毕（如果一个类中既没有类静态变量赋值，也没有静态语句块，那虚拟机可以不为其生成&lt;code&gt;&amp;lt;client&amp;gt;&lt;/code&gt;方法）。&lt;/p&gt;
&lt;p&gt;注意以下几种情形不会执行类初始化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过子类引用父类的静态字段，只会触发父类的初始化。&lt;/li&gt;
&lt;li&gt;定义对象数组，不会触发该类的初始化。&lt;/li&gt;
&lt;li&gt;常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在类的初始化。&lt;/li&gt;
&lt;li&gt;通过类名获取Class对象，不会触发初始化。&lt;/li&gt;
&lt;li&gt;通过Class.forName加载指定类时，如果指定参数initialize为false（initialize是告诉虚拟机是否要对该类进行初始化），也不会触发类的初始化。&lt;/li&gt;
&lt;li&gt;通过ClassLoader默认的loadClass方法，不会触发类初始化。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;类加载器&#34;&gt;类加载器&lt;/h3&gt;
&lt;p&gt;类的加载并没有发生在JVM中，而是由应用程序来确定如何获取所需要的类。为此JVM提供了三种类加载器，如下：&lt;/p&gt;
&lt;p&gt;1、启动类加载器（Bootstrap ClassLoader）：负责加载JAVA_HOME\lib目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可的类（按文件名识别，如：rt.jar）。&lt;/p&gt;
&lt;p&gt;2、扩展类加载器（Extension ClassLoader）：负责加载JAVA_HOME\lib\ext目录中的，或通过java.ext.dirs系统变量指定路径中的类库。&lt;/p&gt;
&lt;p&gt;3、应用程序类加载器（Application ClassLoader）：负责加载用户路径（classpath）上的类库。&lt;/p&gt;
&lt;h3 id=&#34;双亲委派模型&#34;&gt;双亲委派模型&lt;/h3&gt;
&lt;p&gt;JVM通过双亲委派模型进行类的加载，当然，开发者也可以通过集成java.lang.ClassLoader实现自定义的类加载器。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301028.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;双亲委派过程：当一个类收到类加载请求时，它首先不会尝试自己去加载这个类，而是将这个请求委派给父类去完成，每一层次的类加载器都是如此操作，因此所有的类加载请求都应该会传送到启动类加载器中，只有当父加载器无法加载此类时（在它的加载路径下没有找到所需加载的Class），子加载器才会尝试自己去加载。&lt;/p&gt;
&lt;p&gt;双亲委派解决了java基础类统一加载的问题，但某些情况下父类加载器需要委托子类加载器去加载Class文件，例如SPI（Service Provider Interface）代码（spi是一种服务发现机制：即为某个接口寻找服务实现的机制。）。&lt;/p&gt;
&lt;h3 id=&#34;以jdbc为例谈双亲委派模型的破坏&#34;&gt;以JDBC为例谈双亲委派模型的破坏&lt;/h3&gt;
&lt;p&gt;Java本身有一套资源管理服务JNDI（Java Naming and Directory Interface，根据名称可以在其中查找对应的方法或者其他参数），其放置于rt.jar中，由启动类加载器进行加载。&lt;/p&gt;
&lt;p&gt;以数据库管理JDBC为例，java给数据库操作提供了一个Driver（java.sql.Driver）接口，并提供了一个DriverManager（java.sql.DriverManager）来管理Driver的具体实现。&lt;/p&gt;
&lt;h4 id=&#34;不破坏双亲委派模型不使用jdni&#34;&gt;不破坏双亲委派模型（不使用JDNI）&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;// 加载数据库驱动
Class.forName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;);
// 连接到数据库上去
Connection connection = DriverManager.getConnection(&amp;quot;jdbc:mysql://localhost:3306/db?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;allowMultiQueries=true&amp;amp;serverTimezone=Asia/Shanghai&amp;quot;,&amp;quot;root&amp;quot;,&amp;quot;root&amp;quot;);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Class.forName()触发了mysql驱动类的加载，通过源码可以发现，mysql的驱动类已经在静态块中被注册到了DriverManager中，所以后续使用时可以直接建立连接。其核心实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class Driver extends NonRegisteringDriver implements java.sql.Driver {
    public Driver() throws SQLException {
    }

    static {
        try {
            DriverManager.registerDriver(new Driver());
        } catch (SQLException var1) {
            throw new RuntimeException(&amp;quot;Can&#39;t register driver!&amp;quot;);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;public static synchronized void registerDriver(java.sql.Driver driver,
        DriverAction da)
    throws SQLException {

    /* Register the driver if it has not already been added to our list */
    if(driver != null) {
        registeredDrivers.addIfAbsent(new DriverInfo(driver, da));
    } else {
        // This is for compatibility with the original DriverManager
        throw new NullPointerException();
    }

    println(&amp;quot;registerDriver: &amp;quot; + driver);

}

&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;破坏双亲委派模型使用jdni&#34;&gt;破坏双亲委派模型（使用JDNI）&lt;/h4&gt;
&lt;p&gt;JDBC4.0以后，开始支持spi注册Driver，具体做法便是在mysql的jar中的META-INF/services/java.sql.Driver文件中指明当前的Driver，然后通过下列方式即可使用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 连接到数据库上去
Connection connection = DriverManager.getConnection(&amp;quot;jdbc:mysql://localhost:3306/db?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;allowMultiQueries=true&amp;amp;serverTimezone=Asia/Shanghai&amp;quot;,&amp;quot;root&amp;quot;,&amp;quot;root&amp;quot;);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此处相比于不破坏双亲委派模型，少了一句Class.forName()，即加载驱动类的步骤。其对应的Driver是配置在META-INF/services/java.sql.Drive文件中的，由此可以知道其操作为：先从配置文件中读取Driver，随后再进行加载（使用Class.forName()）&lt;/p&gt;
&lt;p&gt;需要注意的是，Class.forName()加载的是调用者的ClassLoader，这个调用者DriverManager是在rt.jar中，ClassLoader是启动类加载器，而com.mysql.cj.jdbc.Driver并没有位于&amp;lt;JAVA_HOME&amp;gt;/lib下，所以肯定是无法直接加载到mysql的这个类的。这边是双亲委派的局限性，父类加载器无法加载子类加载器路径中的类（父对子透明，子对父不透明）。&lt;/p&gt;
&lt;p&gt;为了让父类加载器加载子类加载器路径中的类，可以通过线程上下文加载器去加载第三方jar包中的Driver，这便打破了双亲委派模型。&lt;/p&gt;
&lt;p&gt;以DriverManager为例，当调用其getConnection()方法时，会先执行器静态块中的初始化代码，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/**
 * Load the initial JDBC drivers by checking the System property
 * jdbc.properties and then use the {@code ServiceLoader} mechanism
 */
static {
    loadInitialDrivers();
    println(&amp;quot;JDBC DriverManager initialized&amp;quot;);
}

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;AccessController.doPrivileged(new PrivilegedAction&amp;lt;Void&amp;gt;() {
    public Void run() {
        // 各个sql厂商在自己的jar包中通过spi注册的驱动
        ServiceLoader&amp;lt;Driver&amp;gt; loadedDrivers = ServiceLoader.load(Driver.class);
        Iterator&amp;lt;Driver&amp;gt; driversIterator = loadedDrivers.iterator();

        /* Load these drivers, so that they can be instantiated.
         * It may be the case that the driver class may not be there
         * i.e. there may be a packaged driver with the service class
         * as implementation of java.sql.Driver but the actual class
         * may be missing. In that case a java.util.ServiceConfigurationError
         * will be thrown at runtime by the VM trying to locate
         * and load the service.
         *
         * Adding a try catch block to catch those runtime errors
         * if driver not available in classpath but it&#39;s
         * packaged as service and that service is there in classpath.
         */
        try{
            while(driversIterator.hasNext()) {
                driversIterator.next();
            }
        } catch(Throwable t) {
        // Do nothing
        }
        return null;
    }
});

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中ServiceLoader.load()便是拿到线程上下文加载器，并构造了一个ServiceLoader进行返回，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static &amp;lt;S&amp;gt; ServiceLoader&amp;lt;S&amp;gt; load(Class&amp;lt;S&amp;gt; service) {
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    return ServiceLoader.load(service, cl);
}

public static &amp;lt;S&amp;gt; ServiceLoader&amp;lt;S&amp;gt; load(Class&amp;lt;S&amp;gt; service,
                                        ClassLoader loader)
{
    return new ServiceLoader&amp;lt;&amp;gt;(service, loader);
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DriverManager中的doPrivileged()中还有一句driversIterator.next()，其中实现了类加载过程，具体实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private S nextService() {
    if (!hasNextService())
        throw new NoSuchElementException();
    String cn = nextName;
    nextName = null;
    Class&amp;lt;?&amp;gt; c = null;
    try {
        // 此处的cn便是便是厂商在META-INF/services/java.sql.Drive文件中配置的全限定驱动类名
        // loader则是上文中ServiceLoader.load()返回的线程上下文加载器。
        c = Class.forName(cn, false, loader);
    } catch (ClassNotFoundException x) {
        fail(service,
             &amp;quot;Provider &amp;quot; + cn + &amp;quot; not found&amp;quot;);
    }
    if (!service.isAssignableFrom(c)) {
        fail(service,
             &amp;quot;Provider &amp;quot; + cn  + &amp;quot; not a subtype&amp;quot;);
    }
    try {
        S p = service.cast(c.newInstance());
        providers.put(cn, p);
        return p;
    } catch (Throwable x) {
        fail(service,
             &amp;quot;Provider &amp;quot; + cn + &amp;quot; could not be instantiated&amp;quot;,
             x);
    }
    throw new Error();          // This cannot happen
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hotspot-jvm虚拟机对象探究&#34;&gt;Hotspot JVM虚拟机对象探究&lt;/h2&gt;
&lt;h3 id=&#34;对象的创建以普通java对象new指令为例&#34;&gt;对象的创建（以普通Java对象new指令为例）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;当虚拟机遇到一条new指令时，首先会去常量池中检查是否存在这个对象的引用，并且检查该引用所代表的类是否已经被加载，解析和初始化过，如果没有，则先执行类加载。&lt;/li&gt;
&lt;li&gt;当类加载检查通过之后，虚拟机将会为新生对象分配内存（对象所需的内存大小在类加载完成之后就已经确认了，为对象分配空间就是在Java堆上划分出一块内存来。一般有两种分配方式，根据内存规整程度分为：指针碰撞（规整）以及空闲列表（不规整））。&lt;/li&gt;
&lt;li&gt;针对并发情况下对象内存分配冲突解决方案有：一是同步处理，二是使用本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）（虚拟机是否使用本地线程分配缓冲可通过-XX:+/-UseTLAB参数来设定）。&lt;/li&gt;
&lt;li&gt;内存分配完毕之后，虚拟机会将对应的内存空间初始化为零值（不包括对象头）。接着会对这个对象进行必要的设置，例如此对象是哪个类的实例，如何查找类的元数据信息，对象的哈希码，对象的GC分代年龄等等，这些信息都放在了对象头中。&lt;/li&gt;
&lt;li&gt;执行完new指令之后还需要执行&lt;code&gt;&amp;lt;init&amp;gt;&lt;/code&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算是完全创建好了。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;对象的内存布局&#34;&gt;对象的内存布局&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header），实例数据（Instance Data）以及对齐填充（Padding）。&lt;/li&gt;
&lt;li&gt;对象头（Header）主要包含两部分信息：第一部分用于存储对象自身的运行时数据（如哈希码（HashCode），GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据长度在32位或者64位的虚拟机中分别为32bit以及64bit，官方称之为“Mark Word”）；第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机可以通过这个指针来确定该对象属于哪个类的实例（并不是所有的虚拟机实现都需要在对象数据上保留类型指针，即查找对象的元数据信息并不一定要经过对象本身），如果对象是一个Java数组，那么对象头还需要记录该数组长度，因为普通的Java对象可以通过元数据信息确认对象大小，而数组却不行。&lt;/li&gt;
&lt;li&gt;实例数据（Instance Data）存储着对象真正有效的信息，即各种类型的字段，无论是继承父类还是子类自定义。&lt;/li&gt;
&lt;li&gt;对齐填充（Padding）不是必然存在的，也没有特殊的含义，仅仅起到占位符的作用，保证对象大小是某个字节的整数倍（HotSpot VM 的自动内存管理系统要求对象起始地址必须为8字节的整数倍）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;对象的访问定位&#34;&gt;对象的访问定位&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;建立对象的目的是为了使用该对象，Java程序是通过栈上的reference指针来操作堆上的具体对象的。&lt;/li&gt;
&lt;li&gt;目前主流的访问方式有句柄和直接指针两种。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;句柄访问定位&#34;&gt;句柄访问定位&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用句柄的话，Java堆将会划分出一块内存来作为句柄池，reference中存放的也就是对象的句柄地址（句柄中包含了对象实例数据和类型数据各自的地址）。&lt;/li&gt;
&lt;li&gt;句柄的优势在于其稳定性更高，如果对象频繁的发生移动（GC操作时移动对象），那么只会改变句柄中的实例数据的指针，reference本身不需要改变。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301029.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;直接访问定位&#34;&gt;直接访问定位&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用直接指针，那么reference将直接指向对象对应的地址（Java堆布局时需要考虑如何存放访问类型数据的相关信息）。&lt;/li&gt;
&lt;li&gt;直接指针的优势在于其速度更快，因为减少了一次指针定位的操作。如果对象访问频繁，那么使用直接访问将会提高相当不错的效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301030.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">java中引用&IO&类加载&对象创建过程</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/jvm-xiang-jie/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述JVM，包括jvm线程，jvm运行时区域，jvm垃圾回收机制--回收算法以及垃圾回收器&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountains-139012_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;jvm概述&#34;&gt;JVM概述&lt;/h2&gt;
&lt;h3 id=&#34;基本概念&#34;&gt;基本概念&lt;/h3&gt;
&lt;p&gt;JVM是运行java代码的虚拟计算机平台，它运行于计算机操作系统之上，并不直接与硬件进行交互。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301019.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;运行过程&#34;&gt;运行过程&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;x.java源文件，通过编译器产生对应的&lt;/em&gt;.Class字节码文件，之后又通过java虚拟机中的解释器，编译成特定机器上的机器码。&lt;/p&gt;
&lt;p&gt;流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Java源文件 ----&amp;gt; 编译器 ----&amp;gt; 字节码文件&lt;/li&gt;
&lt;li&gt;字节码文件 ----&amp;gt; JVM解释器 ----&amp;gt; 机器码&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每一种平台的解释器都是不同的，但其依赖的虚拟机是一样的，这也就是java跨平台运行的核心原理。&lt;/p&gt;
&lt;p&gt;虚拟机实例随着程序的运行而启动，程序退出或关闭则会使对应的虚拟机实例消亡。多个程序启动会存在多个虚拟机实例，各个虚拟机实例之间互不干扰，数据独立。&lt;/p&gt;
&lt;h2 id=&#34;jvm线程&#34;&gt;JVM线程&lt;/h2&gt;
&lt;h3 id=&#34;线程&#34;&gt;线程&lt;/h3&gt;
&lt;p&gt;此处所说的线程为程序执行过程中的一个线程实体。JVM允许一个应用并发执行多个线程。&lt;/p&gt;
&lt;p&gt;Hotspot JVM中的java线程与操作系统原生线程存在直接的映射关系：当java线程创建完毕后，会同步创建一个操作系统原生线程。java线程结束，原生线程也会随之被回收（原生线程由操作系统负责调度，如将其分配至可用的CPU）。&lt;/p&gt;
&lt;p&gt;Hotspot JVM 后台运行的系统线程如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301020.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;jvm内存区域&#34;&gt;JVM内存区域&lt;/h2&gt;
&lt;h3 id=&#34;内存区域图&#34;&gt;内存区域图&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301021.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;运行时数据区域&#34;&gt;运行时数据区域&lt;/h3&gt;
&lt;p&gt;Java虚拟机在执行java程序时，定义了若干程序运行期间会使用到的运行时数据区域，其中线程共享区域随着虚拟机的启动/关闭而创建/销毁，线程私有区域则与用户线程一一对应，会随着用户线程的启动/关闭而创建/销毁（ Hotspot JVM中，用户线程会与原生线程对应）。&lt;/p&gt;
&lt;p&gt;运行时数据区域图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301022.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;程序计数器program-counter-register&#34;&gt;程序计数器（Program Counter Register）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;是一块内存小，线程私有，且不会发生OOM（OutOfMemoryError）的区域（因为它只是当前线程所执行的字节码的行号指示器）。&lt;/li&gt;
&lt;li&gt;在Java虚拟机概念模型中（仅仅指概念模型，各类不同的虚拟机可能有更高效的处理方式），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行指令的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖计数器来完成。&lt;/li&gt;
&lt;li&gt;Java虚拟机可以支持多线程同时执行（可参考《Java 语言规范》第 17 章），是通过轮转时间片的方式让处理器来执行线程的。在任意时刻，一个处理器（对于多核处理器来说是指一个内核）只会处理一个线程中的指令，为了保证线程切换能够回到正确的执行指令，Java虚拟机针对每个线程分配了一个独立的程序计数器，各线程之间的计数器互不干扰，独立存储。&lt;/li&gt;
&lt;li&gt;如果线程正在执行的方法不是 native的（即Java方法），那程序计数器就保存 Java 虚拟机正在执行的字节码指令的地址，如果该方法是 native 的，那程序计数器的值是 undefined。&lt;/li&gt;
&lt;li&gt;程序计数器的容量至少应当能保存一个 returnAddress 类型的数据或者一个与平台相关的本地指针的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;java虚拟机栈java-virtual-machine-stack&#34;&gt;Java虚拟机栈（Java Virtual Machine Stack）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Java虚拟机栈是线程私有的，它的生命周期与线程一致。&lt;/li&gt;
&lt;li&gt;虚拟机栈描述的是 Java 方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧从虚拟机栈中入栈到出栈的过程。&lt;/li&gt;
&lt;li&gt;局部变量表存放了编译期可知的各种基本类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference类型，它不等同于对象本身)和 returnAddress 类型(指向了一条字节码指令的地址)。&lt;/li&gt;
&lt;li&gt;需要注意的是64位的long以及double类型的数据会占用两个局部变量空间（Slot），其余的数据类型只占一个。局部变量表所需的内存空间在编译期间就已经完成了分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是已经确认了的，在方法运行期间不会去改变局部变量表的大小。&lt;/li&gt;
&lt;li&gt;Java虚拟机栈有可能发生以下两种异常状况：如果线程请求分配的栈容量（栈深度）超过 Java 虚拟机栈允许的最大容量（深度）时，Java 虚拟机将会抛出一 个StackOverflowError异常；如果Java 虚拟机栈可以动态扩展（目前大部分虚拟机都支持动态扩展），并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个 OutOfMemoryError异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;本地方法栈native-method-stack&#34;&gt;本地方法栈（Native Method Stack）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;本地方法栈与Java虚拟机栈是非常类似的，他们的主要区别是Java虚拟机栈是服务于Java方法（字节码）的，而本地方法栈则是服务于Native方法的。&lt;/li&gt;
&lt;li&gt;与Java虚拟机栈一样，本地方法栈同样会出现StackOverflowError异常和OutOfMemoryError异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;java堆java-heap&#34;&gt;Java堆（Java Heap）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在 Java 虚拟机中，堆（Heap）是可供各条线程共享的运行时内存区域，也是供所有类实例和数组对象分配内存的区域，一般而言堆（Heap）占用的内存空间也是最大的。&lt;/li&gt;
&lt;li&gt;Java 堆在虚拟机启动的时候就被创建，它存储了被自动内存管理系统（Automatic Storage Management System，也即是常说的“Garbage Collector（垃圾收集器）”）所管理的各种对象，这些受管理的对象无需，也无法显式地被销毁。所以一般我们也称Java堆为GC堆（Garbage Collected Heap）。&lt;/li&gt;
&lt;li&gt;如果实际所需的堆超过了自动内存管理系统能提供的最大容量（或者说堆中没有内存来完成实例分配，且无法扩展），那 Java 虚拟机将会抛出一个 OutOfMemoryError异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;方法区method-area&#34;&gt;方法区（Method Area）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在 Java 虚拟机中，方法区（Method Area）是可供各条线程共享的运行时内存区域。&lt;/li&gt;
&lt;li&gt;它存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法（即存储着已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据）。&lt;/li&gt;
&lt;li&gt;如果方法区的内存空间不能满足内存分配请求，那 Java 虚拟机将抛出一个 OutOfMemoryError异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;运行时常量池runtime-constant-pool&#34;&gt;运行时常量池（Runtime Constant Pool）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;运行时常量池是方法区（Method Area）的一部分。&lt;/li&gt;
&lt;li&gt;它是每一个类或接口的常量池（Constant_Pool）的运行时表示形式，它包括了若干种不同的常量：从编译期可知的数值字面量到必须运行期解析后才能获得的方法或字段引用。&lt;/li&gt;
&lt;li&gt;一般情况下，除了保存Class文件中描述的符号引用外，还会把翻译过来的直接引用也保存在运行时常量池中。&lt;/li&gt;
&lt;li&gt;运行时常量池相对于Class文件常量池的另一个特征是具备动态性，即运行期间也可将新的常量放入池中，比如String.intern()方法。&lt;/li&gt;
&lt;li&gt;当创建类或接口的时候，如果构造运行时常量池所需要的内存空间超过了方法区所能提供的最大值，那 Java 虚拟机将会抛出一个 OutOfMemoryError 异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;直接内存direct-memory&#34;&gt;直接内存（Direct Memory）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;直接内存并不属于Java虚拟机运行时内存区域，也不是Java虚拟机规范中定义的内存区域。&lt;/li&gt;
&lt;li&gt;在这里提出来的主要原因是因为Java在1.4版本引入了NIO类，是一种基于通道（Channel）和缓存区（Buffer）的IO操作，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。&lt;/li&gt;
&lt;li&gt;在某些情况下，通过减少Java堆和Native堆来回复制数据的操作，从而提高一些性能。&lt;/li&gt;
&lt;li&gt;因为这块内存也是实际存在的，所以受硬件总内存影响，如果需要对虚拟机内存进行扩容操作，需要考虑虚拟机内存加直接内存超过物理内存限制所引起的 OutOfMemoryError异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;jvm运行时内存&#34;&gt;JVM运行时内存&lt;/h3&gt;
&lt;h4 id=&#34;分代&#34;&gt;分代&lt;/h4&gt;
&lt;p&gt;Java堆从GC角度还可以细分为新生代（Eden区，From Survivor区，To Survivor区），老年代。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301023.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;新生代&#34;&gt;新生代&lt;/h4&gt;
&lt;p&gt;用于存储初创对象，一般占据堆内存1/3。对象的创建频繁且杂多，所以此区域会经常触发MinorGC进行垃圾回收。&lt;/p&gt;
&lt;h5 id=&#34;新生代细分区域&#34;&gt;新生代细分区域&lt;/h5&gt;
&lt;p&gt;Eden区：Java新对象的出生地（如果新创建的对象占用内存过大，将直接被分配至老年代），当Eden内存不足时，将触发一次MinorGC，对其进行垃圾回收。&lt;/p&gt;
&lt;p&gt;From Survivor区：上一次GC的幸存者存放在此区域，将作为这一次GC的扫描对象。&lt;/p&gt;
&lt;p&gt;To Survivor区：经历一次MinorGC过程的幸存者。&lt;/p&gt;
&lt;h5 id=&#34;新生代gc过程复制算法&#34;&gt;新生代GC过程（复制算法）&lt;/h5&gt;
&lt;p&gt;首先将Eden和From Survivor区域中存活的对象复制到To Survivor区域（From Survivor区如果存在对象年龄且大于阈值，则直接复制到老年代），同时将这些对象的年龄+1（如果To Survivor区被填满了，剩余的对象会被复制到老年代中）。随后清空Eden和From Survivor区域中的死对象。最后，将From Survivor和To Survivor调换名字，这样，在下一次GC时，原To Survivor将成为From Survivor。&lt;/p&gt;
&lt;h4 id=&#34;老年代&#34;&gt;老年代&lt;/h4&gt;
&lt;p&gt;主要存储应用程序中生命周期较长的内存对象。进入老年代的对象一般都比较稳定，所以不会频繁地执行MajorGC。&lt;/p&gt;
&lt;p&gt;MajorGC采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收未标记的对象。此过程耗时较长，且会产生内存碎片。&lt;/p&gt;
&lt;h4 id=&#34;永久代&#34;&gt;永久代&lt;/h4&gt;
&lt;p&gt;内存的永久保存区域，主要存放Class以及Meta（元数据）信息。Class在被加载时便放入永久区域，它跟存放实例的区域不同，GC不会在主程序执行期间对永久区域进行清理。所以，这也导致了永久区域随着加载的Class增多而不断膨胀，最终抛出OOM异常。&lt;/p&gt;
&lt;p&gt;Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所替代。元空间的本质与永久代类似，它们之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。&lt;/p&gt;
&lt;h3 id=&#34;垃圾回收与算法&#34;&gt;垃圾回收与算法&lt;/h3&gt;
&lt;h4 id=&#34;gc算法图&#34;&gt;GC算法图&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301024.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;垃圾确认算法&#34;&gt;垃圾确认算法&lt;/h4&gt;
&lt;p&gt;引用计数法：对象被引用则+1，否则-1，为0时将被回收（存在循环引用问题）。&lt;/p&gt;
&lt;p&gt;可达性分析：为了避免引用计数法中的循环引用问题，如今java一般采用可达性分析，通过一系列的GC ROOTS（VM栈中的引用，方法区中的静态引用，JNI中的引用等）作为对象的起点搜索。如果GC ROOTS和一个对象之间没有可达路径，则称其为不可达。需要注意的是：不可达对象不等价于可回收对象，不可达对象变为可回收对象最少需要经历两次标记过程，如果仍然不可达，则会面临回收。&lt;/p&gt;
&lt;h4 id=&#34;垃圾收集算法&#34;&gt;垃圾收集算法&lt;/h4&gt;
&lt;h5 id=&#34;标记清除算法mark-sweep&#34;&gt;标记清除算法（Mark-Sweep）&lt;/h5&gt;
&lt;p&gt;最基础的垃圾回收算法，分为两个阶段，标记和清除。如下图所示（容易出现内存碎片）：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301025.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;复制算法copying&#34;&gt;复制算法（copying）&lt;/h5&gt;
&lt;p&gt;为了解决Mark-Sweep算法中内存碎片化的缺陷而被提出的算法。&lt;/p&gt;
&lt;p&gt;它按内存容量将内存划分为等大小的两块，每次只使用其中一块，当这一块内存满了之后，便将其中存活的对象移至另一块内存上去，同时把已使用的内存清理掉。&lt;/p&gt;
&lt;p&gt;这种算法实现简单，内存效率高，不易产生碎片，但同时也带来了一个问题，那就是可用内存被压缩到了原来的一半，且当存活对象过多时，其算法效率又会大大降低。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301026.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;分代收集算法&#34;&gt;分代收集算法&lt;/h5&gt;
&lt;p&gt;此算法是目前大部分JVM所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域。&lt;/p&gt;
&lt;p&gt;一般情况下，会将GC堆划分为老年代（Tenured/Old Generation）和新生代（Young Generation）。&lt;/p&gt;
&lt;p&gt;老年代的特点是每次需要回收的对象很少，新生代则与之相反，因此可以根据不同的区域选择不同的算法。&lt;/p&gt;
&lt;p&gt;新生代由于需要经常进行垃圾回收，所以可以采用复制算法（一般会将其再次划分为Eden，From Survivor以及To Survivor三个区域，比例为8:1:1（实际调优需要根据具体的业务调整））。&lt;/p&gt;
&lt;p&gt;老年代则一般采用标记复制算法或者标记整理算法，可根据具体场景指定。&lt;/p&gt;
&lt;h3 id=&#34;gc垃圾收集器&#34;&gt;GC垃圾收集器&lt;/h3&gt;
&lt;h4 id=&#34;serial垃圾收集器单线程复制算法&#34;&gt;Serial垃圾收集器（单线程，复制算法）&lt;/h4&gt;
&lt;p&gt;Serial是最基本的垃圾收集器，使用复制算法。JDK1.3.1之前，它是新生代唯一的垃圾收集器。&lt;/p&gt;
&lt;p&gt;Serial是一个单线程的收集器，它不但只会用一个CPU或一条线程去完成垃圾收集工作，并且在进行垃圾收集的过程中，还要暂停其他所有线程（stop the world），直到垃圾收集结束。&lt;/p&gt;
&lt;p&gt;Serial在执行时虽然会暂停其他所有线程，但其简单高效，对于限定单个CPU的环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率。&lt;/p&gt;
&lt;p&gt;因此，Serial依旧是java虚拟机运行在Client模式下新生代的默认垃圾收集器。&lt;/p&gt;
&lt;h4 id=&#34;parnew垃圾收集器serial-多线程&#34;&gt;ParNew垃圾收集器（serial + 多线程）&lt;/h4&gt;
&lt;p&gt;ParNew其实是Serial收集器的多线程版本，除了多线程之外，其余与Serial完全一致。&lt;/p&gt;
&lt;p&gt;ParNew默认开启和CPU数目相同的线程数，可以通过-XX:ParallelGCThreads参数来限制垃圾收集器的线程数。&lt;/p&gt;
&lt;p&gt;相较于Seria而言，ParNew是java虚拟机运行在Server模式下新生代的默认垃圾收集器。&lt;/p&gt;
&lt;h4 id=&#34;parallel-scavenge垃圾收集器多线程复制算法高效&#34;&gt;Parallel Scavenge垃圾收集器（多线程复制算法，高效）&lt;/h4&gt;
&lt;p&gt;Parallel Scavenge 是一个新生代垃圾收集器，使用复制算法，且为多线程。其重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU用于运行用户代码时间/CPU总消耗时间，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间））。&lt;/p&gt;
&lt;p&gt;高吞吐量可以最高效率的利用CPU时间，尽快地完成程序的运行任务，主要适用于在后台运算，而不需要太多交互的任务。&lt;/p&gt;
&lt;p&gt;自适应调节策略也是Parallel Scavenge与ParNew的一个重要区别。&lt;/p&gt;
&lt;h4 id=&#34;serial-old垃圾收集器单线程标记整理算法&#34;&gt;Serial Old垃圾收集器（单线程，标记整理算法）&lt;/h4&gt;
&lt;p&gt;Serial Old是Serial垃圾收集器的老年代版本，它同样是单线程的，使用的算法为标记整理。Serial Old是java虚拟机运行在Client模式下老年代的默认垃圾收集器。&lt;/p&gt;
&lt;p&gt;其在Server模式下，主要有两个用途：&lt;/p&gt;
&lt;p&gt;1、在JDK1.5之前版本与新生代的Parallel Scavenge收集器搭配使用。&lt;/p&gt;
&lt;p&gt;2、作为老年代中CMS的后备垃圾收集器。&lt;/p&gt;
&lt;h4 id=&#34;parallel-old垃圾收集器多线程标记整理算法&#34;&gt;Parallel Old垃圾收集器（多线程，标记整理算法）&lt;/h4&gt;
&lt;p&gt;Parallel Old是Parallel Scavenge垃圾收集器的老年代版本，它同样是多线程的，使用的算法为标记整理（JDK1.6之后才提供）。&lt;/p&gt;
&lt;h4 id=&#34;cms垃圾收集器多线程标记清除算法&#34;&gt;CMS垃圾收集器（多线程，标记清除算法）&lt;/h4&gt;
&lt;p&gt;Concurrent Mark Sweep是一种老年代垃圾收集器，其主要目的是为了获取最短垃圾回收停顿时间（在交互过程中提高用户体验），使用的算法为标记清除。&lt;/p&gt;
&lt;p&gt;CMS执行过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始标记：标记一下GC ROOTS能直接关联的对象，速度很快，需要暂停工作线程。&lt;/li&gt;
&lt;li&gt;并发标记：进行GC ROOTS跟踪的过程，和用户线程一起工作，不需要暂停工作线程。&lt;/li&gt;
&lt;li&gt;重新标记：为了修正并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记录，需要暂停工作线程。&lt;/li&gt;
&lt;li&gt;并发清除：清除GC ROOTS不可达对象，和用户线程一起工作，不需要暂停工作线程，由于耗时最长的并发标记和并发清除是与用户线程一起工作的，所以总体上来看，CMS收集过程与用户线程是并发执行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;g1垃圾收集器多线程标记整理算法&#34;&gt;G1垃圾收集器（多线程，标记整理算法）&lt;/h4&gt;
&lt;p&gt;Garbage first是目前垃圾收集器理论发展的最前沿成果，相比于CMS收集器，G1最突出的两个改进为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于标记整理算法，不会产生内存碎片。&lt;/li&gt;
&lt;li&gt;可以非常精准的控制停顿时间，在不牺牲吞吐量的前提下，实现低停顿回收。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;G1避免全区域的垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。&lt;/p&gt;
&lt;p&gt;区域划分和优先级区域回收机制，确保了G1可以在有限的时间内获得最高的垃圾收集效率。&lt;/p&gt;
">JVM详解</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java8-xin-te-xing-streamandcompletablefuture/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java8新特性，主要是Stream和CompletableFuture的常用例子&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/mountain-477832_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;stream&#34;&gt;Stream&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;// 获取某个属性的和
System.out.println(personPojos.stream().mapToInt(PersonPojo::getCount).sum());
// 最大值
System.out.println(personPojos.stream().mapToInt(PersonPojo::getCount).max());
// 最小值
System.out.println(personPojos.stream().mapToInt(PersonPojo::getCount).min());
// 平均值
System.out.println(personPojos.stream().mapToInt(PersonPojo::getCount).average());

// 获取某个属性值最大的集合
Optional&amp;lt;PersonPojo&amp;gt; couponConfigOptional = personPojos.stream().
        filter(Objects::nonNull).
        filter(personPojo -&amp;gt; StringUtils.isNotEmpty(personPojo.getEndTime())).
        max(Comparator.comparing(PersonPojo::getEndTime));
couponConfigOptional.ifPresent(personPojo -&amp;gt; System.out.println(JSONObject.toJSONString(personPojo)));


// 以对象的某个属性分组
Map&amp;lt;String, List&amp;lt;PersonPojo&amp;gt;&amp;gt; resultMap = personPojos.stream().collect(Collectors.groupingBy(PersonPojo::getName));
System.out.println(JSONObject.toJSONString(resultMap));

// 以对象某个属性分组，同时只取列表中的第一条数据
Map&amp;lt;String, PersonPojo&amp;gt; resultMap = personPojos.stream().collect(Collectors.groupingBy(PersonPojo::getName,Collectors.collectingAndThen(Collectors.toList(), value-&amp;gt;value.get(0)))))));
System.out.println(JSONObject.toJSONString(resultMap));

// 以对象的某个属性分组，并只汇总某一个属性字段
Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; map = personPojos.stream().collect(Collectors.groupingBy(PersonPojo::getId, Collectors.mapping(PersonPojo::getName, Collectors.toList())));
System.out.println(JSONObject.toJSONString(map));

// 过滤不包含某个对象
List&amp;lt;PersonPojo&amp;gt; filters = personPojos.stream().filter(personPojo-&amp;gt;!personPojos.contains(personPojo)).collect(Collectors.toList());
System.out.println(JSONObject.toJSONString(filters));

// 移除不在有效期内的数据
long currentTime = System.currentTimeMillis();
personPojos.removeIf(personPojo -&amp;gt; currentTime &amp;lt; personPojo.getStartTime().getTime() || currentTime &amp;gt; personPojo.getEndTime().getTime());

// 获取某个字段作为新的list
List&amp;lt;String&amp;gt; names =personPojos.stream().map(PersonPojo::getName).collect(Collectors.toList());
System.out.println(JSONObject.toJSONString(names));

// 获取某个字段作为新的list，去重
List&amp;lt;String&amp;gt; distinctNames =personPojos.stream().map(PersonPojo::getName).distinct().collect(Collectors.toList());
System.out.println(JSONObject.toJSONString(distinctNames));

// 判断对象组中是否存在包含指定值的对象
boolean match = personPojos.stream().anyMatch(personPojo -&amp;gt; &amp;quot;zhangsan&amp;quot;.equals(personPojo.getName()));
System.out.println(match);
// 判断对象组是否都是包含指定值的对象
boolean match2 = personPojos.stream().allMatch(personPojo -&amp;gt; &amp;quot;zhangsan&amp;quot;.equals(personPojo.getName()));
System.out.println(match2);

//返回 对象集合以类属性一升序排序
list.stream().sorted(Comparator.comparing(类::属性一));

//返回 对象集合以类属性一降序排序 注意两种写法
list.stream().sorted(Comparator.comparing(类::属性一).reversed());//先以属性一升序,结果进行属性一降序
list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder()));//以属性一降序

//返回 对象集合以类属性一升序 属性二升序
list.stream().sorted(Comparator.comparing(类::属性一).thenComparing(类::属性二));

//返回 对象集合以类属性一降序 属性二升序 注意两种写法
//先以属性一升序,升序结果进行属性一降序,再进行属性二升序
list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二));
//先以属性一降序,再进行属性二升序
list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder()).thenComparing(类::属性二));

//返回 对象集合以类属性一降序 属性二降序 注意两种写法
//先以属性一升序,升序结果进行属性一降序,再进行属性二降序
list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二,Comparator.reverseOrder()));
//先以属性一降序,再进行属性二降序
list.stream().sorted(Comparator.comparing(类::属性一,Comparator.reverseOrder()).thenComparing(类::属性二,Comparator.reverseOrder()));

//返回 对象集合以类属性一升序 属性二降序 注意两种写法
//先以属性一升序,升序结果进行属性一降序,再进行属性二升序,结果进行属性一降序属性二降序
list.stream().sorted(Comparator.comparing(类::属性一).reversed().thenComparing(类::属性二).reversed());
//先以属性一升序,再进行属性二降序
list.stream().sorted(Comparator.comparing(类::属性一).thenComparing(类::属性二,Comparator.reverseOrder()));

// 多属性分组
Map&amp;lt;String, Map&amp;lt;String, List&amp;lt;PersonPojo&amp;gt;&amp;gt;&amp;gt; mapMap = personPojos.stream()
        .collect(Collectors.groupingBy(PersonPojo::getId, Collectors.groupingBy(PersonPojo::getName)));
System.out.println(JSONObject.toJSONString(mapMap));

// 多个属性合成一个属性
Map&amp;lt;String, List&amp;lt;PersonPojo&amp;gt;&amp;gt; map = personPojos.stream().collect(Collectors.groupingBy(Test5::fetchGroupKey));
System.out.println(JSONObject.toJSONString(map));
private static String fetchGroupKey(PersonPojo p) {
    return p.getId() + &amp;quot;_&amp;quot; + p.getName();
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;completablefuture&#34;&gt;CompletableFuture&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;package com.philosopherzb.demo.test;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.ThreadLocalRandom;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

/**
 * @author philosopherZB
 * @date 2021/9/28
 */
public class Test10 {
    public static void main(String[] args) {
//        Test10.testThenAccept();
//        Test10.testThenRun();
//        Test10.testThenApply();
//        Test10.testThenCombine();
//        Test10.testThenCompose();
//        Test10.testApplyToEither();
//        Test10.testExceptionally();
//        Test10.testHandle();
        Test10.testAllOf();
//        Test10.testGet();
    }

    /**
     * 功能: 当前任务正常完成后执行，且当前任务的返回值可作为下个任务的入参；thenAccept本身并没有返回值
     * 样例: 接受第一个任务执行结果的字符串，并将其与第二个任务的字符串进行拼接操作
     */
    private static void testThenAccept() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;first&amp;quot;);
        first.thenAccept(f -&amp;gt; {
            System.out.println(&amp;quot;accept firstFuture result: &amp;quot; + f);
            System.out.println(&amp;quot;Splicing result: &amp;quot; + f + &amp;quot;second&amp;quot;);
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 当前任务正常完成后执行；thenRun本身并没有返回值
     * 样例: 异步顺序执行
     */
    private static void testThenRun() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; {
            System.out.println(&amp;quot;first&amp;quot;);
            return &amp;quot;first&amp;quot;;
        });
        first.thenRun(() -&amp;gt; System.out.println(&amp;quot;result: &amp;quot; + &amp;quot;second&amp;quot;)).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 当前任务正常完成后执行，且当前任务的返回值可作为下个任务的入参；thenApply本身有返回值
     * 样例: 接受第一个任务执行结果的字符串，并将其与第二个任务的字符串进行拼接操作，最后将结果与第三个任务的字符串拼接（多个任务串行）
     */
    private static void testThenApply() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;first&amp;quot;);
        CompletableFuture&amp;lt;String&amp;gt; second = first.thenApply(f -&amp;gt; {
            System.out.println(&amp;quot;second accept firstFuture result: &amp;quot; + f);
            System.out.println(&amp;quot;second Splicing result: &amp;quot; + f + &amp;quot;second&amp;quot;);
            return f + &amp;quot;second&amp;quot;;
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
        second.thenApply(s -&amp;gt; {
            System.out.println(&amp;quot;second.thenApply accept firstFuture result: &amp;quot; + s);
            System.out.println(&amp;quot;second.thenApply Splicing result: &amp;quot; + s + &amp;quot;third&amp;quot;);
            return s + &amp;quot;third&amp;quot;;
        }).whenComplete((r, throwable) -&amp;gt; {
            System.out.println(&amp;quot;third result: &amp;quot; + r);
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 处理两个CompletionStage的结果并进行返回；thenCombine 本身有返回值
     * 样例: 拼接字符串
     */
    private static void testThenCombine() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;first&amp;quot;);
        CompletableFuture&amp;lt;String&amp;gt; second = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;second&amp;quot;);
        // 有返回值
        first.thenCombine(second, (f, s) -&amp;gt; f + s).whenComplete((r, throwable) -&amp;gt; {
            System.out.println(&amp;quot;thenCombine result: &amp;quot; + r);
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
        // 无返回值
        first.thenAcceptBoth(second, (f, s) -&amp;gt; {
            System.out.println(&amp;quot;thenAcceptBoth result: &amp;quot; + f + s);
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
        // 无返回值, 在两个任务执行后执行
        first.runAfterBoth(second, () -&amp;gt; {
            System.out.println(&amp;quot;runAfterBoth result: &amp;quot;);
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 处理两个CompletionStage的结果并进行返回, 与thenApply类似，不过lambda接受的是一个CompletableFuture；thenCompose 本身有返回值
     * 样例: 拼接字符串
     */
    private static void testThenCompose() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;first&amp;quot;);
        CompletableFuture&amp;lt;String&amp;gt; second = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;second&amp;quot;);
        // 有返回值
        first.thenCompose(f -&amp;gt; second.thenApply(s -&amp;gt; f + s)).whenComplete((r, throwable) -&amp;gt; {
            System.out.println(&amp;quot;thenCompose result: &amp;quot; + r);
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 运行两个CompletionStage，并将最先处理结束的结果返回；applyToEither 本身有返回值
     * 样例: 返回最快处理结果
     */
    private static void testApplyToEither() {
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; {
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return &amp;quot;first-sleep-1000&amp;quot;;
        });
        CompletableFuture&amp;lt;String&amp;gt; second = CompletableFuture.supplyAsync(() -&amp;gt; {
            try {
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return &amp;quot;second-sleep-2000&amp;quot;;
        });
        // 获取一下返回值，否则以下代码不会执行
        System.out.println(&amp;quot;=====&amp;gt;&amp;quot; + second.join());
        // 有返回值
        CompletableFuture&amp;lt;String&amp;gt; third = first.applyToEither(second, s -&amp;gt; s).whenComplete((r, throwable) -&amp;gt; {
            System.out.println(&amp;quot;applyToEither result: &amp;quot; + r);
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
        // 无返回值
        first.acceptEither(second, s -&amp;gt; {
            System.out.println(&amp;quot;acceptEither result: &amp;quot; + s);
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
        // 无返回值, 在两个任务执行后执行
        first.runAfterEither(second, () -&amp;gt; {
            System.out.println(&amp;quot;runAfterEither result: &amp;quot;);
        }).whenComplete((aVoid, throwable) -&amp;gt; {
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        });
    }

    /**
     * 功能: 处理运行时异常，并进行额外的补偿操作（类似于try catch）；exceptionally 本身有返回值
     * 样例: 处理异常
     */
    private static void testExceptionally() {
        // 发生异常，thenApply不会执行（thenApply必须在程序正常运行后才会执行）
        CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;result: &amp;quot; + (3 / 0))
                .thenApply(s -&amp;gt; {
                    System.out.println(&amp;quot;first not running: &amp;quot; + s);
                    return s;
                })
                .exceptionally(throwable -&amp;gt; {
                    System.out.println(&amp;quot;first e: &amp;quot; + throwable.getLocalizedMessage());
                    return &amp;quot;first occur exception&amp;quot;;
                })
                .whenComplete((r, throwable) -&amp;gt; {
                    System.out.println(&amp;quot;first exceptionally result: &amp;quot; + r);
                    if (throwable != null) {
                        System.out.println(throwable.getLocalizedMessage());
                    }
                });
        // 正常运行，thenApply执行
        CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;result: &amp;quot; + (3 / 1))
                .thenApply(s -&amp;gt; {
                    System.out.println(&amp;quot;second running: &amp;quot; + s);
                    return s;
                })
                .exceptionally(throwable -&amp;gt; {
                    System.out.println(&amp;quot;second e: &amp;quot; + throwable.getLocalizedMessage());
                    return &amp;quot;second occur exception&amp;quot;;
                })
                .whenComplete((r, throwable) -&amp;gt; {
                    System.out.println(&amp;quot;second exceptionally result: &amp;quot; + r);
                    if (throwable != null) {
                        System.out.println(throwable.getLocalizedMessage());
                    }
                });
    }

    /**
     * 功能: handle类似于whenComplete，区别在于：handle 有返回值， whenComplete 无返回值
     * 样例: 打印返回值
     */
    private static void testHandle() {
        // 发生异常，thenApply不会执行（thenApply必须在程序正常运行后才会执行）
        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;result: &amp;quot; + (3 / 0))
                .thenApply(s -&amp;gt; {
                    System.out.println(&amp;quot;first not running: &amp;quot; + s);
                    return s;
                })
                .exceptionally(throwable -&amp;gt; {
                    System.out.println(&amp;quot;first e: &amp;quot; + throwable.getLocalizedMessage());
                    return &amp;quot;first occur exception&amp;quot;;
                })
                .handle((r, throwable) -&amp;gt; {
                    System.out.println(&amp;quot;first handle result: &amp;quot; + r);
                    if (throwable != null) {
                        System.out.println(throwable.getLocalizedMessage());
                    }
                    return r;
                });
        // 正常运行，thenApply执行
        CompletableFuture&amp;lt;String&amp;gt; second = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;result: &amp;quot; + (3 / 1))
                .thenApply(s -&amp;gt; {
                    System.out.println(&amp;quot;second running: &amp;quot; + s);
                    return s;
                })
                .exceptionally(throwable -&amp;gt; {
                    System.out.println(&amp;quot;second e: &amp;quot; + throwable.getLocalizedMessage());
                    return &amp;quot;second occur exception&amp;quot;;
                })
                .handle((r, throwable) -&amp;gt; {
                    System.out.println(&amp;quot;second handle result: &amp;quot; + r);
                    if (throwable != null) {
                        System.out.println(throwable.getLocalizedMessage());
                    }
                    return r;
                });

        System.out.println(&amp;quot;join result: &amp;quot; + first.join());
        System.out.println(&amp;quot;join result: &amp;quot; + second.join());
    }

    /**
     * 功能: 所有任务完成后执行:allOf; 任意任务完成后执行：anyOf
     * 样例: 异步查询三个任务信息并返回
     */
    private static void testAllOf() {
        ExecutorService executorService = Executors.newFixedThreadPool(3);
        long start = System.currentTimeMillis();

        CompletableFuture&amp;lt;String&amp;gt; first = CompletableFuture.supplyAsync(() -&amp;gt; {
            try {
                Thread.sleep(1000 + ThreadLocalRandom.current().nextInt(1000));
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return &amp;quot;first&amp;quot;;
        }, executorService);
        CompletableFuture&amp;lt;String&amp;gt; second = CompletableFuture.supplyAsync(() -&amp;gt; {
            try {
                Thread.sleep(1000 + ThreadLocalRandom.current().nextInt(1000));
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return &amp;quot;second&amp;quot;;
        }, executorService);
        CompletableFuture&amp;lt;String&amp;gt; third = CompletableFuture.supplyAsync(() -&amp;gt; {
            try {
                Thread.sleep(1000 + ThreadLocalRandom.current().nextInt(1000));
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return &amp;quot;third&amp;quot;;
        }, executorService);
        // 所有任务完成后执行
        CompletableFuture.allOf(first, second, third).join();
        System.out.println(first.join() + second.join() + third.join());
        System.out.println(System.currentTimeMillis() - start);

        // 任意任务完成后执行
        CompletableFuture.anyOf(first, second, third).join();
        System.out.println(first.join() + second.join() + third.join());
        System.out.println(System.currentTimeMillis() - start);
    }

    /**
     * 获取返回值
     */
    private static void testGet() {
        CompletableFuture cf = CompletableFuture.supplyAsync(() -&amp;gt; &amp;quot;content&amp;quot;).whenComplete(((result, throwable) -&amp;gt; {
            System.out.println(&amp;quot;result: &amp;quot; + result);
            if (throwable != null) {
                System.out.println(throwable.getLocalizedMessage());
            }
        }));
        try {
            System.out.println(&amp;quot;cf get: &amp;quot; + cf.get());
            System.out.println(&amp;quot;cf getWithTimeOut: &amp;quot; + cf.get(1, TimeUnit.SECONDS));
            System.out.println(&amp;quot;cf join: &amp;quot; + cf.join());
        } catch (InterruptedException | ExecutionException | TimeoutException e) {
            e.printStackTrace();
        }

    }
}

&lt;/code&gt;&lt;/pre&gt;
">Java8新特性Stream&CompletableFuture</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/arraylist-yuan-ma-jie-xi-jdk8/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中的ArrayList的源码以及其中如何进行扩容的逻辑分析（jdk8）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/road-1072821_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;源码来自于jdk8&#34;&gt;源码来自于JDK8&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;package java.util;

import java.util.function.Consumer;
import java.util.function.Predicate;
import java.util.function.UnaryOperator;
import sun.misc.SharedSecrets;

//其中实现了RandomAccess接口表示支持随机访问
public class ArrayList&amp;lt;E&amp;gt; extends AbstractList&amp;lt;E&amp;gt;
        implements List&amp;lt;E&amp;gt;, RandomAccess, Cloneable, java.io.Serializable
{
    //序列号
    private static final long serialVersionUID = 8683452581122892189L;

    /**
     * 默认初始容量
     */
    private static final int DEFAULT_CAPACITY = 10;

    /**
     * 共享的空数组实例（用于空实例）
     * 当ArrayList(int initialCapacity)，ArrayList(Collection&amp;lt;? extends E&amp;gt; c)中的容量等于0的时候使用
     */
    private static final Object[] EMPTY_ELEMENTDATA = {};

    /**
     * 共享的空数组实例（用于默认大小的空实例）
     * 将其与EMPTY_ELEMENTDATA区分开来，主要是为了知道第一次添加元素的时候需要扩容多少
     * 用于ArrayList()构造器
     */
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};

    /**
     * ArrayList保存有序元素的数组
     * ArraylList容量为数组容量
     * 任何空数组都使用 elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA
     * 当第一次添加元素的时候其容量将会扩容至 DEFAULT_CAPACITY（10）
     */
    transient Object[] elementData; // non-private to simplify nested class access

    /**
     * ArrayList的大小（包含元素的数量）
     * @serial
     */
    private int size;

    /**
     * 带指定容量参数的构造器，如果元素数量较大的话，可以使用此构造器，防止频繁扩容造成的性能损失
     */
    public ArrayList(int initialCapacity) {
        //如果传入值大于0，则创建一个该容量大小的数组。
        if (initialCapacity &amp;gt; 0) {
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            //否则如果传入值等于0，则创建默认空数组
            this.elementData = EMPTY_ELEMENTDATA;
        } else {
            //如果小于0则抛出异常
            throw new IllegalArgumentException(&amp;quot;Illegal Capacity: &amp;quot;+
                    initialCapacity);
        }
    }

    /**
     * 默认构造函数，其初始容量为10（注意，这里一开始其实是一个空数组，只是当add时才会进行扩容至10的操作，一定程度上减小了内存消耗。）
     */
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }

    /**
     * 构造一个包含指定集合元素的列表，元素顺序由集合的迭代器所返回。
     */
    public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) {
        //集合转数组
        elementData = c.toArray();
        //指定集合含有元素
        if ((size = elementData.length) != 0) {
            // c.toArray可能不会返回Object[] (see 6260652)
            //使用反射进行运行时判断elementData是否属于Object[]
            if (elementData.getClass() != Object[].class)
                //拷贝数组
                elementData = Arrays.copyOf(elementData, size, Object[].class);
        } else {
            // 由空数组代替
            this.elementData = EMPTY_ELEMENTDATA;
        }
    }

    /**
     * 修改ArrayList容量为list的当前大小
     * 一个应用可以使用此操作来最小化一个ArrayList的存储
     */
    public void trimToSize() {
        modCount++;
        //如果当前数组元素个数小于数组容量
        if (size &amp;lt; elementData.length) {
            //没有元素返回空数组，否则返回元素个数的数组。
            elementData = (size == 0)
                    ? EMPTY_ELEMENTDATA
                    : Arrays.copyOf(elementData, size);
        }
    }

    /**
     * 如果有必要去增加ArrayList的容量，请确保它至少可以容纳由最小容量参数指定的元素数量
     * @param   minCapacity   所需的最小容量
     */
    public void ensureCapacity(int minCapacity) {
        //默认最小容量，空数组以及默认大小10
        int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)
                // any size if not default element table
                ? 0
                // larger than default for default empty table. It&#39;s already
                // supposed to be at default size.
                : DEFAULT_CAPACITY;

        //如果传入容量大于最小容量，则进行扩容
        if (minCapacity &amp;gt; minExpand) {
            ensureExplicitCapacity(minCapacity);
        }
    }

    private static int calculateCapacity(Object[] elementData, int minCapacity) {
        //如果elementData为默认空数组，则比较传入值与默认值（10），返回两者中的较大值
        //elementData为默认空数组指的是通过ArrayList()这个构造器创建的ArrayList对象
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        //返回传入值
        return minCapacity;
    }

    private void ensureCapacityInternal(int minCapacity) {
        //先通过calculateCapacity方法计算最终容量，以确认实际容量
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }

    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        //如果最终确认容量大于数组容量，则进行grow()扩容
        if (minCapacity - elementData.length &amp;gt; 0)
            grow(minCapacity);
    }

    /**
     * 可分配数组最大大小
     */
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    /**
     * 增加ArrayList的容量，以确保它至少可以容纳由最小容量参数指定的元素数量
     * @param minCapacity 所需的最小容量
     */
    private void grow(int minCapacity) {
        // overflow-conscious code
        //oldCapacity表示旧容量
        int oldCapacity = elementData.length;
        //newCapacity表示新容量，计算规则为旧容量+旧容量的0.5，即旧容量的1.5倍。如果超过int的最大值会返回一个负数。
        //oldCapacity &amp;gt;&amp;gt; 1表示右移一位，对应除以2的1次方。
        int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1);
        //如果新容量小于最小容量，则将最小容量赋值给新容量(有时手动扩容可能也会返回&amp;lt;0，对应方法为ensureCapacity())
        if (newCapacity - minCapacity &amp;lt; 0)
            newCapacity = minCapacity;
        //如果新容量大于MAX_ARRAY_SIZE，则执行hugeCapacity(minCapacity)返回对应值
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        //复制旧数组到新容量数组中，完成扩容操作
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

    private static int hugeCapacity(int minCapacity) {
        //如果最小容量超过了int的最大值，minCapacity会是一个负数，此时抛出内存溢出错误
        if (minCapacity &amp;lt; 0) // overflow
            throw new OutOfMemoryError();
        //比较最小容量是否大于MAX_ARRAY_SIZE，如果是则返回Integer.MAX_VALUE，否则返回MAX_ARRAY_SIZE
        return (minCapacity &amp;gt; MAX_ARRAY_SIZE) ?
                Integer.MAX_VALUE :
                MAX_ARRAY_SIZE;
    }

    /**
     * 返回列表元素数
     */
    public int size() {
        return size;
    }

    /**
     * 如果列表不包含元素，返回true
     */
    public boolean isEmpty() {
        return size == 0;
    }

    /**
     * 如果列表包含指定元素，返回true
     */
    public boolean contains(Object o) {
        //返回此列表中指定元素第一次出现的索引，如果列表中不包含指定元素，则为-1
        return indexOf(o) &amp;gt;= 0;
    }

    /**
     * 返回此列表中指定元素第一次出现的索引，如果列表中不包含指定元素，则为-1
     */
    public int indexOf(Object o) {
        if (o == null) {
            for (int i = 0; i &amp;lt; size; i++)
                if (elementData[i]==null)
                    return i;
        } else {
            for (int i = 0; i &amp;lt; size; i++)
                if (o.equals(elementData[i]))
                    return i;
        }
        return -1;
    }

    /**
     * 返回此列表中指定元素最后一次出现的索引，如果列表中不包含指定元素，则为-1
     */
    public int lastIndexOf(Object o) {
        if (o == null) {
            for (int i = size-1; i &amp;gt;= 0; i--)
                if (elementData[i]==null)
                    return i;
        } else {
            for (int i = size-1; i &amp;gt;= 0; i--)
                if (o.equals(elementData[i]))
                    return i;
        }
        return -1;
    }

    /**
     * 返回ArrayList实例的一个浅拷贝，列表中的元素不会被拷贝
     */
    public Object clone() {
        try {
            ArrayList&amp;lt;?&amp;gt; v = (ArrayList&amp;lt;?&amp;gt;) super.clone();
            v.elementData = Arrays.copyOf(elementData, size);
            v.modCount = 0;
            return v;
        } catch (CloneNotSupportedException e) {
            // this shouldn&#39;t happen, since we are Cloneable
            throw new InternalError(e);
        }
    }

    /**
     * 以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。
     * 返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。
     * 因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。
     */
    public Object[] toArray() {
        return Arrays.copyOf(elementData, size);
    }

    /**
     * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）;
     * 返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。
     * 否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。
     * 如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。
     *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。）
     */
    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
    public &amp;lt;T&amp;gt; T[] toArray(T[] a) {
        if (a.length &amp;lt; size)
            //创建一个新的运行时类型数组，内容为ArrayList数组的
            return (T[]) Arrays.copyOf(elementData, size, a.getClass());
        System.arraycopy(elementData, 0, a, 0, size);
        if (a.length &amp;gt; size)
            a[size] = null;
        return a;
    }

    // 位置访问操作

    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
    E elementData(int index) {
        return (E) elementData[index];
    }

    /**
     * 返回此列表中指定位置的元素
     */
    public E get(int index) {
        //检查索引是否越界
        rangeCheck(index);

        return elementData(index);
    }

    /**
     * 用指定元素替换列表中的指定位置的元素
     */
    public E set(int index, E element) {
        //检查索引是否越界
        rangeCheck(index);

        E oldValue = elementData(index);
        elementData[index] = element;
        return oldValue;
    }

    /**
     * 将指定元素追加到数组末尾
     */
    public boolean add(E e) {
        //添加之前先确认是否需要扩容
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        //新加入的元素是添加在了数组的末尾，随后数组size自增。
        elementData[size++] = e;
        return true;
    }

    /**
     * 插入指定元素到此列表中的指定位置
     * 先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大；
     * 再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。
     */
    public void add(int index, E element) {
        rangeCheckForAdd(index);

        ensureCapacityInternal(size + 1);  // Increments modCount!!
        //自己复制自己
        System.arraycopy(elementData, index, elementData, index + 1,
                size - index);
        elementData[index] = element;
        size++;
    }

    /**
     * 将列表中指定位置的元素移除，后续所有元素移到左端（从他们的索引中减去一个）
     */
    public E remove(int index) {
        rangeCheck(index);

        modCount++;
        E oldValue = elementData(index);

        int numMoved = size - index - 1;
        if (numMoved &amp;gt; 0)
            System.arraycopy(elementData, index+1, elementData, index,
                    numMoved);
        elementData[--size] = null; //  清理工作交给GC

        return oldValue;
    }

    /**
     * 从列表中移除第一次出现的指定元素，如果不存在，则不更改
     */
    public boolean remove(Object o) {
        if (o == null) {
            for (int index = 0; index &amp;lt; size; index++)
                if (elementData[index] == null) {
                    fastRemove(index);
                    return true;
                }
        } else {
            for (int index = 0; index &amp;lt; size; index++)
                if (o.equals(elementData[index])) {
                    fastRemove(index);
                    return true;
                }
        }
        return false;
    }

    /*
     * Private remove method that skips bounds checking and does not
     * return the value removed.
     */
    private void fastRemove(int index) {
        modCount++;
        int numMoved = size - index - 1;
        if (numMoved &amp;gt; 0)
            System.arraycopy(elementData, index+1, elementData, index,
                    numMoved);
        elementData[--size] = null; // clear to let GC do its work
    }

    /**
     * 移除列表中的所有元素，之后会返回一个空数组
     */
    public void clear() {
        modCount++;

        // clear to let GC do its work
        for (int i = 0; i &amp;lt; size; i++)
            elementData[i] = null;

        size = 0;
    }

    /**
     * 将指定集合中的元素以Iterator返回的顺序，追加到列表末尾
     */
    public boolean addAll(Collection&amp;lt;? extends E&amp;gt; c) {
        Object[] a = c.toArray();
        int numNew = a.length;
        ensureCapacityInternal(size + numNew);  // Increments modCount
        System.arraycopy(a, 0, elementData, size, numNew);
        size += numNew;
        return numNew != 0;
    }

    /**
     * 将指定集合中的元素以Iterator返回的顺序，插入到指定位置
     */
    public boolean addAll(int index, Collection&amp;lt;? extends E&amp;gt; c) {
        rangeCheckForAdd(index);

        Object[] a = c.toArray();
        int numNew = a.length;
        ensureCapacityInternal(size + numNew);  // Increments modCount

        int numMoved = size - index;
        if (numMoved &amp;gt; 0)
            System.arraycopy(elementData, index, elementData, index + numNew,
                    numMoved);

        System.arraycopy(a, 0, elementData, index, numNew);
        size += numNew;
        return numNew != 0;
    }

    /**
     * 移除[fromIndex,toIndex)之间的元素，后续元素移到左端
     */
    protected void removeRange(int fromIndex, int toIndex) {
        modCount++;
        int numMoved = size - toIndex;
        System.arraycopy(elementData, toIndex, elementData, fromIndex,
                numMoved);

        // clear to let GC do its work
        int newSize = size - (toIndex-fromIndex);
        for (int i = newSize; i &amp;lt; size; i++) {
            elementData[i] = null;
        }
        size = newSize;
    }

    /**
     *检查给定索引是否在界限内。
     */
    private void rangeCheck(int index) {
        if (index &amp;gt;= size)
            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));
    }

    /**
     * add and addAll使用的rangeCheck
     */
    private void rangeCheckForAdd(int index) {
        if (index &amp;gt; size || index &amp;lt; 0)
            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));
    }

    /**
     * 返回 an IndexOutOfBoundsException 的细节信息
     */
    private String outOfBoundsMsg(int index) {
        return &amp;quot;Index: &amp;quot;+index+&amp;quot;, Size: &amp;quot;+size;
    }

    /**
     * 从列表中移除指定集合包含的所有元素
     */
    public boolean removeAll(Collection&amp;lt;?&amp;gt; c) {
        Objects.requireNonNull(c);
        return batchRemove(c, false);
    }

    /**
     * 保留此列表中指定集合的所有元素
     */
    public boolean retainAll(Collection&amp;lt;?&amp;gt; c) {
        Objects.requireNonNull(c);
        return batchRemove(c, true);
    }

    //批量移除
    private boolean batchRemove(Collection&amp;lt;?&amp;gt; c, boolean complement) {
        final Object[] elementData = this.elementData;
        int r = 0, w = 0;
        boolean modified = false;
        try {
            for (; r &amp;lt; size; r++)
                if (c.contains(elementData[r]) == complement)
                    elementData[w++] = elementData[r];
        } finally {
            // Preserve behavioral compatibility with AbstractCollection,
            // even if c.contains() throws.
            if (r != size) {
                System.arraycopy(elementData, r,
                        elementData, w,
                        size - r);
                w += size - r;
            }
            if (w != size) {
                // clear to let GC do its work
                for (int i = w; i &amp;lt; size; i++)
                    elementData[i] = null;
                modCount += size - w;
                size = w;
                modified = true;
            }
        }
        return modified;
    }

    /**
     * 保存ArrayList状态到一个流中（即序列化）
     */
    private void writeObject(java.io.ObjectOutputStream s)
            throws java.io.IOException{
        // Write out element count, and any hidden stuff
        int expectedModCount = modCount;
        s.defaultWriteObject();

        // Write out size as capacity for behavioural compatibility with clone()
        s.writeInt(size);

        // Write out all elements in the proper order.
        for (int i=0; i&amp;lt;size; i++) {
            s.writeObject(elementData[i]);
        }

        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }
    }

    /**
     * 从一个流中读取ArrayList（即反序列化）
     */
    private void readObject(java.io.ObjectInputStream s)
            throws java.io.IOException, ClassNotFoundException {
        elementData = EMPTY_ELEMENTDATA;

        // Read in size, and any hidden stuff
        s.defaultReadObject();

        // Read in capacity
        s.readInt(); // ignored

        if (size &amp;gt; 0) {
            // be like clone(), allocate array based upon size not capacity
            int capacity = calculateCapacity(elementData, size);
            SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity);
            ensureCapacityInternal(size);

            Object[] a = elementData;
            // Read in all elements in the proper order.
            for (int i=0; i&amp;lt;size; i++) {
                a[i] = s.readObject();
            }
        }
    }

    /**
     *  从列表中的指定位置开始，返回之后所有元素的列表迭代器（按正确的顺序）
     *  指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。
     *  返回的列表迭代器是fail-fast 。
     */
    public ListIterator&amp;lt;E&amp;gt; listIterator(int index) {
        if (index &amp;lt; 0 || index &amp;gt; size)
            throw new IndexOutOfBoundsException(&amp;quot;Index: &amp;quot;+index);
        return new ListItr(index);
    }

    /**
     * 返回列表中的包含所有元素的列表迭代器（按正确的顺序）。
     * 返回的列表迭代器是fail-fast 。
     */
    public ListIterator&amp;lt;E&amp;gt; listIterator() {
        return new ListItr(0);
    }

    /**
     * 以正确的顺序返回列表中的包含所有元素的迭代器。
     * 返回的迭代器是fail-fast 。
     */
    public Iterator&amp;lt;E&amp;gt; iterator() {
        return new Itr();
    }

    @Override
    public void forEach(Consumer&amp;lt;? super E&amp;gt; action) {
        Objects.requireNonNull(action);
        final int expectedModCount = modCount;
        @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
        final E[] elementData = (E[]) this.elementData;
        final int size = this.size;
        for (int i=0; modCount == expectedModCount &amp;amp;&amp;amp; i &amp;lt; size; i++) {
            action.accept(elementData[i]);
        }
        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }
    }


    @Override
    public boolean removeIf(Predicate&amp;lt;? super E&amp;gt; filter) {
        Objects.requireNonNull(filter);
        // figure out which elements are to be removed
        // any exception thrown from the filter predicate at this stage
        // will leave the collection unmodified
        int removeCount = 0;
        final BitSet removeSet = new BitSet(size);
        final int expectedModCount = modCount;
        final int size = this.size;
        for (int i=0; modCount == expectedModCount &amp;amp;&amp;amp; i &amp;lt; size; i++) {
            @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
            final E element = (E) elementData[i];
            if (filter.test(element)) {
                removeSet.set(i);
                removeCount++;
            }
        }
        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }

        // shift surviving elements left over the spaces left by removed elements
        final boolean anyToRemove = removeCount &amp;gt; 0;
        if (anyToRemove) {
            final int newSize = size - removeCount;
            for (int i=0, j=0; (i &amp;lt; size) &amp;amp;&amp;amp; (j &amp;lt; newSize); i++, j++) {
                i = removeSet.nextClearBit(i);
                elementData[j] = elementData[i];
            }
            for (int k=newSize; k &amp;lt; size; k++) {
                elementData[k] = null;  // Let gc do its work
            }
            this.size = newSize;
            if (modCount != expectedModCount) {
                throw new ConcurrentModificationException();
            }
            modCount++;
        }

        return anyToRemove;
    }

    @Override
    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
    public void replaceAll(UnaryOperator&amp;lt;E&amp;gt; operator) {
        Objects.requireNonNull(operator);
        final int expectedModCount = modCount;
        final int size = this.size;
        for (int i=0; modCount == expectedModCount &amp;amp;&amp;amp; i &amp;lt; size; i++) {
            elementData[i] = operator.apply((E) elementData[i]);
        }
        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }
        modCount++;
    }

    @Override
    @SuppressWarnings(&amp;quot;unchecked&amp;quot;)
    public void sort(Comparator&amp;lt;? super E&amp;gt; c) {
        final int expectedModCount = modCount;
        Arrays.sort((E[]) elementData, 0, size, c);
        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }
        modCount++;
    }
}

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;扩容源码解析jdk8&#34;&gt;扩容源码解析（JDK8）&lt;/h2&gt;
&lt;p&gt;首先我们使用 ArrayList &lt;code&gt;&amp;lt;String&amp;gt;&lt;/code&gt; list = new ArrayList&amp;lt;&amp;gt;(5)创建一个ArrayLsit，这表明创建的ArrayList初始容量为5.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    //默认初始容量10
    private static final int DEFAULT_CAPACITY = 10;
    //一个空的默认对象数组，当ArrayList(int initialCapacity)，ArrayList(Collection&amp;lt;? extends E&amp;gt; c)中的容量等于0的时候使用
    private static final Object[] EMPTY_ELEMENTDATA = {};
    //一个空的默认对象数组，用于ArrayList()构造器
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
    //一个对象数组，transient表示不能序列化
    transient Object[] elementData;
    //数组大小
    private int size;

    //以传入的容量构造一个空的list
    public ArrayList(int initialCapacity) {
        //如果传入值大于0，则创建一个该容量大小的数组。
        if (initialCapacity &amp;gt; 0) {
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            //否则如果传入值等于0，则创建默认空数组
            this.elementData = EMPTY_ELEMENTDATA;
        } else {
            //如果小于0则抛出异常
            throw new IllegalArgumentException(&amp;quot;Illegal Capacity: &amp;quot;+
                    initialCapacity);
        }
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;接着我们使用add方法添加一个字符串到该list中，list.add(&amp;quot;Test&amp;quot;)。进入add源码会发现，真正的扩容是发生在add操作之前的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    //默认添加在数组末尾
    public boolean add(E e) {
        //添加之前先确认是否需要扩容
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        //新加入的元素是添加在了数组的末尾，随后数组size自增。
        elementData[size++] = e;
        return true;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;进入ensureCapacityInternal()方法查看对应源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    private void ensureCapacityInternal(int minCapacity) {
        //先通过calculateCapacity方法计算最终容量，以确认实际容量
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;到这一步，我们需要先进入calculateCapacity()方法看看他是如何计算最后容量的，源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    private static int calculateCapacity(Object[] elementData, int minCapacity) {
        //如果elementData为默认空数组，则比较传入值与默认值（10），返回两者中的较大值
        //elementData为默认空数组指的是通过ArrayList()这个构造器创建的ArrayList对象
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        //返回传入值
        return minCapacity;
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在我们确认了最终容量，那么进入ensureExplicitCapacity，查看源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;
        // overflow-conscious code
        //如果最终确认容量大于数组容量，则进行grow()扩容
        if (minCapacity - elementData.length &amp;gt; 0)
            grow(minCapacity);
    }

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到，只有当最终容量大于数组容量时才会进行扩容。那么以我们上面的例子而言具体分析如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先因为我们创建的时候就赋了初始容量5，所以elementData.length = 5。&lt;/li&gt;
&lt;li&gt;当我们add第一个元素的时候，minCapacity是等于size + 1 = 1的。&lt;/li&gt;
&lt;li&gt;此时minCapacity - elementData.length &amp;gt; 0条件不成立，所以不会进入grow(minCapacity)方法进行扩容。&lt;/li&gt;
&lt;li&gt;以此类推，只有添加到第五个元素的时候，minCapacity = 6 大于 elementData.length = 5，这时就会进入grow(minCapacity)方法进行扩容。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;grow()以及hugeCapacity()源码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    //可分配的最大数组大小
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    //扩容
    private void grow(int minCapacity) {
        // overflow-conscious code
        //oldCapacity表示旧容量
        int oldCapacity = elementData.length;
        //newCapacity表示新容量，计算规则为旧容量+旧容量的0.5，即旧容量的1.5倍。如果超过int的最大值会返回一个负数。
        //oldCapacity &amp;gt;&amp;gt; 1表示右移一位，对应除以2的1次方。
        int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1);
        //如果新容量小于最小容量，则将最小容量赋值给新容量(有时手动扩容可能也会返回&amp;lt;0，对应方法为ensureCapacity())
        if (newCapacity - minCapacity &amp;lt; 0)
            newCapacity = minCapacity;
        //如果新容量大于MAX_ARRAY_SIZE，则执行hugeCapacity(minCapacity)返回对应值
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        //复制旧数组到新容量数组中，完成扩容操作
        elementData = Arrays.copyOf(elementData, newCapacity);
    }

    private static int hugeCapacity(int minCapacity) {
        //如果最小容量超过了int的最大值，minCapacity会是一个负数，此时抛出内存溢出错误
        if (minCapacity &amp;lt; 0) // overflow
            throw new OutOfMemoryError();
        //比较最小容量是否大于MAX_ARRAY_SIZE，如果是则返回Integer.MAX_VALUE，否则返回MAX_ARRAY_SIZE
        return (minCapacity &amp;gt; MAX_ARRAY_SIZE) ?
                Integer.MAX_VALUE :
                MAX_ARRAY_SIZE;
    }

&lt;/code&gt;&lt;/pre&gt;
">ArrayList源码解析(JDK8)</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-zhong-de-suo/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中的锁，包括锁类型，锁升级，锁优化等细节内容。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/railroad-g16c0f522b_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;锁的类型&#34;&gt;锁的类型&lt;/h2&gt;
&lt;h3 id=&#34;乐观锁&#34;&gt;乐观锁&lt;/h3&gt;
&lt;p&gt;乐观锁认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁。但是，在更新的时候会判断一下在此期间别人有没有去修改这个数据，采取写时先读出当前版本号，然后加锁操作（比较上一次的版本号，一致则更新），如果失败则重复读-比较-写操作。&lt;/p&gt;
&lt;p&gt;CAS便是典型的乐观锁机制，其中会使用到sun.misc.Unsafe这个类进行Compare And Swap操作。&lt;/p&gt;
&lt;p&gt;CAS 即比较并交换。是解决多线程并行情况下使用锁造成性能损耗的一种机制，CAS 操作包含三个操作数——内存位置(V)、预期原值(A)和新值(B)。如果内存位置的值(V)与预期原值(A)相匹配，那么处理器会自动将该位置值更新为新值(B)。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置(V)应该包含值(A)。如果包含该值，则将新值(B)放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可”。&lt;/p&gt;
&lt;h3 id=&#34;悲观锁&#34;&gt;悲观锁&lt;/h3&gt;
&lt;p&gt;悲观锁认为写操作更多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以会在每次读写的时候上锁，这样别人想读写这个数据便会block直到获取锁。&lt;/p&gt;
&lt;p&gt;Synchronized便是典型的悲观锁，AQS框架下的锁会先尝试CAS获取锁，获取不到便会转为悲观锁。&lt;/p&gt;
&lt;h2 id=&#34;线程切换及其代价&#34;&gt;线程切换及其代价&lt;/h2&gt;
&lt;h3 id=&#34;线程切换&#34;&gt;线程切换&lt;/h3&gt;
&lt;p&gt;java线程与操作系统上的原生线程是一一映射的。如果需要阻塞或者唤醒一个线程，便需要操作系统的介入，并切换用户态与内核态（这样的切换需要消耗大量的系统资源）。&lt;/p&gt;
&lt;h4 id=&#34;用户态切换到内核态的步骤主要如下&#34;&gt;用户态切换到内核态的步骤主要如下&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;从当前进程的描述符中提取其内核栈的ss0及esp0信息。&lt;/li&gt;
&lt;li&gt;使用ss0和esp0指向的内核栈将当前进程的cs，eip，eflags，ss，esp信息保存起来，这个过程也完成了由用户态到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。&lt;/li&gt;
&lt;li&gt;将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;名词解释如下&#34;&gt;名词解释如下&lt;/h4&gt;
&lt;p&gt;CS：代码段寄存器；存放当前正在运行的程序代码所在段的段基值；联合ip作为cpu指向当前正在执行的指令，不能随便修改。&lt;/p&gt;
&lt;p&gt;DS：数据段寄存器；存放数据段的段基值；定义了一个数据段。&lt;/p&gt;
&lt;p&gt;SS：堆栈段寄存器；存放堆栈段的段基值，联合sp定义一个堆栈值，一旦确定了堆栈地址，将不能随便改变。&lt;/p&gt;
&lt;p&gt;内核态切换到用户态主要使用PSW（Program Status Word，程序状态字，又称状态寄存器），其一般用于反映处理器的状态及某些计算结果以及控制指令的执行：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301001.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;切换的代价&#34;&gt;切换的代价&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果线程切换是一个高频操作，那将耗费很多CPU处理时间（用户态，内核态之间的切换）。&lt;/li&gt;
&lt;li&gt;甚至，如果同步代码块中的内容过于简单，状态切换消耗的时间有可能比用户代码执行的时间还要长。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;java对象结构之对象头&#34;&gt;Java对象结构之对象头&lt;/h2&gt;
&lt;h3 id=&#34;对象头&#34;&gt;对象头&lt;/h3&gt;
&lt;p&gt;对象头（Header）主要包含两部分信息：第一部分用于存储对象自身的运行时数据（如哈希码（HashCode），GC分代年龄，锁状态标志，线程持有的锁，偏向线程ID，偏向时间戳等，这部分数据长度在32位或者64位的虚拟机中分别为32bit以及64bit，官方称之为“Mark Word”）；&lt;/p&gt;
&lt;p&gt;第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机可以通过这个指针来确定该对象属于哪个类的实例（并不是所有的虚拟机实现都需要在对象数据上保留类型指针，即查找对象的元数据信息并不一定要经过对象本身）。&lt;/p&gt;
&lt;p&gt;如果对象是一个Java数组，那么对象头还需要记录该数组长度，因为普通的Java对象可以通过元数据信息确认对象大小，而数组却不行。&lt;/p&gt;
&lt;h3 id=&#34;markword&#34;&gt;MarkWord&lt;/h3&gt;
&lt;p&gt;markword数据的长度在32位和64位（未开启压缩指针）的虚拟机中分别为32bit和64bit，它的最后两位便是锁状态标识位，用来标记当前对象的状态，常用值如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301002.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;32位虚拟机在不同状态下markword的结构图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;java中的锁&#34;&gt;Java中的锁&lt;/h2&gt;
&lt;h3 id=&#34;主流锁图&#34;&gt;主流锁图&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;自旋锁基于cas&#34;&gt;自旋锁（基于CAS）&lt;/h3&gt;
&lt;p&gt;如果持有锁的线程可以在很短的时间内释放锁，那么那些等待锁的线程便不需要进入阻塞挂起状态，而是自旋等待一会儿便可获取到同步资源，从而避免了线程切换的开销，这就是自旋锁。&lt;/p&gt;
&lt;p&gt;自旋锁本身是有缺点的，它不能代替阻塞。&lt;/p&gt;
&lt;p&gt;自旋锁虽然避免了线程切换的开销，但其占据了CPU处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好；反之，则会白白浪费处理器资源。甚至，当线程过多时，还会影响系统的整体性能。&lt;/p&gt;
&lt;p&gt;因此，自旋等待的时间需要有一个限度，如果超过限定次数（默认10次，可以使用-XX:PreBlockSpin来更改）没有获取到锁，则应当挂起线程。&lt;/p&gt;
&lt;p&gt;自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。&lt;/p&gt;
&lt;p&gt;自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。&lt;/p&gt;
&lt;p&gt;如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301005.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;jvm针对当前cpu的负荷情况还做了如下自旋锁优化操作&#34;&gt;JVM针对当前CPU的负荷情况还做了如下自旋锁优化操作：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;如果平均负载小于CPUs则一直自旋&lt;/li&gt;
&lt;li&gt;如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞&lt;/li&gt;
&lt;li&gt;如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞&lt;/li&gt;
&lt;li&gt;如果CPU处于节电模式则停止自旋&lt;/li&gt;
&lt;li&gt;自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）&lt;/li&gt;
&lt;li&gt;自旋时会适当放弃线程优先级之间的差异&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;synchronized无锁偏向锁轻量级锁重量级锁&#34;&gt;Synchronized（无锁，偏向锁，轻量级锁，重量级锁）&lt;/h3&gt;
&lt;h4 id=&#34;synchronized队列&#34;&gt;Synchronized队列&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301006.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;可以看出，synchronized有多个队列，当多个线程一起访问某个对象监视器（monitor，其是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步））的时候，对象监视器会将这些线程存储在不同的容器里。&lt;/p&gt;
&lt;h5 id=&#34;结构概述&#34;&gt;结构概述&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ContentionList：竞争队列，所有请求锁的线程首先会被放入此队列中。&lt;/li&gt;
&lt;li&gt;EntryList：ContentionList中一些有资格获取同步资源的线程将被移动到此队列中。&lt;/li&gt;
&lt;li&gt;WaitSet：调用wait方法被阻塞的线程，放于此处。&lt;/li&gt;
&lt;li&gt;OnDeck：任何时刻，最多只有一个线程正在竞争锁，该线程便是OnDeck。&lt;/li&gt;
&lt;li&gt;Owner：已经获取到锁的线程被称为Owner。&lt;/li&gt;
&lt;li&gt;!Owner：已经释放锁的线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;队列协作过程&#34;&gt;队列协作过程&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;JVM每次都会从队列尾部取出一个线程用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。&lt;/li&gt;
&lt;li&gt;Owner在unlock时，也会将ContentionList中的部分线程迁移到EntryList，并指定EntryList中的某个线程为Ondeck（一般是最先进去的线程）。&lt;/li&gt;
&lt;li&gt;Owner不会直接将锁传递给OnDeck，而是将锁竞争的权利交给OnDeck，OnDeck需要重新去竞争锁。这样虽然牺牲了一些公平性，但能极大的提高系统吞吐量，在JVM中，这种选择行为被称为“竞争切换”。&lt;/li&gt;
&lt;li&gt;OnDeck获取到锁后就会变为Owner，而没有得到锁的则仍然停留在EntryList；如果OnDeck线程被wait阻塞，则会被移动至WaitSet，直到某个时刻被notify或notifyAll唤醒，才能重新进入EntryLIst。&lt;/li&gt;
&lt;li&gt;处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;无锁cas&#34;&gt;无锁（CAS）&lt;/h4&gt;
&lt;p&gt;无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。&lt;/p&gt;
&lt;p&gt;无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。&lt;/p&gt;
&lt;h4 id=&#34;偏向锁&#34;&gt;偏向锁&lt;/h4&gt;
&lt;p&gt;偏向锁是指一段同步代码一直被一个线程所访问，那么这个线程便会自动获取锁，降低了获取锁的代价。&lt;/p&gt;
&lt;p&gt;在运行过程中，不存在多线程竞争，则线程不需要触发同步，此时为了提高线程执行同步代码的效率，便出现了偏向锁。&lt;/p&gt;
&lt;h5 id=&#34;偏向锁执行过程&#34;&gt;偏向锁执行过程&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;访问MarkWord中偏向锁的标识位是否设置为1，锁标识位是否设置为01，确认为可偏向状态。&lt;/li&gt;
&lt;li&gt;如果为可偏向状态，则判断线程id是否指向当前线程，如果是，则进入步骤5，否则进入步骤3。&lt;/li&gt;
&lt;li&gt;如果线程id未指向当前线程，则通过CAS操作竞争锁，如果竞争成功，则将MarkWord中的线程id设置为当前线程id，然后执行步骤5，否则进入步骤4。&lt;/li&gt;
&lt;li&gt;如果CAS获取锁失败，则表示存在锁竞争。当到达全局安全点（safepoint，会导致很短时间的stop-the-world）时，获取偏向锁的线程将被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。&lt;/li&gt;
&lt;li&gt;执行同步代码。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;偏向锁的释放&#34;&gt;偏向锁的释放&lt;/h5&gt;
&lt;p&gt;偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。&lt;/p&gt;
&lt;p&gt;偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。&lt;/p&gt;
&lt;h5 id=&#34;偏向锁适用场景&#34;&gt;偏向锁适用场景&lt;/h5&gt;
&lt;p&gt;始终只有一个线程操作同步资源，也就是锁无竞争状况下使用。一旦有了竞争，偏向锁便会升级为轻量级锁（升级需要撤销偏向锁，这个过程会stop-the-world）。&lt;/p&gt;
&lt;p&gt;如果存在高并发锁竞争，应当禁用偏向锁，这样可以适当提高程序性能。&lt;/p&gt;
&lt;h5 id=&#34;jvm开启关闭偏向锁&#34;&gt;jvm开启/关闭偏向锁&lt;/h5&gt;
&lt;p&gt;开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0&lt;br&gt;
（-XX:BiasedLockingStartupDelay=0的作用是在虚拟机启动后，立即启用偏向锁，如果不设置该参数，默认虚拟会在4秒后，才启动偏向锁。）&lt;/p&gt;
&lt;p&gt;关闭偏向锁：-XX:-UseBiasedLocking&lt;/p&gt;
&lt;h4 id=&#34;轻量级锁&#34;&gt;轻量级锁&lt;/h4&gt;
&lt;p&gt;轻量级锁是由偏向锁升级而来的，当一个线程持有偏向锁执行同步块时，存在另外的线程来竞争锁，这时偏向锁便会升级为轻量级锁。&lt;/p&gt;
&lt;p&gt;轻量级锁执行过程：&lt;/p&gt;
&lt;p&gt;a、在代码进入同步块的时候，如果同步对象状态为无锁状态（锁标识位：01，是否偏向锁标识位：0），虚拟机首先会在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储对象目前的MarkWord的拷贝（官方称之为Displaced Mark Word）。线程堆栈与对象头状态图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301007.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;b、拷贝对象头的MarkWord复制到锁记录中。&lt;/p&gt;
&lt;p&gt;c、拷贝成功后，虚拟机将使用CAS操作尝试将对象的MarkWord更新为指向Lock Record的指针，并将Lock Record中的owner指针指向object mark word，如果更新成功，则执行步骤d，否则执行步骤e。&lt;/p&gt;
&lt;p&gt;d、更新成功后，该线程便拥有了这个对象的锁，此时对象MarkWord中的锁标识位将被设置为‘00’，表示此对象处于轻量级锁定状态。线程堆栈与对象头状态图如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301008.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;e、如果这个更新操作失败了，虚拟机首先会检查对象的MarkWord是否指向当前线程的栈帧，如果是，则表示当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明有多个线程在竞争锁。&lt;/p&gt;
&lt;p&gt;若当前只有一个等待线程，则该线程进行自旋等待，当自旋超过阈值，或者一个线程持有锁，一个在自旋，又有第三个来访问锁时，轻量级锁便会膨胀为重量级锁。&lt;/p&gt;
&lt;p&gt;锁的标识位将被设置为‘10’，MarkWord中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也会进入阻塞状态。&lt;/p&gt;
&lt;h4 id=&#34;整体执行过程&#34;&gt;整体执行过程&lt;/h4&gt;
&lt;h5 id=&#34;锁升级流程图&#34;&gt;锁升级流程图：&lt;/h5&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301009.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;synchronized执行过程&#34;&gt;synchronized执行过程：&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;检测Mark Word中的锁标识是否为可偏向状态（锁标识位：01，是否偏向锁：1），如果是，则为偏向锁。&lt;/li&gt;
&lt;li&gt;如果不是，则检查Mark Word里面的线程id是不是当前线程的ID，如果是，表示当前线程处于偏向锁&lt;/li&gt;
&lt;li&gt;如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1&lt;/li&gt;
&lt;li&gt;如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。&lt;/li&gt;
&lt;li&gt;当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁&lt;/li&gt;
&lt;li&gt;如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。&lt;/li&gt;
&lt;li&gt;如果自旋成功则依然处于轻量级状态。&lt;/li&gt;
&lt;li&gt;如果自旋失败，则升级为重量级锁。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;锁优化&#34;&gt;锁优化&lt;/h3&gt;
&lt;h4 id=&#34;减少锁的时间&#34;&gt;减少锁的时间&lt;/h4&gt;
&lt;p&gt;不需要同步执行的代码，尽量不要放在同步块中，这样可以让锁更快的释放。&lt;/p&gt;
&lt;h4 id=&#34;减少锁的粒度&#34;&gt;减少锁的粒度&lt;/h4&gt;
&lt;p&gt;锁粒度的减少核心思想是利用空间换时间，它将物理上的一个锁，拆分为逻辑上的多个锁，增加并发度，从而降低了锁竞争。&lt;/p&gt;
&lt;p&gt;典型代表有：ConcurrentHashMap（jdk1.8之前，有用到Segment数组）；LongAdder（实现机制与ConcurrentHashMap类似，其中有一个根据当前并发状态动态改变的Cell数组，注意：其竞争维度为cell个数+1，因为还有一个base数组）；LinkedBlockQueue（出队，入队采用了不同的锁，增加了并行效率）。&lt;/p&gt;
&lt;p&gt;锁的拆分不能无限拆，需要根据当前系统CPU核数进行限制（不能超过CPU核数）。&lt;/p&gt;
&lt;h4 id=&#34;锁粗化&#34;&gt;锁粗化&lt;/h4&gt;
&lt;p&gt;大部分情况下，是要求将锁粒度减小，但某些情况下，也需要粗化锁粒度，比如循环中加锁。&lt;/p&gt;
&lt;h4 id=&#34;使用读写锁&#34;&gt;使用读写锁&lt;/h4&gt;
&lt;p&gt;ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写。例如：CopyOnWriteArrayList 、CopyOnWriteArraySet&lt;/p&gt;
&lt;p&gt;CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。&lt;/p&gt;
&lt;p&gt;CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的。&lt;/p&gt;
&lt;h4 id=&#34;使用cas&#34;&gt;使用CAS&lt;/h4&gt;
&lt;p&gt;如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择。&lt;/p&gt;
&lt;h4 id=&#34;消除缓存行的伪共享&#34;&gt;消除缓存行的伪共享&lt;/h4&gt;
&lt;p&gt;除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。&lt;/p&gt;
&lt;p&gt;在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。&lt;/p&gt;
&lt;p&gt;例如，多个不需要同步的变量因为存储在连续的32字节或64字节里面，当需要其中的一个变量时，就将它们作为一个缓存行一起加载到某个cup-1私有的缓存中（虽然只需要一个变量，但是cpu读取会以缓存行为最小单位，将其相邻的变量一起读入），被读入cpu缓存的变量相当于是对主内存变量的一个拷贝，也相当于变相的将在同一个缓存行中的几个变量加了一把锁，这个缓存行中任何一个变量发生了变化，当cup-2需要读取这个缓存行时，就需要先将cup-1中被改变了的整个缓存行更新回主存（即使其它变量没有更改），然后cup-2才能够读取，而cup-2可能需要更改这个缓存行的变量与cpu-1已经更改的缓存行中的变量是不一样的，所以这相当于给几个毫不相关的变量加了一把同步锁；&lt;/p&gt;
&lt;p&gt;为了防止伪共享，不同jdk版本实现方式是不一样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在jdk1.7之前会 将需要独占缓存行的变量前后添加一组long类型的变量，依靠这些无意义的数组的填充做到一个变量自己独占一个缓存行；&lt;/li&gt;
&lt;li&gt;在jdk1.7因为jvm会将这些没有用到的变量优化掉，所以采用继承一个声明了好多long变量的类的方式来实现；&lt;/li&gt;
&lt;li&gt;在jdk1.8中通过添加sun.misc.Contended注解来解决这个问题，若要使该注解有效必须在jvm中添加以下参数：-XX:-RestrictContended。sun.misc.Contended注解会在变量前面添加128字节的padding将当前变量与其他变量进行隔离&lt;/li&gt;
&lt;/ol&gt;
">Java中的锁</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-xian-cheng-chi-xiang-jie/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中关于线程池的优势，参数说明以及常用线程数配置。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/beach-gc2b0bd8e5_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;线程池&#34;&gt;线程池&lt;/h2&gt;
&lt;h3 id=&#34;线程池的优势&#34;&gt;线程池的优势&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;降低系统资源消耗：通过重用已存在的线程，降低线程创建和销毁所造成的资源消耗。&lt;/li&gt;
&lt;li&gt;提供系统响应速度：当任务来临时，直接复用已存在的线程进行工作，而无需等待线程的创建。&lt;/li&gt;
&lt;li&gt;方便线程数的管控：过多的线程创建，会导致性能的急剧下降（线程上下文切换十分耗费性能），甚至出现OOM。&lt;/li&gt;
&lt;li&gt;提供更加强大的功能，如延时定时线程池。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;线程池的主要参数&#34;&gt;线程池的主要参数&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&amp;lt;Runnable&amp;gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;corePoolSize：核心线程数，默认情况下，核心线程一直存活在线程池中，即使它们处于闲置状态（可通过allowCoreThreadTimeOut进行控制）。当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会创建一个新的线程来执行任务，直到创建的线程数大于或等于corePoolSize时才进行线程复用（可通过prestartCoreThread()或者prestartAllCoreThreads()来提前启动线程池中的基本线程）。&lt;/li&gt;
&lt;li&gt;maximumPoolSize：最大线程数，当队列满了，且已创建线程数小于maximumPoolSize时，线程池会创建新的线程来执行任务。&lt;/li&gt;
&lt;li&gt;keepAliveTime：线程闲置时长，超过此时长将会被销毁。默认只对非核心线程生效，只有当ThreadPoolExecutor中的allowCoreThreadTimeOut设置为true时，才会对核心线程生效。&lt;/li&gt;
&lt;li&gt;unit：用于指定keepAliveTime参数的时间单位。&lt;/li&gt;
&lt;li&gt;workQueue：工作队列，用于保存等待执行的任务的阻塞队列。通过线程池的execute方法提交的Runnable对象都会存储在该队列中。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;ArrayBlockingQueue：基于数组实现的有界的阻塞队列,该队列按照FIFO（先进先出）原则对队列中的元素进行排序。&lt;/li&gt;
&lt;li&gt;LinkedBlockingQueue：基于链表实现的阻塞队列，该队列按照FIFO（先进先出）原则对队列中的元素进行排序。&lt;/li&gt;
&lt;li&gt;SynchronousQueue：内部没有任何容量的阻塞队列。在它内部没有任何的缓存空间。对于SynchronousQueue中的数据元素只有当我们试着取走的时候才可能存在。&lt;/li&gt;
&lt;li&gt;PriorityBlockingQueue：具有优先级的无限阻塞队列。&lt;/li&gt;
&lt;li&gt;通过实现BlockingQueue接口来自定义所需要的阻塞队列&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;threadFactory：线程工厂，用于创建新线程。&lt;/li&gt;
&lt;li&gt;handler：拒绝策略，当线程池饱和时（任务队列以及活动线程数都已达到最大值），此时便会执行对应的拒绝策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;CallerRunsPolicy：使用调用者所在线程来运行任务。&lt;/li&gt;
&lt;li&gt;AbortPolicy：直接抛出RejectedExecutionException异常。&lt;/li&gt;
&lt;li&gt;DiscardPolicy：丢弃掉该任务，不进行处理&lt;/li&gt;
&lt;li&gt;DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;线程池流程图&#34;&gt;线程池流程图&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;如果在线程池中的线程数量没有达到核心线程数量，这时候就会启动一个核心线程来执行任务（等于核心线程数时，会复用线程池中已存在的线程）。&lt;/li&gt;
&lt;li&gt;如果线程池中的线程数量已经超过核心线程数，这时候任务就会被插入到任务队列中排队等待执行。&lt;/li&gt;
&lt;li&gt;由于任务队列已满，无法将任务插入到任务队列中。这个时候如果线程池中的线程数量没有达到线程池所设定的最大值（maximumPoolSize），那么这时候就会立即启动一个非核心线程来执行任务。&lt;/li&gt;
&lt;li&gt;如果线程池中的数量达到了所规定的最大值（maximumPoolSize），那么就会拒绝执行此任务，这时候就会调用RejectedExecutionHandler中的rejectedExecution方法来通知调用者。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230228001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;四种线程池一般不推荐使用&#34;&gt;四种线程池（一般不推荐使用）&lt;/h3&gt;
&lt;p&gt;1、newCachedThreadPool：用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换），无界线程池，容易发生OOM。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue&amp;lt;Runnable&amp;gt;());
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2、newFixedThreadPool：创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&amp;lt;Runnable&amp;gt;());
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;3、newSingleThreadExecutor：创建一个单线程的线程池，适用于需要保证顺序执行各个任务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue&amp;lt;Runnable&amp;gt;()));
}

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4、newScheduledThreadPool：适用于执行延时或者周期性任务.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
    return new ScheduledThreadPoolExecutor(corePoolSize);
}
public ScheduledThreadPoolExecutor(int corePoolSize) {
    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
          new DelayedWorkQueue());
}
//实例：
ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
service.schedule(() -&amp;gt; System.out.println(Thread.currentThread().getName()+&amp;quot;延迟三秒执行&amp;quot;), 3, TimeUnit.SECONDS);
service.scheduleAtFixedRate(() -&amp;gt; System.out.println(Thread.currentThread().getName()+&amp;quot;延迟三秒后每隔2秒执行&amp;quot;), 3, 2, TimeUnit.SECONDS);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;schedule(Runnable command, long delay, TimeUnit unit)：延迟一定时间后执行Runnable任务；&lt;/p&gt;
&lt;p&gt;schedule(Callable callable, long delay, TimeUnit unit)：延迟一定时间后执行Callable任务；&lt;/p&gt;
&lt;p&gt;scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)：延迟一定时间后，以间隔period时间的频率周期性地执行任务(固定频率的含义就是可能设定的固定时间不足以完成线程任务，但是它不管，达到设定的延迟时间了就要执行下一次了)；&lt;/p&gt;
&lt;p&gt;scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,TimeUnit unit)：与scheduleAtFixedRate()方法很类似，但是不同的是scheduleWithFixedDelay()方法的周期时间间隔是以上一个任务执行结束到下一个任务开始执行的间隔，而scheduleAtFixedRate()方法的周期时间间隔是以上一个任务开始执行到下一个任务开始执行的间隔，也就是这一些任务系列的触发时间都是可预知的.&lt;/p&gt;
&lt;h3 id=&#34;线程池中的线程数配置&#34;&gt;线程池中的线程数配置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CPU密集型任务：线程池中线程个数应尽量少，如配置N+1个线程的线程池；&lt;/li&gt;
&lt;li&gt;IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数 时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率，如2*N；&lt;/li&gt;
&lt;li&gt;混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。&lt;/li&gt;
&lt;/ul&gt;
">Java线程池详解</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/shu-ju-jie-gou-ji-chu-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述数据结构的基本知识，包括数组，队列，栈，链表，散列表，图，树，堆等基本介绍。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/maldives-3220702_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;数据结构基础知识&#34;&gt;数据结构基础知识&lt;/h2&gt;
&lt;h3 id=&#34;数组array&#34;&gt;数组（Array）&lt;/h3&gt;
&lt;p&gt;数组是一种聚合数据类型，它是将具有相同类型的若干变量有序地组合在一起的集合。&lt;/p&gt;
&lt;h3 id=&#34;栈stack&#34;&gt;栈（Stack）&lt;/h3&gt;
&lt;p&gt;又称堆栈，它是一种运算受限的线性表，即限定在表尾进行插入删除操作的线性表。这一端被称为栈顶，相对地，把另一端称为栈底。向一个栈插入新元素又称作进栈、入栈或压栈，它是把新元素放到栈顶元素的上面，使之成为新的栈顶元素；从一个栈删除元素又称作出栈或退栈，它是把栈顶元素删除掉，使其相邻的元素成为新的栈顶元素。&lt;/p&gt;
&lt;p&gt;栈作为一种&lt;a href=&#34;https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84&#34;&gt;数据结构&lt;/a&gt;，是一种只能在一端进行插入和删除操作的特殊&lt;a href=&#34;https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E8%A1%A8&#34;&gt;线性表&lt;/a&gt;。它按照先进后出的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。栈具有记忆作用，对栈的插入与删除操作中，不需要改变栈底&lt;a href=&#34;https://baike.baidu.com/item/%E6%8C%87%E9%92%88&#34;&gt;指针&lt;/a&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;队列queue&#34;&gt;队列（Queue）&lt;/h3&gt;
&lt;p&gt;是一种特殊的线性表，其特殊之处在于它只允许在表的前端（front）进行删除操作，表的后端（rear）进行插入操作（顺序队列，循环队列）。&lt;/p&gt;
&lt;p&gt;和栈一样，队列是一种操作受限制的线性表，进行插入操作的端被称为队尾，而删除操作的端被称为队头。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;链表linked-list&#34;&gt;链表（Linked List）&lt;/h3&gt;
&lt;p&gt;是一种数据元素按照链式存储结构（这种结构具有非连续性存储的特点）进行存储的数据结构。&lt;/p&gt;
&lt;p&gt;链表由一系列数据结点构成，每个数据结点都包括数据域和指针域两部分。其中，指针域保存了数据结构中下一个元素存放的地址。&lt;/p&gt;
&lt;p&gt;链表结构中数据元素的逻辑顺序是通过指针域连接次序来实现的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302003.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;散列表hash-table&#34;&gt;散列表（Hash Table）&lt;/h3&gt;
&lt;p&gt;散列表源自于散列函数（Hash Function），其思想是如果在结构中存在关键字和T相等的记录，那么必定可以在F(T)的位置找到该记录，这样便不用进行比较操作，就可直接取到数据。&lt;/p&gt;
&lt;p&gt;常用的构造散列函数有：直接定址法，数字分析法，平方取值，折叠法，除留余数法，随机数法。&lt;/p&gt;
&lt;h3 id=&#34;树tree&#34;&gt;树（Tree）&lt;/h3&gt;
&lt;p&gt;是由n(n&amp;gt;0)个有限结点组成一个具有层次关系的集合。非线性结构。&lt;/p&gt;
&lt;h4 id=&#34;它具有如下特性&#34;&gt;它具有如下特性&lt;/h4&gt;
&lt;p&gt;a、每个节点有零个或多个子节点。&lt;/p&gt;
&lt;p&gt;b、没有父节点的节点称为根节点。&lt;/p&gt;
&lt;p&gt;c、每一个非根节点有且只有一个根节点。&lt;/p&gt;
&lt;p&gt;d、除了根节点外，每个子节点可以分为多个不相交的子树。&lt;/p&gt;
&lt;h4 id=&#34;种类&#34;&gt;种类&lt;/h4&gt;
&lt;p&gt;无序树：树中任意节点的子结点之间没有顺序关系，这种树称为无序树,也称为自由树；&lt;/p&gt;
&lt;p&gt;有序树：树中任意节点的子结点之间有顺序关系，这种树称为有序树；&lt;/p&gt;
&lt;p&gt;二叉树：每个节点最多含有两个子树的树称为二叉树；&lt;/p&gt;
&lt;p&gt;满二叉树：叶节点除外的所有节点均含有两个子树的树被称为满二叉树；&lt;/p&gt;
&lt;p&gt;完全二叉树：有2^k-1个节点的满二叉树称为完全二叉树；&lt;/p&gt;
&lt;p&gt;哈夫曼树（最优二叉树）：带权路径最短的二叉树称为哈夫曼树或最优二叉树。&lt;/p&gt;
&lt;h4 id=&#34;遍历表达法&#34;&gt;遍历表达法&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%85%88%E5%BA%8F%E9%81%8D%E5%8E%86/6442839&#34;&gt;先序遍历&lt;/a&gt;（又称先根遍历）为ABDECF（根-左-右）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86/757281&#34;&gt;中序遍历&lt;/a&gt;（又称中根遍历）为DBEAFC（左-根-右）（仅二叉树有&lt;a href=&#34;https://baike.baidu.com/item/%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86/757281&#34;&gt;中序遍历&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86/1214806&#34;&gt;后序遍历&lt;/a&gt;（又称后根遍历）为DEBFCA（左-右-根）&lt;/p&gt;
&lt;p&gt;层次遍历为ABCDEF（同广度优先搜索）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230302004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;图graph&#34;&gt;图（Graph）&lt;/h3&gt;
&lt;p&gt;是一种非线性数据结构，在图结构中，数据结点一般称为顶点，而边是顶点的有序偶对。如果两个顶点之间存在一条边，那么就表示这两个顶点具有相邻关系。&lt;/p&gt;
&lt;h3 id=&#34;堆heap&#34;&gt;堆（Heap）&lt;/h3&gt;
&lt;p&gt;是一种特殊的树形数据结构，一般讨论的堆都是二叉堆。堆的特点是根结点的值是所有结点中最小的或者最大的，并且根结点的两个子树也是一个堆结构。&lt;/p&gt;
">数据结构基础知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-duo-xian-cheng-ji-chu/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中关于多线程的基础知识，几种创建线程的方式以及线程安全性&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/sea-g5a284195e_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;多线程基础&#34;&gt;多线程基础&lt;/h2&gt;
&lt;h3 id=&#34;java多线程并发库&#34;&gt;java多线程并发库&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230227001.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;进程与线程&#34;&gt;进程与线程&lt;/h3&gt;
&lt;p&gt;进程：是程序运行以及资源分配的基本单位，一个程序至少有一个进程。&lt;/p&gt;
&lt;p&gt;线程：是CPU调度和分配的基本单位，一个进程至少有一个线程。同一个进程中的线程共享其资源（减少切换，可提高效率），且可以并发执行（并发：同一时间间隔可以做多件事；并行：同一时刻可以做多件事（多核））。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230227002.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;线程的上文切换&#34;&gt;线程的上文切换&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一个CPU核在任意时刻只能执行一个线程，如果有多个线程（超过CPU核数）存在，CPU将会采用时间片轮转的方式进行线程切换，即给每一个线程分配一个时间片，当一个线程的时间片用完的时候便会处于就绪状态，并让出CPU给其他线程使用，这就是一次上下文切换。&lt;/li&gt;
&lt;li&gt;上下文切换时是通过运行时数据区中的程序计数器来存储各个线程的运行状态的，以便于下次运行线程时可以接着上次指令继续运行（比如线程A做了一次计算准备返回数据时，切换到了线程B，然后又切回线程A，是直接返回数据，而不是再去计算一遍）。&lt;/li&gt;
&lt;li&gt;程序计数器指的是JVM中的一块内存区域，它可以看作是当前线程所执行字节码的行号指示器，通过它，Java可以知道每个线程执行到了哪一步指令（由此可以看出程序计数器是线程私有的）。&lt;/li&gt;
&lt;li&gt;一般而言，上下文切换是比较耗费CPU时间的一种操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;线程的几种状态&#34;&gt;线程的几种状态&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建：指的是生成线程对象，此时并没有调用start方法。&lt;/li&gt;
&lt;li&gt;就绪：调用线程的start方法后，线程便进入了就绪状态，此时等待系统调度。&lt;/li&gt;
&lt;li&gt;运行：通过系统调度，开始运行线程中的run函数。&lt;/li&gt;
&lt;li&gt;等待：调用了Object.wait()会进入等待队列。一般需要等待其他线程做出一些特定的通知或者中断。&lt;/li&gt;
&lt;li&gt;超时等待：该状态与等待状态有一点区别就是它会自动返回，比如调用Threa.sleep(long)，在超时之后，会自动返回进入就绪状态。&lt;/li&gt;
&lt;li&gt;阻塞：指的是去获取锁时(等待进入synchronized方法或块)，发现同步锁被占用了，这时线程会被放入锁池，等待获取锁。&lt;/li&gt;
&lt;li&gt;死亡：运行完run方法，main方法（main方法指的是主线程）之后正常退出，也有可能出现异常导致死亡；死亡的线程不能重新启用，否则报错。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;创建线程的几种方式&#34;&gt;创建线程的几种方式&lt;/h2&gt;
&lt;h3 id=&#34;继承thread&#34;&gt;继承Thread&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public class ThreadTest {
    public static void main(String[] args){
        new TestThread().start();
    }
}

class TestThread extends Thread{
    @Override
    public void run(){
        System.out.println(&amp;quot;Test Thread&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;实现runnable&#34;&gt;实现Runnable&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public class ThreadTest {
    public static void main(String[] args){
        new Thread(new TestRunnable()).start();
    }
}

class TestRunnable implements Runnable{
    @Override
    public void run() {
        System.out.println(&amp;quot;Test Runnable&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;实现callable&#34;&gt;实现Callable&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;public class ThreadTest {
    public static void main(String[] args){
        FutureTask&amp;lt;Integer&amp;gt; task = new FutureTask(new TestCallable());
        new Thread(task).start();
        try {
            System.out.println(task.get());//get方法会得到call执行完之后的值
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
    }
}

class TestCallable implements Callable&amp;lt;Integer&amp;gt; {
    @Override
    public Integer call() throws Exception {
        int num = 0;
        while(num &amp;lt; 5){
            num++;
        }
        return num;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;线程安全性&#34;&gt;线程安全性&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;原子性：同一时刻只允许一个线程对数据进行操作（atomic开头的原子类,synchronized，Lock）。&lt;/li&gt;
&lt;li&gt;可见性：一个线程对共享变量的修改，可以及时地被其他线程观察到，（synchronized,volatile，Lock）。&lt;/li&gt;
&lt;li&gt;有序性：指的是可以观察到其他线程的指令执行顺序，由于指令重排，一般情况下是无序的（happens-before原则）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;线程死锁&#34;&gt;线程死锁&lt;/h3&gt;
&lt;h4 id=&#34;死锁&#34;&gt;死锁&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;指的是多个线程在执行过程中，因争夺资源而陷入环路阻塞的一种现象。&lt;/li&gt;
&lt;li&gt;示例代码如下（运行之后，两个线程陷入死锁中，如果没有外力中断，将会一直锁定）：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public class ThreadTest {
    //共享资源A
    private static final Object A = new Object();
    //共享资源B
    private static final Object B = new Object();

    public static void main(String[] args){
        new Thread(() -&amp;gt; {
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---A&amp;quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &amp;quot;：去获取资源---B&amp;quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---B&amp;quot;);
                }
            }
        },&amp;quot;Thread-01&amp;quot;).start();

        new Thread(() -&amp;gt; {
            synchronized (B){
                System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---B&amp;quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &amp;quot;：去获取资源---A&amp;quot;);
                synchronized (A){
                    System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---A&amp;quot;);
                }
            }
        },&amp;quot;Thread-02&amp;quot;).start();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;死锁四个必要条件以及如何避免死锁&#34;&gt;死锁四个必要条件以及如何避免死锁&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;互斥条件：一个资源在任意时刻只能被一个线程占用，如果有其他线程请求该资源，需要等待原线程释放资源（此条件不能被破坏，因为锁本身就是为了互斥访问）。&lt;/li&gt;
&lt;li&gt;请求和保持条件：一个线程已经获取了一部分资源，又去请求其他资源，如果其他资源正被占用，原线程陷入阻塞，且不会释放自己占用的资源（一次性申请所有资源；或者阻塞时，释放自己占用的资源）。&lt;/li&gt;
&lt;li&gt;不可剥夺条件：一个线程已经获得的资源，在自己未使用完之前不能被其他线程剥夺，只能自己使用结束后释放（如果去获取正在被其他线程使用的资源而阻塞时，可以释放自己占用的资源）。&lt;/li&gt;
&lt;li&gt;环路等待条件：多个进程之间形成一种头尾相接的循环等待资源关系（按一定的顺序来获取资源）。&lt;/li&gt;
&lt;li&gt;针对上述例子而言，可以让现线程1先获取资源AB，执行完之后，再让线程2获取资源AB，改动如下（执行顺序为：线程1先获取资源A，接着释放CPU，线程2执行准备去获取资源A，发现资源A已被占用，此时线程2阻塞，然后一秒之后释放CPU，线程1接着执行，去获取资源B，正常获取，执行完毕，释放CPU；线程2开始获取资源A，由于线程1已经执行完毕释放了锁，所以线程2正常获取资源A，接着休眠一秒释放CPU，然后又去获取资源B，同样正常获取，执行完毕）：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;public class ThreadTest {
    //共享资源A
    private static final Object A = new Object();
    //共享资源B
    private static final Object B = new Object();

    public static void main(String[] args){
        new Thread(() -&amp;gt; {
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---A&amp;quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &amp;quot;：去获取资源---B&amp;quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---B&amp;quot;);
                }
            }
        },&amp;quot;Thread-01&amp;quot;).start();

        new Thread(() -&amp;gt; {
            //线程2去获取A时被阻塞
            synchronized (A){
                System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---A&amp;quot;);
                try {
                    Thread.sleep(1000);//此处休眠是为了让其他线程获得执行机会
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() + &amp;quot;：去获取资源---B&amp;quot;);
                synchronized (B){
                    System.out.println(Thread.currentThread().getName() + &amp;quot;：得到资源---B&amp;quot;);
                }
            }
        },&amp;quot;Thread-02&amp;quot;).start();
    }
}
&lt;/code&gt;&lt;/pre&gt;
">Java多线程基础</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-ji-he-ji-chu-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中的集合，list，set，map等结构。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/beach-418742_1280.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;接口继承关系和实现&#34;&gt;接口继承关系和实现&lt;/h2&gt;
&lt;h3 id=&#34;集合类概念&#34;&gt;集合类概念&lt;/h3&gt;
&lt;p&gt;集合类存放于java.util包中，主要有三种，set（集），list（列表包含Queue），map（映射）。&lt;/p&gt;
&lt;p&gt;Collection：集合类的通用接口，直接继承接口有List和Set。&lt;/p&gt;
&lt;p&gt;Iterator：一个轻量级对象（创建代价小），主要用来对集合进行遍历移除等操作。&lt;/p&gt;
&lt;p&gt;Map：使用键值对存储的容器，映射表的基础接口。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301010.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301011.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;list&#34;&gt;List&lt;/h3&gt;
&lt;p&gt;有序集合，是一个非常常用的数据类型，它的实现类有ArrayList，Vector以及LinkedList。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301012.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;ArrayList：底层数据结构是一个数组，查询效率比较高，添加删除较慢（默认添加在末尾，在指定位置添加元素效率比较低，因为需要将指定位置后续的元素都往后移位）。&lt;/p&gt;
&lt;p&gt;Vector：与ArrayList基本一致，唯一的差别就是其操作为同步（加了锁），即某一个时刻只有一个线程能够写Vector，这也导致其查询效率比ArrayList慢。&lt;/p&gt;
&lt;p&gt;LinkedList：底层数据结构是一个双向链表（prev指向前节点，next指向后节点），查询效率比较慢，添加删除比较快。另外，它还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当做堆栈，队列和双向队列来使用。&lt;/p&gt;
&lt;h3 id=&#34;set&#34;&gt;Set&lt;/h3&gt;
&lt;p&gt;Set注重独一无二的性质，其特点是无序且不能出现重复值。对象的相等性本质是由对象的hashCode值（java是根据对象的内存地址计算出的此序号）判断的。如果两个对象相等，则其hashCode以及equals比较结果必然相等。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301013.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;HashSet（hash表）：哈希表中存放的是哈希值，hashSet存储元素并不是按照存入时的顺序（无序），而是按照哈希值来存的，故其取数据也是依据哈希值。元素的哈希值是通过元素的hashCode方法获取的。&lt;/p&gt;
&lt;p&gt;hashSet判断两个元素相等：先判断两个元素的哈希值是否相等，如果哈希值一样，再比较equals方法，如果返回true则两个元素相等，否则不相等。&lt;/p&gt;
&lt;p&gt;hashSet通过hashCode值来确定元素在内存中的位置。一个hashCode位置上可以存放多个元素（equals结果为false）。&lt;/p&gt;
&lt;p&gt;TreeSet（二叉树）：会对插入的元素进行排序（依据二叉树）。如果是自定义的类需要进行排序，需要自定义类实现Comparable，覆写对应的compareTo()函数，并返回相应的值。&lt;/p&gt;
&lt;p&gt;LinkHashSet（hashSet+LinkedHashMap）：其继承于HashSet，底层使用LinkedHashMap保存数据。&lt;/p&gt;
&lt;h3 id=&#34;map&#34;&gt;Map&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301014.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;hashTable（线程安全）：是一个遗留类，与hashMap类似，只是加了全局锁，保证了多线程下的安全。现在已不建议使用，如果需要线程安全，推荐使用ConcurrentHashMap。&lt;/p&gt;
&lt;p&gt;TreeMap（可排序）：实现了SortedMap接口，能够将其保存的记录按键进行排序（默认升序）。&lt;/p&gt;
&lt;p&gt;LinkHashMap（有序）：hashMap+双向链表，是hashMap的一个子类，保存了记录的插入顺序，在使用Iterator遍历时，先得的数据必然是先插入的（有序），不过也可以对其进行设置，关键参数为accessOrder（true则是访问顺序，false则是插入顺序）。&lt;/p&gt;
&lt;h4 id=&#34;hashmap&#34;&gt;hashMap&lt;/h4&gt;
&lt;p&gt;hashMap（数组+链表+红黑树）：根据键的hashCode值存储数据。非线程安全（Collections的synchronizedMap以及ConcurrentHashMap可实现线程安全），允许空键值，执行效率相对较高。&lt;/p&gt;
&lt;p&gt;capacity：当前数组容量，始终保持2^n，可以扩容，扩容后数组大小为当前的2倍。&lt;/p&gt;
&lt;p&gt;loadFactor：负载因子，默认为0.75。其大小决定了散列表空间的稀密度（越大，越密集，链表越长，索引越慢；越小，越稀疏，链表越短，索引越快）。&lt;/p&gt;
&lt;p&gt;threshold：扩容阈值，等于capacity * loadFactor&lt;/p&gt;
&lt;p&gt;Java7中，hashMap结构如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301015.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Java8中，hashMap结构如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301016.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;concurrenthashmap&#34;&gt;ConcurrenthashMap&lt;/h4&gt;
&lt;p&gt;ConcurrenthashMap：相比于hashMap而言，它是线程安全的，其余基本一致。java7中，使用的是分段锁（Segment，默认并行度16）；java8中使用的是节点锁（粒度更细，且引入了红黑树）。&lt;/p&gt;
&lt;p&gt;Java7中，ConcurrenthashMap结构如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301017.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Java8中，ConcurrenthashMap结构如下：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/clipboard20230301018.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">Java集合基础知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/java-ji-chu-zhi-shi/"" data-c="
          &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本章主要简述Java中面向对象的三大特性，基本数据结构，六大基本原则。作为博客的第一篇文章，略显简单，不过对于我而言，却是向前迈出了一大步。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/philosopherZB/blog-images/master/blogImg/flowers-g5952415a3_1280.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;面向对象的三大特性&#34;&gt;面向对象的三大特性&lt;/h2&gt;
&lt;h3 id=&#34;封装&#34;&gt;封装&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;将现实中的客观事物封装成抽象的类。&lt;/li&gt;
&lt;li&gt;对一个类中的变量，方法进行访问符修饰，以达到有些变量，方法对外开放，有些变量，方法隐藏。&lt;/li&gt;
&lt;li&gt;针对第2点对应的访问修饰符有(范围从大到小)：public &amp;gt; protected &amp;gt; default &amp;gt; private。&lt;/li&gt;
&lt;li&gt;由于封装隐藏了具体实现，仅提供接口供外部调用，所以在一定程度上可以提高安全性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;继承&#34;&gt;继承&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可以实现已存在的类的变量，方法（非private），并可以扩展单属于自我的变量及方法。&lt;/li&gt;
&lt;li&gt;继承在Java中为单继承，即一个子类只能继承一个父类（可以实现多个接口）。&lt;/li&gt;
&lt;li&gt;通过继承创建的类称为“子类”，“派生类”。&lt;/li&gt;
&lt;li&gt;被继承的类称为“父类”，“基类”，“超类”。&lt;/li&gt;
&lt;li&gt;继承的关系是is-a，比如说老师是人，狮子是动物等。&lt;/li&gt;
&lt;li&gt;继承可以降低代码的重复性，方便后续对公共行为的维护，不过同时也增加了代码的耦合度。&lt;/li&gt;
&lt;li&gt;子类不继承父类的构造器，而是显示或隐式的调用（如果父类中存在不带参构造器，则子类隐式调用该构造器；否则如果父类中仅存在带参构造器，则子类需要通过super来显示调用父类带参构造器）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;多态&#34;&gt;多态&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;对同一个行为体现出不同的表现形式，比如吃，可以吃饭，吃零食等。&lt;/li&gt;
&lt;li&gt;在Java中体现为对方法的重写以及重载，即传入参数来决定做哪一种具体的动作（重载）不同类之间同一方法不同表现（重写）。&lt;/li&gt;
&lt;li&gt;重写一般为父子类之间对方法的不同操作，重载一般为同一个类中对方法的不同操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基本数据类型四个整数两个浮点一个字符一个布尔&#34;&gt;基本数据类型（四个整数，两个浮点，一个字符，一个布尔）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;byte，占8位，1字节，默认值：0，包装类：java.lang.Byte&lt;/li&gt;
&lt;li&gt;short，占16位，2字节，默认值：0，包装类：java.lang.Short&lt;/li&gt;
&lt;li&gt;int，占32位，4字节，默认值：0，包装类：java.lang.Integer&lt;/li&gt;
&lt;li&gt;long，占64位，8字节，默认值：0L，包装类：java.lang.Long&lt;/li&gt;
&lt;li&gt;float，占32位，4字节，默认值：0.0f，包装类：java.lang.Float&lt;/li&gt;
&lt;li&gt;double，占64位，8字节，默认值：0.fd，包装类：java.lang.Double&lt;/li&gt;
&lt;li&gt;char，可以存储任何字符，包装类：java.lang.Character&lt;/li&gt;
&lt;li&gt;boolean，默认值：false，包装类：java.lang.Boolean&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;面向对象的六大基本原册&#34;&gt;面向对象的六大基本原册&lt;/h2&gt;
&lt;h3 id=&#34;单一职责原则single-responsibility-priciple&#34;&gt;单一职责原则（Single Responsibility Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;对于一个类而言，应该只有一个引起他变化的原因。&lt;/li&gt;
&lt;li&gt;比如，不要将teacher,doctor都放在一个person类中，而是将其拆成teacher类，doctor类。&lt;/li&gt;
&lt;li&gt;能够一定程度上降低耦合度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;开闭原则open-close-priciple&#34;&gt;开闭原则（Open Close Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;对于扩展是开放的，对于修改是关闭的。&lt;/li&gt;
&lt;li&gt;一般来说就是不要修改之前的代码，可以选择继承或者实现接口来扩展对应的功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;里式替换原则liskov-substitution-priciple&#34;&gt;里式替换原则（Liskov Substitution Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;所有引用父类的地方都可以透明的使用其子类对象。&lt;/li&gt;
&lt;li&gt;即父类出现的地方，把父类换成子类不会出现异常或错误；反之，子类出现的地方，把子类换成父类可能会出现异常或错误。&lt;/li&gt;
&lt;li&gt;比如,person类具有eat功能，那么将person.eat换成teacher.eat是没有问题的；而如果teacher类具有独特的teach功能，那么如果将teacher.teach换成person.teach就会出现错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;依赖倒置原则dependence-inversion-priciple&#34;&gt;依赖倒置原则（Dependence Inversion Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;高层模块不依赖低层模块，而是应该依赖其抽象&lt;/li&gt;
&lt;li&gt;抽象不依赖于细节，细节依赖于抽象&lt;/li&gt;
&lt;li&gt;比如teacher类中应该尽量做一些老师共有的抽象行为，比如教书，这样后面的语文老师，数学老师等可以继承该抽象老师类进行扩展。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;接口隔离原则interface-segregation-priciple&#34;&gt;接口隔离原则（Interface Segregation Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;客户端不应该依赖它不需要的接口;一个类对另一个类的依赖应该建立在最小的接口上&lt;/li&gt;
&lt;li&gt;尽量一个接口只实现一个功能，如果接口功能太多可进行拆分。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;迪米特原则law-of-demeter-or-least-knowlegde-priciple&#34;&gt;迪米特原则（Law of Demeter or Least Knowlegde Priciple）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一个对象应该对其他对象有最少的了解。&lt;/li&gt;
&lt;li&gt;此原则与接口隔离原则可以结合使用，尽量保持一个方法一个具体行为，而不要涵盖多个行为。&lt;/li&gt;
&lt;/ul&gt;
">Java基础知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://philosopherzb.github.io/post/about/"" data-c="
          &lt;blockquote&gt;
&lt;p&gt;欢迎来到我的小站呀，很高兴遇见你！🤝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;关于本站&#34;&gt;🏠 关于本站&lt;/h2&gt;
&lt;p&gt;本站使用github-pages及Gridea搭建而成，专门用于技术分享，欢迎大家一起参与。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;github-pages doc: &lt;a href=&#34;https://docs.github.com/en/pages&#34;&gt;https://docs.github.com/en/pages&lt;/a&gt;&lt;br&gt;
gridea doc: &lt;a href=&#34;https://gridea.dev/gridea-start/&#34;&gt;https://gridea.dev/gridea-start/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;博主是谁&#34;&gt;👨‍💻 博主是谁&lt;/h2&gt;
&lt;p&gt;求知路上的陌生人&lt;/p&gt;
&lt;h2 id=&#34;联系我呀&#34;&gt;📬 联系我呀&lt;/h2&gt;
&lt;p&gt;有问题可以留言讨论哈😄&lt;/p&gt;
">关于</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  !function () {
    let times = document.querySelectorAll('.publish-time');
    for (let i = 0; i < times.length; i++) {
      let date = times[i].dataset.t;
      let time = Math.floor((new Date().getTime() - new Date(date).getTime()) / 1000);
      if (time < 60) {
        str = time + '秒之前';
      } else if (time < 3600) {
        str = Math.floor(time / 60) + '分钟之前';
      } else if (time >= 3600 && time < 86400) {
        str = Math.floor(time / 3600) + '小时之前';
      } else if (time >= 86400 && time < 259200) {
        str = Math.floor(time / 86400) + '天之前';
      } else {
        str = times[i].textContent;
      }
      times[i].textContent = str;
    }
  }();
</script>

<script>
  let language = '';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>


<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 200
  });
</script>






</html>